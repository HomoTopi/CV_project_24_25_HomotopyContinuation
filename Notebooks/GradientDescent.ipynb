{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bf8c720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import HomoTopiContinuation.Plotter.Plotter as Plotter\n",
    "import HomoTopiContinuation.SceneGenerator.scene_generator as sg\n",
    "import HomoTopiContinuation.Rectifier.standard_rectifier as sr\n",
    "import HomoTopiContinuation.Rectifier.homotopyc_rectifier as hr\n",
    "import HomoTopiContinuation.Rectifier.numeric_rectifier as nr\n",
    "from HomoTopiContinuation.DataStructures.datastructures import Circle, ConicJax, ConicsJax, Homography\n",
    "from HomoTopiContinuation.ConicWarper.ConicWarper import ConicWarper\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "064f42ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circle 1:\n",
      "[[     1      0   -310]\n",
      " [     0      1   -100]\n",
      " [  -310   -100 105200]]\n",
      "[1.0, 0.0, 1.0, -620.0, -200.0, 105200.0]\n",
      "Circle 2:\n",
      "[[     1      0   -330]\n",
      " [     0      1   -150]\n",
      " [  -330   -150 131375]]\n",
      "[1.0, 0.0, 1.0, -660.0, -300.0, 131375.0]\n",
      "Circle 3:\n",
      "[[     1      0   -350]\n",
      " [     0      1   -200]\n",
      " [  -350   -200 162475]]\n",
      "[1.0, 0.0, 1.0, -700.0, -400.0, 162475.0]\n",
      "[Scene Described]\n",
      "No distortion params provided, using true conics\n",
      "[Scene Generated]\n"
     ]
    }
   ],
   "source": [
    "def sceneDefinition() -> sg.SceneDescription:\n",
    "    # Parameters\n",
    "    f = 100\n",
    "    theta = 60\n",
    "\n",
    "    # Define the circles\n",
    "    c1 = Circle(\n",
    "        np.array([10+300, 100]), 30)\n",
    "    c2 = Circle(\n",
    "        np.array([30+300, 150]), 5)\n",
    "    c3 = Circle(\n",
    "        np.array([50+300, 200]), 5)\n",
    "\n",
    "    print(\"Circle 1:\")\n",
    "    print(c1.to_conic().M)\n",
    "    print([float(p) for p in c1.to_conic().to_algebraic_form()])\n",
    "    print(\"Circle 2:\")\n",
    "    print(c2.to_conic().M)\n",
    "    print([float(p) for p in c2.to_conic().to_algebraic_form()])\n",
    "    print(\"Circle 3:\")\n",
    "    print(c3.to_conic().M)\n",
    "    print([float(p) for p in c3.to_conic().to_algebraic_form()])\n",
    "\n",
    "    offset = np.array([0, 0, 100])\n",
    "    noiseScale = 0.00000000\n",
    "\n",
    "    return sg.SceneDescription(f, theta, offset, c1, c2, c3, noiseScale)\n",
    "\n",
    "sceneDescription = sceneDefinition()\n",
    "print(\"[Scene Described]\")\n",
    "\n",
    "img = sg.SceneGenerator().generate_scene(sceneDescription)\n",
    "print(\"[Scene Generated]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b96516aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\polimi\\master\\2sem\\cv_homotopy_project\\repo\\src\\HomoTopiContinuation\\Plotter\\Plotter.py:80: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  self.ax.legend()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the results\n",
    "plotter = Plotter.Plotter(2, 2, title=\"Base Scene with Circles\")\n",
    "\n",
    "plotter.plotScene(\n",
    "    sceneDescription=sceneDescription,\n",
    "    img=img,\n",
    ")\n",
    "\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03d0d0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2025-06-05 16:20:50,985:jax._src.xla_bridge:749: Unable to initialize backend 'tpu': UNIMPLEMENTED: LoadPjrtPlugin is not implemented on windows yet.\n"
     ]
    }
   ],
   "source": [
    "warpedConics = ConicsJax(img.C_img_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9b1ce3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.9999997e-05  5.3693575e-04 -9.4693571e-02]\n",
      " [ 5.3693575e-04  4.2488202e-03 -6.8078732e-01]\n",
      " [-9.4693571e-02 -6.8078732e-01  1.1138927e+02]]\n",
      "[[ 9.9999997e-05  5.7157676e-04 -1.0015768e-01]\n",
      " [ 5.7157676e-04  5.3804806e-03 -8.5275388e-01]\n",
      " [-1.0015768e-01 -8.5275388e-01  1.3748347e+02]]\n",
      "[[ 9.9999997e-05  6.0621777e-04 -1.0562178e-01]\n",
      " [ 6.0621777e-04  6.6598905e-03 -1.0480258e+00]\n",
      " [-1.0562178e-01 -1.0480258e+00  1.6725375e+02]]\n"
     ]
    }
   ],
   "source": [
    "for c in warpedConics:\n",
    "    print(c._M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c5560a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(2.4793816, dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loss(H_inv: jnp.array, conic: ConicJax) -> float:\n",
    "    warpedConic = conic.applyHomographyFromInv(H_inv)\n",
    "    axes = warpedConic.computeSemiAxes()\n",
    "    return jnp.abs(jnp.log(axes[0]/axes[1]))\n",
    "\n",
    "loss = jax.jit(loss, static_argnames=['conic'])\n",
    "\n",
    "def lossConics(H_inv:jnp.array, conics: ConicsJax) -> float:\n",
    "    return jnp.mean(\n",
    "        jnp.array([\n",
    "            loss(H_inv, conics.C1),\n",
    "            loss(H_inv, conics.C2),\n",
    "            loss(H_inv, conics.C3)\n",
    "        ])\n",
    "    )\n",
    "\n",
    "lossConics = jax.jit(lossConics, static_argnames=['conics'])\n",
    "\n",
    "H_inv = jnp.eye(3)\n",
    "lossConics(H_inv, warpedConics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80878c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[  -0.9762672 ,    0.21463752,    0.        ],\n",
       "       [   0.21463624,    0.97626716,    0.        ],\n",
       "       [ 212.90979   , -182.20139   ,    0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient = jax.grad(lossConics, argnums=0)\n",
    "gradient = jax.jit(gradient, static_argnames=['conics'])\n",
    "\n",
    "H_inv = jnp.eye(3)\n",
    "gradient(H_inv, warpedConics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2bc8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 2.4785964488983154\n",
      "Iteration 1, Loss: 2.477811574935913\n",
      "Iteration 2, Loss: 2.477027416229248\n",
      "Iteration 3, Loss: 2.476243734359741\n",
      "Iteration 4, Loss: 2.4754600524902344\n",
      "Iteration 5, Loss: 2.474677085876465\n",
      "Iteration 6, Loss: 2.4738948345184326\n",
      "Iteration 7, Loss: 2.4731128215789795\n",
      "Iteration 8, Loss: 2.4723310470581055\n",
      "Iteration 9, Loss: 2.4715499877929688\n",
      "Iteration 10, Loss: 2.4707694053649902\n",
      "Iteration 11, Loss: 2.46998929977417\n",
      "Iteration 12, Loss: 2.4692091941833496\n",
      "Iteration 13, Loss: 2.4684300422668457\n",
      "Iteration 14, Loss: 2.467651128768921\n",
      "Iteration 15, Loss: 2.4668726921081543\n",
      "Iteration 16, Loss: 2.466094732284546\n",
      "Iteration 17, Loss: 2.4653167724609375\n",
      "Iteration 18, Loss: 2.4645395278930664\n",
      "Iteration 19, Loss: 2.4637629985809326\n",
      "Iteration 20, Loss: 2.462986707687378\n",
      "Iteration 21, Loss: 2.4622106552124023\n",
      "Iteration 22, Loss: 2.461435317993164\n",
      "Iteration 23, Loss: 2.460660457611084\n",
      "Iteration 24, Loss: 2.459885597229004\n",
      "Iteration 25, Loss: 2.459111213684082\n",
      "Iteration 26, Loss: 2.4583375453948975\n",
      "Iteration 27, Loss: 2.457564353942871\n",
      "Iteration 28, Loss: 2.4567911624908447\n",
      "Iteration 29, Loss: 2.4560189247131348\n",
      "Iteration 30, Loss: 2.4552464485168457\n",
      "Iteration 31, Loss: 2.454474925994873\n",
      "Iteration 32, Loss: 2.4537036418914795\n",
      "Iteration 33, Loss: 2.452932834625244\n",
      "Iteration 34, Loss: 2.452162265777588\n",
      "Iteration 35, Loss: 2.45139217376709\n",
      "Iteration 36, Loss: 2.45062255859375\n",
      "Iteration 37, Loss: 2.4498534202575684\n",
      "Iteration 38, Loss: 2.449084520339966\n",
      "Iteration 39, Loss: 2.4483160972595215\n",
      "Iteration 40, Loss: 2.4475479125976562\n",
      "Iteration 41, Loss: 2.446780204772949\n",
      "Iteration 42, Loss: 2.4460132122039795\n",
      "Iteration 43, Loss: 2.445246458053589\n",
      "Iteration 44, Loss: 2.4444799423217773\n",
      "Iteration 45, Loss: 2.443713903427124\n",
      "Iteration 46, Loss: 2.442948341369629\n",
      "Iteration 47, Loss: 2.442183017730713\n",
      "Iteration 48, Loss: 2.441418409347534\n",
      "Iteration 49, Loss: 2.4406538009643555\n",
      "Iteration 50, Loss: 2.439889907836914\n",
      "Iteration 51, Loss: 2.4391260147094727\n",
      "Iteration 52, Loss: 2.4383628368377686\n",
      "Iteration 53, Loss: 2.4375996589660645\n",
      "Iteration 54, Loss: 2.436837673187256\n",
      "Iteration 55, Loss: 2.436075210571289\n",
      "Iteration 56, Loss: 2.4353137016296387\n",
      "Iteration 57, Loss: 2.4345521926879883\n",
      "Iteration 58, Loss: 2.433791160583496\n",
      "Iteration 59, Loss: 2.433030605316162\n",
      "Iteration 60, Loss: 2.432270050048828\n",
      "Iteration 61, Loss: 2.4315104484558105\n",
      "Iteration 62, Loss: 2.430751323699951\n",
      "Iteration 63, Loss: 2.4299919605255127\n",
      "Iteration 64, Loss: 2.4292333126068115\n",
      "Iteration 65, Loss: 2.4284749031066895\n",
      "Iteration 66, Loss: 2.4277169704437256\n",
      "Iteration 67, Loss: 2.42695951461792\n",
      "Iteration 68, Loss: 2.4262022972106934\n",
      "Iteration 69, Loss: 2.425445318222046\n",
      "Iteration 70, Loss: 2.4246888160705566\n",
      "Iteration 71, Loss: 2.4239325523376465\n",
      "Iteration 72, Loss: 2.4231770038604736\n",
      "Iteration 73, Loss: 2.422421455383301\n",
      "Iteration 74, Loss: 2.4216666221618652\n",
      "Iteration 75, Loss: 2.4209117889404297\n",
      "Iteration 76, Loss: 2.4201574325561523\n",
      "Iteration 77, Loss: 2.4194037914276123\n",
      "Iteration 78, Loss: 2.418649911880493\n",
      "Iteration 79, Loss: 2.4178967475891113\n",
      "Iteration 80, Loss: 2.4171438217163086\n",
      "Iteration 81, Loss: 2.416391372680664\n",
      "Iteration 82, Loss: 2.4156394004821777\n",
      "Iteration 83, Loss: 2.4148874282836914\n",
      "Iteration 84, Loss: 2.4141359329223633\n",
      "Iteration 85, Loss: 2.4133849143981934\n",
      "Iteration 86, Loss: 2.4126343727111816\n",
      "Iteration 87, Loss: 2.411883592605591\n",
      "Iteration 88, Loss: 2.4111335277557373\n",
      "Iteration 89, Loss: 2.410383701324463\n",
      "Iteration 90, Loss: 2.409634590148926\n",
      "Iteration 91, Loss: 2.4088854789733887\n",
      "Iteration 92, Loss: 2.4081368446350098\n",
      "Iteration 93, Loss: 2.407388687133789\n",
      "Iteration 94, Loss: 2.4066405296325684\n",
      "Iteration 95, Loss: 2.4058926105499268\n",
      "Iteration 96, Loss: 2.4051456451416016\n",
      "Iteration 97, Loss: 2.4043986797332764\n",
      "Iteration 98, Loss: 2.4036519527435303\n",
      "Iteration 99, Loss: 2.4029054641723633\n",
      "Iteration 100, Loss: 2.4021596908569336\n",
      "Iteration 101, Loss: 2.401413917541504\n",
      "Iteration 102, Loss: 2.4006686210632324\n",
      "Iteration 103, Loss: 2.399923801422119\n",
      "Iteration 104, Loss: 2.3991787433624268\n",
      "Iteration 105, Loss: 2.398434638977051\n",
      "Iteration 106, Loss: 2.3976902961730957\n",
      "Iteration 107, Loss: 2.396946907043457\n",
      "Iteration 108, Loss: 2.3962035179138184\n",
      "Iteration 109, Loss: 2.395460367202759\n",
      "Iteration 110, Loss: 2.3947176933288574\n",
      "Iteration 111, Loss: 2.3939757347106934\n",
      "Iteration 112, Loss: 2.393233299255371\n",
      "Iteration 113, Loss: 2.392491579055786\n",
      "Iteration 114, Loss: 2.3917500972747803\n",
      "Iteration 115, Loss: 2.3910090923309326\n",
      "Iteration 116, Loss: 2.390268087387085\n",
      "Iteration 117, Loss: 2.3895277976989746\n",
      "Iteration 118, Loss: 2.3887877464294434\n",
      "Iteration 119, Loss: 2.388047933578491\n",
      "Iteration 120, Loss: 2.3873085975646973\n",
      "Iteration 121, Loss: 2.386569023132324\n",
      "Iteration 122, Loss: 2.3858304023742676\n",
      "Iteration 123, Loss: 2.385091781616211\n",
      "Iteration 124, Loss: 2.3843531608581543\n",
      "Iteration 125, Loss: 2.383615255355835\n",
      "Iteration 126, Loss: 2.382877826690674\n",
      "Iteration 127, Loss: 2.3821401596069336\n",
      "Iteration 128, Loss: 2.3814034461975098\n",
      "Iteration 129, Loss: 2.380666732788086\n",
      "Iteration 130, Loss: 2.379929780960083\n",
      "Iteration 131, Loss: 2.3791940212249756\n",
      "Iteration 132, Loss: 2.37845778465271\n",
      "Iteration 133, Loss: 2.3777225017547607\n",
      "Iteration 134, Loss: 2.3769872188568115\n",
      "Iteration 135, Loss: 2.3762521743774414\n",
      "Iteration 136, Loss: 2.3755176067352295\n",
      "Iteration 137, Loss: 2.374783515930176\n",
      "Iteration 138, Loss: 2.374049186706543\n",
      "Iteration 139, Loss: 2.3733155727386475\n",
      "Iteration 140, Loss: 2.37258243560791\n",
      "Iteration 141, Loss: 2.3718490600585938\n",
      "Iteration 142, Loss: 2.3711159229278564\n",
      "Iteration 143, Loss: 2.3703837394714355\n",
      "Iteration 144, Loss: 2.3696513175964355\n",
      "Iteration 145, Loss: 2.3689193725585938\n",
      "Iteration 146, Loss: 2.368187665939331\n",
      "Iteration 147, Loss: 2.3674559593200684\n",
      "Iteration 148, Loss: 2.366724967956543\n",
      "Iteration 149, Loss: 2.3659939765930176\n",
      "Iteration 150, Loss: 2.3652634620666504\n",
      "Iteration 151, Loss: 2.3645331859588623\n",
      "Iteration 152, Loss: 2.3638033866882324\n",
      "Iteration 153, Loss: 2.3630733489990234\n",
      "Iteration 154, Loss: 2.3623437881469727\n",
      "Iteration 155, Loss: 2.36161470413208\n",
      "Iteration 156, Loss: 2.3608860969543457\n",
      "Iteration 157, Loss: 2.360157012939453\n",
      "Iteration 158, Loss: 2.359428644180298\n",
      "Iteration 159, Loss: 2.358700752258301\n",
      "Iteration 160, Loss: 2.357973098754883\n",
      "Iteration 161, Loss: 2.357245445251465\n",
      "Iteration 162, Loss: 2.356518268585205\n",
      "Iteration 163, Loss: 2.3557913303375244\n",
      "Iteration 164, Loss: 2.3550643920898438\n",
      "Iteration 165, Loss: 2.3543381690979004\n",
      "Iteration 166, Loss: 2.353611707687378\n",
      "Iteration 167, Loss: 2.3528859615325928\n",
      "Iteration 168, Loss: 2.3521604537963867\n",
      "Iteration 169, Loss: 2.3514351844787598\n",
      "Iteration 170, Loss: 2.350710391998291\n",
      "Iteration 171, Loss: 2.349985122680664\n",
      "Iteration 172, Loss: 2.3492608070373535\n",
      "Iteration 173, Loss: 2.348536252975464\n",
      "Iteration 174, Loss: 2.3478119373321533\n",
      "Iteration 175, Loss: 2.34708833694458\n",
      "Iteration 176, Loss: 2.3463644981384277\n",
      "Iteration 177, Loss: 2.345641613006592\n",
      "Iteration 178, Loss: 2.344918727874756\n",
      "Iteration 179, Loss: 2.34419584274292\n",
      "Iteration 180, Loss: 2.343473196029663\n",
      "Iteration 181, Loss: 2.3427510261535645\n",
      "Iteration 182, Loss: 2.342029094696045\n",
      "Iteration 183, Loss: 2.3413071632385254\n",
      "Iteration 184, Loss: 2.340585947036743\n",
      "Iteration 185, Loss: 2.339864730834961\n",
      "Iteration 186, Loss: 2.3391435146331787\n",
      "Iteration 187, Loss: 2.3384227752685547\n",
      "Iteration 188, Loss: 2.3377022743225098\n",
      "Iteration 189, Loss: 2.336982250213623\n",
      "Iteration 190, Loss: 2.3362622261047363\n",
      "Iteration 191, Loss: 2.3355424404144287\n",
      "Iteration 192, Loss: 2.3348228931427\n",
      "Iteration 193, Loss: 2.334103584289551\n",
      "Iteration 194, Loss: 2.3333845138549805\n",
      "Iteration 195, Loss: 2.3326659202575684\n",
      "Iteration 196, Loss: 2.3319473266601562\n",
      "Iteration 197, Loss: 2.3312289714813232\n",
      "Iteration 198, Loss: 2.3305106163024902\n",
      "Iteration 199, Loss: 2.3297929763793945\n",
      "Iteration 200, Loss: 2.329075574874878\n",
      "Iteration 201, Loss: 2.3283581733703613\n",
      "Iteration 202, Loss: 2.3276407718658447\n",
      "Iteration 203, Loss: 2.3269243240356445\n",
      "Iteration 204, Loss: 2.3262076377868652\n",
      "Iteration 205, Loss: 2.325490951538086\n",
      "Iteration 206, Loss: 2.324775218963623\n",
      "Iteration 207, Loss: 2.324059247970581\n",
      "Iteration 208, Loss: 2.323343276977539\n",
      "Iteration 209, Loss: 2.3226280212402344\n",
      "Iteration 210, Loss: 2.3219125270843506\n",
      "Iteration 211, Loss: 2.321197509765625\n",
      "Iteration 212, Loss: 2.3204827308654785\n",
      "Iteration 213, Loss: 2.319768190383911\n",
      "Iteration 214, Loss: 2.3190536499023438\n",
      "Iteration 215, Loss: 2.3183398246765137\n",
      "Iteration 216, Loss: 2.3176259994506836\n",
      "Iteration 217, Loss: 2.3169124126434326\n",
      "Iteration 218, Loss: 2.3161988258361816\n",
      "Iteration 219, Loss: 2.3154854774475098\n",
      "Iteration 220, Loss: 2.314772367477417\n",
      "Iteration 221, Loss: 2.3140599727630615\n",
      "Iteration 222, Loss: 2.313347578048706\n",
      "Iteration 223, Loss: 2.3126349449157715\n",
      "Iteration 224, Loss: 2.311923027038574\n",
      "Iteration 225, Loss: 2.311210870742798\n",
      "Iteration 226, Loss: 2.3104991912841797\n",
      "Iteration 227, Loss: 2.3097875118255615\n",
      "Iteration 228, Loss: 2.3090765476226807\n",
      "Iteration 229, Loss: 2.3083655834198\n",
      "Iteration 230, Loss: 2.307654619216919\n",
      "Iteration 231, Loss: 2.306943893432617\n",
      "Iteration 232, Loss: 2.3062336444854736\n",
      "Iteration 233, Loss: 2.30552339553833\n",
      "Iteration 234, Loss: 2.3048136234283447\n",
      "Iteration 235, Loss: 2.3041036128997803\n",
      "Iteration 236, Loss: 2.303394079208374\n",
      "Iteration 237, Loss: 2.3026845455169678\n",
      "Iteration 238, Loss: 2.301975727081299\n",
      "Iteration 239, Loss: 2.301266670227051\n",
      "Iteration 240, Loss: 2.300557851791382\n",
      "Iteration 241, Loss: 2.299849033355713\n",
      "Iteration 242, Loss: 2.299140691757202\n",
      "Iteration 243, Loss: 2.2984328269958496\n",
      "Iteration 244, Loss: 2.297724723815918\n",
      "Iteration 245, Loss: 2.2970170974731445\n",
      "Iteration 246, Loss: 2.296309471130371\n",
      "Iteration 247, Loss: 2.2956020832061768\n",
      "Iteration 248, Loss: 2.2948946952819824\n",
      "Iteration 249, Loss: 2.2941880226135254\n",
      "Iteration 250, Loss: 2.2934815883636475\n",
      "Iteration 251, Loss: 2.2927746772766113\n",
      "Iteration 252, Loss: 2.2920684814453125\n",
      "Iteration 253, Loss: 2.2913618087768555\n",
      "Iteration 254, Loss: 2.290656089782715\n",
      "Iteration 255, Loss: 2.289950370788574\n",
      "Iteration 256, Loss: 2.2892446517944336\n",
      "Iteration 257, Loss: 2.288539409637451\n",
      "Iteration 258, Loss: 2.2878341674804688\n",
      "Iteration 259, Loss: 2.2871291637420654\n",
      "Iteration 260, Loss: 2.286424398422241\n",
      "Iteration 261, Loss: 2.285719871520996\n",
      "Iteration 262, Loss: 2.285015344619751\n",
      "Iteration 263, Loss: 2.284311056137085\n",
      "Iteration 264, Loss: 2.283607006072998\n",
      "Iteration 265, Loss: 2.2829031944274902\n",
      "Iteration 266, Loss: 2.2821993827819824\n",
      "Iteration 267, Loss: 2.2814958095550537\n",
      "Iteration 268, Loss: 2.280792236328125\n",
      "Iteration 269, Loss: 2.2800891399383545\n",
      "Iteration 270, Loss: 2.279386520385742\n",
      "Iteration 271, Loss: 2.2786834239959717\n",
      "Iteration 272, Loss: 2.2779808044433594\n",
      "Iteration 273, Loss: 2.2772786617279053\n",
      "Iteration 274, Loss: 2.276576042175293\n",
      "Iteration 275, Loss: 2.275874137878418\n",
      "Iteration 276, Loss: 2.275172233581543\n",
      "Iteration 277, Loss: 2.274470567703247\n",
      "Iteration 278, Loss: 2.2737691402435303\n",
      "Iteration 279, Loss: 2.2730672359466553\n",
      "Iteration 280, Loss: 2.2723660469055176\n",
      "Iteration 281, Loss: 2.271665096282959\n",
      "Iteration 282, Loss: 2.2709641456604004\n",
      "Iteration 283, Loss: 2.270263671875\n",
      "Iteration 284, Loss: 2.2695631980895996\n",
      "Iteration 285, Loss: 2.268862724304199\n",
      "Iteration 286, Loss: 2.268162727355957\n",
      "Iteration 287, Loss: 2.2674622535705566\n",
      "Iteration 288, Loss: 2.2667624950408936\n",
      "Iteration 289, Loss: 2.2660629749298096\n",
      "Iteration 290, Loss: 2.2653634548187256\n",
      "Iteration 291, Loss: 2.2646641731262207\n",
      "Iteration 292, Loss: 2.2639646530151367\n",
      "Iteration 293, Loss: 2.263265609741211\n",
      "Iteration 294, Loss: 2.2625668048858643\n",
      "Iteration 295, Loss: 2.2618682384490967\n",
      "Iteration 296, Loss: 2.26116943359375\n",
      "Iteration 297, Loss: 2.2604711055755615\n",
      "Iteration 298, Loss: 2.259772777557373\n",
      "Iteration 299, Loss: 2.2590746879577637\n",
      "Iteration 300, Loss: 2.2583770751953125\n",
      "Iteration 301, Loss: 2.257678985595703\n",
      "Iteration 302, Loss: 2.256981611251831\n",
      "Iteration 303, Loss: 2.256284236907959\n",
      "Iteration 304, Loss: 2.255587100982666\n",
      "Iteration 305, Loss: 2.254889965057373\n",
      "Iteration 306, Loss: 2.254192590713501\n",
      "Iteration 307, Loss: 2.253495931625366\n",
      "Iteration 308, Loss: 2.2527995109558105\n",
      "Iteration 309, Loss: 2.2521026134490967\n",
      "Iteration 310, Loss: 2.25140643119812\n",
      "Iteration 311, Loss: 2.2507100105285645\n",
      "Iteration 312, Loss: 2.250014066696167\n",
      "Iteration 313, Loss: 2.2493181228637695\n",
      "Iteration 314, Loss: 2.2486226558685303\n",
      "Iteration 315, Loss: 2.247926712036133\n",
      "Iteration 316, Loss: 2.2472314834594727\n",
      "Iteration 317, Loss: 2.2465357780456543\n",
      "Iteration 318, Loss: 2.2458407878875732\n",
      "Iteration 319, Loss: 2.245145797729492\n",
      "Iteration 320, Loss: 2.2444510459899902\n",
      "Iteration 321, Loss: 2.243756055831909\n",
      "Iteration 322, Loss: 2.2430613040924072\n",
      "Iteration 323, Loss: 2.2423667907714844\n",
      "Iteration 324, Loss: 2.2416725158691406\n",
      "Iteration 325, Loss: 2.240978240966797\n",
      "Iteration 326, Loss: 2.2402842044830322\n",
      "Iteration 327, Loss: 2.2395901679992676\n",
      "Iteration 328, Loss: 2.2388968467712402\n",
      "Iteration 329, Loss: 2.2382030487060547\n",
      "Iteration 330, Loss: 2.237509250640869\n",
      "Iteration 331, Loss: 2.236815929412842\n",
      "Iteration 332, Loss: 2.2361226081848145\n",
      "Iteration 333, Loss: 2.235429525375366\n",
      "Iteration 334, Loss: 2.234736919403076\n",
      "Iteration 335, Loss: 2.234043836593628\n",
      "Iteration 336, Loss: 2.2333507537841797\n",
      "Iteration 337, Loss: 2.2326583862304688\n",
      "Iteration 338, Loss: 2.2319657802581787\n",
      "Iteration 339, Loss: 2.231273651123047\n",
      "Iteration 340, Loss: 2.230581283569336\n",
      "Iteration 341, Loss: 2.229888916015625\n",
      "Iteration 342, Loss: 2.2291972637176514\n",
      "Iteration 343, Loss: 2.2285056114196777\n",
      "Iteration 344, Loss: 2.227813720703125\n",
      "Iteration 345, Loss: 2.2271223068237305\n",
      "Iteration 346, Loss: 2.226430654525757\n",
      "Iteration 347, Loss: 2.2257397174835205\n",
      "Iteration 348, Loss: 2.225048542022705\n",
      "Iteration 349, Loss: 2.2243576049804688\n",
      "Iteration 350, Loss: 2.223666191101074\n",
      "Iteration 351, Loss: 2.222975730895996\n",
      "Iteration 352, Loss: 2.222285032272339\n",
      "Iteration 353, Loss: 2.2215943336486816\n",
      "Iteration 354, Loss: 2.2209038734436035\n",
      "Iteration 355, Loss: 2.2202134132385254\n",
      "Iteration 356, Loss: 2.2195236682891846\n",
      "Iteration 357, Loss: 2.2188334465026855\n",
      "Iteration 358, Loss: 2.2181432247161865\n",
      "Iteration 359, Loss: 2.2174530029296875\n",
      "Iteration 360, Loss: 2.216763496398926\n",
      "Iteration 361, Loss: 2.216073513031006\n",
      "Iteration 362, Loss: 2.2153842449188232\n",
      "Iteration 363, Loss: 2.2146949768066406\n",
      "Iteration 364, Loss: 2.214005470275879\n",
      "Iteration 365, Loss: 2.2133164405822754\n",
      "Iteration 366, Loss: 2.212627410888672\n",
      "Iteration 367, Loss: 2.21193790435791\n",
      "Iteration 368, Loss: 2.211249351501465\n",
      "Iteration 369, Loss: 2.2105607986450195\n",
      "Iteration 370, Loss: 2.209872245788574\n",
      "Iteration 371, Loss: 2.20918345451355\n",
      "Iteration 372, Loss: 2.208495616912842\n",
      "Iteration 373, Loss: 2.2078065872192383\n",
      "Iteration 374, Loss: 2.207118511199951\n",
      "Iteration 375, Loss: 2.206430435180664\n",
      "Iteration 376, Loss: 2.205742120742798\n",
      "Iteration 377, Loss: 2.205054521560669\n",
      "Iteration 378, Loss: 2.204366683959961\n",
      "Iteration 379, Loss: 2.203678846359253\n",
      "Iteration 380, Loss: 2.202991485595703\n",
      "Iteration 381, Loss: 2.2023043632507324\n",
      "Iteration 382, Loss: 2.2016165256500244\n",
      "Iteration 383, Loss: 2.2009291648864746\n",
      "Iteration 384, Loss: 2.200241804122925\n",
      "Iteration 385, Loss: 2.199554920196533\n",
      "Iteration 386, Loss: 2.1988677978515625\n",
      "Iteration 387, Loss: 2.198180675506592\n",
      "Iteration 388, Loss: 2.1974945068359375\n",
      "Iteration 389, Loss: 2.196807384490967\n",
      "Iteration 390, Loss: 2.1961207389831543\n",
      "Iteration 391, Loss: 2.1954336166381836\n",
      "Iteration 392, Loss: 2.1947476863861084\n",
      "Iteration 393, Loss: 2.194061040878296\n",
      "Iteration 394, Loss: 2.1933746337890625\n",
      "Iteration 395, Loss: 2.1926889419555664\n",
      "Iteration 396, Loss: 2.192002773284912\n",
      "Iteration 397, Loss: 2.191316604614258\n",
      "Iteration 398, Loss: 2.1906309127807617\n",
      "Iteration 399, Loss: 2.1899452209472656\n",
      "Iteration 400, Loss: 2.1892595291137695\n",
      "Iteration 401, Loss: 2.1885735988616943\n",
      "Iteration 402, Loss: 2.1878881454467773\n",
      "Iteration 403, Loss: 2.1872029304504395\n",
      "Iteration 404, Loss: 2.1865172386169434\n",
      "Iteration 405, Loss: 2.1858317852020264\n",
      "Iteration 406, Loss: 2.1851468086242676\n",
      "Iteration 407, Loss: 2.1844615936279297\n",
      "Iteration 408, Loss: 2.18377685546875\n",
      "Iteration 409, Loss: 2.183091640472412\n",
      "Iteration 410, Loss: 2.1824071407318115\n",
      "Iteration 411, Loss: 2.1817221641540527\n",
      "Iteration 412, Loss: 2.181037425994873\n",
      "Iteration 413, Loss: 2.1803526878356934\n",
      "Iteration 414, Loss: 2.1796681880950928\n",
      "Iteration 415, Loss: 2.178983688354492\n",
      "Iteration 416, Loss: 2.1782994270324707\n",
      "Iteration 417, Loss: 2.177615165710449\n",
      "Iteration 418, Loss: 2.1769309043884277\n",
      "Iteration 419, Loss: 2.176246404647827\n",
      "Iteration 420, Loss: 2.1755623817443848\n",
      "Iteration 421, Loss: 2.1748785972595215\n",
      "Iteration 422, Loss: 2.1741950511932373\n",
      "Iteration 423, Loss: 2.1735105514526367\n",
      "Iteration 424, Loss: 2.1728267669677734\n",
      "Iteration 425, Loss: 2.1721434593200684\n",
      "Iteration 426, Loss: 2.171459674835205\n",
      "Iteration 427, Loss: 2.170775890350342\n",
      "Iteration 428, Loss: 2.1700925827026367\n",
      "Iteration 429, Loss: 2.1694090366363525\n",
      "Iteration 430, Loss: 2.1687259674072266\n",
      "Iteration 431, Loss: 2.1680421829223633\n",
      "Iteration 432, Loss: 2.1673591136932373\n",
      "Iteration 433, Loss: 2.1666760444641113\n",
      "Iteration 434, Loss: 2.1659927368164062\n",
      "Iteration 435, Loss: 2.1653096675872803\n",
      "Iteration 436, Loss: 2.164626359939575\n",
      "Iteration 437, Loss: 2.1639435291290283\n",
      "Iteration 438, Loss: 2.1632604598999023\n",
      "Iteration 439, Loss: 2.1625776290893555\n",
      "Iteration 440, Loss: 2.161895275115967\n",
      "Iteration 441, Loss: 2.16121244430542\n",
      "Iteration 442, Loss: 2.1605300903320312\n",
      "Iteration 443, Loss: 2.1598474979400635\n",
      "Iteration 444, Loss: 2.1591649055480957\n",
      "Iteration 445, Loss: 2.158482551574707\n",
      "Iteration 446, Loss: 2.1578001976013184\n",
      "Iteration 447, Loss: 2.1571176052093506\n",
      "Iteration 448, Loss: 2.15643572807312\n",
      "Iteration 449, Loss: 2.1557533740997314\n",
      "Iteration 450, Loss: 2.155071258544922\n",
      "Iteration 451, Loss: 2.1543893814086914\n",
      "Iteration 452, Loss: 2.1537070274353027\n",
      "Iteration 453, Loss: 2.1530251502990723\n",
      "Iteration 454, Loss: 2.152343273162842\n",
      "Iteration 455, Loss: 2.151660680770874\n",
      "Iteration 456, Loss: 2.1509790420532227\n",
      "Iteration 457, Loss: 2.1502976417541504\n",
      "Iteration 458, Loss: 2.149615526199341\n",
      "Iteration 459, Loss: 2.1489341259002686\n",
      "Iteration 460, Loss: 2.148252487182617\n",
      "Iteration 461, Loss: 2.1475706100463867\n",
      "Iteration 462, Loss: 2.1468896865844727\n",
      "Iteration 463, Loss: 2.146207809448242\n",
      "Iteration 464, Loss: 2.14552640914917\n",
      "Iteration 465, Loss: 2.144845485687256\n",
      "Iteration 466, Loss: 2.1441636085510254\n",
      "Iteration 467, Loss: 2.143482208251953\n",
      "Iteration 468, Loss: 2.142801284790039\n",
      "Iteration 469, Loss: 2.142119884490967\n",
      "Iteration 470, Loss: 2.1414384841918945\n",
      "Iteration 471, Loss: 2.1407575607299805\n",
      "Iteration 472, Loss: 2.1400763988494873\n",
      "Iteration 473, Loss: 2.139395236968994\n",
      "Iteration 474, Loss: 2.138714075088501\n",
      "Iteration 475, Loss: 2.138032913208008\n",
      "Iteration 476, Loss: 2.137352466583252\n",
      "Iteration 477, Loss: 2.136671543121338\n",
      "Iteration 478, Loss: 2.135990858078003\n",
      "Iteration 479, Loss: 2.1353096961975098\n",
      "Iteration 480, Loss: 2.1346287727355957\n",
      "Iteration 481, Loss: 2.1339478492736816\n",
      "Iteration 482, Loss: 2.133267402648926\n",
      "Iteration 483, Loss: 2.1325864791870117\n",
      "Iteration 484, Loss: 2.131906032562256\n",
      "Iteration 485, Loss: 2.131225347518921\n",
      "Iteration 486, Loss: 2.130544662475586\n",
      "Iteration 487, Loss: 2.12986421585083\n",
      "Iteration 488, Loss: 2.129183292388916\n",
      "Iteration 489, Loss: 2.1285030841827393\n",
      "Iteration 490, Loss: 2.1278226375579834\n",
      "Iteration 491, Loss: 2.1271419525146484\n",
      "Iteration 492, Loss: 2.1264615058898926\n",
      "Iteration 493, Loss: 2.125781536102295\n",
      "Iteration 494, Loss: 2.12510085105896\n",
      "Iteration 495, Loss: 2.124420642852783\n",
      "Iteration 496, Loss: 2.1237406730651855\n",
      "Iteration 497, Loss: 2.1230602264404297\n",
      "Iteration 498, Loss: 2.122380018234253\n",
      "Iteration 499, Loss: 2.121699810028076\n",
      "Iteration 500, Loss: 2.1210193634033203\n",
      "Iteration 501, Loss: 2.1203389167785645\n",
      "Iteration 502, Loss: 2.119658946990967\n",
      "Iteration 503, Loss: 2.118978977203369\n",
      "Iteration 504, Loss: 2.1182985305786133\n",
      "Iteration 505, Loss: 2.1176183223724365\n",
      "Iteration 506, Loss: 2.1169381141662598\n",
      "Iteration 507, Loss: 2.116258144378662\n",
      "Iteration 508, Loss: 2.1155786514282227\n",
      "Iteration 509, Loss: 2.1148977279663086\n",
      "Iteration 510, Loss: 2.114218235015869\n",
      "Iteration 511, Loss: 2.1135380268096924\n",
      "Iteration 512, Loss: 2.1128575801849365\n",
      "Iteration 513, Loss: 2.112177848815918\n",
      "Iteration 514, Loss: 2.1114978790283203\n",
      "Iteration 515, Loss: 2.1108176708221436\n",
      "Iteration 516, Loss: 2.110137939453125\n",
      "Iteration 517, Loss: 2.1094579696655273\n",
      "Iteration 518, Loss: 2.1087779998779297\n",
      "Iteration 519, Loss: 2.108098030090332\n",
      "Iteration 520, Loss: 2.1074185371398926\n",
      "Iteration 521, Loss: 2.106738805770874\n",
      "Iteration 522, Loss: 2.106058359146118\n",
      "Iteration 523, Loss: 2.1053786277770996\n",
      "Iteration 524, Loss: 2.104698896408081\n",
      "Iteration 525, Loss: 2.1040189266204834\n",
      "Iteration 526, Loss: 2.1033389568328857\n",
      "Iteration 527, Loss: 2.102659225463867\n",
      "Iteration 528, Loss: 2.1019792556762695\n",
      "Iteration 529, Loss: 2.10129976272583\n",
      "Iteration 530, Loss: 2.1006200313568115\n",
      "Iteration 531, Loss: 2.0999395847320557\n",
      "Iteration 532, Loss: 2.099260091781616\n",
      "Iteration 533, Loss: 2.0985803604125977\n",
      "Iteration 534, Loss: 2.097900390625\n",
      "Iteration 535, Loss: 2.0972208976745605\n",
      "Iteration 536, Loss: 2.096540927886963\n",
      "Iteration 537, Loss: 2.0958609580993652\n",
      "Iteration 538, Loss: 2.0951809883117676\n",
      "Iteration 539, Loss: 2.094501495361328\n",
      "Iteration 540, Loss: 2.0938212871551514\n",
      "Iteration 541, Loss: 2.093141555786133\n",
      "Iteration 542, Loss: 2.092461585998535\n",
      "Iteration 543, Loss: 2.0917820930480957\n",
      "Iteration 544, Loss: 2.091101884841919\n",
      "Iteration 545, Loss: 2.090421676635742\n",
      "Iteration 546, Loss: 2.089742660522461\n",
      "Iteration 547, Loss: 2.089062452316284\n",
      "Iteration 548, Loss: 2.0883822441101074\n",
      "Iteration 549, Loss: 2.087702512741089\n",
      "Iteration 550, Loss: 2.0870227813720703\n",
      "Iteration 551, Loss: 2.0863428115844727\n",
      "Iteration 552, Loss: 2.085662603378296\n",
      "Iteration 553, Loss: 2.0849828720092773\n",
      "Iteration 554, Loss: 2.0843029022216797\n",
      "Iteration 555, Loss: 2.083622694015503\n",
      "Iteration 556, Loss: 2.0829429626464844\n",
      "Iteration 557, Loss: 2.0822629928588867\n",
      "Iteration 558, Loss: 2.081583261489868\n",
      "Iteration 559, Loss: 2.0809028148651123\n",
      "Iteration 560, Loss: 2.0802230834960938\n",
      "Iteration 561, Loss: 2.079543113708496\n",
      "Iteration 562, Loss: 2.0788629055023193\n",
      "Iteration 563, Loss: 2.0781829357147217\n",
      "Iteration 564, Loss: 2.077502965927124\n",
      "Iteration 565, Loss: 2.0768227577209473\n",
      "Iteration 566, Loss: 2.0761430263519287\n",
      "Iteration 567, Loss: 2.0754623413085938\n",
      "Iteration 568, Loss: 2.074782609939575\n",
      "Iteration 569, Loss: 2.0741024017333984\n",
      "Iteration 570, Loss: 2.0734219551086426\n",
      "Iteration 571, Loss: 2.072742223739624\n",
      "Iteration 572, Loss: 2.07206130027771\n",
      "Iteration 573, Loss: 2.0713815689086914\n",
      "Iteration 574, Loss: 2.0707011222839355\n",
      "Iteration 575, Loss: 2.0700206756591797\n",
      "Iteration 576, Loss: 2.069340229034424\n",
      "Iteration 577, Loss: 2.068660259246826\n",
      "Iteration 578, Loss: 2.0679798126220703\n",
      "Iteration 579, Loss: 2.0672993659973145\n",
      "Iteration 580, Loss: 2.0666184425354004\n",
      "Iteration 581, Loss: 2.0659384727478027\n",
      "Iteration 582, Loss: 2.0652570724487305\n",
      "Iteration 583, Loss: 2.064577102661133\n",
      "Iteration 584, Loss: 2.0638961791992188\n",
      "Iteration 585, Loss: 2.063216209411621\n",
      "Iteration 586, Loss: 2.062535285949707\n",
      "Iteration 587, Loss: 2.061854362487793\n",
      "Iteration 588, Loss: 2.061173915863037\n",
      "Iteration 589, Loss: 2.060493230819702\n",
      "Iteration 590, Loss: 2.059812545776367\n",
      "Iteration 591, Loss: 2.059131622314453\n",
      "Iteration 592, Loss: 2.0584511756896973\n",
      "Iteration 593, Loss: 2.057769775390625\n",
      "Iteration 594, Loss: 2.057089328765869\n",
      "Iteration 595, Loss: 2.056407928466797\n",
      "Iteration 596, Loss: 2.055727005004883\n",
      "Iteration 597, Loss: 2.0550460815429688\n",
      "Iteration 598, Loss: 2.0543651580810547\n",
      "Iteration 599, Loss: 2.0536839962005615\n",
      "Iteration 600, Loss: 2.0530028343200684\n",
      "Iteration 601, Loss: 2.0523219108581543\n",
      "Iteration 602, Loss: 2.051640510559082\n",
      "Iteration 603, Loss: 2.0509591102600098\n",
      "Iteration 604, Loss: 2.0502777099609375\n",
      "Iteration 605, Loss: 2.0495972633361816\n",
      "Iteration 606, Loss: 2.048915386199951\n",
      "Iteration 607, Loss: 2.0482335090637207\n",
      "Iteration 608, Loss: 2.0475521087646484\n",
      "Iteration 609, Loss: 2.046870470046997\n",
      "Iteration 610, Loss: 2.046189069747925\n",
      "Iteration 611, Loss: 2.0455076694488525\n",
      "Iteration 612, Loss: 2.044825792312622\n",
      "Iteration 613, Loss: 2.04414439201355\n",
      "Iteration 614, Loss: 2.0434625148773193\n",
      "Iteration 615, Loss: 2.042780637741089\n",
      "Iteration 616, Loss: 2.0420985221862793\n",
      "Iteration 617, Loss: 2.041417121887207\n",
      "Iteration 618, Loss: 2.0407352447509766\n",
      "Iteration 619, Loss: 2.040052890777588\n",
      "Iteration 620, Loss: 2.0393707752227783\n",
      "Iteration 621, Loss: 2.0386886596679688\n",
      "Iteration 622, Loss: 2.038006544113159\n",
      "Iteration 623, Loss: 2.0373241901397705\n",
      "Iteration 624, Loss: 2.036642074584961\n",
      "Iteration 625, Loss: 2.0359597206115723\n",
      "Iteration 626, Loss: 2.0352771282196045\n",
      "Iteration 627, Loss: 2.0345945358276367\n",
      "Iteration 628, Loss: 2.033912181854248\n",
      "Iteration 629, Loss: 2.0332298278808594\n",
      "Iteration 630, Loss: 2.0325465202331543\n",
      "Iteration 631, Loss: 2.0318641662597656\n",
      "Iteration 632, Loss: 2.0311813354492188\n",
      "Iteration 633, Loss: 2.03049898147583\n",
      "Iteration 634, Loss: 2.029815673828125\n",
      "Iteration 635, Loss: 2.029132604598999\n",
      "Iteration 636, Loss: 2.028449773788452\n",
      "Iteration 637, Loss: 2.027766466140747\n",
      "Iteration 638, Loss: 2.027083396911621\n",
      "Iteration 639, Loss: 2.026400327682495\n",
      "Iteration 640, Loss: 2.025716781616211\n",
      "Iteration 641, Loss: 2.025033950805664\n",
      "Iteration 642, Loss: 2.0243499279022217\n",
      "Iteration 643, Loss: 2.0236668586730957\n",
      "Iteration 644, Loss: 2.0229833126068115\n",
      "Iteration 645, Loss: 2.0222995281219482\n",
      "Iteration 646, Loss: 2.021616220474243\n",
      "Iteration 647, Loss: 2.020932674407959\n",
      "Iteration 648, Loss: 2.0202484130859375\n",
      "Iteration 649, Loss: 2.019564390182495\n",
      "Iteration 650, Loss: 2.0188803672790527\n",
      "Iteration 651, Loss: 2.0181965827941895\n",
      "Iteration 652, Loss: 2.017512321472168\n",
      "Iteration 653, Loss: 2.0168280601501465\n",
      "Iteration 654, Loss: 2.016143798828125\n",
      "Iteration 655, Loss: 2.0154597759246826\n",
      "Iteration 656, Loss: 2.014774799346924\n",
      "Iteration 657, Loss: 2.0140905380249023\n",
      "Iteration 658, Loss: 2.0134057998657227\n",
      "Iteration 659, Loss: 2.012721061706543\n",
      "Iteration 660, Loss: 2.0120368003845215\n",
      "Iteration 661, Loss: 2.0113515853881836\n",
      "Iteration 662, Loss: 2.010666847229004\n",
      "Iteration 663, Loss: 2.009981632232666\n",
      "Iteration 664, Loss: 2.009296417236328\n",
      "Iteration 665, Loss: 2.0086114406585693\n",
      "Iteration 666, Loss: 2.0079259872436523\n",
      "Iteration 667, Loss: 2.0072407722473145\n",
      "Iteration 668, Loss: 2.0065553188323975\n",
      "Iteration 669, Loss: 2.0058698654174805\n",
      "Iteration 670, Loss: 2.0051839351654053\n",
      "Iteration 671, Loss: 2.0044989585876465\n",
      "Iteration 672, Loss: 2.0038132667541504\n",
      "Iteration 673, Loss: 2.003127098083496\n",
      "Iteration 674, Loss: 2.00244140625\n",
      "Iteration 675, Loss: 2.0017547607421875\n",
      "Iteration 676, Loss: 2.0010690689086914\n",
      "Iteration 677, Loss: 2.000382900238037\n",
      "Iteration 678, Loss: 1.999696135520935\n",
      "Iteration 679, Loss: 1.9990100860595703\n",
      "Iteration 680, Loss: 1.9983234405517578\n",
      "Iteration 681, Loss: 1.997637152671814\n",
      "Iteration 682, Loss: 1.996950387954712\n",
      "Iteration 683, Loss: 1.9962635040283203\n",
      "Iteration 684, Loss: 1.9955768585205078\n",
      "Iteration 685, Loss: 1.9948896169662476\n",
      "Iteration 686, Loss: 1.994202971458435\n",
      "Iteration 687, Loss: 1.9935157299041748\n",
      "Iteration 688, Loss: 1.9928282499313354\n",
      "Iteration 689, Loss: 1.9921410083770752\n",
      "Iteration 690, Loss: 1.9914534091949463\n",
      "Iteration 691, Loss: 1.9907662868499756\n",
      "Iteration 692, Loss: 1.9900784492492676\n",
      "Iteration 693, Loss: 1.9893907308578491\n",
      "Iteration 694, Loss: 1.9887025356292725\n",
      "Iteration 695, Loss: 1.988014578819275\n",
      "Iteration 696, Loss: 1.9873266220092773\n",
      "Iteration 697, Loss: 1.9866384267807007\n",
      "Iteration 698, Loss: 1.985950231552124\n",
      "Iteration 699, Loss: 1.9852619171142578\n",
      "Iteration 700, Loss: 1.9845733642578125\n",
      "Iteration 701, Loss: 1.9838852882385254\n",
      "Iteration 702, Loss: 1.983196496963501\n",
      "Iteration 703, Loss: 1.9825074672698975\n",
      "Iteration 704, Loss: 1.9818181991577148\n",
      "Iteration 705, Loss: 1.9811294078826904\n",
      "Iteration 706, Loss: 1.9804408550262451\n",
      "Iteration 707, Loss: 1.979751467704773\n",
      "Iteration 708, Loss: 1.9790619611740112\n",
      "Iteration 709, Loss: 1.978372573852539\n",
      "Iteration 710, Loss: 1.9776828289031982\n",
      "Iteration 711, Loss: 1.9769935607910156\n",
      "Iteration 712, Loss: 1.9763034582138062\n",
      "Iteration 713, Loss: 1.9756135940551758\n",
      "Iteration 714, Loss: 1.9749234914779663\n",
      "Iteration 715, Loss: 1.9742335081100464\n",
      "Iteration 716, Loss: 1.9735430479049683\n",
      "Iteration 717, Loss: 1.9728527069091797\n",
      "Iteration 718, Loss: 1.9721622467041016\n",
      "Iteration 719, Loss: 1.9714715480804443\n",
      "Iteration 720, Loss: 1.9707807302474976\n",
      "Iteration 721, Loss: 1.9700899124145508\n",
      "Iteration 722, Loss: 1.969398856163025\n",
      "Iteration 723, Loss: 1.9687080383300781\n",
      "Iteration 724, Loss: 1.9680169820785522\n",
      "Iteration 725, Loss: 1.9673254489898682\n",
      "Iteration 726, Loss: 1.9666341543197632\n",
      "Iteration 727, Loss: 1.9659422636032104\n",
      "Iteration 728, Loss: 1.9652509689331055\n",
      "Iteration 729, Loss: 1.9645588397979736\n",
      "Iteration 730, Loss: 1.963866949081421\n",
      "Iteration 731, Loss: 1.9631747007369995\n",
      "Iteration 732, Loss: 1.9624824523925781\n",
      "Iteration 733, Loss: 1.9617900848388672\n",
      "Iteration 734, Loss: 1.9610975980758667\n",
      "Iteration 735, Loss: 1.9604051113128662\n",
      "Iteration 736, Loss: 1.959712028503418\n",
      "Iteration 737, Loss: 1.9590190649032593\n",
      "Iteration 738, Loss: 1.9583261013031006\n",
      "Iteration 739, Loss: 1.9576330184936523\n",
      "Iteration 740, Loss: 1.9569400548934937\n",
      "Iteration 741, Loss: 1.956246256828308\n",
      "Iteration 742, Loss: 1.9555528163909912\n",
      "Iteration 743, Loss: 1.9548590183258057\n",
      "Iteration 744, Loss: 1.9541653394699097\n",
      "Iteration 745, Loss: 1.9534711837768555\n",
      "Iteration 746, Loss: 1.9527771472930908\n",
      "Iteration 747, Loss: 1.9520833492279053\n",
      "Iteration 748, Loss: 1.9513890743255615\n",
      "Iteration 749, Loss: 1.950693964958191\n",
      "Iteration 750, Loss: 1.949999213218689\n",
      "Iteration 751, Loss: 1.9493045806884766\n",
      "Iteration 752, Loss: 1.948609709739685\n",
      "Iteration 753, Loss: 1.9479148387908936\n",
      "Iteration 754, Loss: 1.9472192525863647\n",
      "Iteration 755, Loss: 1.9465240240097046\n",
      "Iteration 756, Loss: 1.9458286762237549\n",
      "Iteration 757, Loss: 1.9451327323913574\n",
      "Iteration 758, Loss: 1.944437026977539\n",
      "Iteration 759, Loss: 1.9437408447265625\n",
      "Iteration 760, Loss: 1.9430450201034546\n",
      "Iteration 761, Loss: 1.9423487186431885\n",
      "Iteration 762, Loss: 1.9416522979736328\n",
      "Iteration 763, Loss: 1.940955400466919\n",
      "Iteration 764, Loss: 1.9402589797973633\n",
      "Iteration 765, Loss: 1.9395617246627808\n",
      "Iteration 766, Loss: 1.938865065574646\n",
      "Iteration 767, Loss: 1.938167929649353\n",
      "Iteration 768, Loss: 1.9374704360961914\n",
      "Iteration 769, Loss: 1.9367733001708984\n",
      "Iteration 770, Loss: 1.9360754489898682\n",
      "Iteration 771, Loss: 1.9353774785995483\n",
      "Iteration 772, Loss: 1.9346798658370972\n",
      "Iteration 773, Loss: 1.9339816570281982\n",
      "Iteration 774, Loss: 1.9332833290100098\n",
      "Iteration 775, Loss: 1.9325851202011108\n",
      "Iteration 776, Loss: 1.9318864345550537\n",
      "Iteration 777, Loss: 1.931187391281128\n",
      "Iteration 778, Loss: 1.93048894405365\n",
      "Iteration 779, Loss: 1.9297895431518555\n",
      "Iteration 780, Loss: 1.9290902614593506\n",
      "Iteration 781, Loss: 1.9283909797668457\n",
      "Iteration 782, Loss: 1.9276912212371826\n",
      "Iteration 783, Loss: 1.9269918203353882\n",
      "Iteration 784, Loss: 1.9262917041778564\n",
      "Iteration 785, Loss: 1.9255918264389038\n",
      "Iteration 786, Loss: 1.924891471862793\n",
      "Iteration 787, Loss: 1.924190878868103\n",
      "Iteration 788, Loss: 1.9234905242919922\n",
      "Iteration 789, Loss: 1.9227899312973022\n",
      "Iteration 790, Loss: 1.922088623046875\n",
      "Iteration 791, Loss: 1.9213879108428955\n",
      "Iteration 792, Loss: 1.9206864833831787\n",
      "Iteration 793, Loss: 1.9199851751327515\n",
      "Iteration 794, Loss: 1.9192829132080078\n",
      "Iteration 795, Loss: 1.9185817241668701\n",
      "Iteration 796, Loss: 1.917879581451416\n",
      "Iteration 797, Loss: 1.917177438735962\n",
      "Iteration 798, Loss: 1.9164752960205078\n",
      "Iteration 799, Loss: 1.9157724380493164\n",
      "Iteration 800, Loss: 1.9150699377059937\n",
      "Iteration 801, Loss: 1.914367437362671\n",
      "Iteration 802, Loss: 1.9136643409729004\n",
      "Iteration 803, Loss: 1.9129610061645508\n",
      "Iteration 804, Loss: 1.9122576713562012\n",
      "Iteration 805, Loss: 1.9115540981292725\n",
      "Iteration 806, Loss: 1.9108505249023438\n",
      "Iteration 807, Loss: 1.9101464748382568\n",
      "Iteration 808, Loss: 1.9094423055648804\n",
      "Iteration 809, Loss: 1.9087378978729248\n",
      "Iteration 810, Loss: 1.9080337285995483\n",
      "Iteration 811, Loss: 1.9073289632797241\n",
      "Iteration 812, Loss: 1.9066238403320312\n",
      "Iteration 813, Loss: 1.905918836593628\n",
      "Iteration 814, Loss: 1.905213713645935\n",
      "Iteration 815, Loss: 1.904508352279663\n",
      "Iteration 816, Loss: 1.9038026332855225\n",
      "Iteration 817, Loss: 1.9030966758728027\n",
      "Iteration 818, Loss: 1.9023908376693726\n",
      "Iteration 819, Loss: 1.9016854763031006\n",
      "Iteration 820, Loss: 1.9009780883789062\n",
      "Iteration 821, Loss: 1.9002716541290283\n",
      "Iteration 822, Loss: 1.8995651006698608\n",
      "Iteration 823, Loss: 1.8988579511642456\n",
      "Iteration 824, Loss: 1.8981504440307617\n",
      "Iteration 825, Loss: 1.8974436521530151\n",
      "Iteration 826, Loss: 1.8967359066009521\n",
      "Iteration 827, Loss: 1.8960285186767578\n",
      "Iteration 828, Loss: 1.8953202962875366\n",
      "Iteration 829, Loss: 1.894612193107605\n",
      "Iteration 830, Loss: 1.8939037322998047\n",
      "Iteration 831, Loss: 1.8931950330734253\n",
      "Iteration 832, Loss: 1.892486572265625\n",
      "Iteration 833, Loss: 1.891777515411377\n",
      "Iteration 834, Loss: 1.891068458557129\n",
      "Iteration 835, Loss: 1.8903584480285645\n",
      "Iteration 836, Loss: 1.8896491527557373\n",
      "Iteration 837, Loss: 1.8889397382736206\n",
      "Iteration 838, Loss: 1.8882297277450562\n",
      "Iteration 839, Loss: 1.887519121170044\n",
      "Iteration 840, Loss: 1.8868088722229004\n",
      "Iteration 841, Loss: 1.8860986232757568\n",
      "Iteration 842, Loss: 1.8853874206542969\n",
      "Iteration 843, Loss: 1.8846763372421265\n",
      "Iteration 844, Loss: 1.883965015411377\n",
      "Iteration 845, Loss: 1.883253574371338\n",
      "Iteration 846, Loss: 1.8825421333312988\n",
      "Iteration 847, Loss: 1.8818302154541016\n",
      "Iteration 848, Loss: 1.8811180591583252\n",
      "Iteration 849, Loss: 1.880405306816101\n",
      "Iteration 850, Loss: 1.8796929121017456\n",
      "Iteration 851, Loss: 1.8789803981781006\n",
      "Iteration 852, Loss: 1.878267765045166\n",
      "Iteration 853, Loss: 1.877554178237915\n",
      "Iteration 854, Loss: 1.8768408298492432\n",
      "Iteration 855, Loss: 1.876127004623413\n",
      "Iteration 856, Loss: 1.8754136562347412\n",
      "Iteration 857, Loss: 1.874699354171753\n",
      "Iteration 858, Loss: 1.8739843368530273\n",
      "Iteration 859, Loss: 1.8732703924179077\n",
      "Iteration 860, Loss: 1.8725559711456299\n",
      "Iteration 861, Loss: 1.871840476989746\n",
      "Iteration 862, Loss: 1.8711254596710205\n",
      "Iteration 863, Loss: 1.8704097270965576\n",
      "Iteration 864, Loss: 1.8696941137313843\n",
      "Iteration 865, Loss: 1.8689779043197632\n",
      "Iteration 866, Loss: 1.8682620525360107\n",
      "Iteration 867, Loss: 1.8675458431243896\n",
      "Iteration 868, Loss: 1.8668291568756104\n",
      "Iteration 869, Loss: 1.8661119937896729\n",
      "Iteration 870, Loss: 1.8653945922851562\n",
      "Iteration 871, Loss: 1.8646776676177979\n",
      "Iteration 872, Loss: 1.8639600276947021\n",
      "Iteration 873, Loss: 1.8632420301437378\n",
      "Iteration 874, Loss: 1.8625237941741943\n",
      "Iteration 875, Loss: 1.8618059158325195\n",
      "Iteration 876, Loss: 1.8610873222351074\n",
      "Iteration 877, Loss: 1.8603686094284058\n",
      "Iteration 878, Loss: 1.8596491813659668\n",
      "Iteration 879, Loss: 1.8589309453964233\n",
      "Iteration 880, Loss: 1.8582110404968262\n",
      "Iteration 881, Loss: 1.8574910163879395\n",
      "Iteration 882, Loss: 1.8567713499069214\n",
      "Iteration 883, Loss: 1.8560508489608765\n",
      "Iteration 884, Loss: 1.855330467224121\n",
      "Iteration 885, Loss: 1.854609489440918\n",
      "Iteration 886, Loss: 1.8538888692855835\n",
      "Iteration 887, Loss: 1.8531675338745117\n",
      "Iteration 888, Loss: 1.852446436882019\n",
      "Iteration 889, Loss: 1.85172438621521\n",
      "Iteration 890, Loss: 1.85100257396698\n",
      "Iteration 891, Loss: 1.8502798080444336\n",
      "Iteration 892, Loss: 1.849557638168335\n",
      "Iteration 893, Loss: 1.848834753036499\n",
      "Iteration 894, Loss: 1.8481115102767944\n",
      "Iteration 895, Loss: 1.8473892211914062\n",
      "Iteration 896, Loss: 1.846665382385254\n",
      "Iteration 897, Loss: 1.8459410667419434\n",
      "Iteration 898, Loss: 1.8452174663543701\n",
      "Iteration 899, Loss: 1.8444931507110596\n",
      "Iteration 900, Loss: 1.8437689542770386\n",
      "Iteration 901, Loss: 1.8430436849594116\n",
      "Iteration 902, Loss: 1.8423190116882324\n",
      "Iteration 903, Loss: 1.841593623161316\n",
      "Iteration 904, Loss: 1.8408682346343994\n",
      "Iteration 905, Loss: 1.8401421308517456\n",
      "Iteration 906, Loss: 1.8394159078598022\n",
      "Iteration 907, Loss: 1.8386895656585693\n",
      "Iteration 908, Loss: 1.8379631042480469\n",
      "Iteration 909, Loss: 1.8372361660003662\n",
      "Iteration 910, Loss: 1.8365087509155273\n",
      "Iteration 911, Loss: 1.8357815742492676\n",
      "Iteration 912, Loss: 1.8350534439086914\n",
      "Iteration 913, Loss: 1.8343257904052734\n",
      "Iteration 914, Loss: 1.8335976600646973\n",
      "Iteration 915, Loss: 1.8328689336776733\n",
      "Iteration 916, Loss: 1.8321402072906494\n",
      "Iteration 917, Loss: 1.8314108848571777\n",
      "Iteration 918, Loss: 1.8306816816329956\n",
      "Iteration 919, Loss: 1.8299516439437866\n",
      "Iteration 920, Loss: 1.8292220830917358\n",
      "Iteration 921, Loss: 1.8284916877746582\n",
      "Iteration 922, Loss: 1.8277616500854492\n",
      "Iteration 923, Loss: 1.827030897140503\n",
      "Iteration 924, Loss: 1.8262996673583984\n",
      "Iteration 925, Loss: 1.8255680799484253\n",
      "Iteration 926, Loss: 1.8248367309570312\n",
      "Iteration 927, Loss: 1.8241046667099\n",
      "Iteration 928, Loss: 1.8233726024627686\n",
      "Iteration 929, Loss: 1.8226398229599\n",
      "Iteration 930, Loss: 1.8219068050384521\n",
      "Iteration 931, Loss: 1.8211740255355835\n",
      "Iteration 932, Loss: 1.8204405307769775\n",
      "Iteration 933, Loss: 1.8197072744369507\n",
      "Iteration 934, Loss: 1.8189730644226074\n",
      "Iteration 935, Loss: 1.8182390928268433\n",
      "Iteration 936, Loss: 1.8175041675567627\n",
      "Iteration 937, Loss: 1.8167693614959717\n",
      "Iteration 938, Loss: 1.8160340785980225\n",
      "Iteration 939, Loss: 1.8152984380722046\n",
      "Iteration 940, Loss: 1.8145630359649658\n",
      "Iteration 941, Loss: 1.813827395439148\n",
      "Iteration 942, Loss: 1.8130906820297241\n",
      "Iteration 943, Loss: 1.812354326248169\n",
      "Iteration 944, Loss: 1.8116172552108765\n",
      "Iteration 945, Loss: 1.810880184173584\n",
      "Iteration 946, Loss: 1.8101423978805542\n",
      "Iteration 947, Loss: 1.809404730796814\n",
      "Iteration 948, Loss: 1.8086665868759155\n",
      "Iteration 949, Loss: 1.807928442955017\n",
      "Iteration 950, Loss: 1.8071893453598022\n",
      "Iteration 951, Loss: 1.8064502477645874\n",
      "Iteration 952, Loss: 1.805710792541504\n",
      "Iteration 953, Loss: 1.8049710988998413\n",
      "Iteration 954, Loss: 1.8042311668395996\n",
      "Iteration 955, Loss: 1.8034909963607788\n",
      "Iteration 956, Loss: 1.802750587463379\n",
      "Iteration 957, Loss: 1.8020094633102417\n",
      "Iteration 958, Loss: 1.8012679815292358\n",
      "Iteration 959, Loss: 1.8005261421203613\n",
      "Iteration 960, Loss: 1.7997844219207764\n",
      "Iteration 961, Loss: 1.7990421056747437\n",
      "Iteration 962, Loss: 1.7982993125915527\n",
      "Iteration 963, Loss: 1.7975566387176514\n",
      "Iteration 964, Loss: 1.796813726425171\n",
      "Iteration 965, Loss: 1.796069860458374\n",
      "Iteration 966, Loss: 1.7953259944915771\n",
      "Iteration 967, Loss: 1.7945817708969116\n",
      "Iteration 968, Loss: 1.793837547302246\n",
      "Iteration 969, Loss: 1.7930922508239746\n",
      "Iteration 970, Loss: 1.7923479080200195\n",
      "Iteration 971, Loss: 1.7916018962860107\n",
      "Iteration 972, Loss: 1.7908557653427124\n",
      "Iteration 973, Loss: 1.7901099920272827\n",
      "Iteration 974, Loss: 1.7893632650375366\n",
      "Iteration 975, Loss: 1.7886165380477905\n",
      "Iteration 976, Loss: 1.7878693342208862\n",
      "Iteration 977, Loss: 1.7871217727661133\n",
      "Iteration 978, Loss: 1.7863744497299194\n",
      "Iteration 979, Loss: 1.78562593460083\n",
      "Iteration 980, Loss: 1.7848773002624512\n",
      "Iteration 981, Loss: 1.7841291427612305\n",
      "Iteration 982, Loss: 1.7833797931671143\n",
      "Iteration 983, Loss: 1.7826298475265503\n",
      "Iteration 984, Loss: 1.7818801403045654\n",
      "Iteration 985, Loss: 1.7811295986175537\n",
      "Iteration 986, Loss: 1.780379056930542\n",
      "Iteration 987, Loss: 1.7796287536621094\n",
      "Iteration 988, Loss: 1.7788772583007812\n",
      "Iteration 989, Loss: 1.7781256437301636\n",
      "Iteration 990, Loss: 1.7773735523223877\n",
      "Iteration 991, Loss: 1.7766212224960327\n",
      "Iteration 992, Loss: 1.7758684158325195\n",
      "Iteration 993, Loss: 1.7751154899597168\n",
      "Iteration 994, Loss: 1.7743620872497559\n",
      "Iteration 995, Loss: 1.7736085653305054\n",
      "Iteration 996, Loss: 1.7728543281555176\n",
      "Iteration 997, Loss: 1.7720999717712402\n",
      "Iteration 998, Loss: 1.7713453769683838\n",
      "Iteration 999, Loss: 1.7705901861190796\n",
      "Iteration 1000, Loss: 1.7698345184326172\n",
      "Iteration 1001, Loss: 1.7690786123275757\n",
      "Iteration 1002, Loss: 1.768322467803955\n",
      "Iteration 1003, Loss: 1.7675659656524658\n",
      "Iteration 1004, Loss: 1.7668088674545288\n",
      "Iteration 1005, Loss: 1.7660516500473022\n",
      "Iteration 1006, Loss: 1.7652935981750488\n",
      "Iteration 1007, Loss: 1.764535665512085\n",
      "Iteration 1008, Loss: 1.763777494430542\n",
      "Iteration 1009, Loss: 1.763018012046814\n",
      "Iteration 1010, Loss: 1.7622588872909546\n",
      "Iteration 1011, Loss: 1.7614996433258057\n",
      "Iteration 1012, Loss: 1.7607396841049194\n",
      "Iteration 1013, Loss: 1.7599797248840332\n",
      "Iteration 1014, Loss: 1.7592179775238037\n",
      "Iteration 1015, Loss: 1.7584574222564697\n",
      "Iteration 1016, Loss: 1.7576956748962402\n",
      "Iteration 1017, Loss: 1.7569345235824585\n",
      "Iteration 1018, Loss: 1.756171703338623\n",
      "Iteration 1019, Loss: 1.7554091215133667\n",
      "Iteration 1020, Loss: 1.7546463012695312\n",
      "Iteration 1021, Loss: 1.7538831233978271\n",
      "Iteration 1022, Loss: 1.7531189918518066\n",
      "Iteration 1023, Loss: 1.7523550987243652\n",
      "Iteration 1024, Loss: 1.7515907287597656\n",
      "Iteration 1025, Loss: 1.7508256435394287\n",
      "Iteration 1026, Loss: 1.7500600814819336\n",
      "Iteration 1027, Loss: 1.7492942810058594\n",
      "Iteration 1028, Loss: 1.7485284805297852\n",
      "Iteration 1029, Loss: 1.747761607170105\n",
      "Iteration 1030, Loss: 1.746995210647583\n",
      "Iteration 1031, Loss: 1.746227741241455\n",
      "Iteration 1032, Loss: 1.7454599142074585\n",
      "Iteration 1033, Loss: 1.7446918487548828\n",
      "Iteration 1034, Loss: 1.7439236640930176\n",
      "Iteration 1035, Loss: 1.7431544065475464\n",
      "Iteration 1036, Loss: 1.7423856258392334\n",
      "Iteration 1037, Loss: 1.741615653038025\n",
      "Iteration 1038, Loss: 1.7408454418182373\n",
      "Iteration 1039, Loss: 1.7400751113891602\n",
      "Iteration 1040, Loss: 1.7393039464950562\n",
      "Iteration 1041, Loss: 1.738532543182373\n",
      "Iteration 1042, Loss: 1.7377610206604004\n",
      "Iteration 1043, Loss: 1.73698890209198\n",
      "Iteration 1044, Loss: 1.7362160682678223\n",
      "Iteration 1045, Loss: 1.735442876815796\n",
      "Iteration 1046, Loss: 1.7346699237823486\n",
      "Iteration 1047, Loss: 1.733896255493164\n",
      "Iteration 1048, Loss: 1.733121633529663\n",
      "Iteration 1049, Loss: 1.732347011566162\n",
      "Iteration 1050, Loss: 1.7315725088119507\n",
      "Iteration 1051, Loss: 1.7307965755462646\n",
      "Iteration 1052, Loss: 1.730020523071289\n",
      "Iteration 1053, Loss: 1.7292439937591553\n",
      "Iteration 1054, Loss: 1.7284672260284424\n",
      "Iteration 1055, Loss: 1.7276901006698608\n",
      "Iteration 1056, Loss: 1.726912498474121\n",
      "Iteration 1057, Loss: 1.7261346578598022\n",
      "Iteration 1058, Loss: 1.725356101989746\n",
      "Iteration 1059, Loss: 1.7245771884918213\n",
      "Iteration 1060, Loss: 1.72379732131958\n",
      "Iteration 1061, Loss: 1.7230174541473389\n",
      "Iteration 1062, Loss: 1.7222379446029663\n",
      "Iteration 1063, Loss: 1.7214572429656982\n",
      "Iteration 1064, Loss: 1.7206761837005615\n",
      "Iteration 1065, Loss: 1.7198946475982666\n",
      "Iteration 1066, Loss: 1.7191128730773926\n",
      "Iteration 1067, Loss: 1.718329906463623\n",
      "Iteration 1068, Loss: 1.7175474166870117\n",
      "Iteration 1069, Loss: 1.7167638540267944\n",
      "Iteration 1070, Loss: 1.715980052947998\n",
      "Iteration 1071, Loss: 1.7151960134506226\n",
      "Iteration 1072, Loss: 1.7144111394882202\n",
      "Iteration 1073, Loss: 1.7136259078979492\n",
      "Iteration 1074, Loss: 1.7128404378890991\n",
      "Iteration 1075, Loss: 1.7120544910430908\n",
      "Iteration 1076, Loss: 1.7112679481506348\n",
      "Iteration 1077, Loss: 1.71048104763031\n",
      "Iteration 1078, Loss: 1.709693431854248\n",
      "Iteration 1079, Loss: 1.708905577659607\n",
      "Iteration 1080, Loss: 1.7081173658370972\n",
      "Iteration 1081, Loss: 1.7073287963867188\n",
      "Iteration 1082, Loss: 1.7065391540527344\n",
      "Iteration 1083, Loss: 1.70574951171875\n",
      "Iteration 1084, Loss: 1.7049592733383179\n",
      "Iteration 1085, Loss: 1.7041685581207275\n",
      "Iteration 1086, Loss: 1.7033777236938477\n",
      "Iteration 1087, Loss: 1.7025859355926514\n",
      "Iteration 1088, Loss: 1.7017940282821655\n",
      "Iteration 1089, Loss: 1.7010014057159424\n",
      "Iteration 1090, Loss: 1.7002077102661133\n",
      "Iteration 1091, Loss: 1.6994147300720215\n",
      "Iteration 1092, Loss: 1.6986205577850342\n",
      "Iteration 1093, Loss: 1.6978263854980469\n",
      "Iteration 1094, Loss: 1.6970312595367432\n",
      "Iteration 1095, Loss: 1.6962361335754395\n",
      "Iteration 1096, Loss: 1.6954402923583984\n",
      "Iteration 1097, Loss: 1.6946437358856201\n",
      "Iteration 1098, Loss: 1.6938467025756836\n",
      "Iteration 1099, Loss: 1.6930488348007202\n",
      "Iteration 1100, Loss: 1.692251205444336\n",
      "Iteration 1101, Loss: 1.691452980041504\n",
      "Iteration 1102, Loss: 1.6906542778015137\n",
      "Iteration 1103, Loss: 1.6898549795150757\n",
      "Iteration 1104, Loss: 1.6890552043914795\n",
      "Iteration 1105, Loss: 1.6882550716400146\n",
      "Iteration 1106, Loss: 1.6874539852142334\n",
      "Iteration 1107, Loss: 1.686652421951294\n",
      "Iteration 1108, Loss: 1.6858506202697754\n",
      "Iteration 1109, Loss: 1.6850484609603882\n",
      "Iteration 1110, Loss: 1.6842454671859741\n",
      "Iteration 1111, Loss: 1.6834419965744019\n",
      "Iteration 1112, Loss: 1.6826379299163818\n",
      "Iteration 1113, Loss: 1.6818339824676514\n",
      "Iteration 1114, Loss: 1.6810288429260254\n",
      "Iteration 1115, Loss: 1.6802237033843994\n",
      "Iteration 1116, Loss: 1.6794180870056152\n",
      "Iteration 1117, Loss: 1.6786112785339355\n",
      "Iteration 1118, Loss: 1.6778043508529663\n",
      "Iteration 1119, Loss: 1.6769970655441284\n",
      "Iteration 1120, Loss: 1.6761893033981323\n",
      "Iteration 1121, Loss: 1.6753809452056885\n",
      "Iteration 1122, Loss: 1.6745717525482178\n",
      "Iteration 1123, Loss: 1.673762321472168\n",
      "Iteration 1124, Loss: 1.6729519367218018\n",
      "Iteration 1125, Loss: 1.6721413135528564\n",
      "Iteration 1126, Loss: 1.6713298559188843\n",
      "Iteration 1127, Loss: 1.6705182790756226\n",
      "Iteration 1128, Loss: 1.6697063446044922\n",
      "Iteration 1129, Loss: 1.6688932180404663\n",
      "Iteration 1130, Loss: 1.6680803298950195\n",
      "Iteration 1131, Loss: 1.667266607284546\n",
      "Iteration 1132, Loss: 1.6664522886276245\n",
      "Iteration 1133, Loss: 1.665637493133545\n",
      "Iteration 1134, Loss: 1.6648218631744385\n",
      "Iteration 1135, Loss: 1.664006233215332\n",
      "Iteration 1136, Loss: 1.6631892919540405\n",
      "Iteration 1137, Loss: 1.662372350692749\n",
      "Iteration 1138, Loss: 1.6615545749664307\n",
      "Iteration 1139, Loss: 1.6607369184494019\n",
      "Iteration 1140, Loss: 1.659918189048767\n",
      "Iteration 1141, Loss: 1.6590988636016846\n",
      "Iteration 1142, Loss: 1.6582791805267334\n",
      "Iteration 1143, Loss: 1.6574586629867554\n",
      "Iteration 1144, Loss: 1.656637191772461\n",
      "Iteration 1145, Loss: 1.6558160781860352\n",
      "Iteration 1146, Loss: 1.6549947261810303\n",
      "Iteration 1147, Loss: 1.654171347618103\n",
      "Iteration 1148, Loss: 1.6533482074737549\n",
      "Iteration 1149, Loss: 1.6525248289108276\n",
      "Iteration 1150, Loss: 1.651700735092163\n",
      "Iteration 1151, Loss: 1.650875449180603\n",
      "Iteration 1152, Loss: 1.6500499248504639\n",
      "Iteration 1153, Loss: 1.6492242813110352\n",
      "Iteration 1154, Loss: 1.648397445678711\n",
      "Iteration 1155, Loss: 1.6475703716278076\n",
      "Iteration 1156, Loss: 1.6467422246932983\n",
      "Iteration 1157, Loss: 1.645914077758789\n",
      "Iteration 1158, Loss: 1.645085096359253\n",
      "Iteration 1159, Loss: 1.6442556381225586\n",
      "Iteration 1160, Loss: 1.6434253454208374\n",
      "Iteration 1161, Loss: 1.642594814300537\n",
      "Iteration 1162, Loss: 1.641763687133789\n",
      "Iteration 1163, Loss: 1.640931487083435\n",
      "Iteration 1164, Loss: 1.6400989294052124\n",
      "Iteration 1165, Loss: 1.6392663717269897\n",
      "Iteration 1166, Loss: 1.6384320259094238\n",
      "Iteration 1167, Loss: 1.6375977993011475\n",
      "Iteration 1168, Loss: 1.6367629766464233\n",
      "Iteration 1169, Loss: 1.6359279155731201\n",
      "Iteration 1170, Loss: 1.6350921392440796\n",
      "Iteration 1171, Loss: 1.6342551708221436\n",
      "Iteration 1172, Loss: 1.6334178447723389\n",
      "Iteration 1173, Loss: 1.6325801610946655\n",
      "Iteration 1174, Loss: 1.6317415237426758\n",
      "Iteration 1175, Loss: 1.6309025287628174\n",
      "Iteration 1176, Loss: 1.6300625801086426\n",
      "Iteration 1177, Loss: 1.6292228698730469\n",
      "Iteration 1178, Loss: 1.6283814907073975\n",
      "Iteration 1179, Loss: 1.6275399923324585\n",
      "Iteration 1180, Loss: 1.6266977787017822\n",
      "Iteration 1181, Loss: 1.6258549690246582\n",
      "Iteration 1182, Loss: 1.6250114440917969\n",
      "Iteration 1183, Loss: 1.6241676807403564\n",
      "Iteration 1184, Loss: 1.62332284450531\n",
      "Iteration 1185, Loss: 1.622477412223816\n",
      "Iteration 1186, Loss: 1.621631383895874\n",
      "Iteration 1187, Loss: 1.620785117149353\n",
      "Iteration 1188, Loss: 1.6199374198913574\n",
      "Iteration 1189, Loss: 1.6190898418426514\n",
      "Iteration 1190, Loss: 1.618241310119629\n",
      "Iteration 1191, Loss: 1.6173923015594482\n",
      "Iteration 1192, Loss: 1.6165422201156616\n",
      "Iteration 1193, Loss: 1.6156915426254272\n",
      "Iteration 1194, Loss: 1.6148402690887451\n",
      "Iteration 1195, Loss: 1.6139891147613525\n",
      "Iteration 1196, Loss: 1.6131365299224854\n",
      "Iteration 1197, Loss: 1.6122831106185913\n",
      "Iteration 1198, Loss: 1.6114296913146973\n",
      "Iteration 1199, Loss: 1.6105754375457764\n",
      "Iteration 1200, Loss: 1.6097201108932495\n",
      "Iteration 1201, Loss: 1.6088645458221436\n",
      "Iteration 1202, Loss: 1.608008623123169\n",
      "Iteration 1203, Loss: 1.6071513891220093\n",
      "Iteration 1204, Loss: 1.6062934398651123\n",
      "Iteration 1205, Loss: 1.6054346561431885\n",
      "Iteration 1206, Loss: 1.6045758724212646\n",
      "Iteration 1207, Loss: 1.6037158966064453\n",
      "Iteration 1208, Loss: 1.6028556823730469\n",
      "Iteration 1209, Loss: 1.601994276046753\n",
      "Iteration 1210, Loss: 1.6011326313018799\n",
      "Iteration 1211, Loss: 1.6002702713012695\n",
      "Iteration 1212, Loss: 1.5994069576263428\n",
      "Iteration 1213, Loss: 1.5985430479049683\n",
      "Iteration 1214, Loss: 1.5976780652999878\n",
      "Iteration 1215, Loss: 1.5968129634857178\n",
      "Iteration 1216, Loss: 1.595947265625\n",
      "Iteration 1217, Loss: 1.5950807332992554\n",
      "Iteration 1218, Loss: 1.5942132472991943\n",
      "Iteration 1219, Loss: 1.5933451652526855\n",
      "Iteration 1220, Loss: 1.59247624874115\n",
      "Iteration 1221, Loss: 1.5916070938110352\n",
      "Iteration 1222, Loss: 1.5907371044158936\n",
      "Iteration 1223, Loss: 1.5898663997650146\n",
      "Iteration 1224, Loss: 1.5889943838119507\n",
      "Iteration 1225, Loss: 1.5881223678588867\n",
      "Iteration 1226, Loss: 1.587249517440796\n",
      "Iteration 1227, Loss: 1.5863755941390991\n",
      "Iteration 1228, Loss: 1.585500717163086\n",
      "Iteration 1229, Loss: 1.5846259593963623\n",
      "Iteration 1230, Loss: 1.5837501287460327\n",
      "Iteration 1231, Loss: 1.5828735828399658\n",
      "Iteration 1232, Loss: 1.5819963216781616\n",
      "Iteration 1233, Loss: 1.581118106842041\n",
      "Iteration 1234, Loss: 1.5802388191223145\n",
      "Iteration 1235, Loss: 1.579359531402588\n",
      "Iteration 1236, Loss: 1.578479528427124\n",
      "Iteration 1237, Loss: 1.5775985717773438\n",
      "Iteration 1238, Loss: 1.576716423034668\n",
      "Iteration 1239, Loss: 1.575834035873413\n",
      "Iteration 1240, Loss: 1.574951171875\n",
      "Iteration 1241, Loss: 1.5740668773651123\n",
      "Iteration 1242, Loss: 1.5731821060180664\n",
      "Iteration 1243, Loss: 1.5722968578338623\n",
      "Iteration 1244, Loss: 1.5714104175567627\n",
      "Iteration 1245, Loss: 1.5705235004425049\n",
      "Iteration 1246, Loss: 1.5696353912353516\n",
      "Iteration 1247, Loss: 1.5687470436096191\n",
      "Iteration 1248, Loss: 1.5678577423095703\n",
      "Iteration 1249, Loss: 1.5669677257537842\n",
      "Iteration 1250, Loss: 1.5660765171051025\n",
      "Iteration 1251, Loss: 1.5651848316192627\n",
      "Iteration 1252, Loss: 1.5642926692962646\n",
      "Iteration 1253, Loss: 1.5633995532989502\n",
      "Iteration 1254, Loss: 1.5625056028366089\n",
      "Iteration 1255, Loss: 1.5616105794906616\n",
      "Iteration 1256, Loss: 1.5607154369354248\n",
      "Iteration 1257, Loss: 1.5598186254501343\n",
      "Iteration 1258, Loss: 1.5589215755462646\n",
      "Iteration 1259, Loss: 1.558023452758789\n",
      "Iteration 1260, Loss: 1.5571248531341553\n",
      "Iteration 1261, Loss: 1.556225299835205\n",
      "Iteration 1262, Loss: 1.5553252696990967\n",
      "Iteration 1263, Loss: 1.5544241666793823\n",
      "Iteration 1264, Loss: 1.553521990776062\n",
      "Iteration 1265, Loss: 1.5526193380355835\n",
      "Iteration 1266, Loss: 1.551715612411499\n",
      "Iteration 1267, Loss: 1.550811529159546\n",
      "Iteration 1268, Loss: 1.5499062538146973\n",
      "Iteration 1269, Loss: 1.5490005016326904\n",
      "Iteration 1270, Loss: 1.548093318939209\n",
      "Iteration 1271, Loss: 1.5471858978271484\n",
      "Iteration 1272, Loss: 1.5462770462036133\n",
      "Iteration 1273, Loss: 1.5453680753707886\n",
      "Iteration 1274, Loss: 1.5444577932357788\n",
      "Iteration 1275, Loss: 1.5435470342636108\n",
      "Iteration 1276, Loss: 1.5426349639892578\n",
      "Iteration 1277, Loss: 1.541722297668457\n",
      "Iteration 1278, Loss: 1.5408085584640503\n",
      "Iteration 1279, Loss: 1.5398945808410645\n",
      "Iteration 1280, Loss: 1.5389792919158936\n",
      "Iteration 1281, Loss: 1.5380630493164062\n",
      "Iteration 1282, Loss: 1.5371465682983398\n",
      "Iteration 1283, Loss: 1.5362284183502197\n",
      "Iteration 1284, Loss: 1.5353095531463623\n",
      "Iteration 1285, Loss: 1.5343904495239258\n",
      "Iteration 1286, Loss: 1.5334699153900146\n",
      "Iteration 1287, Loss: 1.5325486660003662\n",
      "Iteration 1288, Loss: 1.5316261053085327\n",
      "Iteration 1289, Loss: 1.5307033061981201\n",
      "Iteration 1290, Loss: 1.5297796726226807\n",
      "Iteration 1291, Loss: 1.5288550853729248\n",
      "Iteration 1292, Loss: 1.5279293060302734\n",
      "Iteration 1293, Loss: 1.5270025730133057\n",
      "Iteration 1294, Loss: 1.5260753631591797\n",
      "Iteration 1295, Loss: 1.5251468420028687\n",
      "Iteration 1296, Loss: 1.5242180824279785\n",
      "Iteration 1297, Loss: 1.5232881307601929\n",
      "Iteration 1298, Loss: 1.5223569869995117\n",
      "Iteration 1299, Loss: 1.5214252471923828\n",
      "Iteration 1300, Loss: 1.5204927921295166\n",
      "Iteration 1301, Loss: 1.5195589065551758\n",
      "Iteration 1302, Loss: 1.5186240673065186\n",
      "Iteration 1303, Loss: 1.5176886320114136\n",
      "Iteration 1304, Loss: 1.5167526006698608\n",
      "Iteration 1305, Loss: 1.5158151388168335\n",
      "Iteration 1306, Loss: 1.5148768424987793\n",
      "Iteration 1307, Loss: 1.5139377117156982\n",
      "Iteration 1308, Loss: 1.5129978656768799\n",
      "Iteration 1309, Loss: 1.5120563507080078\n",
      "Iteration 1310, Loss: 1.5111145973205566\n",
      "Iteration 1311, Loss: 1.5101712942123413\n",
      "Iteration 1312, Loss: 1.5092277526855469\n",
      "Iteration 1313, Loss: 1.508283019065857\n",
      "Iteration 1314, Loss: 1.5073373317718506\n",
      "Iteration 1315, Loss: 1.5063903331756592\n",
      "Iteration 1316, Loss: 1.5054428577423096\n",
      "Iteration 1317, Loss: 1.504494071006775\n",
      "Iteration 1318, Loss: 1.5035446882247925\n",
      "Iteration 1319, Loss: 1.502593994140625\n",
      "Iteration 1320, Loss: 1.5016424655914307\n",
      "Iteration 1321, Loss: 1.50068998336792\n",
      "Iteration 1322, Loss: 1.4997366666793823\n",
      "Iteration 1323, Loss: 1.4987821578979492\n",
      "Iteration 1324, Loss: 1.4978269338607788\n",
      "Iteration 1325, Loss: 1.4968700408935547\n",
      "Iteration 1326, Loss: 1.495913028717041\n",
      "Iteration 1327, Loss: 1.4949544668197632\n",
      "Iteration 1328, Loss: 1.493995189666748\n",
      "Iteration 1329, Loss: 1.4930347204208374\n",
      "Iteration 1330, Loss: 1.4920734167099\n",
      "Iteration 1331, Loss: 1.491111159324646\n",
      "Iteration 1332, Loss: 1.490147590637207\n",
      "Iteration 1333, Loss: 1.4891833066940308\n",
      "Iteration 1334, Loss: 1.488218069076538\n",
      "Iteration 1335, Loss: 1.48725163936615\n",
      "Iteration 1336, Loss: 1.4862844944000244\n",
      "Iteration 1337, Loss: 1.4853156805038452\n",
      "Iteration 1338, Loss: 1.4843463897705078\n",
      "Iteration 1339, Loss: 1.4833757877349854\n",
      "Iteration 1340, Loss: 1.4824039936065674\n",
      "Iteration 1341, Loss: 1.4814318418502808\n",
      "Iteration 1342, Loss: 1.4804584980010986\n",
      "Iteration 1343, Loss: 1.4794836044311523\n",
      "Iteration 1344, Loss: 1.4785079956054688\n",
      "Iteration 1345, Loss: 1.4775313138961792\n",
      "Iteration 1346, Loss: 1.4765533208847046\n",
      "Iteration 1347, Loss: 1.4755744934082031\n",
      "Iteration 1348, Loss: 1.4745948314666748\n",
      "Iteration 1349, Loss: 1.4736136198043823\n",
      "Iteration 1350, Loss: 1.4726314544677734\n",
      "Iteration 1351, Loss: 1.4716484546661377\n",
      "Iteration 1352, Loss: 1.4706645011901855\n",
      "Iteration 1353, Loss: 1.4696788787841797\n",
      "Iteration 1354, Loss: 1.4686921834945679\n",
      "Iteration 1355, Loss: 1.4677047729492188\n",
      "Iteration 1356, Loss: 1.4667165279388428\n",
      "Iteration 1357, Loss: 1.465726613998413\n",
      "Iteration 1358, Loss: 1.464735984802246\n",
      "Iteration 1359, Loss: 1.4637439250946045\n",
      "Iteration 1360, Loss: 1.4627511501312256\n",
      "Iteration 1361, Loss: 1.4617570638656616\n",
      "Iteration 1362, Loss: 1.460761547088623\n",
      "Iteration 1363, Loss: 1.459766149520874\n",
      "Iteration 1364, Loss: 1.4587678909301758\n",
      "Iteration 1365, Loss: 1.457769751548767\n",
      "Iteration 1366, Loss: 1.4567698240280151\n",
      "Iteration 1367, Loss: 1.4557690620422363\n",
      "Iteration 1368, Loss: 1.4547672271728516\n",
      "Iteration 1369, Loss: 1.4537642002105713\n",
      "Iteration 1370, Loss: 1.4527597427368164\n",
      "Iteration 1371, Loss: 1.4517545700073242\n",
      "Iteration 1372, Loss: 1.4507479667663574\n",
      "Iteration 1373, Loss: 1.4497404098510742\n",
      "Iteration 1374, Loss: 1.448731780052185\n",
      "Iteration 1375, Loss: 1.4477214813232422\n",
      "Iteration 1376, Loss: 1.4467105865478516\n",
      "Iteration 1377, Loss: 1.4456981420516968\n",
      "Iteration 1378, Loss: 1.444684386253357\n",
      "Iteration 1379, Loss: 1.4436700344085693\n",
      "Iteration 1380, Loss: 1.442654013633728\n",
      "Iteration 1381, Loss: 1.4416368007659912\n",
      "Iteration 1382, Loss: 1.4406185150146484\n",
      "Iteration 1383, Loss: 1.4395993947982788\n",
      "Iteration 1384, Loss: 1.4385783672332764\n",
      "Iteration 1385, Loss: 1.4375566244125366\n",
      "Iteration 1386, Loss: 1.4365336894989014\n",
      "Iteration 1387, Loss: 1.4355090856552124\n",
      "Iteration 1388, Loss: 1.434483528137207\n",
      "Iteration 1389, Loss: 1.4334572553634644\n",
      "Iteration 1390, Loss: 1.4324288368225098\n",
      "Iteration 1391, Loss: 1.4313998222351074\n",
      "Iteration 1392, Loss: 1.4303696155548096\n",
      "Iteration 1393, Loss: 1.4293378591537476\n",
      "Iteration 1394, Loss: 1.4283050298690796\n",
      "Iteration 1395, Loss: 1.4272708892822266\n",
      "Iteration 1396, Loss: 1.4262354373931885\n",
      "Iteration 1397, Loss: 1.4251984357833862\n",
      "Iteration 1398, Loss: 1.4241604804992676\n",
      "Iteration 1399, Loss: 1.423121452331543\n",
      "Iteration 1400, Loss: 1.4220808744430542\n",
      "Iteration 1401, Loss: 1.4210389852523804\n",
      "Iteration 1402, Loss: 1.4199962615966797\n",
      "Iteration 1403, Loss: 1.4189517498016357\n",
      "Iteration 1404, Loss: 1.4179058074951172\n",
      "Iteration 1405, Loss: 1.4168593883514404\n",
      "Iteration 1406, Loss: 1.4158109426498413\n",
      "Iteration 1407, Loss: 1.4147614240646362\n",
      "Iteration 1408, Loss: 1.4137104749679565\n",
      "Iteration 1409, Loss: 1.412658452987671\n",
      "Iteration 1410, Loss: 1.4116047620773315\n",
      "Iteration 1411, Loss: 1.410549521446228\n",
      "Iteration 1412, Loss: 1.409493327140808\n",
      "Iteration 1413, Loss: 1.4084362983703613\n",
      "Iteration 1414, Loss: 1.4073771238327026\n",
      "Iteration 1415, Loss: 1.406317114830017\n",
      "Iteration 1416, Loss: 1.4052555561065674\n",
      "Iteration 1417, Loss: 1.4041929244995117\n",
      "Iteration 1418, Loss: 1.4031285047531128\n",
      "Iteration 1419, Loss: 1.4020628929138184\n",
      "Iteration 1420, Loss: 1.4009959697723389\n",
      "Iteration 1421, Loss: 1.3999276161193848\n",
      "Iteration 1422, Loss: 1.3988574743270874\n",
      "Iteration 1423, Loss: 1.3977864980697632\n",
      "Iteration 1424, Loss: 1.3967139720916748\n",
      "Iteration 1425, Loss: 1.395640254020691\n",
      "Iteration 1426, Loss: 1.3945646286010742\n",
      "Iteration 1427, Loss: 1.3934882879257202\n",
      "Iteration 1428, Loss: 1.392410159111023\n",
      "Iteration 1429, Loss: 1.391330599784851\n",
      "Iteration 1430, Loss: 1.3902499675750732\n",
      "Iteration 1431, Loss: 1.3891671895980835\n",
      "Iteration 1432, Loss: 1.3880834579467773\n",
      "Iteration 1433, Loss: 1.3869984149932861\n",
      "Iteration 1434, Loss: 1.3859117031097412\n",
      "Iteration 1435, Loss: 1.3848233222961426\n",
      "Iteration 1436, Loss: 1.383734107017517\n",
      "Iteration 1437, Loss: 1.382643461227417\n",
      "Iteration 1438, Loss: 1.381550669670105\n",
      "Iteration 1439, Loss: 1.3804569244384766\n",
      "Iteration 1440, Loss: 1.3793611526489258\n",
      "Iteration 1441, Loss: 1.3782641887664795\n",
      "Iteration 1442, Loss: 1.3771655559539795\n",
      "Iteration 1443, Loss: 1.376065969467163\n",
      "Iteration 1444, Loss: 1.3749642372131348\n",
      "Iteration 1445, Loss: 1.37386155128479\n",
      "Iteration 1446, Loss: 1.3727569580078125\n",
      "Iteration 1447, Loss: 1.37165105342865\n",
      "Iteration 1448, Loss: 1.3705438375473022\n",
      "Iteration 1449, Loss: 1.3694347143173218\n",
      "Iteration 1450, Loss: 1.3683241605758667\n",
      "Iteration 1451, Loss: 1.3672120571136475\n",
      "Iteration 1452, Loss: 1.3660987615585327\n",
      "Iteration 1453, Loss: 1.3649834394454956\n",
      "Iteration 1454, Loss: 1.3638668060302734\n",
      "Iteration 1455, Loss: 1.3627485036849976\n",
      "Iteration 1456, Loss: 1.361628770828247\n",
      "Iteration 1457, Loss: 1.3605074882507324\n",
      "Iteration 1458, Loss: 1.3593847751617432\n",
      "Iteration 1459, Loss: 1.3582595586776733\n",
      "Iteration 1460, Loss: 1.3571337461471558\n",
      "Iteration 1461, Loss: 1.3560056686401367\n",
      "Iteration 1462, Loss: 1.3548762798309326\n",
      "Iteration 1463, Loss: 1.353745460510254\n",
      "Iteration 1464, Loss: 1.3526133298873901\n",
      "Iteration 1465, Loss: 1.3514790534973145\n",
      "Iteration 1466, Loss: 1.3503432273864746\n",
      "Iteration 1467, Loss: 1.3492053747177124\n",
      "Iteration 1468, Loss: 1.3480662107467651\n",
      "Iteration 1469, Loss: 1.346925973892212\n",
      "Iteration 1470, Loss: 1.3457831144332886\n",
      "Iteration 1471, Loss: 1.3446388244628906\n",
      "Iteration 1472, Loss: 1.3434933423995972\n",
      "Iteration 1473, Loss: 1.3423460721969604\n",
      "Iteration 1474, Loss: 1.3411970138549805\n",
      "Iteration 1475, Loss: 1.3400458097457886\n",
      "Iteration 1476, Loss: 1.3388934135437012\n",
      "Iteration 1477, Loss: 1.3377392292022705\n",
      "Iteration 1478, Loss: 1.3365833759307861\n",
      "Iteration 1479, Loss: 1.3354253768920898\n",
      "Iteration 1480, Loss: 1.334266185760498\n",
      "Iteration 1481, Loss: 1.3331050872802734\n",
      "Iteration 1482, Loss: 1.3319424390792847\n",
      "Iteration 1483, Loss: 1.330777645111084\n",
      "Iteration 1484, Loss: 1.3296115398406982\n",
      "Iteration 1485, Loss: 1.3284430503845215\n",
      "Iteration 1486, Loss: 1.3272736072540283\n",
      "Iteration 1487, Loss: 1.3261017799377441\n",
      "Iteration 1488, Loss: 1.3249285221099854\n",
      "Iteration 1489, Loss: 1.3237532377243042\n",
      "Iteration 1490, Loss: 1.3225758075714111\n",
      "Iteration 1491, Loss: 1.321397304534912\n",
      "Iteration 1492, Loss: 1.3202168941497803\n",
      "Iteration 1493, Loss: 1.319034457206726\n",
      "Iteration 1494, Loss: 1.3178499937057495\n",
      "Iteration 1495, Loss: 1.3166639804840088\n",
      "Iteration 1496, Loss: 1.3154757022857666\n",
      "Iteration 1497, Loss: 1.3142859935760498\n",
      "Iteration 1498, Loss: 1.3130943775177002\n",
      "Iteration 1499, Loss: 1.3119009733200073\n",
      "Iteration 1500, Loss: 1.310705542564392\n",
      "Iteration 1501, Loss: 1.3095080852508545\n",
      "Iteration 1502, Loss: 1.3083089590072632\n",
      "Iteration 1503, Loss: 1.30710768699646\n",
      "Iteration 1504, Loss: 1.3059051036834717\n",
      "Iteration 1505, Loss: 1.304700255393982\n",
      "Iteration 1506, Loss: 1.3034934997558594\n",
      "Iteration 1507, Loss: 1.3022844791412354\n",
      "Iteration 1508, Loss: 1.3010742664337158\n",
      "Iteration 1509, Loss: 1.2998613119125366\n",
      "Iteration 1510, Loss: 1.2986468076705933\n",
      "Iteration 1511, Loss: 1.2974305152893066\n",
      "Iteration 1512, Loss: 1.2962117195129395\n",
      "Iteration 1513, Loss: 1.2949912548065186\n",
      "Iteration 1514, Loss: 1.293769121170044\n",
      "Iteration 1515, Loss: 1.2925446033477783\n",
      "Iteration 1516, Loss: 1.2913182973861694\n",
      "Iteration 1517, Loss: 1.290089726448059\n",
      "Iteration 1518, Loss: 1.2888593673706055\n",
      "Iteration 1519, Loss: 1.2876269817352295\n",
      "Iteration 1520, Loss: 1.2863922119140625\n",
      "Iteration 1521, Loss: 1.2851555347442627\n",
      "Iteration 1522, Loss: 1.2839165925979614\n",
      "Iteration 1523, Loss: 1.282676100730896\n",
      "Iteration 1524, Loss: 1.28143310546875\n",
      "Iteration 1525, Loss: 1.2801883220672607\n",
      "Iteration 1526, Loss: 1.2789413928985596\n",
      "Iteration 1527, Loss: 1.2776920795440674\n",
      "Iteration 1528, Loss: 1.276440978050232\n",
      "Iteration 1529, Loss: 1.275187611579895\n",
      "Iteration 1530, Loss: 1.2739320993423462\n",
      "Iteration 1531, Loss: 1.2726746797561646\n",
      "Iteration 1532, Loss: 1.271415114402771\n",
      "Iteration 1533, Loss: 1.270153284072876\n",
      "Iteration 1534, Loss: 1.2688889503479004\n",
      "Iteration 1535, Loss: 1.2676228284835815\n",
      "Iteration 1536, Loss: 1.2663543224334717\n",
      "Iteration 1537, Loss: 1.2650840282440186\n",
      "Iteration 1538, Loss: 1.2638108730316162\n",
      "Iteration 1539, Loss: 1.2625360488891602\n",
      "Iteration 1540, Loss: 1.2612589597702026\n",
      "Iteration 1541, Loss: 1.2599796056747437\n",
      "Iteration 1542, Loss: 1.2586973905563354\n",
      "Iteration 1543, Loss: 1.2574137449264526\n",
      "Iteration 1544, Loss: 1.2561275959014893\n",
      "Iteration 1545, Loss: 1.2548388242721558\n",
      "Iteration 1546, Loss: 1.2535480260849\n",
      "Iteration 1547, Loss: 1.2522552013397217\n",
      "Iteration 1548, Loss: 1.2509596347808838\n",
      "Iteration 1549, Loss: 1.249662160873413\n",
      "Iteration 1550, Loss: 1.2483619451522827\n",
      "Iteration 1551, Loss: 1.24705970287323\n",
      "Iteration 1552, Loss: 1.2457547187805176\n",
      "Iteration 1553, Loss: 1.2444475889205933\n",
      "Iteration 1554, Loss: 1.2431384325027466\n",
      "Iteration 1555, Loss: 1.2418266534805298\n",
      "Iteration 1556, Loss: 1.2405121326446533\n",
      "Iteration 1557, Loss: 1.239195704460144\n",
      "Iteration 1558, Loss: 1.2378766536712646\n",
      "Iteration 1559, Loss: 1.2365554571151733\n",
      "Iteration 1560, Loss: 1.2352315187454224\n",
      "Iteration 1561, Loss: 1.2339049577713013\n",
      "Iteration 1562, Loss: 1.2325760126113892\n",
      "Iteration 1563, Loss: 1.2312445640563965\n",
      "Iteration 1564, Loss: 1.229910969734192\n",
      "Iteration 1565, Loss: 1.228574514389038\n",
      "Iteration 1566, Loss: 1.2272357940673828\n",
      "Iteration 1567, Loss: 1.2258943319320679\n",
      "Iteration 1568, Loss: 1.2245502471923828\n",
      "Iteration 1569, Loss: 1.2232038974761963\n",
      "Iteration 1570, Loss: 1.2218546867370605\n",
      "Iteration 1571, Loss: 1.2205032110214233\n",
      "Iteration 1572, Loss: 1.2191489934921265\n",
      "Iteration 1573, Loss: 1.2177923917770386\n",
      "Iteration 1574, Loss: 1.216432809829712\n",
      "Iteration 1575, Loss: 1.2150713205337524\n",
      "Iteration 1576, Loss: 1.213706374168396\n",
      "Iteration 1577, Loss: 1.212339162826538\n",
      "Iteration 1578, Loss: 1.2109694480895996\n",
      "Iteration 1579, Loss: 1.2095969915390015\n",
      "Iteration 1580, Loss: 1.2082219123840332\n",
      "Iteration 1581, Loss: 1.2068438529968262\n",
      "Iteration 1582, Loss: 1.2054634094238281\n",
      "Iteration 1583, Loss: 1.2040798664093018\n",
      "Iteration 1584, Loss: 1.2026939392089844\n",
      "Iteration 1585, Loss: 1.201305627822876\n",
      "Iteration 1586, Loss: 1.199913501739502\n",
      "Iteration 1587, Loss: 1.198519229888916\n",
      "Iteration 1588, Loss: 1.1971224546432495\n",
      "Iteration 1589, Loss: 1.1957224607467651\n",
      "Iteration 1590, Loss: 1.194319725036621\n",
      "Iteration 1591, Loss: 1.1929141283035278\n",
      "Iteration 1592, Loss: 1.1915059089660645\n",
      "Iteration 1593, Loss: 1.1900944709777832\n",
      "Iteration 1594, Loss: 1.1886807680130005\n",
      "Iteration 1595, Loss: 1.1872638463974\n",
      "Iteration 1596, Loss: 1.185843825340271\n",
      "Iteration 1597, Loss: 1.1844210624694824\n",
      "Iteration 1598, Loss: 1.182995319366455\n",
      "Iteration 1599, Loss: 1.1815664768218994\n",
      "Iteration 1600, Loss: 1.180134892463684\n",
      "Iteration 1601, Loss: 1.1787002086639404\n",
      "Iteration 1602, Loss: 1.1772626638412476\n",
      "Iteration 1603, Loss: 1.1758222579956055\n",
      "Iteration 1604, Loss: 1.1743783950805664\n",
      "Iteration 1605, Loss: 1.1729316711425781\n",
      "Iteration 1606, Loss: 1.171481966972351\n",
      "Iteration 1607, Loss: 1.1700295209884644\n",
      "Iteration 1608, Loss: 1.1685733795166016\n",
      "Iteration 1609, Loss: 1.167114496231079\n",
      "Iteration 1610, Loss: 1.1656522750854492\n",
      "Iteration 1611, Loss: 1.164186954498291\n",
      "Iteration 1612, Loss: 1.1627187728881836\n",
      "Iteration 1613, Loss: 1.1612472534179688\n",
      "Iteration 1614, Loss: 1.1597727537155151\n",
      "Iteration 1615, Loss: 1.158294677734375\n",
      "Iteration 1616, Loss: 1.156813621520996\n",
      "Iteration 1617, Loss: 1.1553294658660889\n",
      "Iteration 1618, Loss: 1.1538413763046265\n",
      "Iteration 1619, Loss: 1.152350664138794\n",
      "Iteration 1620, Loss: 1.1508567333221436\n",
      "Iteration 1621, Loss: 1.1493597030639648\n",
      "Iteration 1622, Loss: 1.147858738899231\n",
      "Iteration 1623, Loss: 1.1463549137115479\n",
      "Iteration 1624, Loss: 1.1448473930358887\n",
      "Iteration 1625, Loss: 1.1433368921279907\n",
      "Iteration 1626, Loss: 1.1418226957321167\n",
      "Iteration 1627, Loss: 1.1403050422668457\n",
      "Iteration 1628, Loss: 1.1387836933135986\n",
      "Iteration 1629, Loss: 1.137259602546692\n",
      "Iteration 1630, Loss: 1.1357312202453613\n",
      "Iteration 1631, Loss: 1.1341997385025024\n",
      "Iteration 1632, Loss: 1.1326651573181152\n",
      "Iteration 1633, Loss: 1.1311266422271729\n",
      "Iteration 1634, Loss: 1.1295846700668335\n",
      "Iteration 1635, Loss: 1.128039002418518\n",
      "Iteration 1636, Loss: 1.1264901161193848\n",
      "Iteration 1637, Loss: 1.1249372959136963\n",
      "Iteration 1638, Loss: 1.1233808994293213\n",
      "Iteration 1639, Loss: 1.1218204498291016\n",
      "Iteration 1640, Loss: 1.1202571392059326\n",
      "Iteration 1641, Loss: 1.118689775466919\n",
      "Iteration 1642, Loss: 1.11711847782135\n",
      "Iteration 1643, Loss: 1.1155437231063843\n",
      "Iteration 1644, Loss: 1.1139655113220215\n",
      "Iteration 1645, Loss: 1.1123828887939453\n",
      "Iteration 1646, Loss: 1.1107971668243408\n",
      "Iteration 1647, Loss: 1.1092071533203125\n",
      "Iteration 1648, Loss: 1.10761296749115\n",
      "Iteration 1649, Loss: 1.1060161590576172\n",
      "Iteration 1650, Loss: 1.104414463043213\n",
      "Iteration 1651, Loss: 1.1028094291687012\n",
      "Iteration 1652, Loss: 1.1012003421783447\n",
      "Iteration 1653, Loss: 1.0995867252349854\n",
      "Iteration 1654, Loss: 1.0979695320129395\n",
      "Iteration 1655, Loss: 1.0963490009307861\n",
      "Iteration 1656, Loss: 1.0947234630584717\n",
      "Iteration 1657, Loss: 1.0930944681167603\n",
      "Iteration 1658, Loss: 1.091461181640625\n",
      "Iteration 1659, Loss: 1.0898239612579346\n",
      "Iteration 1660, Loss: 1.0881824493408203\n",
      "Iteration 1661, Loss: 1.0865371227264404\n",
      "Iteration 1662, Loss: 1.0848875045776367\n",
      "Iteration 1663, Loss: 1.0832337141036987\n",
      "Iteration 1664, Loss: 1.0815753936767578\n",
      "Iteration 1665, Loss: 1.0799130201339722\n",
      "Iteration 1666, Loss: 1.078246831893921\n",
      "Iteration 1667, Loss: 1.0765761137008667\n",
      "Iteration 1668, Loss: 1.0749009847640991\n",
      "Iteration 1669, Loss: 1.0732215642929077\n",
      "Iteration 1670, Loss: 1.071537733078003\n",
      "Iteration 1671, Loss: 1.0698496103286743\n",
      "Iteration 1672, Loss: 1.0681570768356323\n",
      "Iteration 1673, Loss: 1.0664600133895874\n",
      "Iteration 1674, Loss: 1.064758539199829\n",
      "Iteration 1675, Loss: 1.0630526542663574\n",
      "Iteration 1676, Loss: 1.0613422393798828\n",
      "Iteration 1677, Loss: 1.0596271753311157\n",
      "Iteration 1678, Loss: 1.0579077005386353\n",
      "Iteration 1679, Loss: 1.0561833381652832\n",
      "Iteration 1680, Loss: 1.0544543266296387\n",
      "Iteration 1681, Loss: 1.0527210235595703\n",
      "Iteration 1682, Loss: 1.0509824752807617\n",
      "Iteration 1683, Loss: 1.0492397546768188\n",
      "Iteration 1684, Loss: 1.0474920272827148\n",
      "Iteration 1685, Loss: 1.0457394123077393\n",
      "Iteration 1686, Loss: 1.0439820289611816\n",
      "Iteration 1687, Loss: 1.042220115661621\n",
      "Iteration 1688, Loss: 1.0404529571533203\n",
      "Iteration 1689, Loss: 1.0386812686920166\n",
      "Iteration 1690, Loss: 1.0369045734405518\n",
      "Iteration 1691, Loss: 1.0351228713989258\n",
      "Iteration 1692, Loss: 1.0333364009857178\n",
      "Iteration 1693, Loss: 1.03154456615448\n",
      "Iteration 1694, Loss: 1.0297478437423706\n",
      "Iteration 1695, Loss: 1.0279459953308105\n",
      "Iteration 1696, Loss: 1.0261386632919312\n",
      "Iteration 1697, Loss: 1.0243268013000488\n",
      "Iteration 1698, Loss: 1.0225090980529785\n",
      "Iteration 1699, Loss: 1.020686388015747\n",
      "Iteration 1700, Loss: 1.0188586711883545\n",
      "Iteration 1701, Loss: 1.0170254707336426\n",
      "Iteration 1702, Loss: 1.0151866674423218\n",
      "Iteration 1703, Loss: 1.013343095779419\n",
      "Iteration 1704, Loss: 1.0114939212799072\n",
      "Iteration 1705, Loss: 1.009639024734497\n",
      "Iteration 1706, Loss: 1.0077787637710571\n",
      "Iteration 1707, Loss: 1.0059130191802979\n",
      "Iteration 1708, Loss: 1.0040415525436401\n",
      "Iteration 1709, Loss: 1.0021648406982422\n",
      "Iteration 1710, Loss: 1.0002821683883667\n",
      "Iteration 1711, Loss: 0.9983940124511719\n",
      "Iteration 1712, Loss: 0.9964999556541443\n",
      "Iteration 1713, Loss: 0.9946002960205078\n",
      "Iteration 1714, Loss: 0.9926950335502625\n",
      "Iteration 1715, Loss: 0.9907835721969604\n",
      "Iteration 1716, Loss: 0.9888663291931152\n",
      "Iteration 1717, Loss: 0.9869431853294373\n",
      "Iteration 1718, Loss: 0.9850141406059265\n",
      "Iteration 1719, Loss: 0.9830791354179382\n",
      "Iteration 1720, Loss: 0.9811379909515381\n",
      "Iteration 1721, Loss: 0.9791908264160156\n",
      "Iteration 1722, Loss: 0.9772377014160156\n",
      "Iteration 1723, Loss: 0.9752780795097351\n",
      "Iteration 1724, Loss: 0.9733126163482666\n",
      "Iteration 1725, Loss: 0.9713410139083862\n",
      "Iteration 1726, Loss: 0.9693622589111328\n",
      "Iteration 1727, Loss: 0.9673780798912048\n",
      "Iteration 1728, Loss: 0.9653870463371277\n",
      "Iteration 1729, Loss: 0.9633895754814148\n",
      "Iteration 1730, Loss: 0.9613858461380005\n",
      "Iteration 1731, Loss: 0.9593753218650818\n",
      "Iteration 1732, Loss: 0.9573582410812378\n",
      "Iteration 1733, Loss: 0.9553346633911133\n",
      "Iteration 1734, Loss: 0.9533044099807739\n",
      "Iteration 1735, Loss: 0.951267659664154\n",
      "Iteration 1736, Loss: 0.9492237567901611\n",
      "Iteration 1737, Loss: 0.9471733570098877\n",
      "Iteration 1738, Loss: 0.9451159834861755\n",
      "Iteration 1739, Loss: 0.9430514574050903\n",
      "Iteration 1740, Loss: 0.9409803152084351\n",
      "Iteration 1741, Loss: 0.9389017820358276\n",
      "Iteration 1742, Loss: 0.9368163347244263\n",
      "Iteration 1743, Loss: 0.9347231388092041\n",
      "Iteration 1744, Loss: 0.9326233863830566\n",
      "Iteration 1745, Loss: 0.9305164217948914\n",
      "Iteration 1746, Loss: 0.9284021854400635\n",
      "Iteration 1747, Loss: 0.9262802004814148\n",
      "Iteration 1748, Loss: 0.9241511225700378\n",
      "Iteration 1749, Loss: 0.9220142364501953\n",
      "Iteration 1750, Loss: 0.9198698997497559\n",
      "Iteration 1751, Loss: 0.9177183508872986\n",
      "Iteration 1752, Loss: 0.9155586957931519\n",
      "Iteration 1753, Loss: 0.9133917093276978\n",
      "Iteration 1754, Loss: 0.9112168550491333\n",
      "Iteration 1755, Loss: 0.909034252166748\n",
      "Iteration 1756, Loss: 0.906843364238739\n",
      "Iteration 1757, Loss: 0.9046446681022644\n",
      "Iteration 1758, Loss: 0.9024381041526794\n",
      "Iteration 1759, Loss: 0.9002229571342468\n",
      "Iteration 1760, Loss: 0.8980001211166382\n",
      "Iteration 1761, Loss: 0.8957688808441162\n",
      "Iteration 1762, Loss: 0.8935295343399048\n",
      "Iteration 1763, Loss: 0.8912814855575562\n",
      "Iteration 1764, Loss: 0.8890255689620972\n",
      "Iteration 1765, Loss: 0.8867606520652771\n",
      "Iteration 1766, Loss: 0.8844870924949646\n",
      "Iteration 1767, Loss: 0.8822051882743835\n",
      "Iteration 1768, Loss: 0.8799146413803101\n",
      "Iteration 1769, Loss: 0.8776149153709412\n",
      "Iteration 1770, Loss: 0.8753063082695007\n",
      "Iteration 1771, Loss: 0.8729890584945679\n",
      "Iteration 1772, Loss: 0.8706626296043396\n",
      "Iteration 1773, Loss: 0.8683270812034607\n",
      "Iteration 1774, Loss: 0.865982711315155\n",
      "Iteration 1775, Loss: 0.8636282682418823\n",
      "Iteration 1776, Loss: 0.8612650632858276\n",
      "Iteration 1777, Loss: 0.8588924407958984\n",
      "Iteration 1778, Loss: 0.85651034116745\n",
      "Iteration 1779, Loss: 0.8541181087493896\n",
      "Iteration 1780, Loss: 0.8517169952392578\n",
      "Iteration 1781, Loss: 0.8493058681488037\n",
      "Iteration 1782, Loss: 0.8468847274780273\n",
      "Iteration 1783, Loss: 0.8444535732269287\n",
      "Iteration 1784, Loss: 0.8420127630233765\n",
      "Iteration 1785, Loss: 0.8395617008209229\n",
      "Iteration 1786, Loss: 0.8371002674102783\n",
      "Iteration 1787, Loss: 0.8346285223960876\n",
      "Iteration 1788, Loss: 0.8321466445922852\n",
      "Iteration 1789, Loss: 0.8296539187431335\n",
      "Iteration 1790, Loss: 0.827150821685791\n",
      "Iteration 1791, Loss: 0.8246371150016785\n",
      "Iteration 1792, Loss: 0.8221127390861511\n",
      "Iteration 1793, Loss: 0.8195770978927612\n",
      "Iteration 1794, Loss: 0.8170307874679565\n",
      "Iteration 1795, Loss: 0.8144730925559998\n",
      "Iteration 1796, Loss: 0.8119044303894043\n",
      "Iteration 1797, Loss: 0.8093244433403015\n",
      "Iteration 1798, Loss: 0.8067330718040466\n",
      "Iteration 1799, Loss: 0.8041300177574158\n",
      "Iteration 1800, Loss: 0.8015153408050537\n",
      "Iteration 1801, Loss: 0.7988886833190918\n",
      "Iteration 1802, Loss: 0.7962508201599121\n",
      "Iteration 1803, Loss: 0.7936005592346191\n",
      "Iteration 1804, Loss: 0.7909382581710815\n",
      "Iteration 1805, Loss: 0.788263738155365\n",
      "Iteration 1806, Loss: 0.7855771780014038\n",
      "Iteration 1807, Loss: 0.7828776836395264\n",
      "Iteration 1808, Loss: 0.7801657915115356\n",
      "Iteration 1809, Loss: 0.777441680431366\n",
      "Iteration 1810, Loss: 0.7747039794921875\n",
      "Iteration 1811, Loss: 0.7719535827636719\n",
      "Iteration 1812, Loss: 0.7691901922225952\n",
      "Iteration 1813, Loss: 0.7664132118225098\n",
      "Iteration 1814, Loss: 0.7636231184005737\n",
      "Iteration 1815, Loss: 0.760819673538208\n",
      "Iteration 1816, Loss: 0.7580022811889648\n",
      "Iteration 1817, Loss: 0.7551710605621338\n",
      "Iteration 1818, Loss: 0.7523261308670044\n",
      "Iteration 1819, Loss: 0.7494670748710632\n",
      "Iteration 1820, Loss: 0.7465936541557312\n",
      "Iteration 1821, Loss: 0.743706226348877\n",
      "Iteration 1822, Loss: 0.7408040761947632\n",
      "Iteration 1823, Loss: 0.7378870844841003\n",
      "Iteration 1824, Loss: 0.7349551916122437\n",
      "Iteration 1825, Loss: 0.7320083379745483\n",
      "Iteration 1826, Loss: 0.7290463447570801\n",
      "Iteration 1827, Loss: 0.7260688543319702\n",
      "Iteration 1828, Loss: 0.7230759859085083\n",
      "Iteration 1829, Loss: 0.7200671434402466\n",
      "Iteration 1830, Loss: 0.7170425653457642\n",
      "Iteration 1831, Loss: 0.7140018939971924\n",
      "Iteration 1832, Loss: 0.7109452486038208\n",
      "Iteration 1833, Loss: 0.7078721523284912\n",
      "Iteration 1834, Loss: 0.7047823667526245\n",
      "Iteration 1835, Loss: 0.7016756534576416\n",
      "Iteration 1836, Loss: 0.6985520124435425\n",
      "Iteration 1837, Loss: 0.6954111456871033\n",
      "Iteration 1838, Loss: 0.6922531127929688\n",
      "Iteration 1839, Loss: 0.6890770792961121\n",
      "Iteration 1840, Loss: 0.6858832240104675\n",
      "Iteration 1841, Loss: 0.6826716661453247\n",
      "Iteration 1842, Loss: 0.6794416308403015\n",
      "Iteration 1843, Loss: 0.6761934757232666\n",
      "Iteration 1844, Loss: 0.6729263663291931\n",
      "Iteration 1845, Loss: 0.6696407198905945\n",
      "Iteration 1846, Loss: 0.6663358211517334\n",
      "Iteration 1847, Loss: 0.6630113124847412\n",
      "Iteration 1848, Loss: 0.6596674919128418\n",
      "Iteration 1849, Loss: 0.6563038229942322\n",
      "Iteration 1850, Loss: 0.6529198884963989\n",
      "Iteration 1851, Loss: 0.6495153903961182\n",
      "Iteration 1852, Loss: 0.6460905075073242\n",
      "Iteration 1853, Loss: 0.6426448822021484\n",
      "Iteration 1854, Loss: 0.6391780376434326\n",
      "Iteration 1855, Loss: 0.6356897354125977\n",
      "Iteration 1856, Loss: 0.6321799755096436\n",
      "Iteration 1857, Loss: 0.6286478042602539\n",
      "Iteration 1858, Loss: 0.625093400478363\n",
      "Iteration 1859, Loss: 0.6215164065361023\n",
      "Iteration 1860, Loss: 0.6179168224334717\n",
      "Iteration 1861, Loss: 0.6142944097518921\n",
      "Iteration 1862, Loss: 0.6106480360031128\n",
      "Iteration 1863, Loss: 0.6069779992103577\n",
      "Iteration 1864, Loss: 0.6032835841178894\n",
      "Iteration 1865, Loss: 0.5995649099349976\n",
      "Iteration 1866, Loss: 0.5958213210105896\n",
      "Iteration 1867, Loss: 0.5920529365539551\n",
      "Iteration 1868, Loss: 0.588259220123291\n",
      "Iteration 1869, Loss: 0.5844395160675049\n",
      "Iteration 1870, Loss: 0.580593466758728\n",
      "Iteration 1871, Loss: 0.57672119140625\n",
      "Iteration 1872, Loss: 0.5728214979171753\n",
      "Iteration 1873, Loss: 0.5688945055007935\n",
      "Iteration 1874, Loss: 0.5649399161338806\n",
      "Iteration 1875, Loss: 0.5609573125839233\n",
      "Iteration 1876, Loss: 0.5569462776184082\n",
      "Iteration 1877, Loss: 0.5529060363769531\n",
      "Iteration 1878, Loss: 0.5488365292549133\n",
      "Iteration 1879, Loss: 0.5447369813919067\n",
      "Iteration 1880, Loss: 0.5406073927879333\n",
      "Iteration 1881, Loss: 0.5364471673965454\n",
      "Iteration 1882, Loss: 0.5322553515434265\n",
      "Iteration 1883, Loss: 0.5280324220657349\n",
      "Iteration 1884, Loss: 0.5237770080566406\n",
      "Iteration 1885, Loss: 0.5194889903068542\n",
      "Iteration 1886, Loss: 0.5151678323745728\n",
      "Iteration 1887, Loss: 0.5108128786087036\n",
      "Iteration 1888, Loss: 0.5064235925674438\n",
      "Iteration 1889, Loss: 0.5020000338554382\n",
      "Iteration 1890, Loss: 0.4975407123565674\n",
      "Iteration 1891, Loss: 0.49304577708244324\n",
      "Iteration 1892, Loss: 0.4885144829750061\n",
      "Iteration 1893, Loss: 0.48394569754600525\n",
      "Iteration 1894, Loss: 0.4793400466442108\n",
      "Iteration 1895, Loss: 0.47469544410705566\n",
      "Iteration 1896, Loss: 0.4700124263763428\n",
      "Iteration 1897, Loss: 0.4652896821498871\n",
      "Iteration 1898, Loss: 0.46052655577659607\n",
      "Iteration 1899, Loss: 0.4557228982448578\n",
      "Iteration 1900, Loss: 0.45087742805480957\n",
      "Iteration 1901, Loss: 0.44598984718322754\n",
      "Iteration 1902, Loss: 0.44105929136276245\n",
      "Iteration 1903, Loss: 0.4360853135585785\n",
      "Iteration 1904, Loss: 0.4310663938522339\n",
      "Iteration 1905, Loss: 0.42600297927856445\n",
      "Iteration 1906, Loss: 0.420893132686615\n",
      "Iteration 1907, Loss: 0.4157366454601288\n",
      "Iteration 1908, Loss: 0.4105329215526581\n",
      "Iteration 1909, Loss: 0.4052806794643402\n",
      "Iteration 1910, Loss: 0.3999793231487274\n",
      "Iteration 1911, Loss: 0.39462780952453613\n",
      "Iteration 1912, Loss: 0.3892258107662201\n",
      "Iteration 1913, Loss: 0.38377195596694946\n",
      "Iteration 1914, Loss: 0.3782653212547302\n",
      "Iteration 1915, Loss: 0.37270545959472656\n",
      "Iteration 1916, Loss: 0.36709094047546387\n",
      "Iteration 1917, Loss: 0.3614211678504944\n",
      "Iteration 1918, Loss: 0.3556954562664032\n",
      "Iteration 1919, Loss: 0.34991252422332764\n",
      "Iteration 1920, Loss: 0.34407150745391846\n",
      "Iteration 1921, Loss: 0.33817124366760254\n",
      "Iteration 1922, Loss: 0.332211434841156\n",
      "Iteration 1923, Loss: 0.3261910080909729\n",
      "Iteration 1924, Loss: 0.3201087713241577\n",
      "Iteration 1925, Loss: 0.3139643371105194\n",
      "Iteration 1926, Loss: 0.30775654315948486\n",
      "Iteration 1927, Loss: 0.3014846742153168\n",
      "Iteration 1928, Loss: 0.29514822363853455\n",
      "Iteration 1929, Loss: 0.2887458801269531\n",
      "Iteration 1930, Loss: 0.2822781205177307\n",
      "Iteration 1931, Loss: 0.27574363350868225\n",
      "Iteration 1932, Loss: 0.2691422700881958\n",
      "Iteration 1933, Loss: 0.2624738812446594\n",
      "Iteration 1934, Loss: 0.2557385563850403\n",
      "Iteration 1935, Loss: 0.24893668293952942\n",
      "Iteration 1936, Loss: 0.2420678585767746\n",
      "Iteration 1937, Loss: 0.23513418436050415\n",
      "Iteration 1938, Loss: 0.22813498973846436\n",
      "Iteration 1939, Loss: 0.22107402980327606\n",
      "Iteration 1940, Loss: 0.21395182609558105\n",
      "Iteration 1941, Loss: 0.20677241683006287\n",
      "Iteration 1942, Loss: 0.1995382308959961\n",
      "Iteration 1943, Loss: 0.19225531816482544\n",
      "Iteration 1944, Loss: 0.18492889404296875\n",
      "Iteration 1945, Loss: 0.17756544053554535\n",
      "Iteration 1946, Loss: 0.170175239443779\n",
      "Iteration 1947, Loss: 0.16276812553405762\n",
      "Iteration 1948, Loss: 0.15535877645015717\n",
      "Iteration 1949, Loss: 0.14796245098114014\n",
      "Iteration 1950, Loss: 0.1406007707118988\n",
      "Iteration 1951, Loss: 0.13329604268074036\n",
      "Iteration 1952, Loss: 0.1260780692100525\n",
      "Iteration 1953, Loss: 0.11898128688335419\n",
      "Iteration 1954, Loss: 0.11204412579536438\n",
      "Iteration 1955, Loss: 0.10531207174062729\n",
      "Iteration 1956, Loss: 0.09883499145507812\n",
      "Iteration 1957, Loss: 0.09266635030508041\n",
      "Iteration 1958, Loss: 0.08685898035764694\n",
      "Iteration 1959, Loss: 0.08146412670612335\n",
      "Iteration 1960, Loss: 0.07652166485786438\n",
      "Iteration 1961, Loss: 0.07205850630998611\n",
      "Iteration 1962, Loss: 0.06808318942785263\n",
      "Iteration 1963, Loss: 0.06458418071269989\n",
      "Iteration 1964, Loss: 0.06153231859207153\n",
      "Iteration 1965, Loss: 0.05888363718986511\n",
      "Iteration 1966, Loss: 0.05658585950732231\n",
      "Iteration 1967, Loss: 0.05458451434969902\n",
      "Iteration 1968, Loss: 0.05386132746934891\n",
      "Iteration 1969, Loss: 0.05414098501205444\n",
      "Iteration 1970, Loss: 0.054180972278118134\n",
      "Iteration 1971, Loss: 0.0537857711315155\n",
      "Iteration 1972, Loss: 0.05444929003715515\n",
      "Iteration 1973, Loss: 0.053611546754837036\n",
      "Iteration 1974, Loss: 0.05454271659255028\n",
      "Iteration 1975, Loss: 0.05367954820394516\n",
      "Iteration 1976, Loss: 0.05441763252019882\n",
      "Iteration 1977, Loss: 0.05382373183965683\n",
      "Iteration 1978, Loss: 0.0542362742125988\n",
      "Iteration 1979, Loss: 0.05398353934288025\n",
      "Iteration 1980, Loss: 0.0540611557662487\n",
      "Iteration 1981, Loss: 0.05412868782877922\n",
      "Iteration 1982, Loss: 0.053941331803798676\n",
      "Iteration 1983, Loss: 0.05422261357307434\n",
      "Iteration 1984, Loss: 0.05391956493258476\n",
      "Iteration 1985, Loss: 0.05422380194067955\n",
      "Iteration 1986, Loss: 0.053989049047231674\n",
      "Iteration 1987, Loss: 0.05413752421736717\n",
      "Iteration 1988, Loss: 0.05409596115350723\n",
      "Iteration 1989, Loss: 0.054024647921323776\n",
      "Iteration 1990, Loss: 0.05419537425041199\n",
      "Iteration 1991, Loss: 0.05393455550074577\n",
      "Iteration 1992, Loss: 0.05426079034805298\n",
      "Iteration 1993, Loss: 0.05388907715678215\n",
      "Iteration 1994, Loss: 0.054281096905469894\n",
      "Iteration 1995, Loss: 0.05388779565691948\n",
      "Iteration 1996, Loss: 0.054262012243270874\n",
      "Iteration 1997, Loss: 0.05391722917556763\n",
      "Iteration 1998, Loss: 0.054219938814640045\n",
      "Iteration 1999, Loss: 0.05396057292819023\n",
      "Iteration 2000, Loss: 0.05417311191558838\n",
      "Iteration 2001, Loss: 0.05400277301669121\n",
      "Iteration 2002, Loss: 0.05413631349802017\n",
      "Iteration 2003, Loss: 0.05403223633766174\n",
      "Iteration 2004, Loss: 0.054118718951940536\n",
      "Iteration 2005, Loss: 0.05404273793101311\n",
      "Iteration 2006, Loss: 0.05412144958972931\n",
      "Iteration 2007, Loss: 0.054034553468227386\n",
      "Iteration 2008, Loss: 0.054138652980327606\n",
      "Iteration 2009, Loss: 0.054014772176742554\n",
      "Iteration 2010, Loss: 0.054161619395017624\n",
      "Iteration 2011, Loss: 0.05399229750037193\n",
      "Iteration 2012, Loss: 0.05418188497424126\n",
      "Iteration 2013, Loss: 0.05397512763738632\n",
      "Iteration 2014, Loss: 0.054193802177906036\n",
      "Iteration 2015, Loss: 0.053966980427503586\n",
      "Iteration 2016, Loss: 0.05419626086950302\n",
      "Iteration 2017, Loss: 0.05396793782711029\n",
      "Iteration 2018, Loss: 0.054190874099731445\n",
      "Iteration 2019, Loss: 0.053975146263837814\n",
      "Iteration 2020, Loss: 0.05418100953102112\n",
      "Iteration 2021, Loss: 0.05398504436016083\n",
      "Iteration 2022, Loss: 0.05417078360915184\n",
      "Iteration 2023, Loss: 0.05399443954229355\n",
      "Iteration 2024, Loss: 0.05416324734687805\n",
      "Iteration 2025, Loss: 0.05400001257658005\n",
      "Iteration 2026, Loss: 0.054160457104444504\n",
      "Iteration 2027, Loss: 0.054001323878765106\n",
      "Iteration 2028, Loss: 0.054161570966243744\n",
      "Iteration 2029, Loss: 0.05399898812174797\n",
      "Iteration 2030, Loss: 0.05416563153266907\n",
      "Iteration 2031, Loss: 0.05399467796087265\n",
      "Iteration 2032, Loss: 0.05417054891586304\n",
      "Iteration 2033, Loss: 0.05398987978696823\n",
      "Iteration 2034, Loss: 0.05417455732822418\n",
      "Iteration 2035, Loss: 0.053986430168151855\n",
      "Iteration 2036, Loss: 0.054176997393369675\n",
      "Iteration 2037, Loss: 0.053984783589839935\n",
      "Iteration 2038, Loss: 0.054177455604076385\n",
      "Iteration 2039, Loss: 0.05398518964648247\n",
      "Iteration 2040, Loss: 0.0541759729385376\n",
      "Iteration 2041, Loss: 0.05398699641227722\n",
      "Iteration 2042, Loss: 0.054173704236745834\n",
      "Iteration 2043, Loss: 0.05398936569690704\n",
      "Iteration 2044, Loss: 0.05417140573263168\n",
      "Iteration 2045, Loss: 0.053991373628377914\n",
      "Iteration 2046, Loss: 0.054169826209545135\n",
      "Iteration 2047, Loss: 0.05399243161082268\n",
      "Iteration 2048, Loss: 0.054169438779354095\n",
      "Iteration 2049, Loss: 0.05399268865585327\n",
      "Iteration 2050, Loss: 0.05416988581418991\n",
      "Iteration 2051, Loss: 0.05399186536669731\n",
      "Iteration 2052, Loss: 0.05417092889547348\n",
      "Iteration 2053, Loss: 0.053990721702575684\n",
      "Iteration 2054, Loss: 0.05417199060320854\n",
      "Iteration 2055, Loss: 0.05398958921432495\n",
      "Iteration 2056, Loss: 0.0541728213429451\n",
      "Iteration 2057, Loss: 0.053989045321941376\n",
      "Iteration 2058, Loss: 0.05417313426733017\n",
      "Iteration 2059, Loss: 0.05398900434374809\n",
      "Iteration 2060, Loss: 0.054173003882169724\n",
      "Iteration 2061, Loss: 0.05398939177393913\n",
      "Iteration 2062, Loss: 0.05417240783572197\n",
      "Iteration 2063, Loss: 0.05398990958929062\n",
      "Iteration 2064, Loss: 0.054171930998563766\n",
      "Iteration 2065, Loss: 0.053990378975868225\n",
      "Iteration 2066, Loss: 0.05417146533727646\n",
      "Iteration 2067, Loss: 0.05399131774902344\n",
      "Iteration 2068, Loss: 0.05417138338088989\n",
      "Iteration 2069, Loss: 0.05399123951792717\n",
      "Iteration 2070, Loss: 0.05417166277766228\n",
      "Iteration 2071, Loss: 0.053990885615348816\n",
      "Iteration 2072, Loss: 0.054172467440366745\n",
      "Iteration 2073, Loss: 0.053990304470062256\n",
      "Iteration 2074, Loss: 0.054173003882169724\n",
      "Iteration 2075, Loss: 0.053990066051483154\n",
      "Iteration 2076, Loss: 0.054173171520233154\n",
      "Iteration 2077, Loss: 0.05398997664451599\n",
      "Iteration 2078, Loss: 0.0541730634868145\n",
      "Iteration 2079, Loss: 0.053989868611097336\n",
      "Iteration 2080, Loss: 0.054172903299331665\n",
      "Iteration 2081, Loss: 0.05399010330438614\n",
      "Iteration 2082, Loss: 0.05417273938655853\n",
      "Iteration 2083, Loss: 0.053990334272384644\n",
      "Iteration 2084, Loss: 0.05417265743017197\n",
      "Iteration 2085, Loss: 0.05399038642644882\n",
      "Iteration 2086, Loss: 0.0541725754737854\n",
      "Iteration 2087, Loss: 0.05399038642644882\n",
      "Iteration 2088, Loss: 0.054172731935977936\n",
      "Iteration 2089, Loss: 0.05399042367935181\n",
      "Iteration 2090, Loss: 0.05417276546359062\n",
      "Iteration 2091, Loss: 0.05399037525057793\n",
      "Iteration 2092, Loss: 0.05417288467288017\n",
      "Iteration 2093, Loss: 0.05399030074477196\n",
      "Iteration 2094, Loss: 0.05417289584875107\n",
      "Iteration 2095, Loss: 0.053990330547094345\n",
      "Iteration 2096, Loss: 0.054173003882169724\n",
      "Iteration 2097, Loss: 0.05399010702967644\n",
      "Iteration 2098, Loss: 0.054173003882169724\n",
      "Iteration 2099, Loss: 0.053990256041288376\n",
      "Iteration 2100, Loss: 0.054172735661268234\n",
      "Iteration 2101, Loss: 0.053990304470062256\n",
      "Iteration 2102, Loss: 0.05417269095778465\n",
      "Iteration 2103, Loss: 0.05399038642644882\n",
      "Iteration 2104, Loss: 0.054172586649656296\n",
      "Iteration 2105, Loss: 0.05399053543806076\n",
      "Iteration 2106, Loss: 0.05417277663946152\n",
      "Iteration 2107, Loss: 0.05399014800786972\n",
      "Iteration 2108, Loss: 0.05417293310165405\n",
      "Iteration 2109, Loss: 0.05399029701948166\n",
      "Iteration 2110, Loss: 0.05417308211326599\n",
      "Iteration 2111, Loss: 0.053990211337804794\n",
      "Iteration 2112, Loss: 0.054173052310943604\n",
      "Iteration 2113, Loss: 0.053990140557289124\n",
      "Iteration 2114, Loss: 0.05417312681674957\n",
      "Iteration 2115, Loss: 0.05398991331458092\n",
      "Iteration 2116, Loss: 0.05417294055223465\n",
      "Iteration 2117, Loss: 0.05399010702967644\n",
      "Iteration 2118, Loss: 0.05417288839817047\n",
      "Iteration 2119, Loss: 0.05399026721715927\n",
      "Iteration 2120, Loss: 0.054172661155462265\n",
      "Iteration 2121, Loss: 0.053990304470062256\n",
      "Iteration 2122, Loss: 0.0541725754737854\n",
      "Iteration 2123, Loss: 0.05399050563573837\n",
      "Iteration 2124, Loss: 0.0541725754737854\n",
      "Iteration 2125, Loss: 0.05398976057767868\n",
      "Iteration 2126, Loss: 0.054172735661268234\n",
      "Iteration 2127, Loss: 0.05398974567651749\n",
      "Iteration 2128, Loss: 0.05417361110448837\n",
      "Iteration 2129, Loss: 0.053989313542842865\n",
      "Iteration 2130, Loss: 0.05417368561029434\n",
      "Iteration 2131, Loss: 0.05398954078555107\n",
      "Iteration 2132, Loss: 0.05417349189519882\n",
      "Iteration 2133, Loss: 0.05398958548903465\n",
      "Iteration 2134, Loss: 0.05417332798242569\n",
      "Iteration 2135, Loss: 0.05398979038000107\n",
      "Iteration 2136, Loss: 0.0541728213429451\n",
      "Iteration 2137, Loss: 0.053990185260772705\n",
      "Iteration 2138, Loss: 0.05417250096797943\n",
      "Iteration 2139, Loss: 0.05399049445986748\n",
      "Iteration 2140, Loss: 0.05417230725288391\n",
      "Iteration 2141, Loss: 0.05399053543806076\n",
      "Iteration 2142, Loss: 0.05417249724268913\n",
      "Iteration 2143, Loss: 0.053990572690963745\n",
      "Iteration 2144, Loss: 0.054172538220882416\n",
      "Iteration 2145, Loss: 0.05399042367935181\n",
      "Iteration 2146, Loss: 0.0541725754737854\n",
      "Iteration 2147, Loss: 0.053990453481674194\n",
      "Iteration 2148, Loss: 0.0541725754737854\n",
      "Iteration 2149, Loss: 0.05399037525057793\n",
      "Iteration 2150, Loss: 0.05417277663946152\n",
      "Iteration 2151, Loss: 0.053990256041288376\n",
      "Iteration 2152, Loss: 0.05417289584875107\n",
      "Iteration 2153, Loss: 0.05399010330438614\n",
      "Iteration 2154, Loss: 0.05417309328913689\n",
      "Iteration 2155, Loss: 0.05399005860090256\n",
      "Iteration 2156, Loss: 0.054173052310943604\n",
      "Iteration 2157, Loss: 0.05398993939161301\n",
      "Iteration 2158, Loss: 0.054173171520233154\n",
      "Iteration 2159, Loss: 0.05398993939161301\n",
      "Iteration 2160, Loss: 0.05417320132255554\n",
      "Iteration 2161, Loss: 0.05398982763290405\n",
      "Iteration 2162, Loss: 0.05417286604642868\n",
      "Iteration 2163, Loss: 0.053989291191101074\n",
      "Iteration 2164, Loss: 0.054172810167074203\n",
      "Iteration 2165, Loss: 0.05398957058787346\n",
      "Iteration 2166, Loss: 0.05417250096797943\n",
      "Iteration 2167, Loss: 0.05398976057767868\n",
      "Iteration 2168, Loss: 0.0541718415915966\n",
      "Iteration 2169, Loss: 0.053989849984645844\n",
      "Iteration 2170, Loss: 0.0541716143488884\n",
      "Iteration 2171, Loss: 0.05399007722735405\n",
      "Iteration 2172, Loss: 0.054171688854694366\n",
      "Iteration 2173, Loss: 0.05398983880877495\n",
      "Iteration 2174, Loss: 0.054171957075595856\n",
      "Iteration 2175, Loss: 0.053989797830581665\n",
      "Iteration 2176, Loss: 0.05417211353778839\n",
      "Iteration 2177, Loss: 0.053989484906196594\n",
      "Iteration 2178, Loss: 0.05417223274707794\n",
      "Iteration 2179, Loss: 0.05398936569690704\n",
      "Iteration 2180, Loss: 0.054172348231077194\n",
      "Iteration 2181, Loss: 0.05398925393819809\n",
      "Iteration 2182, Loss: 0.05417242646217346\n",
      "Iteration 2183, Loss: 0.05398944020271301\n",
      "Iteration 2184, Loss: 0.05417222902178764\n",
      "Iteration 2185, Loss: 0.053989481180906296\n",
      "Iteration 2186, Loss: 0.054172150790691376\n",
      "Iteration 2187, Loss: 0.05398964136838913\n",
      "Iteration 2188, Loss: 0.054171882569789886\n",
      "Iteration 2189, Loss: 0.05398973077535629\n",
      "Iteration 2190, Loss: 0.05417172238230705\n",
      "Iteration 2191, Loss: 0.05398999899625778\n",
      "Iteration 2192, Loss: 0.05417168140411377\n",
      "Iteration 2193, Loss: 0.05399002879858017\n",
      "Iteration 2194, Loss: 0.0541718415915966\n",
      "Iteration 2195, Loss: 0.053989872336387634\n",
      "Iteration 2196, Loss: 0.054171960800886154\n",
      "Iteration 2197, Loss: 0.0539897195994854\n",
      "Iteration 2198, Loss: 0.054172154515981674\n",
      "Iteration 2199, Loss: 0.05398952215909958\n",
      "Iteration 2200, Loss: 0.05417212098836899\n",
      "Iteration 2201, Loss: 0.05398952215909958\n",
      "Iteration 2202, Loss: 0.05417218804359436\n",
      "Iteration 2203, Loss: 0.05398945137858391\n",
      "Iteration 2204, Loss: 0.05417212098836899\n",
      "Iteration 2205, Loss: 0.05398937314748764\n",
      "Iteration 2206, Loss: 0.054172154515981674\n",
      "Iteration 2207, Loss: 0.05398960039019585\n",
      "Iteration 2208, Loss: 0.05417212098836899\n",
      "Iteration 2209, Loss: 0.053989529609680176\n",
      "Iteration 2210, Loss: 0.054172154515981674\n",
      "Iteration 2211, Loss: 0.05398960039019585\n",
      "Iteration 2212, Loss: 0.05417212098836899\n",
      "Iteration 2213, Loss: 0.053989529609680176\n",
      "Iteration 2214, Loss: 0.05417203903198242\n",
      "Iteration 2215, Loss: 0.05398960039019585\n",
      "Iteration 2216, Loss: 0.05417196452617645\n",
      "Iteration 2217, Loss: 0.053989529609680176\n",
      "Iteration 2218, Loss: 0.05417203530669212\n",
      "Iteration 2219, Loss: 0.053989723324775696\n",
      "Iteration 2220, Loss: 0.0541718527674675\n",
      "Iteration 2221, Loss: 0.05398976057767868\n",
      "Iteration 2222, Loss: 0.054171882569789886\n",
      "Iteration 2223, Loss: 0.05398976057767868\n",
      "Iteration 2224, Loss: 0.054171882569789886\n",
      "Iteration 2225, Loss: 0.05398957058787346\n",
      "Iteration 2226, Loss: 0.05417196452617645\n",
      "Iteration 2227, Loss: 0.053989604115486145\n",
      "Iteration 2228, Loss: 0.05417212098836899\n",
      "Iteration 2229, Loss: 0.05398957058787346\n",
      "Iteration 2230, Loss: 0.05417212098836899\n",
      "Iteration 2231, Loss: 0.05398949235677719\n",
      "Iteration 2232, Loss: 0.05417222902178764\n",
      "Iteration 2233, Loss: 0.053989529609680176\n",
      "Iteration 2234, Loss: 0.05417226254940033\n",
      "Iteration 2235, Loss: 0.053989559412002563\n",
      "Iteration 2236, Loss: 0.054172150790691376\n",
      "Iteration 2237, Loss: 0.053989678621292114\n",
      "Iteration 2238, Loss: 0.054172150790691376\n",
      "Iteration 2239, Loss: 0.05398964136838913\n",
      "Iteration 2240, Loss: 0.05417218804359436\n",
      "Iteration 2241, Loss: 0.053989678621292114\n",
      "Iteration 2242, Loss: 0.05417218804359436\n",
      "Iteration 2243, Loss: 0.0539897195994854\n",
      "Iteration 2244, Loss: 0.05417212098836899\n",
      "Iteration 2245, Loss: 0.05398960039019585\n",
      "Iteration 2246, Loss: 0.05417212098836899\n",
      "Iteration 2247, Loss: 0.05398960039019585\n",
      "Iteration 2248, Loss: 0.05417212098836899\n",
      "Iteration 2249, Loss: 0.05398956686258316\n",
      "Iteration 2250, Loss: 0.05417218804359436\n",
      "Iteration 2251, Loss: 0.05398945137858391\n",
      "Iteration 2252, Loss: 0.05417203903198242\n",
      "Iteration 2253, Loss: 0.053989529609680176\n",
      "Iteration 2254, Loss: 0.0541718453168869\n",
      "Iteration 2255, Loss: 0.05398957058787346\n",
      "Iteration 2256, Loss: 0.0541718415915966\n",
      "Iteration 2257, Loss: 0.05398968979716301\n",
      "Iteration 2258, Loss: 0.054171882569789886\n",
      "Iteration 2259, Loss: 0.053989797830581665\n",
      "Iteration 2260, Loss: 0.054171960800886154\n",
      "Iteration 2261, Loss: 0.05398973077535629\n",
      "Iteration 2262, Loss: 0.054172031581401825\n",
      "Iteration 2263, Loss: 0.0539897195994854\n",
      "Iteration 2264, Loss: 0.05417211353778839\n",
      "Iteration 2265, Loss: 0.05398937687277794\n",
      "Iteration 2266, Loss: 0.054172318428754807\n",
      "Iteration 2267, Loss: 0.05398928374052048\n",
      "Iteration 2268, Loss: 0.05417235940694809\n",
      "Iteration 2269, Loss: 0.053989287465810776\n",
      "Iteration 2270, Loss: 0.054172467440366745\n",
      "Iteration 2271, Loss: 0.05398932844400406\n",
      "Iteration 2272, Loss: 0.05417215824127197\n",
      "Iteration 2273, Loss: 0.05398952588438988\n",
      "Iteration 2274, Loss: 0.054172031581401825\n",
      "Iteration 2275, Loss: 0.05398968979716301\n",
      "Iteration 2276, Loss: 0.054171692579984665\n",
      "Iteration 2277, Loss: 0.05398968979716301\n",
      "Iteration 2278, Loss: 0.05417165160179138\n",
      "Iteration 2279, Loss: 0.05398987978696823\n",
      "Iteration 2280, Loss: 0.05417180061340332\n",
      "Iteration 2281, Loss: 0.05398976057767868\n",
      "Iteration 2282, Loss: 0.05417199432849884\n",
      "Iteration 2283, Loss: 0.053989604115486145\n",
      "Iteration 2284, Loss: 0.05417222902178764\n",
      "Iteration 2285, Loss: 0.05398952215909958\n",
      "Iteration 2286, Loss: 0.05417238920927048\n",
      "Iteration 2287, Loss: 0.053989291191101074\n",
      "Iteration 2288, Loss: 0.05417250841856003\n",
      "Iteration 2289, Loss: 0.053989287465810776\n",
      "Iteration 2290, Loss: 0.054172318428754807\n",
      "Iteration 2291, Loss: 0.05398925766348839\n",
      "Iteration 2292, Loss: 0.05417212098836899\n",
      "Iteration 2293, Loss: 0.05398945137858391\n",
      "Iteration 2294, Loss: 0.054171960800886154\n",
      "Iteration 2295, Loss: 0.05398957058787346\n",
      "Iteration 2296, Loss: 0.05417200177907944\n",
      "Iteration 2297, Loss: 0.0539897195994854\n",
      "Iteration 2298, Loss: 0.05417203530669212\n",
      "Iteration 2299, Loss: 0.0539897195994854\n",
      "Iteration 2300, Loss: 0.054172080010175705\n",
      "Iteration 2301, Loss: 0.05398960039019585\n",
      "Iteration 2302, Loss: 0.05417215824127197\n",
      "Iteration 2303, Loss: 0.05398936569690704\n",
      "Iteration 2304, Loss: 0.05417219549417496\n",
      "Iteration 2305, Loss: 0.05398945137858391\n",
      "Iteration 2306, Loss: 0.05417218804359436\n",
      "Iteration 2307, Loss: 0.05398960039019585\n",
      "Iteration 2308, Loss: 0.05417215824127197\n",
      "Iteration 2309, Loss: 0.05398960039019585\n",
      "Iteration 2310, Loss: 0.05417218804359436\n",
      "Iteration 2311, Loss: 0.05398945137858391\n",
      "Iteration 2312, Loss: 0.054172080010175705\n",
      "Iteration 2313, Loss: 0.05398949235677719\n",
      "Iteration 2314, Loss: 0.05417218804359436\n",
      "Iteration 2315, Loss: 0.0539897084236145\n",
      "Iteration 2316, Loss: 0.05417218804359436\n",
      "Iteration 2317, Loss: 0.053989481180906296\n",
      "Iteration 2318, Loss: 0.05417238920927048\n",
      "Iteration 2319, Loss: 0.053989287465810776\n",
      "Iteration 2320, Loss: 0.054172318428754807\n",
      "Iteration 2321, Loss: 0.05398925393819809\n",
      "Iteration 2322, Loss: 0.05417224019765854\n",
      "Iteration 2323, Loss: 0.05398937314748764\n",
      "Iteration 2324, Loss: 0.054172150790691376\n",
      "Iteration 2325, Loss: 0.053989410400390625\n",
      "Iteration 2326, Loss: 0.054171960800886154\n",
      "Iteration 2327, Loss: 0.053989604115486145\n",
      "Iteration 2328, Loss: 0.0541718415915966\n",
      "Iteration 2329, Loss: 0.05398968979716301\n",
      "Iteration 2330, Loss: 0.05417191982269287\n",
      "Iteration 2331, Loss: 0.053989723324775696\n",
      "Iteration 2332, Loss: 0.054171957075595856\n",
      "Iteration 2333, Loss: 0.0539897195994854\n",
      "Iteration 2334, Loss: 0.05417200177907944\n",
      "Iteration 2335, Loss: 0.05398961156606674\n",
      "Iteration 2336, Loss: 0.05417200177907944\n",
      "Iteration 2337, Loss: 0.05398957058787346\n",
      "Iteration 2338, Loss: 0.054171960800886154\n",
      "Iteration 2339, Loss: 0.053989529609680176\n",
      "Iteration 2340, Loss: 0.054171882569789886\n",
      "Iteration 2341, Loss: 0.05398964881896973\n",
      "Iteration 2342, Loss: 0.054171960800886154\n",
      "Iteration 2343, Loss: 0.05398968979716301\n",
      "Iteration 2344, Loss: 0.0541718527674675\n",
      "Iteration 2345, Loss: 0.053989678621292114\n",
      "Iteration 2346, Loss: 0.05417200177907944\n",
      "Iteration 2347, Loss: 0.05398964509367943\n",
      "Iteration 2348, Loss: 0.05417203530669212\n",
      "Iteration 2349, Loss: 0.0539897195994854\n",
      "Iteration 2350, Loss: 0.05417211353778839\n",
      "Iteration 2351, Loss: 0.05398964136838913\n",
      "Iteration 2352, Loss: 0.054172269999980927\n",
      "Iteration 2353, Loss: 0.05398933216929436\n",
      "Iteration 2354, Loss: 0.054172318428754807\n",
      "Iteration 2355, Loss: 0.053989212960004807\n",
      "Iteration 2356, Loss: 0.05417255684733391\n",
      "Iteration 2357, Loss: 0.05398909002542496\n",
      "Iteration 2358, Loss: 0.05417255312204361\n",
      "Iteration 2359, Loss: 0.05398913472890854\n",
      "Iteration 2360, Loss: 0.054172322154045105\n",
      "Iteration 2361, Loss: 0.053989291191101074\n",
      "Iteration 2362, Loss: 0.05417215824127197\n",
      "Iteration 2363, Loss: 0.05398945137858391\n",
      "Iteration 2364, Loss: 0.054171882569789886\n",
      "Iteration 2365, Loss: 0.05398954078555107\n",
      "Iteration 2366, Loss: 0.05417199432849884\n",
      "Iteration 2367, Loss: 0.0539897195994854\n",
      "Iteration 2368, Loss: 0.054172031581401825\n",
      "Iteration 2369, Loss: 0.05398961156606674\n",
      "Iteration 2370, Loss: 0.054172080010175705\n",
      "Iteration 2371, Loss: 0.05398952588438988\n",
      "Iteration 2372, Loss: 0.054172199219465256\n",
      "Iteration 2373, Loss: 0.05398952215909958\n",
      "Iteration 2374, Loss: 0.054172269999980927\n",
      "Iteration 2375, Loss: 0.05398937314748764\n",
      "Iteration 2376, Loss: 0.05417218804359436\n",
      "Iteration 2377, Loss: 0.05398945137858391\n",
      "Iteration 2378, Loss: 0.054172299802303314\n",
      "Iteration 2379, Loss: 0.05398952588438988\n",
      "Iteration 2380, Loss: 0.05417210981249809\n",
      "Iteration 2381, Loss: 0.05398961156606674\n",
      "Iteration 2382, Loss: 0.054171882569789886\n",
      "Iteration 2383, Loss: 0.05398976057767868\n",
      "Iteration 2384, Loss: 0.054171960800886154\n",
      "Iteration 2385, Loss: 0.053989797830581665\n",
      "Iteration 2386, Loss: 0.054171886295080185\n",
      "Iteration 2387, Loss: 0.0539897195994854\n",
      "Iteration 2388, Loss: 0.054172080010175705\n",
      "Iteration 2389, Loss: 0.053989678621292114\n",
      "Iteration 2390, Loss: 0.054172080010175705\n",
      "Iteration 2391, Loss: 0.053989481180906296\n",
      "Iteration 2392, Loss: 0.05417215824127197\n",
      "Iteration 2393, Loss: 0.05398940667510033\n",
      "Iteration 2394, Loss: 0.05417224019765854\n",
      "Iteration 2395, Loss: 0.05398944765329361\n",
      "Iteration 2396, Loss: 0.05417215824127197\n",
      "Iteration 2397, Loss: 0.05398957058787346\n",
      "Iteration 2398, Loss: 0.05417203530669212\n",
      "Iteration 2399, Loss: 0.05398968607187271\n",
      "Iteration 2400, Loss: 0.05417200177907944\n",
      "Iteration 2401, Loss: 0.05398964509367943\n",
      "Iteration 2402, Loss: 0.054171960800886154\n",
      "Iteration 2403, Loss: 0.05398964881896973\n",
      "Iteration 2404, Loss: 0.054171960800886154\n",
      "Iteration 2405, Loss: 0.05398983880877495\n",
      "Iteration 2406, Loss: 0.05417199432849884\n",
      "Iteration 2407, Loss: 0.05398964509367943\n",
      "Iteration 2408, Loss: 0.054172199219465256\n",
      "Iteration 2409, Loss: 0.05398933216929436\n",
      "Iteration 2410, Loss: 0.05417227745056152\n",
      "Iteration 2411, Loss: 0.053989212960004807\n",
      "Iteration 2412, Loss: 0.054172396659851074\n",
      "Iteration 2413, Loss: 0.05398932099342346\n",
      "Iteration 2414, Loss: 0.054172128438949585\n",
      "Iteration 2415, Loss: 0.05398944020271301\n",
      "Iteration 2416, Loss: 0.05417203903198242\n",
      "Iteration 2417, Loss: 0.053989604115486145\n",
      "Iteration 2418, Loss: 0.05417199432849884\n",
      "Iteration 2419, Loss: 0.05398961156606674\n",
      "Iteration 2420, Loss: 0.05417199432849884\n",
      "Iteration 2421, Loss: 0.05398968979716301\n",
      "Iteration 2422, Loss: 0.054171882569789886\n",
      "Iteration 2423, Loss: 0.05398961156606674\n",
      "Iteration 2424, Loss: 0.054171960800886154\n",
      "Iteration 2425, Loss: 0.05398976057767868\n",
      "Iteration 2426, Loss: 0.05417206883430481\n",
      "Iteration 2427, Loss: 0.05398964136838913\n",
      "Iteration 2428, Loss: 0.05417203903198242\n",
      "Iteration 2429, Loss: 0.053989674896001816\n",
      "Iteration 2430, Loss: 0.05417210981249809\n",
      "Iteration 2431, Loss: 0.05398957058787346\n",
      "Iteration 2432, Loss: 0.05417203903198242\n",
      "Iteration 2433, Loss: 0.05398949235677719\n",
      "Iteration 2434, Loss: 0.054171960800886154\n",
      "Iteration 2435, Loss: 0.05398964881896973\n",
      "Iteration 2436, Loss: 0.05417191982269287\n",
      "Iteration 2437, Loss: 0.05398983508348465\n",
      "Iteration 2438, Loss: 0.05417200177907944\n",
      "Iteration 2439, Loss: 0.05398976057767868\n",
      "Iteration 2440, Loss: 0.054172199219465256\n",
      "Iteration 2441, Loss: 0.05398944765329361\n",
      "Iteration 2442, Loss: 0.05417243391275406\n",
      "Iteration 2443, Loss: 0.05398917198181152\n",
      "Iteration 2444, Loss: 0.05417262762784958\n",
      "Iteration 2445, Loss: 0.05398912355303764\n",
      "Iteration 2446, Loss: 0.05417262762784958\n",
      "Iteration 2447, Loss: 0.0539889857172966\n",
      "Iteration 2448, Loss: 0.05417235940694809\n",
      "Iteration 2449, Loss: 0.053989291191101074\n",
      "Iteration 2450, Loss: 0.054172199219465256\n",
      "Iteration 2451, Loss: 0.05398952215909958\n",
      "Iteration 2452, Loss: 0.05417191982269287\n",
      "Iteration 2453, Loss: 0.053989723324775696\n",
      "Iteration 2454, Loss: 0.054171960800886154\n",
      "Iteration 2455, Loss: 0.053989678621292114\n",
      "Iteration 2456, Loss: 0.05417203903198242\n",
      "Iteration 2457, Loss: 0.0539897158741951\n",
      "Iteration 2458, Loss: 0.05417218804359436\n",
      "Iteration 2459, Loss: 0.05398960039019585\n",
      "Iteration 2460, Loss: 0.054172269999980927\n",
      "Iteration 2461, Loss: 0.053989481180906296\n",
      "Iteration 2462, Loss: 0.054172273725271225\n",
      "Iteration 2463, Loss: 0.05398955196142197\n",
      "Iteration 2464, Loss: 0.05417238920927048\n",
      "Iteration 2465, Loss: 0.05398937314748764\n",
      "Iteration 2466, Loss: 0.05417216941714287\n",
      "Iteration 2467, Loss: 0.05398944020271301\n",
      "Iteration 2468, Loss: 0.05417223274707794\n",
      "Iteration 2469, Loss: 0.05398940667510033\n",
      "Iteration 2470, Loss: 0.05417212098836899\n",
      "Iteration 2471, Loss: 0.053989559412002563\n",
      "Iteration 2472, Loss: 0.05417196452617645\n",
      "Iteration 2473, Loss: 0.05398956686258316\n",
      "Iteration 2474, Loss: 0.05417191982269287\n",
      "Iteration 2475, Loss: 0.05398961156606674\n",
      "Iteration 2476, Loss: 0.05417191982269287\n",
      "Iteration 2477, Loss: 0.05398976057767868\n",
      "Iteration 2478, Loss: 0.05417191982269287\n",
      "Iteration 2479, Loss: 0.05398964136838913\n",
      "Iteration 2480, Loss: 0.05417200177907944\n",
      "Iteration 2481, Loss: 0.05398961156606674\n",
      "Iteration 2482, Loss: 0.054171960800886154\n",
      "Iteration 2483, Loss: 0.05398976057767868\n",
      "Iteration 2484, Loss: 0.054171957075595856\n",
      "Iteration 2485, Loss: 0.053989753127098083\n",
      "Iteration 2486, Loss: 0.05417203903198242\n",
      "Iteration 2487, Loss: 0.053989604115486145\n",
      "Iteration 2488, Loss: 0.05417199432849884\n",
      "Iteration 2489, Loss: 0.053989723324775696\n",
      "Iteration 2490, Loss: 0.05417199060320854\n",
      "Iteration 2491, Loss: 0.0539897195994854\n",
      "Iteration 2492, Loss: 0.05417210981249809\n",
      "Iteration 2493, Loss: 0.05398964136838913\n",
      "Iteration 2494, Loss: 0.05417203903198242\n",
      "Iteration 2495, Loss: 0.05398957058787346\n",
      "Iteration 2496, Loss: 0.05417203903198242\n",
      "Iteration 2497, Loss: 0.053989559412002563\n",
      "Iteration 2498, Loss: 0.05417211353778839\n",
      "Iteration 2499, Loss: 0.05398949235677719\n",
      "Iteration 2500, Loss: 0.0541718527674675\n",
      "Iteration 2501, Loss: 0.05398957058787346\n",
      "Iteration 2502, Loss: 0.05417191982269287\n",
      "Iteration 2503, Loss: 0.053989723324775696\n",
      "Iteration 2504, Loss: 0.054171960800886154\n",
      "Iteration 2505, Loss: 0.05398987978696823\n",
      "Iteration 2506, Loss: 0.05417191609740257\n",
      "Iteration 2507, Loss: 0.053989723324775696\n",
      "Iteration 2508, Loss: 0.05417191982269287\n",
      "Iteration 2509, Loss: 0.053989678621292114\n",
      "Iteration 2510, Loss: 0.05417200177907944\n",
      "Iteration 2511, Loss: 0.05398964509367943\n",
      "Iteration 2512, Loss: 0.054172199219465256\n",
      "Iteration 2513, Loss: 0.05398933216929436\n",
      "Iteration 2514, Loss: 0.05417238920927048\n",
      "Iteration 2515, Loss: 0.05398928374052048\n",
      "Iteration 2516, Loss: 0.05417243763804436\n",
      "Iteration 2517, Loss: 0.053989287465810776\n",
      "Iteration 2518, Loss: 0.05417238920927048\n",
      "Iteration 2519, Loss: 0.053989287465810776\n",
      "Iteration 2520, Loss: 0.054172269999980927\n",
      "Iteration 2521, Loss: 0.053989410400390625\n",
      "Iteration 2522, Loss: 0.05417203903198242\n",
      "Iteration 2523, Loss: 0.05398949235677719\n",
      "Iteration 2524, Loss: 0.054171886295080185\n",
      "Iteration 2525, Loss: 0.053989678621292114\n",
      "Iteration 2526, Loss: 0.05417203903198242\n",
      "Iteration 2527, Loss: 0.0539897158741951\n",
      "Iteration 2528, Loss: 0.054172080010175705\n",
      "Iteration 2529, Loss: 0.053989678621292114\n",
      "Iteration 2530, Loss: 0.05417218804359436\n",
      "Iteration 2531, Loss: 0.053989484906196594\n",
      "Iteration 2532, Loss: 0.05417242646217346\n",
      "Iteration 2533, Loss: 0.053989361971616745\n",
      "Iteration 2534, Loss: 0.054172396659851074\n",
      "Iteration 2535, Loss: 0.05398932844400406\n",
      "Iteration 2536, Loss: 0.054172467440366745\n",
      "Iteration 2537, Loss: 0.053989291191101074\n",
      "Iteration 2538, Loss: 0.05417224019765854\n",
      "Iteration 2539, Loss: 0.053989481180906296\n",
      "Iteration 2540, Loss: 0.05417200177907944\n",
      "Iteration 2541, Loss: 0.0539897195994854\n",
      "Iteration 2542, Loss: 0.05417187511920929\n",
      "Iteration 2543, Loss: 0.05398968979716301\n",
      "Iteration 2544, Loss: 0.0541718415915966\n",
      "Iteration 2545, Loss: 0.053989797830581665\n",
      "Iteration 2546, Loss: 0.0541718453168869\n",
      "Iteration 2547, Loss: 0.05398976057767868\n",
      "Iteration 2548, Loss: 0.05417203903198242\n",
      "Iteration 2549, Loss: 0.05398949235677719\n",
      "Iteration 2550, Loss: 0.05417230725288391\n",
      "Iteration 2551, Loss: 0.053989361971616745\n",
      "Iteration 2552, Loss: 0.054172396659851074\n",
      "Iteration 2553, Loss: 0.05398932844400406\n",
      "Iteration 2554, Loss: 0.05417227745056152\n",
      "Iteration 2555, Loss: 0.053989361971616745\n",
      "Iteration 2556, Loss: 0.054172199219465256\n",
      "Iteration 2557, Loss: 0.05398933216929436\n",
      "Iteration 2558, Loss: 0.05417205020785332\n",
      "Iteration 2559, Loss: 0.05398952215909958\n",
      "Iteration 2560, Loss: 0.05417200177907944\n",
      "Iteration 2561, Loss: 0.05398968607187271\n",
      "Iteration 2562, Loss: 0.05417203530669212\n",
      "Iteration 2563, Loss: 0.053989678621292114\n",
      "Iteration 2564, Loss: 0.054172076284885406\n",
      "Iteration 2565, Loss: 0.05398961156606674\n",
      "Iteration 2566, Loss: 0.05417196452617645\n",
      "Iteration 2567, Loss: 0.053989529609680176\n",
      "Iteration 2568, Loss: 0.05417203903198242\n",
      "Iteration 2569, Loss: 0.05398956686258316\n",
      "Iteration 2570, Loss: 0.05417215824127197\n",
      "Iteration 2571, Loss: 0.05398960039019585\n",
      "Iteration 2572, Loss: 0.05417212098836899\n",
      "Iteration 2573, Loss: 0.05398952215909958\n",
      "Iteration 2574, Loss: 0.05417210981249809\n",
      "Iteration 2575, Loss: 0.05398964136838913\n",
      "Iteration 2576, Loss: 0.0541718453168869\n",
      "Iteration 2577, Loss: 0.0539897195994854\n",
      "Iteration 2578, Loss: 0.05417199432849884\n",
      "Iteration 2579, Loss: 0.05398983508348465\n",
      "Iteration 2580, Loss: 0.05417199060320854\n",
      "Iteration 2581, Loss: 0.053989678621292114\n",
      "Iteration 2582, Loss: 0.05417203530669212\n",
      "Iteration 2583, Loss: 0.05398964136838913\n",
      "Iteration 2584, Loss: 0.05417212098836899\n",
      "Iteration 2585, Loss: 0.053989291191101074\n",
      "Iteration 2586, Loss: 0.054172318428754807\n",
      "Iteration 2587, Loss: 0.05398940667510033\n",
      "Iteration 2588, Loss: 0.05417235195636749\n",
      "Iteration 2589, Loss: 0.053989291191101074\n",
      "Iteration 2590, Loss: 0.05417215824127197\n",
      "Iteration 2591, Loss: 0.05398945137858391\n",
      "Iteration 2592, Loss: 0.05417218804359436\n",
      "Iteration 2593, Loss: 0.05398956686258316\n",
      "Iteration 2594, Loss: 0.054172199219465256\n",
      "Iteration 2595, Loss: 0.053989559412002563\n",
      "Iteration 2596, Loss: 0.05417215824127197\n",
      "Iteration 2597, Loss: 0.053989484906196594\n",
      "Iteration 2598, Loss: 0.05417224019765854\n",
      "Iteration 2599, Loss: 0.053989481180906296\n",
      "Iteration 2600, Loss: 0.054172348231077194\n",
      "Iteration 2601, Loss: 0.05398924648761749\n",
      "Iteration 2602, Loss: 0.05417254567146301\n",
      "Iteration 2603, Loss: 0.053989242762327194\n",
      "Iteration 2604, Loss: 0.05417227745056152\n",
      "Iteration 2605, Loss: 0.05398925393819809\n",
      "Iteration 2606, Loss: 0.05417219549417496\n",
      "Iteration 2607, Loss: 0.053989529609680176\n",
      "Iteration 2608, Loss: 0.05417191982269287\n",
      "Iteration 2609, Loss: 0.05398980900645256\n",
      "Iteration 2610, Loss: 0.05417156219482422\n",
      "Iteration 2611, Loss: 0.05399003624916077\n",
      "Iteration 2612, Loss: 0.05417148396372795\n",
      "Iteration 2613, Loss: 0.05399011820554733\n",
      "Iteration 2614, Loss: 0.054171644151210785\n",
      "Iteration 2615, Loss: 0.0539899580180645\n",
      "Iteration 2616, Loss: 0.05417180806398392\n",
      "Iteration 2617, Loss: 0.05398961156606674\n",
      "Iteration 2618, Loss: 0.054172318428754807\n",
      "Iteration 2619, Loss: 0.053989361971616745\n",
      "Iteration 2620, Loss: 0.054172590374946594\n",
      "Iteration 2621, Loss: 0.05398901551961899\n",
      "Iteration 2622, Loss: 0.054172590374946594\n",
      "Iteration 2623, Loss: 0.0539889857172966\n",
      "Iteration 2624, Loss: 0.054172396659851074\n",
      "Iteration 2625, Loss: 0.053989287465810776\n",
      "Iteration 2626, Loss: 0.054172269999980927\n",
      "Iteration 2627, Loss: 0.05398949235677719\n",
      "Iteration 2628, Loss: 0.054171960800886154\n",
      "Iteration 2629, Loss: 0.05398968607187271\n",
      "Iteration 2630, Loss: 0.054172031581401825\n",
      "Iteration 2631, Loss: 0.05398976057767868\n",
      "Iteration 2632, Loss: 0.054171960800886154\n",
      "Iteration 2633, Loss: 0.05398964136838913\n",
      "Iteration 2634, Loss: 0.054172080010175705\n",
      "Iteration 2635, Loss: 0.0539897195994854\n",
      "Iteration 2636, Loss: 0.05417212098836899\n",
      "Iteration 2637, Loss: 0.05398952215909958\n",
      "Iteration 2638, Loss: 0.05417216569185257\n",
      "Iteration 2639, Loss: 0.0539894700050354\n",
      "Iteration 2640, Loss: 0.05417235940694809\n",
      "Iteration 2641, Loss: 0.053989291191101074\n",
      "Iteration 2642, Loss: 0.05417235195636749\n",
      "Iteration 2643, Loss: 0.053989361971616745\n",
      "Iteration 2644, Loss: 0.05417238175868988\n",
      "Iteration 2645, Loss: 0.053989410400390625\n",
      "Iteration 2646, Loss: 0.05417203903198242\n",
      "Iteration 2647, Loss: 0.05398961156606674\n",
      "Iteration 2648, Loss: 0.05417180061340332\n",
      "Iteration 2649, Loss: 0.05398973077535629\n",
      "Iteration 2650, Loss: 0.05417172238230705\n",
      "Iteration 2651, Loss: 0.05398976802825928\n",
      "Iteration 2652, Loss: 0.05417172238230705\n",
      "Iteration 2653, Loss: 0.05398976802825928\n",
      "Iteration 2654, Loss: 0.05417179688811302\n",
      "Iteration 2655, Loss: 0.05398973077535629\n",
      "Iteration 2656, Loss: 0.05417172238230705\n",
      "Iteration 2657, Loss: 0.05398976802825928\n",
      "Iteration 2658, Loss: 0.0541718415915966\n",
      "Iteration 2659, Loss: 0.05398990958929062\n",
      "Iteration 2660, Loss: 0.05417210981249809\n",
      "Iteration 2661, Loss: 0.053989678621292114\n",
      "Iteration 2662, Loss: 0.05417218804359436\n",
      "Iteration 2663, Loss: 0.053989410400390625\n",
      "Iteration 2664, Loss: 0.054172199219465256\n",
      "Iteration 2665, Loss: 0.05398944020271301\n",
      "Iteration 2666, Loss: 0.054172150790691376\n",
      "Iteration 2667, Loss: 0.05398952215909958\n",
      "Iteration 2668, Loss: 0.05417206883430481\n",
      "Iteration 2669, Loss: 0.05398961156606674\n",
      "Iteration 2670, Loss: 0.05417200177907944\n",
      "Iteration 2671, Loss: 0.05398964509367943\n",
      "Iteration 2672, Loss: 0.05417215824127197\n",
      "Iteration 2673, Loss: 0.05398952215909958\n",
      "Iteration 2674, Loss: 0.05417215824127197\n",
      "Iteration 2675, Loss: 0.05398937314748764\n",
      "Iteration 2676, Loss: 0.054172080010175705\n",
      "Iteration 2677, Loss: 0.05398949235677719\n",
      "Iteration 2678, Loss: 0.05417206883430481\n",
      "Iteration 2679, Loss: 0.05398957058787346\n",
      "Iteration 2680, Loss: 0.05417200177907944\n",
      "Iteration 2681, Loss: 0.05398964509367943\n",
      "Iteration 2682, Loss: 0.054171882569789886\n",
      "Iteration 2683, Loss: 0.05398964509367943\n",
      "Iteration 2684, Loss: 0.05417191982269287\n",
      "Iteration 2685, Loss: 0.05398976430296898\n",
      "Iteration 2686, Loss: 0.05417199432849884\n",
      "Iteration 2687, Loss: 0.0539897084236145\n",
      "Iteration 2688, Loss: 0.05417218804359436\n",
      "Iteration 2689, Loss: 0.05398901551961899\n",
      "Iteration 2690, Loss: 0.054172199219465256\n",
      "Iteration 2691, Loss: 0.05398889631032944\n",
      "Iteration 2692, Loss: 0.054171543568372726\n",
      "Iteration 2693, Loss: 0.05398862808942795\n",
      "Iteration 2694, Loss: 0.05417145416140556\n",
      "Iteration 2695, Loss: 0.0539887472987175\n",
      "Iteration 2696, Loss: 0.054171305149793625\n",
      "Iteration 2697, Loss: 0.053988825529813766\n",
      "Iteration 2698, Loss: 0.05417141318321228\n",
      "Iteration 2699, Loss: 0.05398885905742645\n",
      "Iteration 2700, Loss: 0.054171305149793625\n",
      "Iteration 2701, Loss: 0.053988903760910034\n",
      "Iteration 2702, Loss: 0.05417129397392273\n",
      "Iteration 2703, Loss: 0.05398894473910332\n",
      "Iteration 2704, Loss: 0.05417126417160034\n",
      "Iteration 2705, Loss: 0.053988978266716\n",
      "Iteration 2706, Loss: 0.054171495139598846\n",
      "Iteration 2707, Loss: 0.05398885905742645\n",
      "Iteration 2708, Loss: 0.05417146533727646\n",
      "Iteration 2709, Loss: 0.0539887472987175\n",
      "Iteration 2710, Loss: 0.05417158454656601\n",
      "Iteration 2711, Loss: 0.05398859083652496\n",
      "Iteration 2712, Loss: 0.054171688854694366\n",
      "Iteration 2713, Loss: 0.053988777101039886\n",
      "Iteration 2714, Loss: 0.0541716143488884\n",
      "Iteration 2715, Loss: 0.05398866534233093\n",
      "Iteration 2716, Loss: 0.05417145416140556\n",
      "Iteration 2717, Loss: 0.0539887472987175\n",
      "Iteration 2718, Loss: 0.05417134612798691\n",
      "Iteration 2719, Loss: 0.05398885905742645\n",
      "Iteration 2720, Loss: 0.054171301424503326\n",
      "Iteration 2721, Loss: 0.053988903760910034\n",
      "Iteration 2722, Loss: 0.05417121946811676\n",
      "Iteration 2723, Loss: 0.053989022970199585\n",
      "Iteration 2724, Loss: 0.05417115241289139\n",
      "Iteration 2725, Loss: 0.05398913472890854\n",
      "Iteration 2726, Loss: 0.05417134612798691\n",
      "Iteration 2727, Loss: 0.053988825529813766\n",
      "Iteration 2728, Loss: 0.05417153239250183\n",
      "Iteration 2729, Loss: 0.0539887398481369\n",
      "Iteration 2730, Loss: 0.05417164787650108\n",
      "Iteration 2731, Loss: 0.05398870259523392\n",
      "Iteration 2732, Loss: 0.054171379655599594\n",
      "Iteration 2733, Loss: 0.05398886650800705\n",
      "Iteration 2734, Loss: 0.0541713647544384\n",
      "Iteration 2735, Loss: 0.0539889894425869\n",
      "Iteration 2736, Loss: 0.05417117476463318\n",
      "Iteration 2737, Loss: 0.053989216685295105\n",
      "Iteration 2738, Loss: 0.05417110025882721\n",
      "Iteration 2739, Loss: 0.053989212960004807\n",
      "Iteration 2740, Loss: 0.05417121946811676\n",
      "Iteration 2741, Loss: 0.053989093750715256\n",
      "Iteration 2742, Loss: 0.054171379655599594\n",
      "Iteration 2743, Loss: 0.05398892983794212\n",
      "Iteration 2744, Loss: 0.05417173355817795\n",
      "Iteration 2745, Loss: 0.05398854613304138\n",
      "Iteration 2746, Loss: 0.0541718564927578\n",
      "Iteration 2747, Loss: 0.053988538682460785\n",
      "Iteration 2748, Loss: 0.054171934723854065\n",
      "Iteration 2749, Loss: 0.053988270461559296\n",
      "Iteration 2750, Loss: 0.054171815514564514\n",
      "Iteration 2751, Loss: 0.05398839712142944\n",
      "Iteration 2752, Loss: 0.054171573370695114\n",
      "Iteration 2753, Loss: 0.05398871749639511\n",
      "Iteration 2754, Loss: 0.054171375930309296\n",
      "Iteration 2755, Loss: 0.05398894473910332\n",
      "Iteration 2756, Loss: 0.054171182215213776\n",
      "Iteration 2757, Loss: 0.053989142179489136\n",
      "Iteration 2758, Loss: 0.054171107709407806\n",
      "Iteration 2759, Loss: 0.053989022970199585\n",
      "Iteration 2760, Loss: 0.05417117476463318\n",
      "Iteration 2761, Loss: 0.053989022970199585\n",
      "Iteration 2762, Loss: 0.054171185940504074\n",
      "Iteration 2763, Loss: 0.05398905277252197\n",
      "Iteration 2764, Loss: 0.05417141318321228\n",
      "Iteration 2765, Loss: 0.053988903760910034\n",
      "Iteration 2766, Loss: 0.054171495139598846\n",
      "Iteration 2767, Loss: 0.05398930236697197\n",
      "Iteration 2768, Loss: 0.05417153239250183\n",
      "Iteration 2769, Loss: 0.05398929864168167\n",
      "Iteration 2770, Loss: 0.05417206138372421\n",
      "Iteration 2771, Loss: 0.05398918315768242\n",
      "Iteration 2772, Loss: 0.05417206138372421\n",
      "Iteration 2773, Loss: 0.053989261388778687\n",
      "Iteration 2774, Loss: 0.054171930998563766\n",
      "Iteration 2775, Loss: 0.053989261388778687\n",
      "Iteration 2776, Loss: 0.05417182296514511\n",
      "Iteration 2777, Loss: 0.05398938059806824\n",
      "Iteration 2778, Loss: 0.054171741008758545\n",
      "Iteration 2779, Loss: 0.053989313542842865\n",
      "Iteration 2780, Loss: 0.05417170375585556\n",
      "Iteration 2781, Loss: 0.05398949980735779\n",
      "Iteration 2782, Loss: 0.054171741008758545\n",
      "Iteration 2783, Loss: 0.05398942157626152\n",
      "Iteration 2784, Loss: 0.054171741008758545\n",
      "Iteration 2785, Loss: 0.05398942157626152\n",
      "Iteration 2786, Loss: 0.05417182296514511\n",
      "Iteration 2787, Loss: 0.05398926883935928\n",
      "Iteration 2788, Loss: 0.0541718527674675\n",
      "Iteration 2789, Loss: 0.05398942157626152\n",
      "Iteration 2790, Loss: 0.054171860218048096\n",
      "Iteration 2791, Loss: 0.05398934334516525\n",
      "Iteration 2792, Loss: 0.05417182296514511\n",
      "Iteration 2793, Loss: 0.05398934334516525\n",
      "Iteration 2794, Loss: 0.054172083735466\n",
      "Iteration 2795, Loss: 0.05398918315768242\n",
      "Iteration 2796, Loss: 0.05417202040553093\n",
      "Iteration 2797, Loss: 0.053989067673683167\n",
      "Iteration 2798, Loss: 0.05417187139391899\n",
      "Iteration 2799, Loss: 0.05398929864168167\n",
      "Iteration 2800, Loss: 0.05417170748114586\n",
      "Iteration 2801, Loss: 0.05398938059806824\n",
      "Iteration 2802, Loss: 0.054171547293663025\n",
      "Iteration 2803, Loss: 0.05398949980735779\n",
      "Iteration 2804, Loss: 0.05417146906256676\n",
      "Iteration 2805, Loss: 0.053989581763744354\n",
      "Iteration 2806, Loss: 0.05417146906256676\n",
      "Iteration 2807, Loss: 0.05398955196142197\n",
      "Iteration 2808, Loss: 0.054171543568372726\n",
      "Iteration 2809, Loss: 0.05398961901664734\n",
      "Iteration 2810, Loss: 0.05417158827185631\n",
      "Iteration 2811, Loss: 0.05398949980735779\n",
      "Iteration 2812, Loss: 0.05417190119624138\n",
      "Iteration 2813, Loss: 0.05398918688297272\n",
      "Iteration 2814, Loss: 0.05417210981249809\n",
      "Iteration 2815, Loss: 0.0539889857172966\n",
      "Iteration 2816, Loss: 0.054172366857528687\n",
      "Iteration 2817, Loss: 0.05398886650800705\n",
      "Iteration 2818, Loss: 0.05417228862643242\n",
      "Iteration 2819, Loss: 0.053989022970199585\n",
      "Iteration 2820, Loss: 0.054171979427337646\n",
      "Iteration 2821, Loss: 0.053989067673683167\n",
      "Iteration 2822, Loss: 0.05417190119624138\n",
      "Iteration 2823, Loss: 0.05398938059806824\n",
      "Iteration 2824, Loss: 0.054171621799468994\n",
      "Iteration 2825, Loss: 0.05398957431316376\n",
      "Iteration 2826, Loss: 0.054171621799468994\n",
      "Iteration 2827, Loss: 0.05398954078555107\n",
      "Iteration 2828, Loss: 0.05417158454656601\n",
      "Iteration 2829, Loss: 0.05398964881896973\n",
      "Iteration 2830, Loss: 0.054171666502952576\n",
      "Iteration 2831, Loss: 0.05398938059806824\n",
      "Iteration 2832, Loss: 0.054171934723854065\n",
      "Iteration 2833, Loss: 0.05398937687277794\n",
      "Iteration 2834, Loss: 0.05417186766862869\n",
      "Iteration 2835, Loss: 0.05398914963006973\n",
      "Iteration 2836, Loss: 0.054171930998563766\n",
      "Iteration 2837, Loss: 0.05398930236697197\n",
      "Iteration 2838, Loss: 0.05417182296514511\n",
      "Iteration 2839, Loss: 0.05398926883935928\n",
      "Iteration 2840, Loss: 0.05417178198695183\n",
      "Iteration 2841, Loss: 0.05398926883935928\n",
      "Iteration 2842, Loss: 0.05417178198695183\n",
      "Iteration 2843, Loss: 0.05398930609226227\n",
      "Iteration 2844, Loss: 0.05417182296514511\n",
      "Iteration 2845, Loss: 0.05398926883935928\n",
      "Iteration 2846, Loss: 0.05417182296514511\n",
      "Iteration 2847, Loss: 0.05398937687277794\n",
      "Iteration 2848, Loss: 0.05417182296514511\n",
      "Iteration 2849, Loss: 0.05398945137858391\n",
      "Iteration 2850, Loss: 0.054171930998563766\n",
      "Iteration 2851, Loss: 0.05398930236697197\n",
      "Iteration 2852, Loss: 0.05417190119624138\n",
      "Iteration 2853, Loss: 0.05398910492658615\n",
      "Iteration 2854, Loss: 0.05417182296514511\n",
      "Iteration 2855, Loss: 0.0539892241358757\n",
      "Iteration 2856, Loss: 0.05417183041572571\n",
      "Iteration 2857, Loss: 0.05398934334516525\n",
      "Iteration 2858, Loss: 0.05417183041572571\n",
      "Iteration 2859, Loss: 0.053989261388778687\n",
      "Iteration 2860, Loss: 0.05417194217443466\n",
      "Iteration 2861, Loss: 0.05398929864168167\n",
      "Iteration 2862, Loss: 0.05417190119624138\n",
      "Iteration 2863, Loss: 0.05398929864168167\n",
      "Iteration 2864, Loss: 0.05417190119624138\n",
      "Iteration 2865, Loss: 0.05398918688297272\n",
      "Iteration 2866, Loss: 0.05417194217443466\n",
      "Iteration 2867, Loss: 0.053989194333553314\n",
      "Iteration 2868, Loss: 0.05417182296514511\n",
      "Iteration 2869, Loss: 0.053989194333553314\n",
      "Iteration 2870, Loss: 0.05417189002037048\n",
      "Iteration 2871, Loss: 0.053989261388778687\n",
      "Iteration 2872, Loss: 0.054171815514564514\n",
      "Iteration 2873, Loss: 0.05398934334516525\n",
      "Iteration 2874, Loss: 0.0541718564927578\n",
      "Iteration 2875, Loss: 0.05398942157626152\n",
      "Iteration 2876, Loss: 0.054171741008758545\n",
      "Iteration 2877, Loss: 0.05398938059806824\n",
      "Iteration 2878, Loss: 0.05417170375585556\n",
      "Iteration 2879, Loss: 0.05398949980735779\n",
      "Iteration 2880, Loss: 0.05417162925004959\n",
      "Iteration 2881, Loss: 0.05398942157626152\n",
      "Iteration 2882, Loss: 0.05417163297533989\n",
      "Iteration 2883, Loss: 0.05398938059806824\n",
      "Iteration 2884, Loss: 0.05417197197675705\n",
      "Iteration 2885, Loss: 0.05398930236697197\n",
      "Iteration 2886, Loss: 0.05417201668024063\n",
      "Iteration 2887, Loss: 0.0539892241358757\n",
      "Iteration 2888, Loss: 0.054171979427337646\n",
      "Iteration 2889, Loss: 0.053989142179489136\n",
      "Iteration 2890, Loss: 0.054171930998563766\n",
      "Iteration 2891, Loss: 0.053989261388778687\n",
      "Iteration 2892, Loss: 0.054171741008758545\n",
      "Iteration 2893, Loss: 0.053989388048648834\n",
      "Iteration 2894, Loss: 0.05417158454656601\n",
      "Iteration 2895, Loss: 0.053989510983228683\n",
      "Iteration 2896, Loss: 0.05417157709598541\n",
      "Iteration 2897, Loss: 0.053989510983228683\n",
      "Iteration 2898, Loss: 0.05417155474424362\n",
      "Iteration 2899, Loss: 0.053989510983228683\n",
      "Iteration 2900, Loss: 0.054171741008758545\n",
      "Iteration 2901, Loss: 0.053989313542842865\n",
      "Iteration 2902, Loss: 0.05417202040553093\n",
      "Iteration 2903, Loss: 0.05398903042078018\n",
      "Iteration 2904, Loss: 0.05417221039533615\n",
      "Iteration 2905, Loss: 0.05398891866207123\n",
      "Iteration 2906, Loss: 0.054172202944755554\n",
      "Iteration 2907, Loss: 0.05398910492658615\n",
      "Iteration 2908, Loss: 0.054171930998563766\n",
      "Iteration 2909, Loss: 0.05398926883935928\n",
      "Iteration 2910, Loss: 0.054171741008758545\n",
      "Iteration 2911, Loss: 0.053989313542842865\n",
      "Iteration 2912, Loss: 0.054171547293663025\n",
      "Iteration 2913, Loss: 0.053989581763744354\n",
      "Iteration 2914, Loss: 0.05417146906256676\n",
      "Iteration 2915, Loss: 0.05398949980735779\n",
      "Iteration 2916, Loss: 0.054171543568372726\n",
      "Iteration 2917, Loss: 0.05398958548903465\n",
      "Iteration 2918, Loss: 0.05417170375585556\n",
      "Iteration 2919, Loss: 0.05398949608206749\n",
      "Iteration 2920, Loss: 0.054171860218048096\n",
      "Iteration 2921, Loss: 0.05398903787136078\n",
      "Iteration 2922, Loss: 0.05417206138372421\n",
      "Iteration 2923, Loss: 0.05398903042078018\n",
      "Iteration 2924, Loss: 0.05417228862643242\n",
      "Iteration 2925, Loss: 0.05398891493678093\n",
      "Iteration 2926, Loss: 0.05417210981249809\n",
      "Iteration 2927, Loss: 0.053988873958587646\n",
      "Iteration 2928, Loss: 0.05417206138372421\n",
      "Iteration 2929, Loss: 0.05398907512426376\n",
      "Iteration 2930, Loss: 0.054171860218048096\n",
      "Iteration 2931, Loss: 0.05398915335536003\n",
      "Iteration 2932, Loss: 0.05417177826166153\n",
      "Iteration 2933, Loss: 0.05398942530155182\n",
      "Iteration 2934, Loss: 0.05417157709598541\n",
      "Iteration 2935, Loss: 0.05398965999484062\n",
      "Iteration 2936, Loss: 0.05417139455676079\n",
      "Iteration 2937, Loss: 0.05398965999484062\n",
      "Iteration 2938, Loss: 0.054171543568372726\n",
      "Iteration 2939, Loss: 0.053989581763744354\n",
      "Iteration 2940, Loss: 0.054171591997146606\n",
      "Iteration 2941, Loss: 0.053989432752132416\n",
      "Iteration 2942, Loss: 0.05417170748114586\n",
      "Iteration 2943, Loss: 0.05398938059806824\n",
      "Iteration 2944, Loss: 0.05417178198695183\n",
      "Iteration 2945, Loss: 0.05398930236697197\n",
      "Iteration 2946, Loss: 0.0541715994477272\n",
      "Iteration 2947, Loss: 0.05398934334516525\n",
      "Iteration 2948, Loss: 0.05417167395353317\n",
      "Iteration 2949, Loss: 0.05398938059806824\n",
      "Iteration 2950, Loss: 0.05417182296514511\n",
      "Iteration 2951, Loss: 0.05398938059806824\n",
      "Iteration 2952, Loss: 0.054171860218048096\n",
      "Iteration 2953, Loss: 0.05398930236697197\n",
      "Iteration 2954, Loss: 0.054171930998563766\n",
      "Iteration 2955, Loss: 0.05398934334516525\n",
      "Iteration 2956, Loss: 0.05417189747095108\n",
      "Iteration 2957, Loss: 0.053989261388778687\n",
      "Iteration 2958, Loss: 0.05417205020785332\n",
      "Iteration 2959, Loss: 0.0539892241358757\n",
      "Iteration 2960, Loss: 0.05417205020785332\n",
      "Iteration 2961, Loss: 0.05398903414607048\n",
      "Iteration 2962, Loss: 0.05417194217443466\n",
      "Iteration 2963, Loss: 0.0539892241358757\n",
      "Iteration 2964, Loss: 0.05417182296514511\n",
      "Iteration 2965, Loss: 0.05398927256464958\n",
      "Iteration 2966, Loss: 0.05417182669043541\n",
      "Iteration 2967, Loss: 0.05398930236697197\n",
      "Iteration 2968, Loss: 0.05417190119624138\n",
      "Iteration 2969, Loss: 0.0539892241358757\n",
      "Iteration 2970, Loss: 0.054171860218048096\n",
      "Iteration 2971, Loss: 0.053989261388778687\n",
      "Iteration 2972, Loss: 0.054171860218048096\n",
      "Iteration 2973, Loss: 0.05398927256464958\n",
      "Iteration 2974, Loss: 0.054171934723854065\n",
      "Iteration 2975, Loss: 0.05398966372013092\n",
      "Iteration 2976, Loss: 0.054171860218048096\n",
      "Iteration 2977, Loss: 0.053989630192518234\n",
      "Iteration 2978, Loss: 0.054171692579984665\n",
      "Iteration 2979, Loss: 0.053990092128515244\n",
      "Iteration 2980, Loss: 0.05417109653353691\n",
      "Iteration 2981, Loss: 0.05399029701948166\n",
      "Iteration 2982, Loss: 0.054170794785022736\n",
      "Iteration 2983, Loss: 0.053990256041288376\n",
      "Iteration 2984, Loss: 0.05417106673121452\n",
      "Iteration 2985, Loss: 0.05399012565612793\n",
      "Iteration 2986, Loss: 0.0541716143488884\n",
      "Iteration 2987, Loss: 0.0539894700050354\n",
      "Iteration 2988, Loss: 0.05417197197675705\n",
      "Iteration 2989, Loss: 0.05398911237716675\n",
      "Iteration 2990, Loss: 0.05417229235172272\n",
      "Iteration 2991, Loss: 0.053989022970199585\n",
      "Iteration 2992, Loss: 0.054172419011592865\n",
      "Iteration 2993, Loss: 0.053988829255104065\n",
      "Iteration 2994, Loss: 0.05417260527610779\n",
      "Iteration 2995, Loss: 0.05398879572749138\n",
      "Iteration 2996, Loss: 0.05417228862643242\n",
      "Iteration 2997, Loss: 0.05398911237716675\n",
      "Iteration 2998, Loss: 0.05417197197675705\n",
      "Iteration 2999, Loss: 0.05398942157626152\n",
      "Iteration 3000, Loss: 0.05417165905237198\n",
      "Iteration 3001, Loss: 0.05398973822593689\n",
      "Iteration 3002, Loss: 0.05417139083147049\n",
      "Iteration 3003, Loss: 0.053989775478839874\n",
      "Iteration 3004, Loss: 0.054171618074178696\n",
      "Iteration 3005, Loss: 0.05398973822593689\n",
      "Iteration 3006, Loss: 0.054171621799468994\n",
      "Iteration 3007, Loss: 0.05398949980735779\n",
      "Iteration 3008, Loss: 0.05417197570204735\n",
      "Iteration 3009, Loss: 0.053989227861166\n",
      "Iteration 3010, Loss: 0.05417216941714287\n",
      "Iteration 3011, Loss: 0.0539889931678772\n",
      "Iteration 3012, Loss: 0.05417221784591675\n",
      "Iteration 3013, Loss: 0.05398913845419884\n",
      "Iteration 3014, Loss: 0.05417213961482048\n",
      "Iteration 3015, Loss: 0.05398911237716675\n",
      "Iteration 3016, Loss: 0.0541720911860466\n",
      "Iteration 3017, Loss: 0.05398930236697197\n",
      "Iteration 3018, Loss: 0.05417178198695183\n",
      "Iteration 3019, Loss: 0.05398954078555107\n",
      "Iteration 3020, Loss: 0.05417146906256676\n",
      "Iteration 3021, Loss: 0.053989630192518234\n",
      "Iteration 3022, Loss: 0.05417150259017944\n",
      "Iteration 3023, Loss: 0.05398973822593689\n",
      "Iteration 3024, Loss: 0.05417131632566452\n",
      "Iteration 3025, Loss: 0.05398992821574211\n",
      "Iteration 3026, Loss: 0.054171498864889145\n",
      "Iteration 3027, Loss: 0.05398965999484062\n",
      "Iteration 3028, Loss: 0.05417157709598541\n",
      "Iteration 3029, Loss: 0.05398958548903465\n",
      "Iteration 3030, Loss: 0.054171692579984665\n",
      "Iteration 3031, Loss: 0.05398965999484062\n",
      "Iteration 3032, Loss: 0.05417158454656601\n",
      "Iteration 3033, Loss: 0.05398954078555107\n",
      "Iteration 3034, Loss: 0.05417158827185631\n",
      "Iteration 3035, Loss: 0.053989507257938385\n",
      "Iteration 3036, Loss: 0.05417146906256676\n",
      "Iteration 3037, Loss: 0.053989626467227936\n",
      "Iteration 3038, Loss: 0.05417150259017944\n",
      "Iteration 3039, Loss: 0.05398973822593689\n",
      "Iteration 3040, Loss: 0.05417139083147049\n",
      "Iteration 3041, Loss: 0.05398992821574211\n",
      "Iteration 3042, Loss: 0.054171498864889145\n",
      "Iteration 3043, Loss: 0.053989775478839874\n",
      "Iteration 3044, Loss: 0.054171621799468994\n",
      "Iteration 3045, Loss: 0.05398961901664734\n",
      "Iteration 3046, Loss: 0.05417177081108093\n",
      "Iteration 3047, Loss: 0.05398949980735779\n",
      "Iteration 3048, Loss: 0.05417178198695183\n",
      "Iteration 3049, Loss: 0.05398942530155182\n",
      "Iteration 3050, Loss: 0.05417170375585556\n",
      "Iteration 3051, Loss: 0.05398955196142197\n",
      "Iteration 3052, Loss: 0.054171543568372726\n",
      "Iteration 3053, Loss: 0.053989700973033905\n",
      "Iteration 3054, Loss: 0.0541716143488884\n",
      "Iteration 3055, Loss: 0.05398961901664734\n",
      "Iteration 3056, Loss: 0.054171618074178696\n",
      "Iteration 3057, Loss: 0.053989581763744354\n",
      "Iteration 3058, Loss: 0.054171472787857056\n",
      "Iteration 3059, Loss: 0.05398981273174286\n",
      "Iteration 3060, Loss: 0.05417158454656601\n",
      "Iteration 3061, Loss: 0.05398961901664734\n",
      "Iteration 3062, Loss: 0.05417170375585556\n",
      "Iteration 3063, Loss: 0.05398949980735779\n",
      "Iteration 3064, Loss: 0.054171741008758545\n",
      "Iteration 3065, Loss: 0.05398954078555107\n",
      "Iteration 3066, Loss: 0.05417170375585556\n",
      "Iteration 3067, Loss: 0.053989581763744354\n",
      "Iteration 3068, Loss: 0.054171547293663025\n",
      "Iteration 3069, Loss: 0.05398961901664734\n",
      "Iteration 3070, Loss: 0.05417146906256676\n",
      "Iteration 3071, Loss: 0.053989630192518234\n",
      "Iteration 3072, Loss: 0.054171495139598846\n",
      "Iteration 3073, Loss: 0.05398973822593689\n",
      "Iteration 3074, Loss: 0.054171349853277206\n",
      "Iteration 3075, Loss: 0.05398985743522644\n",
      "Iteration 3076, Loss: 0.054171543568372726\n",
      "Iteration 3077, Loss: 0.05398955196142197\n",
      "Iteration 3078, Loss: 0.05417170375585556\n",
      "Iteration 3079, Loss: 0.0539894625544548\n",
      "Iteration 3080, Loss: 0.05417202040553093\n",
      "Iteration 3081, Loss: 0.0539892241358757\n",
      "Iteration 3082, Loss: 0.0541720986366272\n",
      "Iteration 3083, Loss: 0.05398915335536003\n",
      "Iteration 3084, Loss: 0.05417205020785332\n",
      "Iteration 3085, Loss: 0.0539892315864563\n",
      "Iteration 3086, Loss: 0.05417170375585556\n",
      "Iteration 3087, Loss: 0.05398955196142197\n",
      "Iteration 3088, Loss: 0.054171424359083176\n",
      "Iteration 3089, Loss: 0.05398993939161301\n",
      "Iteration 3090, Loss: 0.05417122691869736\n",
      "Iteration 3091, Loss: 0.053990017622709274\n",
      "Iteration 3092, Loss: 0.05417134612798691\n",
      "Iteration 3093, Loss: 0.053989898413419724\n",
      "Iteration 3094, Loss: 0.054171424359083176\n",
      "Iteration 3095, Loss: 0.05398955196142197\n",
      "Iteration 3096, Loss: 0.054171811789274216\n",
      "Iteration 3097, Loss: 0.053989432752132416\n",
      "Iteration 3098, Loss: 0.0541718564927578\n",
      "Iteration 3099, Loss: 0.0539892315864563\n",
      "Iteration 3100, Loss: 0.054172009229660034\n",
      "Iteration 3101, Loss: 0.05398911237716675\n",
      "Iteration 3102, Loss: 0.054171930998563766\n",
      "Iteration 3103, Loss: 0.053989388048648834\n",
      "Iteration 3104, Loss: 0.05417166277766228\n",
      "Iteration 3105, Loss: 0.05398961901664734\n",
      "Iteration 3106, Loss: 0.054171305149793625\n",
      "Iteration 3107, Loss: 0.053989894688129425\n",
      "Iteration 3108, Loss: 0.05417107045650482\n",
      "Iteration 3109, Loss: 0.05398993939161301\n",
      "Iteration 3110, Loss: 0.05417114496231079\n",
      "Iteration 3111, Loss: 0.05399012565612793\n",
      "Iteration 3112, Loss: 0.05417133867740631\n",
      "Iteration 3113, Loss: 0.053989749401807785\n",
      "Iteration 3114, Loss: 0.054171543568372726\n",
      "Iteration 3115, Loss: 0.05398954451084137\n",
      "Iteration 3116, Loss: 0.054171811789274216\n",
      "Iteration 3117, Loss: 0.0539894662797451\n",
      "Iteration 3118, Loss: 0.054171741008758545\n",
      "Iteration 3119, Loss: 0.05398935079574585\n",
      "Iteration 3120, Loss: 0.05417182296514511\n",
      "Iteration 3121, Loss: 0.05398938059806824\n",
      "Iteration 3122, Loss: 0.054171934723854065\n",
      "Iteration 3123, Loss: 0.05398935079574585\n",
      "Iteration 3124, Loss: 0.05417178198695183\n",
      "Iteration 3125, Loss: 0.05398935079574585\n",
      "Iteration 3126, Loss: 0.054171621799468994\n",
      "Iteration 3127, Loss: 0.0539894700050354\n",
      "Iteration 3128, Loss: 0.054171618074178696\n",
      "Iteration 3129, Loss: 0.053989630192518234\n",
      "Iteration 3130, Loss: 0.05417146533727646\n",
      "Iteration 3131, Loss: 0.05398981273174286\n",
      "Iteration 3132, Loss: 0.054171543568372726\n",
      "Iteration 3133, Loss: 0.05398965999484062\n",
      "Iteration 3134, Loss: 0.0541716143488884\n",
      "Iteration 3135, Loss: 0.05398965999484062\n",
      "Iteration 3136, Loss: 0.05417139083147049\n",
      "Iteration 3137, Loss: 0.05398965999484062\n",
      "Iteration 3138, Loss: 0.05417150259017944\n",
      "Iteration 3139, Loss: 0.05398977920413017\n",
      "Iteration 3140, Loss: 0.054171543568372726\n",
      "Iteration 3141, Loss: 0.053989700973033905\n",
      "Iteration 3142, Loss: 0.05417146533727646\n",
      "Iteration 3143, Loss: 0.05398958921432495\n",
      "Iteration 3144, Loss: 0.05417146533727646\n",
      "Iteration 3145, Loss: 0.05398958921432495\n",
      "Iteration 3146, Loss: 0.054171543568372726\n",
      "Iteration 3147, Loss: 0.05398977920413017\n",
      "Iteration 3148, Loss: 0.0541716143488884\n",
      "Iteration 3149, Loss: 0.05398973822593689\n",
      "Iteration 3150, Loss: 0.05417165160179138\n",
      "Iteration 3151, Loss: 0.05398961901664734\n",
      "Iteration 3152, Loss: 0.054171692579984665\n",
      "Iteration 3153, Loss: 0.05398965999484062\n",
      "Iteration 3154, Loss: 0.05417166277766228\n",
      "Iteration 3155, Loss: 0.05398961901664734\n",
      "Iteration 3156, Loss: 0.05417166277766228\n",
      "Iteration 3157, Loss: 0.05398954078555107\n",
      "Iteration 3158, Loss: 0.05417171120643616\n",
      "Iteration 3159, Loss: 0.05398942530155182\n",
      "Iteration 3160, Loss: 0.05417178198695183\n",
      "Iteration 3161, Loss: 0.05398938059806824\n",
      "Iteration 3162, Loss: 0.054171979427337646\n",
      "Iteration 3163, Loss: 0.05398934707045555\n",
      "Iteration 3164, Loss: 0.05417202040553093\n",
      "Iteration 3165, Loss: 0.05398907512426376\n",
      "Iteration 3166, Loss: 0.054172366857528687\n",
      "Iteration 3167, Loss: 0.05398888140916824\n",
      "Iteration 3168, Loss: 0.05417248606681824\n",
      "Iteration 3169, Loss: 0.05398867651820183\n",
      "Iteration 3170, Loss: 0.054172419011592865\n",
      "Iteration 3171, Loss: 0.053988873958587646\n",
      "Iteration 3172, Loss: 0.05417228862643242\n",
      "Iteration 3173, Loss: 0.05398891866207123\n",
      "Iteration 3174, Loss: 0.05417201668024063\n",
      "Iteration 3175, Loss: 0.053989227861166\n",
      "Iteration 3176, Loss: 0.054171815514564514\n",
      "Iteration 3177, Loss: 0.05398954078555107\n",
      "Iteration 3178, Loss: 0.05417158827185631\n",
      "Iteration 3179, Loss: 0.05398961901664734\n",
      "Iteration 3180, Loss: 0.054171621799468994\n",
      "Iteration 3181, Loss: 0.053989700973033905\n",
      "Iteration 3182, Loss: 0.054171621799468994\n",
      "Iteration 3183, Loss: 0.05398961901664734\n",
      "Iteration 3184, Loss: 0.05417178198695183\n",
      "Iteration 3185, Loss: 0.05398935079574585\n",
      "Iteration 3186, Loss: 0.05417202040553093\n",
      "Iteration 3187, Loss: 0.05398911237716675\n",
      "Iteration 3188, Loss: 0.05417218059301376\n",
      "Iteration 3189, Loss: 0.05398903042078018\n",
      "Iteration 3190, Loss: 0.05417213961482048\n",
      "Iteration 3191, Loss: 0.05398906394839287\n",
      "Iteration 3192, Loss: 0.05417216941714287\n",
      "Iteration 3193, Loss: 0.053989142179489136\n",
      "Iteration 3194, Loss: 0.05417190119624138\n",
      "Iteration 3195, Loss: 0.0539894625544548\n",
      "Iteration 3196, Loss: 0.054171666502952576\n",
      "Iteration 3197, Loss: 0.053989510983228683\n",
      "Iteration 3198, Loss: 0.05417151376605034\n",
      "Iteration 3199, Loss: 0.05398955196142197\n",
      "Iteration 3200, Loss: 0.054171543568372726\n",
      "Iteration 3201, Loss: 0.05398973822593689\n",
      "Iteration 3202, Loss: 0.054171621799468994\n",
      "Iteration 3203, Loss: 0.053989656269550323\n",
      "Iteration 3204, Loss: 0.0541718527674675\n",
      "Iteration 3205, Loss: 0.053989388048648834\n",
      "Iteration 3206, Loss: 0.05417202040553093\n",
      "Iteration 3207, Loss: 0.05398915335536003\n",
      "Iteration 3208, Loss: 0.054172247648239136\n",
      "Iteration 3209, Loss: 0.05398906394839287\n",
      "Iteration 3210, Loss: 0.05417225882411003\n",
      "Iteration 3211, Loss: 0.0539889894425869\n",
      "Iteration 3212, Loss: 0.05417216941714287\n",
      "Iteration 3213, Loss: 0.053989142179489136\n",
      "Iteration 3214, Loss: 0.05417174845933914\n",
      "Iteration 3215, Loss: 0.05398935079574585\n",
      "Iteration 3216, Loss: 0.05417158454656601\n",
      "Iteration 3217, Loss: 0.053989700973033905\n",
      "Iteration 3218, Loss: 0.054171543568372726\n",
      "Iteration 3219, Loss: 0.05398973822593689\n",
      "Iteration 3220, Loss: 0.054171621799468994\n",
      "Iteration 3221, Loss: 0.053989700973033905\n",
      "Iteration 3222, Loss: 0.05417166277766228\n",
      "Iteration 3223, Loss: 0.05398927628993988\n",
      "Iteration 3224, Loss: 0.05417197570204735\n",
      "Iteration 3225, Loss: 0.053989119827747345\n",
      "Iteration 3226, Loss: 0.05417205020785332\n",
      "Iteration 3227, Loss: 0.0539892315864563\n",
      "Iteration 3228, Loss: 0.05417202040553093\n",
      "Iteration 3229, Loss: 0.05398915335536003\n",
      "Iteration 3230, Loss: 0.05417202040553093\n",
      "Iteration 3231, Loss: 0.05398915335536003\n",
      "Iteration 3232, Loss: 0.05417186766862869\n",
      "Iteration 3233, Loss: 0.0539892315864563\n",
      "Iteration 3234, Loss: 0.0541718564927578\n",
      "Iteration 3235, Loss: 0.05398935079574585\n",
      "Iteration 3236, Loss: 0.05417170375585556\n",
      "Iteration 3237, Loss: 0.05398954078555107\n",
      "Iteration 3238, Loss: 0.054171930998563766\n",
      "Iteration 3239, Loss: 0.053989313542842865\n",
      "Iteration 3240, Loss: 0.054172009229660034\n",
      "Iteration 3241, Loss: 0.05398930236697197\n",
      "Iteration 3242, Loss: 0.05417190119624138\n",
      "Iteration 3243, Loss: 0.05398915708065033\n",
      "Iteration 3244, Loss: 0.054171934723854065\n",
      "Iteration 3245, Loss: 0.0539894625544548\n",
      "Iteration 3246, Loss: 0.054171930998563766\n",
      "Iteration 3247, Loss: 0.05398942157626152\n",
      "Iteration 3248, Loss: 0.05417170748114586\n",
      "Iteration 3249, Loss: 0.05398954451084137\n",
      "Iteration 3250, Loss: 0.05417182296514511\n",
      "Iteration 3251, Loss: 0.05398949980735779\n",
      "Iteration 3252, Loss: 0.054171934723854065\n",
      "Iteration 3253, Loss: 0.05398927256464958\n",
      "Iteration 3254, Loss: 0.054172053933143616\n",
      "Iteration 3255, Loss: 0.05398911237716675\n",
      "Iteration 3256, Loss: 0.054172128438949585\n",
      "Iteration 3257, Loss: 0.05398903042078018\n",
      "Iteration 3258, Loss: 0.05417218059301376\n",
      "Iteration 3259, Loss: 0.053989067673683167\n",
      "Iteration 3260, Loss: 0.054172247648239136\n",
      "Iteration 3261, Loss: 0.05398907512426376\n",
      "Iteration 3262, Loss: 0.054172128438949585\n",
      "Iteration 3263, Loss: 0.053989194333553314\n",
      "Iteration 3264, Loss: 0.05417197197675705\n",
      "Iteration 3265, Loss: 0.05398934707045555\n",
      "Iteration 3266, Loss: 0.05417178198695183\n",
      "Iteration 3267, Loss: 0.05398942157626152\n",
      "Iteration 3268, Loss: 0.054171741008758545\n",
      "Iteration 3269, Loss: 0.053989581763744354\n",
      "Iteration 3270, Loss: 0.05417166277766228\n",
      "Iteration 3271, Loss: 0.053989581763744354\n",
      "Iteration 3272, Loss: 0.054171741008758545\n",
      "Iteration 3273, Loss: 0.0539894625544548\n",
      "Iteration 3274, Loss: 0.05417194217443466\n",
      "Iteration 3275, Loss: 0.053989194333553314\n",
      "Iteration 3276, Loss: 0.054172173142433167\n",
      "Iteration 3277, Loss: 0.05398903414607048\n",
      "Iteration 3278, Loss: 0.05417218059301376\n",
      "Iteration 3279, Loss: 0.05398903414607048\n",
      "Iteration 3280, Loss: 0.054172106087207794\n",
      "Iteration 3281, Loss: 0.05398911237716675\n",
      "Iteration 3282, Loss: 0.0541720911860466\n",
      "Iteration 3283, Loss: 0.053989194333553314\n",
      "Iteration 3284, Loss: 0.05417197197675705\n",
      "Iteration 3285, Loss: 0.05398934334516525\n",
      "Iteration 3286, Loss: 0.054171930998563766\n",
      "Iteration 3287, Loss: 0.0539894625544548\n",
      "Iteration 3288, Loss: 0.0541718527674675\n",
      "Iteration 3289, Loss: 0.05398949980735779\n",
      "Iteration 3290, Loss: 0.054171860218048096\n",
      "Iteration 3291, Loss: 0.05398938059806824\n",
      "Iteration 3292, Loss: 0.05417201668024063\n",
      "Iteration 3293, Loss: 0.0539892241358757\n",
      "Iteration 3294, Loss: 0.0541720949113369\n",
      "Iteration 3295, Loss: 0.05398918315768242\n",
      "Iteration 3296, Loss: 0.05417216941714287\n",
      "Iteration 3297, Loss: 0.053989067673683167\n",
      "Iteration 3298, Loss: 0.05417216941714287\n",
      "Iteration 3299, Loss: 0.05398910865187645\n",
      "Iteration 3300, Loss: 0.05417171120643616\n",
      "Iteration 3301, Loss: 0.05398938059806824\n",
      "Iteration 3302, Loss: 0.05417158827185631\n",
      "Iteration 3303, Loss: 0.05398965999484062\n",
      "Iteration 3304, Loss: 0.05417143553495407\n",
      "Iteration 3305, Loss: 0.05398967117071152\n",
      "Iteration 3306, Loss: 0.05417150259017944\n",
      "Iteration 3307, Loss: 0.05398973822593689\n",
      "Iteration 3308, Loss: 0.05417169630527496\n",
      "Iteration 3309, Loss: 0.05398954078555107\n",
      "Iteration 3310, Loss: 0.05417197197675705\n",
      "Iteration 3311, Loss: 0.053989194333553314\n",
      "Iteration 3312, Loss: 0.0541720911860466\n",
      "Iteration 3313, Loss: 0.053989194333553314\n",
      "Iteration 3314, Loss: 0.05417194217443466\n",
      "Iteration 3315, Loss: 0.053989313542842865\n",
      "Iteration 3316, Loss: 0.054172009229660034\n",
      "Iteration 3317, Loss: 0.0539892315864563\n",
      "Iteration 3318, Loss: 0.054172053933143616\n",
      "Iteration 3319, Loss: 0.05398910865187645\n",
      "Iteration 3320, Loss: 0.054172173142433167\n",
      "Iteration 3321, Loss: 0.05398918315768242\n",
      "Iteration 3322, Loss: 0.05417206138372421\n",
      "Iteration 3323, Loss: 0.05398915335536003\n",
      "Iteration 3324, Loss: 0.054172124713659286\n",
      "Iteration 3325, Loss: 0.053989194333553314\n",
      "Iteration 3326, Loss: 0.05417197197675705\n",
      "Iteration 3327, Loss: 0.05398934707045555\n",
      "Iteration 3328, Loss: 0.054171960800886154\n",
      "Iteration 3329, Loss: 0.05398942530155182\n",
      "Iteration 3330, Loss: 0.054171741008758545\n",
      "Iteration 3331, Loss: 0.0539894625544548\n",
      "Iteration 3332, Loss: 0.05417177826166153\n",
      "Iteration 3333, Loss: 0.0539894625544548\n",
      "Iteration 3334, Loss: 0.054171815514564514\n",
      "Iteration 3335, Loss: 0.0539894625544548\n",
      "Iteration 3336, Loss: 0.05417182296514511\n",
      "Iteration 3337, Loss: 0.05398949980735779\n",
      "Iteration 3338, Loss: 0.0541718527674675\n",
      "Iteration 3339, Loss: 0.05398949980735779\n",
      "Iteration 3340, Loss: 0.054171930998563766\n",
      "Iteration 3341, Loss: 0.05398985743522644\n",
      "Iteration 3342, Loss: 0.054172128438949585\n",
      "Iteration 3343, Loss: 0.053989581763744354\n",
      "Iteration 3344, Loss: 0.054172247648239136\n",
      "Iteration 3345, Loss: 0.05398958548903465\n",
      "Iteration 3346, Loss: 0.054172612726688385\n",
      "Iteration 3347, Loss: 0.05398958548903465\n",
      "Iteration 3348, Loss: 0.05417237803339958\n",
      "Iteration 3349, Loss: 0.053989749401807785\n",
      "Iteration 3350, Loss: 0.05417218059301376\n",
      "Iteration 3351, Loss: 0.053990017622709274\n",
      "Iteration 3352, Loss: 0.05417216941714287\n",
      "Iteration 3353, Loss: 0.05399005860090256\n",
      "Iteration 3354, Loss: 0.05417213961482048\n",
      "Iteration 3355, Loss: 0.05399009585380554\n",
      "Iteration 3356, Loss: 0.05417213961482048\n",
      "Iteration 3357, Loss: 0.05399013310670853\n",
      "Iteration 3358, Loss: 0.0541723296046257\n",
      "Iteration 3359, Loss: 0.05398997664451599\n",
      "Iteration 3360, Loss: 0.05417252331972122\n",
      "Iteration 3361, Loss: 0.05398973822593689\n",
      "Iteration 3362, Loss: 0.05417264997959137\n",
      "Iteration 3363, Loss: 0.0539894625544548\n",
      "Iteration 3364, Loss: 0.05417269095778465\n",
      "Iteration 3365, Loss: 0.053989432752132416\n",
      "Iteration 3366, Loss: 0.0541725680232048\n",
      "Iteration 3367, Loss: 0.05398955196142197\n",
      "Iteration 3368, Loss: 0.0541723370552063\n",
      "Iteration 3369, Loss: 0.053989969193935394\n",
      "Iteration 3370, Loss: 0.054172173142433167\n",
      "Iteration 3371, Loss: 0.053990017622709274\n",
      "Iteration 3372, Loss: 0.054171979427337646\n",
      "Iteration 3373, Loss: 0.05399017781019211\n",
      "Iteration 3374, Loss: 0.054172009229660034\n",
      "Iteration 3375, Loss: 0.053990285843610764\n",
      "Iteration 3376, Loss: 0.054171979427337646\n",
      "Iteration 3377, Loss: 0.053990062326192856\n",
      "Iteration 3378, Loss: 0.054172128438949585\n",
      "Iteration 3379, Loss: 0.05399005115032196\n",
      "Iteration 3380, Loss: 0.05417237430810928\n",
      "Iteration 3381, Loss: 0.05398974567651749\n",
      "Iteration 3382, Loss: 0.054172538220882416\n",
      "Iteration 3383, Loss: 0.053989510983228683\n",
      "Iteration 3384, Loss: 0.05417264997959137\n",
      "Iteration 3385, Loss: 0.053989432752132416\n",
      "Iteration 3386, Loss: 0.05417264625430107\n",
      "Iteration 3387, Loss: 0.0539894700050354\n",
      "Iteration 3388, Loss: 0.05417230725288391\n",
      "Iteration 3389, Loss: 0.0539897084236145\n",
      "Iteration 3390, Loss: 0.05417213961482048\n",
      "Iteration 3391, Loss: 0.05398998782038689\n",
      "Iteration 3392, Loss: 0.05417198687791824\n",
      "Iteration 3393, Loss: 0.05399010702967644\n",
      "Iteration 3394, Loss: 0.054171979427337646\n",
      "Iteration 3395, Loss: 0.053990136831998825\n",
      "Iteration 3396, Loss: 0.05417213588953018\n",
      "Iteration 3397, Loss: 0.05398998782038689\n",
      "Iteration 3398, Loss: 0.05417241156101227\n",
      "Iteration 3399, Loss: 0.0539897084236145\n",
      "Iteration 3400, Loss: 0.05417249724268913\n",
      "Iteration 3401, Loss: 0.0539894700050354\n",
      "Iteration 3402, Loss: 0.054172582924366\n",
      "Iteration 3403, Loss: 0.05398940294981003\n",
      "Iteration 3404, Loss: 0.0541725680232048\n",
      "Iteration 3405, Loss: 0.05398974567651749\n",
      "Iteration 3406, Loss: 0.05417225882411003\n",
      "Iteration 3407, Loss: 0.053989868611097336\n",
      "Iteration 3408, Loss: 0.0541720986366272\n",
      "Iteration 3409, Loss: 0.05399002879858017\n",
      "Iteration 3410, Loss: 0.0541720986366272\n",
      "Iteration 3411, Loss: 0.05399002879858017\n",
      "Iteration 3412, Loss: 0.054172106087207794\n",
      "Iteration 3413, Loss: 0.053990017622709274\n",
      "Iteration 3414, Loss: 0.054172299802303314\n",
      "Iteration 3415, Loss: 0.05398979038000107\n",
      "Iteration 3416, Loss: 0.05417249724268913\n",
      "Iteration 3417, Loss: 0.0539894700050354\n",
      "Iteration 3418, Loss: 0.0541725754737854\n",
      "Iteration 3419, Loss: 0.053989436477422714\n",
      "Iteration 3420, Loss: 0.05417260527610779\n",
      "Iteration 3421, Loss: 0.05398961901664734\n",
      "Iteration 3422, Loss: 0.0541725680232048\n",
      "Iteration 3423, Loss: 0.05398967117071152\n",
      "Iteration 3424, Loss: 0.05417240783572197\n",
      "Iteration 3425, Loss: 0.053989749401807785\n",
      "Iteration 3426, Loss: 0.054172225296497345\n",
      "Iteration 3427, Loss: 0.053989749401807785\n",
      "Iteration 3428, Loss: 0.054172299802303314\n",
      "Iteration 3429, Loss: 0.053989674896001816\n",
      "Iteration 3430, Loss: 0.05417221784591675\n",
      "Iteration 3431, Loss: 0.053989823907613754\n",
      "Iteration 3432, Loss: 0.054172333329916\n",
      "Iteration 3433, Loss: 0.053989868611097336\n",
      "Iteration 3434, Loss: 0.05417244881391525\n",
      "Iteration 3435, Loss: 0.05398985743522644\n",
      "Iteration 3436, Loss: 0.05417237803339958\n",
      "Iteration 3437, Loss: 0.05398967117071152\n",
      "Iteration 3438, Loss: 0.0541723370552063\n",
      "Iteration 3439, Loss: 0.053989700973033905\n",
      "Iteration 3440, Loss: 0.05417240783572197\n",
      "Iteration 3441, Loss: 0.05398978292942047\n",
      "Iteration 3442, Loss: 0.0541723296046257\n",
      "Iteration 3443, Loss: 0.05398986488580704\n",
      "Iteration 3444, Loss: 0.054172106087207794\n",
      "Iteration 3445, Loss: 0.05398979038000107\n",
      "Iteration 3446, Loss: 0.05417218431830406\n",
      "Iteration 3447, Loss: 0.053989898413419724\n",
      "Iteration 3448, Loss: 0.05417225882411003\n",
      "Iteration 3449, Loss: 0.053989898413419724\n",
      "Iteration 3450, Loss: 0.054172299802303314\n",
      "Iteration 3451, Loss: 0.05398985743522644\n",
      "Iteration 3452, Loss: 0.05417248606681824\n",
      "Iteration 3453, Loss: 0.053989630192518234\n",
      "Iteration 3454, Loss: 0.054172419011592865\n",
      "Iteration 3455, Loss: 0.05398958921432495\n",
      "Iteration 3456, Loss: 0.05417240783572197\n",
      "Iteration 3457, Loss: 0.053989704698324203\n",
      "Iteration 3458, Loss: 0.05417230352759361\n",
      "Iteration 3459, Loss: 0.053989704698324203\n",
      "Iteration 3460, Loss: 0.054172366857528687\n",
      "Iteration 3461, Loss: 0.05398985743522644\n",
      "Iteration 3462, Loss: 0.0541723296046257\n",
      "Iteration 3463, Loss: 0.05398990213871002\n",
      "Iteration 3464, Loss: 0.05417225882411003\n",
      "Iteration 3465, Loss: 0.05398993939161301\n",
      "Iteration 3466, Loss: 0.054172299802303314\n",
      "Iteration 3467, Loss: 0.053989898413419724\n",
      "Iteration 3468, Loss: 0.05417245626449585\n",
      "Iteration 3469, Loss: 0.053989700973033905\n",
      "Iteration 3470, Loss: 0.0541725680232048\n",
      "Iteration 3471, Loss: 0.05398955196142197\n",
      "Iteration 3472, Loss: 0.054172616451978683\n",
      "Iteration 3473, Loss: 0.05398939177393913\n",
      "Iteration 3474, Loss: 0.05417245626449585\n",
      "Iteration 3475, Loss: 0.05398973822593689\n",
      "Iteration 3476, Loss: 0.0541723370552063\n",
      "Iteration 3477, Loss: 0.05398979038000107\n",
      "Iteration 3478, Loss: 0.05417225882411003\n",
      "Iteration 3479, Loss: 0.05398993939161301\n",
      "Iteration 3480, Loss: 0.05417221412062645\n",
      "Iteration 3481, Loss: 0.05398993939161301\n",
      "Iteration 3482, Loss: 0.05417225882411003\n",
      "Iteration 3483, Loss: 0.05399000644683838\n",
      "Iteration 3484, Loss: 0.054172299802303314\n",
      "Iteration 3485, Loss: 0.053989823907613754\n",
      "Iteration 3486, Loss: 0.05417241156101227\n",
      "Iteration 3487, Loss: 0.053989820182323456\n",
      "Iteration 3488, Loss: 0.05417248606681824\n",
      "Iteration 3489, Loss: 0.05398978292942047\n",
      "Iteration 3490, Loss: 0.05417252704501152\n",
      "Iteration 3491, Loss: 0.05398977920413017\n",
      "Iteration 3492, Loss: 0.05417245253920555\n",
      "Iteration 3493, Loss: 0.05398973822593689\n",
      "Iteration 3494, Loss: 0.05417238175868988\n",
      "Iteration 3495, Loss: 0.05398973822593689\n",
      "Iteration 3496, Loss: 0.05417237430810928\n",
      "Iteration 3497, Loss: 0.053989704698324203\n",
      "Iteration 3498, Loss: 0.05417237430810928\n",
      "Iteration 3499, Loss: 0.0539897084236145\n",
      "Iteration 3500, Loss: 0.054172333329916\n",
      "Iteration 3501, Loss: 0.053989898413419724\n",
      "Iteration 3502, Loss: 0.05417218804359436\n",
      "Iteration 3503, Loss: 0.05398985743522644\n",
      "Iteration 3504, Loss: 0.05417237803339958\n",
      "Iteration 3505, Loss: 0.053989820182323456\n",
      "Iteration 3506, Loss: 0.05417248606681824\n",
      "Iteration 3507, Loss: 0.05398977920413017\n",
      "Iteration 3508, Loss: 0.05417237803339958\n",
      "Iteration 3509, Loss: 0.053989820182323456\n",
      "Iteration 3510, Loss: 0.054172419011592865\n",
      "Iteration 3511, Loss: 0.05398967117071152\n",
      "Iteration 3512, Loss: 0.05417244881391525\n",
      "Iteration 3513, Loss: 0.053989749401807785\n",
      "Iteration 3514, Loss: 0.054172333329916\n",
      "Iteration 3515, Loss: 0.05398979038000107\n",
      "Iteration 3516, Loss: 0.0541723296046257\n",
      "Iteration 3517, Loss: 0.05398993939161301\n",
      "Iteration 3518, Loss: 0.05417225509881973\n",
      "Iteration 3519, Loss: 0.05398993939161301\n",
      "Iteration 3520, Loss: 0.05417218059301376\n",
      "Iteration 3521, Loss: 0.05398985743522644\n",
      "Iteration 3522, Loss: 0.05417237430810928\n",
      "Iteration 3523, Loss: 0.053989775478839874\n",
      "Iteration 3524, Loss: 0.0541723370552063\n",
      "Iteration 3525, Loss: 0.053989700973033905\n",
      "Iteration 3526, Loss: 0.05417240783572197\n",
      "Iteration 3527, Loss: 0.053989823907613754\n",
      "Iteration 3528, Loss: 0.05417229235172272\n",
      "Iteration 3529, Loss: 0.05398985743522644\n",
      "Iteration 3530, Loss: 0.05417214334011078\n",
      "Iteration 3531, Loss: 0.05398985743522644\n",
      "Iteration 3532, Loss: 0.05417221784591675\n",
      "Iteration 3533, Loss: 0.05398993939161301\n",
      "Iteration 3534, Loss: 0.05417225882411003\n",
      "Iteration 3535, Loss: 0.05398985743522644\n",
      "Iteration 3536, Loss: 0.054172419011592865\n",
      "Iteration 3537, Loss: 0.05398974567651749\n",
      "Iteration 3538, Loss: 0.05417249724268913\n",
      "Iteration 3539, Loss: 0.05398966372013092\n",
      "Iteration 3540, Loss: 0.05417260527610779\n",
      "Iteration 3541, Loss: 0.05398954451084137\n",
      "Iteration 3542, Loss: 0.05417276918888092\n",
      "Iteration 3543, Loss: 0.05398939177393913\n",
      "Iteration 3544, Loss: 0.054172810167074203\n",
      "Iteration 3545, Loss: 0.05398938059806824\n",
      "Iteration 3546, Loss: 0.05417276918888092\n",
      "Iteration 3547, Loss: 0.0539894662797451\n",
      "Iteration 3548, Loss: 0.05417245626449585\n",
      "Iteration 3549, Loss: 0.05398967117071152\n",
      "Iteration 3550, Loss: 0.05417221039533615\n",
      "Iteration 3551, Loss: 0.05399005860090256\n",
      "Iteration 3552, Loss: 0.05417190119624138\n",
      "Iteration 3553, Loss: 0.053990330547094345\n",
      "Iteration 3554, Loss: 0.05417194217443466\n",
      "Iteration 3555, Loss: 0.05399021506309509\n",
      "Iteration 3556, Loss: 0.05417213961482048\n",
      "Iteration 3557, Loss: 0.05398986488580704\n",
      "Iteration 3558, Loss: 0.05417249724268913\n",
      "Iteration 3559, Loss: 0.05398935824632645\n",
      "Iteration 3560, Loss: 0.054172735661268234\n",
      "Iteration 3561, Loss: 0.05398930609226227\n",
      "Iteration 3562, Loss: 0.0541728138923645\n",
      "Iteration 3563, Loss: 0.05398935079574585\n",
      "Iteration 3564, Loss: 0.05417269468307495\n",
      "Iteration 3565, Loss: 0.05398939549922943\n",
      "Iteration 3566, Loss: 0.05417264625430107\n",
      "Iteration 3567, Loss: 0.05398958548903465\n",
      "Iteration 3568, Loss: 0.054172299802303314\n",
      "Iteration 3569, Loss: 0.053989823907613754\n",
      "Iteration 3570, Loss: 0.054172173142433167\n",
      "Iteration 3571, Loss: 0.05399002134799957\n",
      "Iteration 3572, Loss: 0.054171979427337646\n",
      "Iteration 3573, Loss: 0.053990136831998825\n",
      "Iteration 3574, Loss: 0.054171979427337646\n",
      "Iteration 3575, Loss: 0.053990211337804794\n",
      "Iteration 3576, Loss: 0.05417199060320854\n",
      "Iteration 3577, Loss: 0.05399009585380554\n",
      "Iteration 3578, Loss: 0.05417218059301376\n",
      "Iteration 3579, Loss: 0.05398982763290405\n",
      "Iteration 3580, Loss: 0.054172299802303314\n",
      "Iteration 3581, Loss: 0.05398977920413017\n",
      "Iteration 3582, Loss: 0.05417245253920555\n",
      "Iteration 3583, Loss: 0.053989626467227936\n",
      "Iteration 3584, Loss: 0.05417241156101227\n",
      "Iteration 3585, Loss: 0.0539897084236145\n",
      "Iteration 3586, Loss: 0.05417210981249809\n",
      "Iteration 3587, Loss: 0.053989868611097336\n",
      "Iteration 3588, Loss: 0.05417194962501526\n",
      "Iteration 3589, Loss: 0.05399002879858017\n",
      "Iteration 3590, Loss: 0.05417198687791824\n",
      "Iteration 3591, Loss: 0.05399005860090256\n",
      "Iteration 3592, Loss: 0.05417221784591675\n",
      "Iteration 3593, Loss: 0.05398982763290405\n",
      "Iteration 3594, Loss: 0.05417248606681824\n",
      "Iteration 3595, Loss: 0.05398974567651749\n",
      "Iteration 3596, Loss: 0.05417237803339958\n",
      "Iteration 3597, Loss: 0.053989704698324203\n",
      "Iteration 3598, Loss: 0.05417229235172272\n",
      "Iteration 3599, Loss: 0.05398985743522644\n",
      "Iteration 3600, Loss: 0.05417225882411003\n",
      "Iteration 3601, Loss: 0.053989823907613754\n",
      "Iteration 3602, Loss: 0.054172299802303314\n",
      "Iteration 3603, Loss: 0.05398978292942047\n",
      "Iteration 3604, Loss: 0.05417237803339958\n",
      "Iteration 3605, Loss: 0.05398973822593689\n",
      "Iteration 3606, Loss: 0.05417245626449585\n",
      "Iteration 3607, Loss: 0.05398977920413017\n",
      "Iteration 3608, Loss: 0.05417249724268913\n",
      "Iteration 3609, Loss: 0.05398965999484062\n",
      "Iteration 3610, Loss: 0.054172612726688385\n",
      "Iteration 3611, Loss: 0.05398958548903465\n",
      "Iteration 3612, Loss: 0.05417249724268913\n",
      "Iteration 3613, Loss: 0.05398958548903465\n",
      "Iteration 3614, Loss: 0.05417248606681824\n",
      "Iteration 3615, Loss: 0.053989704698324203\n",
      "Iteration 3616, Loss: 0.05417221784591675\n",
      "Iteration 3617, Loss: 0.053989868611097336\n",
      "Iteration 3618, Loss: 0.05417213961482048\n",
      "Iteration 3619, Loss: 0.05399005860090256\n",
      "Iteration 3620, Loss: 0.05417202040553093\n",
      "Iteration 3621, Loss: 0.053990136831998825\n",
      "Iteration 3622, Loss: 0.05417216941714287\n",
      "Iteration 3623, Loss: 0.05399009585380554\n",
      "Iteration 3624, Loss: 0.054172299802303314\n",
      "Iteration 3625, Loss: 0.053989820182323456\n",
      "Iteration 3626, Loss: 0.05417245626449585\n",
      "Iteration 3627, Loss: 0.05398965999484062\n",
      "Iteration 3628, Loss: 0.0541725680232048\n",
      "Iteration 3629, Loss: 0.0539894700050354\n",
      "Iteration 3630, Loss: 0.054172493517398834\n",
      "Iteration 3631, Loss: 0.05398958921432495\n",
      "Iteration 3632, Loss: 0.054172299802303314\n",
      "Iteration 3633, Loss: 0.05398982763290405\n",
      "Iteration 3634, Loss: 0.05417210981249809\n",
      "Iteration 3635, Loss: 0.05398993939161301\n",
      "Iteration 3636, Loss: 0.05417218059301376\n",
      "Iteration 3637, Loss: 0.05399004742503166\n",
      "Iteration 3638, Loss: 0.05417225882411003\n",
      "Iteration 3639, Loss: 0.053989820182323456\n",
      "Iteration 3640, Loss: 0.05417249724268913\n",
      "Iteration 3641, Loss: 0.05398973450064659\n",
      "Iteration 3642, Loss: 0.05417264997959137\n",
      "Iteration 3643, Loss: 0.05398954078555107\n",
      "Iteration 3644, Loss: 0.054172664880752563\n",
      "Iteration 3645, Loss: 0.05398939177393913\n",
      "Iteration 3646, Loss: 0.054172735661268234\n",
      "Iteration 3647, Loss: 0.053989313542842865\n",
      "Iteration 3648, Loss: 0.05417277663946152\n",
      "Iteration 3649, Loss: 0.05398935079574585\n",
      "Iteration 3650, Loss: 0.05417250096797943\n",
      "Iteration 3651, Loss: 0.05398973822593689\n",
      "Iteration 3652, Loss: 0.05417248606681824\n",
      "Iteration 3653, Loss: 0.05398973822593689\n",
      "Iteration 3654, Loss: 0.05417221784591675\n",
      "Iteration 3655, Loss: 0.05398997664451599\n",
      "Iteration 3656, Loss: 0.0541720986366272\n",
      "Iteration 3657, Loss: 0.05399002879858017\n",
      "Iteration 3658, Loss: 0.05417213961482048\n",
      "Iteration 3659, Loss: 0.05398998782038689\n",
      "Iteration 3660, Loss: 0.05417202040553093\n",
      "Iteration 3661, Loss: 0.05399002134799957\n",
      "Iteration 3662, Loss: 0.054172031581401825\n",
      "Iteration 3663, Loss: 0.05399009585380554\n",
      "Iteration 3664, Loss: 0.05417221784591675\n",
      "Iteration 3665, Loss: 0.053989898413419724\n",
      "Iteration 3666, Loss: 0.05417237803339958\n",
      "Iteration 3667, Loss: 0.05398974567651749\n",
      "Iteration 3668, Loss: 0.054172538220882416\n",
      "Iteration 3669, Loss: 0.053989581763744354\n",
      "Iteration 3670, Loss: 0.05417264997959137\n",
      "Iteration 3671, Loss: 0.053989630192518234\n",
      "Iteration 3672, Loss: 0.05417245626449585\n",
      "Iteration 3673, Loss: 0.053989749401807785\n",
      "Iteration 3674, Loss: 0.054172299802303314\n",
      "Iteration 3675, Loss: 0.05398979038000107\n",
      "Iteration 3676, Loss: 0.05417221784591675\n",
      "Iteration 3677, Loss: 0.05398993939161301\n",
      "Iteration 3678, Loss: 0.05417218059301376\n",
      "Iteration 3679, Loss: 0.05398993939161301\n",
      "Iteration 3680, Loss: 0.054172366857528687\n",
      "Iteration 3681, Loss: 0.05398979038000107\n",
      "Iteration 3682, Loss: 0.05417245253920555\n",
      "Iteration 3683, Loss: 0.05398977920413017\n",
      "Iteration 3684, Loss: 0.05417248606681824\n",
      "Iteration 3685, Loss: 0.053989555686712265\n",
      "Iteration 3686, Loss: 0.05417241156101227\n",
      "Iteration 3687, Loss: 0.05398985743522644\n",
      "Iteration 3688, Loss: 0.054172299802303314\n",
      "Iteration 3689, Loss: 0.05398992821574211\n",
      "Iteration 3690, Loss: 0.0541723370552063\n",
      "Iteration 3691, Loss: 0.053989820182323456\n",
      "Iteration 3692, Loss: 0.05417249724268913\n",
      "Iteration 3693, Loss: 0.05398954451084137\n",
      "Iteration 3694, Loss: 0.054172419011592865\n",
      "Iteration 3695, Loss: 0.05398955196142197\n",
      "Iteration 3696, Loss: 0.0541723370552063\n",
      "Iteration 3697, Loss: 0.05398966372013092\n",
      "Iteration 3698, Loss: 0.05417237803339958\n",
      "Iteration 3699, Loss: 0.05398966372013092\n",
      "Iteration 3700, Loss: 0.05417244881391525\n",
      "Iteration 3701, Loss: 0.05398977920413017\n",
      "Iteration 3702, Loss: 0.05417240411043167\n",
      "Iteration 3703, Loss: 0.05398982763290405\n",
      "Iteration 3704, Loss: 0.05417218059301376\n",
      "Iteration 3705, Loss: 0.05398993939161301\n",
      "Iteration 3706, Loss: 0.05417213961482048\n",
      "Iteration 3707, Loss: 0.05398993939161301\n",
      "Iteration 3708, Loss: 0.05417213961482048\n",
      "Iteration 3709, Loss: 0.053990017622709274\n",
      "Iteration 3710, Loss: 0.05417221412062645\n",
      "Iteration 3711, Loss: 0.05398993939161301\n",
      "Iteration 3712, Loss: 0.05417240783572197\n",
      "Iteration 3713, Loss: 0.053989898413419724\n",
      "Iteration 3714, Loss: 0.05417245626449585\n",
      "Iteration 3715, Loss: 0.05398965999484062\n",
      "Iteration 3716, Loss: 0.05417272448539734\n",
      "Iteration 3717, Loss: 0.05398949980735779\n",
      "Iteration 3718, Loss: 0.05417254567146301\n",
      "Iteration 3719, Loss: 0.0539894700050354\n",
      "Iteration 3720, Loss: 0.05417238175868988\n",
      "Iteration 3721, Loss: 0.05398966372013092\n",
      "Iteration 3722, Loss: 0.05417218059301376\n",
      "Iteration 3723, Loss: 0.05398993939161301\n",
      "Iteration 3724, Loss: 0.05417218059301376\n",
      "Iteration 3725, Loss: 0.05398993939161301\n",
      "Iteration 3726, Loss: 0.054172106087207794\n",
      "Iteration 3727, Loss: 0.053990017622709274\n",
      "Iteration 3728, Loss: 0.05417225509881973\n",
      "Iteration 3729, Loss: 0.053989868611097336\n",
      "Iteration 3730, Loss: 0.054172299802303314\n",
      "Iteration 3731, Loss: 0.053989749401807785\n",
      "Iteration 3732, Loss: 0.05417245626449585\n",
      "Iteration 3733, Loss: 0.05398967117071152\n",
      "Iteration 3734, Loss: 0.05417264997959137\n",
      "Iteration 3735, Loss: 0.05398954078555107\n",
      "Iteration 3736, Loss: 0.05417276546359062\n",
      "Iteration 3737, Loss: 0.053989432752132416\n",
      "Iteration 3738, Loss: 0.054172687232494354\n",
      "Iteration 3739, Loss: 0.0539894700050354\n",
      "Iteration 3740, Loss: 0.05417237803339958\n",
      "Iteration 3741, Loss: 0.053989749401807785\n",
      "Iteration 3742, Loss: 0.05417218059301376\n",
      "Iteration 3743, Loss: 0.05398998782038689\n",
      "Iteration 3744, Loss: 0.05417187139391899\n",
      "Iteration 3745, Loss: 0.053990136831998825\n",
      "Iteration 3746, Loss: 0.05417187511920929\n",
      "Iteration 3747, Loss: 0.05399025231599808\n",
      "Iteration 3748, Loss: 0.0541720986366272\n",
      "Iteration 3749, Loss: 0.05398993939161301\n",
      "Iteration 3750, Loss: 0.0541723370552063\n",
      "Iteration 3751, Loss: 0.05398958921432495\n",
      "Iteration 3752, Loss: 0.054172538220882416\n",
      "Iteration 3753, Loss: 0.053989581763744354\n",
      "Iteration 3754, Loss: 0.05417269095778465\n",
      "Iteration 3755, Loss: 0.05398954078555107\n",
      "Iteration 3756, Loss: 0.05417265743017197\n",
      "Iteration 3757, Loss: 0.053989432752132416\n",
      "Iteration 3758, Loss: 0.054172616451978683\n",
      "Iteration 3759, Loss: 0.0539894700050354\n",
      "Iteration 3760, Loss: 0.05417230352759361\n",
      "Iteration 3761, Loss: 0.053989674896001816\n",
      "Iteration 3762, Loss: 0.05417218059301376\n",
      "Iteration 3763, Loss: 0.05398990958929062\n",
      "Iteration 3764, Loss: 0.05417194217443466\n",
      "Iteration 3765, Loss: 0.05399010702967644\n",
      "Iteration 3766, Loss: 0.054171979427337646\n",
      "Iteration 3767, Loss: 0.05399017035961151\n",
      "Iteration 3768, Loss: 0.05417206510901451\n",
      "Iteration 3769, Loss: 0.05398997664451599\n",
      "Iteration 3770, Loss: 0.05417244881391525\n",
      "Iteration 3771, Loss: 0.05398973822593689\n",
      "Iteration 3772, Loss: 0.05417260527610779\n",
      "Iteration 3773, Loss: 0.05398954451084137\n",
      "Iteration 3774, Loss: 0.05417269095778465\n",
      "Iteration 3775, Loss: 0.0539889857172966\n",
      "Iteration 3776, Loss: 0.054172854870557785\n",
      "Iteration 3777, Loss: 0.053988706320524216\n",
      "Iteration 3778, Loss: 0.05417357012629509\n",
      "Iteration 3779, Loss: 0.05398844927549362\n",
      "Iteration 3780, Loss: 0.054173216223716736\n",
      "Iteration 3781, Loss: 0.053988873958587646\n",
      "Iteration 3782, Loss: 0.05417277663946152\n",
      "Iteration 3783, Loss: 0.05398942157626152\n",
      "Iteration 3784, Loss: 0.054172366857528687\n",
      "Iteration 3785, Loss: 0.053989820182323456\n",
      "Iteration 3786, Loss: 0.05417206138372421\n",
      "Iteration 3787, Loss: 0.053989868611097336\n",
      "Iteration 3788, Loss: 0.05417202040553093\n",
      "Iteration 3789, Loss: 0.05398993939161301\n",
      "Iteration 3790, Loss: 0.05417216941714287\n",
      "Iteration 3791, Loss: 0.053989898413419724\n",
      "Iteration 3792, Loss: 0.05417216941714287\n",
      "Iteration 3793, Loss: 0.05398997664451599\n",
      "Iteration 3794, Loss: 0.05417206138372421\n",
      "Iteration 3795, Loss: 0.053990017622709274\n",
      "Iteration 3796, Loss: 0.05417199060320854\n",
      "Iteration 3797, Loss: 0.05398997664451599\n",
      "Iteration 3798, Loss: 0.05417221784591675\n",
      "Iteration 3799, Loss: 0.053989820182323456\n",
      "Iteration 3800, Loss: 0.054172299802303314\n",
      "Iteration 3801, Loss: 0.053989581763744354\n",
      "Iteration 3802, Loss: 0.05417242273688316\n",
      "Iteration 3803, Loss: 0.05398954078555107\n",
      "Iteration 3804, Loss: 0.05417245626449585\n",
      "Iteration 3805, Loss: 0.053989510983228683\n",
      "Iteration 3806, Loss: 0.054172419011592865\n",
      "Iteration 3807, Loss: 0.05398939177393913\n",
      "Iteration 3808, Loss: 0.05417245253920555\n",
      "Iteration 3809, Loss: 0.053989581763744354\n",
      "Iteration 3810, Loss: 0.054172299802303314\n",
      "Iteration 3811, Loss: 0.05398977920413017\n",
      "Iteration 3812, Loss: 0.05417221784591675\n",
      "Iteration 3813, Loss: 0.05398993939161301\n",
      "Iteration 3814, Loss: 0.05417221039533615\n",
      "Iteration 3815, Loss: 0.05398997664451599\n",
      "Iteration 3816, Loss: 0.054171979427337646\n",
      "Iteration 3817, Loss: 0.05398990958929062\n",
      "Iteration 3818, Loss: 0.054171979427337646\n",
      "Iteration 3819, Loss: 0.053990017622709274\n",
      "Iteration 3820, Loss: 0.05417213588953018\n",
      "Iteration 3821, Loss: 0.05398985743522644\n",
      "Iteration 3822, Loss: 0.0541723370552063\n",
      "Iteration 3823, Loss: 0.05398954078555107\n",
      "Iteration 3824, Loss: 0.054172538220882416\n",
      "Iteration 3825, Loss: 0.05398934707045555\n",
      "Iteration 3826, Loss: 0.05417246371507645\n",
      "Iteration 3827, Loss: 0.053989432752132416\n",
      "Iteration 3828, Loss: 0.05417237803339958\n",
      "Iteration 3829, Loss: 0.05398965999484062\n",
      "Iteration 3830, Loss: 0.05417225882411003\n",
      "Iteration 3831, Loss: 0.053989898413419724\n",
      "Iteration 3832, Loss: 0.05417202413082123\n",
      "Iteration 3833, Loss: 0.05399004742503166\n",
      "Iteration 3834, Loss: 0.05417194589972496\n",
      "Iteration 3835, Loss: 0.053990017622709274\n",
      "Iteration 3836, Loss: 0.054171979427337646\n",
      "Iteration 3837, Loss: 0.053990017622709274\n",
      "Iteration 3838, Loss: 0.05417213588953018\n",
      "Iteration 3839, Loss: 0.053989823907613754\n",
      "Iteration 3840, Loss: 0.05417225509881973\n",
      "Iteration 3841, Loss: 0.05398973822593689\n",
      "Iteration 3842, Loss: 0.05417252704501152\n",
      "Iteration 3843, Loss: 0.053989432752132416\n",
      "Iteration 3844, Loss: 0.05417250096797943\n",
      "Iteration 3845, Loss: 0.0539894662797451\n",
      "Iteration 3846, Loss: 0.054172493517398834\n",
      "Iteration 3847, Loss: 0.053989507257938385\n",
      "Iteration 3848, Loss: 0.05417237803339958\n",
      "Iteration 3849, Loss: 0.053989700973033905\n",
      "Iteration 3850, Loss: 0.05417241156101227\n",
      "Iteration 3851, Loss: 0.053989700973033905\n",
      "Iteration 3852, Loss: 0.05417225882411003\n",
      "Iteration 3853, Loss: 0.05398977920413017\n",
      "Iteration 3854, Loss: 0.05417225882411003\n",
      "Iteration 3855, Loss: 0.05398977920413017\n",
      "Iteration 3856, Loss: 0.054172269999980927\n",
      "Iteration 3857, Loss: 0.05398965999484062\n",
      "Iteration 3858, Loss: 0.054172538220882416\n",
      "Iteration 3859, Loss: 0.053989432752132416\n",
      "Iteration 3860, Loss: 0.054172612726688385\n",
      "Iteration 3861, Loss: 0.053989432752132416\n",
      "Iteration 3862, Loss: 0.0541725754737854\n",
      "Iteration 3863, Loss: 0.05398935079574585\n",
      "Iteration 3864, Loss: 0.054172419011592865\n",
      "Iteration 3865, Loss: 0.05398954078555107\n",
      "Iteration 3866, Loss: 0.054172419011592865\n",
      "Iteration 3867, Loss: 0.053989700973033905\n",
      "Iteration 3868, Loss: 0.05417221784591675\n",
      "Iteration 3869, Loss: 0.053989898413419724\n",
      "Iteration 3870, Loss: 0.05417213961482048\n",
      "Iteration 3871, Loss: 0.05398993939161301\n",
      "Iteration 3872, Loss: 0.05417210981249809\n",
      "Iteration 3873, Loss: 0.05398977920413017\n",
      "Iteration 3874, Loss: 0.05417237803339958\n",
      "Iteration 3875, Loss: 0.05398961901664734\n",
      "Iteration 3876, Loss: 0.05417250096797943\n",
      "Iteration 3877, Loss: 0.0539894625544548\n",
      "Iteration 3878, Loss: 0.054172616451978683\n",
      "Iteration 3879, Loss: 0.05398935079574585\n",
      "Iteration 3880, Loss: 0.05417238920927048\n",
      "Iteration 3881, Loss: 0.053989581763744354\n",
      "Iteration 3882, Loss: 0.05417237803339958\n",
      "Iteration 3883, Loss: 0.05398973822593689\n",
      "Iteration 3884, Loss: 0.05417218431830406\n",
      "Iteration 3885, Loss: 0.053989898413419724\n",
      "Iteration 3886, Loss: 0.05417202040553093\n",
      "Iteration 3887, Loss: 0.053989898413419724\n",
      "Iteration 3888, Loss: 0.054172031581401825\n",
      "Iteration 3889, Loss: 0.05398986488580704\n",
      "Iteration 3890, Loss: 0.05417214334011078\n",
      "Iteration 3891, Loss: 0.0539897084236145\n",
      "Iteration 3892, Loss: 0.054172299802303314\n",
      "Iteration 3893, Loss: 0.05398958921432495\n",
      "Iteration 3894, Loss: 0.05417225882411003\n",
      "Iteration 3895, Loss: 0.05398951470851898\n",
      "Iteration 3896, Loss: 0.054172299802303314\n",
      "Iteration 3897, Loss: 0.05398958921432495\n",
      "Iteration 3898, Loss: 0.054172299802303314\n",
      "Iteration 3899, Loss: 0.053989820182323456\n",
      "Iteration 3900, Loss: 0.05417225509881973\n",
      "Iteration 3901, Loss: 0.05398977920413017\n",
      "Iteration 3902, Loss: 0.05417225882411003\n",
      "Iteration 3903, Loss: 0.0539897084236145\n",
      "Iteration 3904, Loss: 0.054172299802303314\n",
      "Iteration 3905, Loss: 0.0539897084236145\n",
      "Iteration 3906, Loss: 0.05417238920927048\n",
      "Iteration 3907, Loss: 0.053989581763744354\n",
      "Iteration 3908, Loss: 0.05417238920927048\n",
      "Iteration 3909, Loss: 0.05398949980735779\n",
      "Iteration 3910, Loss: 0.05417238920927048\n",
      "Iteration 3911, Loss: 0.05398961901664734\n",
      "Iteration 3912, Loss: 0.05417249724268913\n",
      "Iteration 3913, Loss: 0.053989510983228683\n",
      "Iteration 3914, Loss: 0.054172419011592865\n",
      "Iteration 3915, Loss: 0.05398939177393913\n",
      "Iteration 3916, Loss: 0.05417237803339958\n",
      "Iteration 3917, Loss: 0.053989581763744354\n",
      "Iteration 3918, Loss: 0.054172299802303314\n",
      "Iteration 3919, Loss: 0.053988974541425705\n",
      "Iteration 3920, Loss: 0.054172106087207794\n",
      "Iteration 3921, Loss: 0.053989242762327194\n",
      "Iteration 3922, Loss: 0.05417190492153168\n",
      "Iteration 3923, Loss: 0.05398940294981003\n",
      "Iteration 3924, Loss: 0.05417116731405258\n",
      "Iteration 3925, Loss: 0.05398951470851898\n",
      "Iteration 3926, Loss: 0.05417116731405258\n",
      "Iteration 3927, Loss: 0.05398944020271301\n",
      "Iteration 3928, Loss: 0.054171524941921234\n",
      "Iteration 3929, Loss: 0.0539892315864563\n",
      "Iteration 3930, Loss: 0.05417183041572571\n",
      "Iteration 3931, Loss: 0.05398888513445854\n",
      "Iteration 3932, Loss: 0.05417191982269287\n",
      "Iteration 3933, Loss: 0.0539887361228466\n",
      "Iteration 3934, Loss: 0.0541718415915966\n",
      "Iteration 3935, Loss: 0.05398888513445854\n",
      "Iteration 3936, Loss: 0.05417172238230705\n",
      "Iteration 3937, Loss: 0.053989045321941376\n",
      "Iteration 3938, Loss: 0.0541716068983078\n",
      "Iteration 3939, Loss: 0.05398908257484436\n",
      "Iteration 3940, Loss: 0.05417156219482422\n",
      "Iteration 3941, Loss: 0.053989164531230927\n",
      "Iteration 3942, Loss: 0.054171524941921234\n",
      "Iteration 3943, Loss: 0.05398920178413391\n",
      "Iteration 3944, Loss: 0.05417148768901825\n",
      "Iteration 3945, Loss: 0.053989049047231674\n",
      "Iteration 3946, Loss: 0.05417155846953392\n",
      "Iteration 3947, Loss: 0.053988974541425705\n",
      "Iteration 3948, Loss: 0.05417156219482422\n",
      "Iteration 3949, Loss: 0.053989049047231674\n",
      "Iteration 3950, Loss: 0.05417167767882347\n",
      "Iteration 3951, Loss: 0.053989049047231674\n",
      "Iteration 3952, Loss: 0.05417156219482422\n",
      "Iteration 3953, Loss: 0.05398900434374809\n",
      "Iteration 3954, Loss: 0.05417171120643616\n",
      "Iteration 3955, Loss: 0.05398900434374809\n",
      "Iteration 3956, Loss: 0.0541716031730175\n",
      "Iteration 3957, Loss: 0.05398919805884361\n",
      "Iteration 3958, Loss: 0.05417156219482422\n",
      "Iteration 3959, Loss: 0.05398912727832794\n",
      "Iteration 3960, Loss: 0.05417144298553467\n",
      "Iteration 3961, Loss: 0.05398917198181152\n",
      "Iteration 3962, Loss: 0.054171524941921234\n",
      "Iteration 3963, Loss: 0.05398912355303764\n",
      "Iteration 3964, Loss: 0.05417168140411377\n",
      "Iteration 3965, Loss: 0.053989045321941376\n",
      "Iteration 3966, Loss: 0.054171763360500336\n",
      "Iteration 3967, Loss: 0.05398881062865257\n",
      "Iteration 3968, Loss: 0.05417172238230705\n",
      "Iteration 3969, Loss: 0.05398895964026451\n",
      "Iteration 3970, Loss: 0.0541716068983078\n",
      "Iteration 3971, Loss: 0.05398919805884361\n",
      "Iteration 3972, Loss: 0.054171524941921234\n",
      "Iteration 3973, Loss: 0.05398912727832794\n",
      "Iteration 3974, Loss: 0.05417148396372795\n",
      "Iteration 3975, Loss: 0.05398905277252197\n",
      "Iteration 3976, Loss: 0.05417156219482422\n",
      "Iteration 3977, Loss: 0.05398901551961899\n",
      "Iteration 3978, Loss: 0.05417156219482422\n",
      "Iteration 3979, Loss: 0.053988970816135406\n",
      "Iteration 3980, Loss: 0.05417175218462944\n",
      "Iteration 3981, Loss: 0.05398900806903839\n",
      "Iteration 3982, Loss: 0.05417172238230705\n",
      "Iteration 3983, Loss: 0.05398881435394287\n",
      "Iteration 3984, Loss: 0.05417172238230705\n",
      "Iteration 3985, Loss: 0.05398893356323242\n",
      "Iteration 3986, Loss: 0.0541716031730175\n",
      "Iteration 3987, Loss: 0.05398894101381302\n",
      "Iteration 3988, Loss: 0.054171524941921234\n",
      "Iteration 3989, Loss: 0.05398908257484436\n",
      "Iteration 3990, Loss: 0.05417148023843765\n",
      "Iteration 3991, Loss: 0.05398920178413391\n",
      "Iteration 3992, Loss: 0.05417148396372795\n",
      "Iteration 3993, Loss: 0.05398912355303764\n",
      "Iteration 3994, Loss: 0.0541716143488884\n",
      "Iteration 3995, Loss: 0.053988926112651825\n",
      "Iteration 3996, Loss: 0.05417191982269287\n",
      "Iteration 3997, Loss: 0.053988732397556305\n",
      "Iteration 3998, Loss: 0.05417197197675705\n",
      "Iteration 3999, Loss: 0.05398857593536377\n",
      "Iteration 4000, Loss: 0.054171960800886154\n",
      "Iteration 4001, Loss: 0.05398865044116974\n",
      "Iteration 4002, Loss: 0.05417187511920929\n",
      "Iteration 4003, Loss: 0.053988777101039886\n",
      "Iteration 4004, Loss: 0.05417168140411377\n",
      "Iteration 4005, Loss: 0.05398912355303764\n",
      "Iteration 4006, Loss: 0.05417140945792198\n",
      "Iteration 4007, Loss: 0.05398920923471451\n",
      "Iteration 4008, Loss: 0.05417124554514885\n",
      "Iteration 4009, Loss: 0.053989291191101074\n",
      "Iteration 4010, Loss: 0.0541711263358593\n",
      "Iteration 4011, Loss: 0.05398936569690704\n",
      "Iteration 4012, Loss: 0.05417116731405258\n",
      "Iteration 4013, Loss: 0.053989436477422714\n",
      "Iteration 4014, Loss: 0.05417140945792198\n",
      "Iteration 4015, Loss: 0.05398913472890854\n",
      "Iteration 4016, Loss: 0.05417172238230705\n",
      "Iteration 4017, Loss: 0.05398900434374809\n",
      "Iteration 4018, Loss: 0.05417191982269287\n",
      "Iteration 4019, Loss: 0.05398857593536377\n",
      "Iteration 4020, Loss: 0.054172080010175705\n",
      "Iteration 4021, Loss: 0.053988538682460785\n",
      "Iteration 4022, Loss: 0.0541718453168869\n",
      "Iteration 4023, Loss: 0.053988926112651825\n",
      "Iteration 4024, Loss: 0.0541716143488884\n",
      "Iteration 4025, Loss: 0.053989045321941376\n",
      "Iteration 4026, Loss: 0.05417148396372795\n",
      "Iteration 4027, Loss: 0.053989093750715256\n",
      "Iteration 4028, Loss: 0.05417129397392273\n",
      "Iteration 4029, Loss: 0.05398932099342346\n",
      "Iteration 4030, Loss: 0.05417124554514885\n",
      "Iteration 4031, Loss: 0.053989291191101074\n",
      "Iteration 4032, Loss: 0.05417124554514885\n",
      "Iteration 4033, Loss: 0.05398932099342346\n",
      "Iteration 4034, Loss: 0.0541713647544384\n",
      "Iteration 4035, Loss: 0.053989168256521225\n",
      "Iteration 4036, Loss: 0.05417151749134064\n",
      "Iteration 4037, Loss: 0.05398905277252197\n",
      "Iteration 4038, Loss: 0.054171644151210785\n",
      "Iteration 4039, Loss: 0.053988926112651825\n",
      "Iteration 4040, Loss: 0.05417175218462944\n",
      "Iteration 4041, Loss: 0.053988777101039886\n",
      "Iteration 4042, Loss: 0.05417175590991974\n",
      "Iteration 4043, Loss: 0.05398892983794212\n",
      "Iteration 4044, Loss: 0.054171763360500336\n",
      "Iteration 4045, Loss: 0.0539887361228466\n",
      "Iteration 4046, Loss: 0.054171718657016754\n",
      "Iteration 4047, Loss: 0.053988855332136154\n",
      "Iteration 4048, Loss: 0.054171718657016754\n",
      "Iteration 4049, Loss: 0.05398889631032944\n",
      "Iteration 4050, Loss: 0.05417172238230705\n",
      "Iteration 4051, Loss: 0.05398889631032944\n",
      "Iteration 4052, Loss: 0.054171718657016754\n",
      "Iteration 4053, Loss: 0.053988855332136154\n",
      "Iteration 4054, Loss: 0.0541716068983078\n",
      "Iteration 4055, Loss: 0.05398896336555481\n",
      "Iteration 4056, Loss: 0.054171569645404816\n",
      "Iteration 4057, Loss: 0.053988974541425705\n",
      "Iteration 4058, Loss: 0.05417156219482422\n",
      "Iteration 4059, Loss: 0.053989164531230927\n",
      "Iteration 4060, Loss: 0.05417151376605034\n",
      "Iteration 4061, Loss: 0.053989164531230927\n",
      "Iteration 4062, Loss: 0.05417156219482422\n",
      "Iteration 4063, Loss: 0.05398893356323242\n",
      "Iteration 4064, Loss: 0.0541716031730175\n",
      "Iteration 4065, Loss: 0.053988855332136154\n",
      "Iteration 4066, Loss: 0.054171767085790634\n",
      "Iteration 4067, Loss: 0.05398881062865257\n",
      "Iteration 4068, Loss: 0.054171886295080185\n",
      "Iteration 4069, Loss: 0.053988732397556305\n",
      "Iteration 4070, Loss: 0.054172150790691376\n",
      "Iteration 4071, Loss: 0.053988538682460785\n",
      "Iteration 4072, Loss: 0.054171960800886154\n",
      "Iteration 4073, Loss: 0.053988661617040634\n",
      "Iteration 4074, Loss: 0.05417179688811302\n",
      "Iteration 4075, Loss: 0.05398901551961899\n",
      "Iteration 4076, Loss: 0.05417148396372795\n",
      "Iteration 4077, Loss: 0.05398928374052048\n",
      "Iteration 4078, Loss: 0.05417117476463318\n",
      "Iteration 4079, Loss: 0.053989361971616745\n",
      "Iteration 4080, Loss: 0.05417116731405258\n",
      "Iteration 4081, Loss: 0.053989559412002563\n",
      "Iteration 4082, Loss: 0.05417121574282646\n",
      "Iteration 4083, Loss: 0.05398932844400406\n",
      "Iteration 4084, Loss: 0.05417140573263168\n",
      "Iteration 4085, Loss: 0.053989045321941376\n",
      "Iteration 4086, Loss: 0.05417183041572571\n",
      "Iteration 4087, Loss: 0.053988926112651825\n",
      "Iteration 4088, Loss: 0.054171960800886154\n",
      "Iteration 4089, Loss: 0.05398854613304138\n",
      "Iteration 4090, Loss: 0.054171886295080185\n",
      "Iteration 4091, Loss: 0.053988587111234665\n",
      "Iteration 4092, Loss: 0.05417183041572571\n",
      "Iteration 4093, Loss: 0.053988855332136154\n",
      "Iteration 4094, Loss: 0.054171591997146606\n",
      "Iteration 4095, Loss: 0.053989093750715256\n",
      "Iteration 4096, Loss: 0.05417124554514885\n",
      "Iteration 4097, Loss: 0.05398944020271301\n",
      "Iteration 4098, Loss: 0.0541711263358593\n",
      "Iteration 4099, Loss: 0.05398958921432495\n",
      "Iteration 4100, Loss: 0.05417116731405258\n",
      "Iteration 4101, Loss: 0.05398960039019585\n",
      "Iteration 4102, Loss: 0.054171085357666016\n",
      "Iteration 4103, Loss: 0.05398952215909958\n",
      "Iteration 4104, Loss: 0.054171256721019745\n",
      "Iteration 4105, Loss: 0.05398920178413391\n",
      "Iteration 4106, Loss: 0.054171573370695114\n",
      "Iteration 4107, Loss: 0.053988851606845856\n",
      "Iteration 4108, Loss: 0.05417191982269287\n",
      "Iteration 4109, Loss: 0.05398857593536377\n",
      "Iteration 4110, Loss: 0.054171960800886154\n",
      "Iteration 4111, Loss: 0.053988538682460785\n",
      "Iteration 4112, Loss: 0.0541718415915966\n",
      "Iteration 4113, Loss: 0.05398889631032944\n",
      "Iteration 4114, Loss: 0.054171450436115265\n",
      "Iteration 4115, Loss: 0.05398913472890854\n",
      "Iteration 4116, Loss: 0.05417105183005333\n",
      "Iteration 4117, Loss: 0.05398937314748764\n",
      "Iteration 4118, Loss: 0.05417077988386154\n",
      "Iteration 4119, Loss: 0.0539897195994854\n",
      "Iteration 4120, Loss: 0.05417066067457199\n",
      "Iteration 4121, Loss: 0.053989723324775696\n",
      "Iteration 4122, Loss: 0.05417073890566826\n",
      "Iteration 4123, Loss: 0.053989674896001816\n",
      "Iteration 4124, Loss: 0.0541711263358593\n",
      "Iteration 4125, Loss: 0.05398940294981003\n",
      "Iteration 4126, Loss: 0.05417148396372795\n",
      "Iteration 4127, Loss: 0.05398908257484436\n",
      "Iteration 4128, Loss: 0.05417167767882347\n",
      "Iteration 4129, Loss: 0.053988851606845856\n",
      "Iteration 4130, Loss: 0.054171763360500336\n",
      "Iteration 4131, Loss: 0.05398884415626526\n",
      "Iteration 4132, Loss: 0.054171644151210785\n",
      "Iteration 4133, Loss: 0.053988974541425705\n",
      "Iteration 4134, Loss: 0.05417144298553467\n",
      "Iteration 4135, Loss: 0.05398924648761749\n",
      "Iteration 4136, Loss: 0.05417124554514885\n",
      "Iteration 4137, Loss: 0.053989477455616\n",
      "Iteration 4138, Loss: 0.05417104810476303\n",
      "Iteration 4139, Loss: 0.053989481180906296\n",
      "Iteration 4140, Loss: 0.05417093262076378\n",
      "Iteration 4141, Loss: 0.05398960039019585\n",
      "Iteration 4142, Loss: 0.05417100712656975\n",
      "Iteration 4143, Loss: 0.05398964136838913\n",
      "Iteration 4144, Loss: 0.05417100712656975\n",
      "Iteration 4145, Loss: 0.053989484906196594\n",
      "Iteration 4146, Loss: 0.05417131632566452\n",
      "Iteration 4147, Loss: 0.05398932099342346\n",
      "Iteration 4148, Loss: 0.054171398282051086\n",
      "Iteration 4149, Loss: 0.05398920178413391\n",
      "Iteration 4150, Loss: 0.054171524941921234\n",
      "Iteration 4151, Loss: 0.05398908257484436\n",
      "Iteration 4152, Loss: 0.05417163297533989\n",
      "Iteration 4153, Loss: 0.05398908257484436\n",
      "Iteration 4154, Loss: 0.05417172238230705\n",
      "Iteration 4155, Loss: 0.053988970816135406\n",
      "Iteration 4156, Loss: 0.05417183041572571\n",
      "Iteration 4157, Loss: 0.053988855332136154\n",
      "Iteration 4158, Loss: 0.05417168140411377\n",
      "Iteration 4159, Loss: 0.05398896336555481\n",
      "Iteration 4160, Loss: 0.0541716031730175\n",
      "Iteration 4161, Loss: 0.053989045321941376\n",
      "Iteration 4162, Loss: 0.05417144298553467\n",
      "Iteration 4163, Loss: 0.05398917198181152\n",
      "Iteration 4164, Loss: 0.05417116731405258\n",
      "Iteration 4165, Loss: 0.053989555686712265\n",
      "Iteration 4166, Loss: 0.054171040654182434\n",
      "Iteration 4167, Loss: 0.053989678621292114\n",
      "Iteration 4168, Loss: 0.05417080968618393\n",
      "Iteration 4169, Loss: 0.053989753127098083\n",
      "Iteration 4170, Loss: 0.05417092144489288\n",
      "Iteration 4171, Loss: 0.05398960039019585\n",
      "Iteration 4172, Loss: 0.0541711263358593\n",
      "Iteration 4173, Loss: 0.05398944020271301\n",
      "Iteration 4174, Loss: 0.0541713647544384\n",
      "Iteration 4175, Loss: 0.05398920178413391\n",
      "Iteration 4176, Loss: 0.05417148396372795\n",
      "Iteration 4177, Loss: 0.053989045321941376\n",
      "Iteration 4178, Loss: 0.05417172238230705\n",
      "Iteration 4179, Loss: 0.05398881435394287\n",
      "Iteration 4180, Loss: 0.05417175218462944\n",
      "Iteration 4181, Loss: 0.05398925393819809\n",
      "Iteration 4182, Loss: 0.054171644151210785\n",
      "Iteration 4183, Loss: 0.05398960039019585\n",
      "Iteration 4184, Loss: 0.0541708841919899\n",
      "Iteration 4185, Loss: 0.053989946842193604\n",
      "Iteration 4186, Loss: 0.054170459508895874\n",
      "Iteration 4187, Loss: 0.05399003252387047\n",
      "Iteration 4188, Loss: 0.05417072772979736\n",
      "Iteration 4189, Loss: 0.053989946842193604\n",
      "Iteration 4190, Loss: 0.054171040654182434\n",
      "Iteration 4191, Loss: 0.053989749401807785\n",
      "Iteration 4192, Loss: 0.05417124554514885\n",
      "Iteration 4193, Loss: 0.053989361971616745\n",
      "Iteration 4194, Loss: 0.05417148768901825\n",
      "Iteration 4195, Loss: 0.053989045321941376\n",
      "Iteration 4196, Loss: 0.05417168140411377\n",
      "Iteration 4197, Loss: 0.05398892983794212\n",
      "Iteration 4198, Loss: 0.054171644151210785\n",
      "Iteration 4199, Loss: 0.053989049047231674\n",
      "Iteration 4200, Loss: 0.05417143926024437\n",
      "Iteration 4201, Loss: 0.05398932099342346\n",
      "Iteration 4202, Loss: 0.054171279072761536\n",
      "Iteration 4203, Loss: 0.05398952215909958\n",
      "Iteration 4204, Loss: 0.05417104810476303\n",
      "Iteration 4205, Loss: 0.05398945137858391\n",
      "Iteration 4206, Loss: 0.054171085357666016\n",
      "Iteration 4207, Loss: 0.05398952588438988\n",
      "Iteration 4208, Loss: 0.0541711263358593\n",
      "Iteration 4209, Loss: 0.05398952215909958\n",
      "Iteration 4210, Loss: 0.05417128652334213\n",
      "Iteration 4211, Loss: 0.05398937314748764\n",
      "Iteration 4212, Loss: 0.05417140573263168\n",
      "Iteration 4213, Loss: 0.053989361971616745\n",
      "Iteration 4214, Loss: 0.05417148023843765\n",
      "Iteration 4215, Loss: 0.053989361971616745\n",
      "Iteration 4216, Loss: 0.05417141318321228\n",
      "Iteration 4217, Loss: 0.05398920923471451\n",
      "Iteration 4218, Loss: 0.05417148396372795\n",
      "Iteration 4219, Loss: 0.053989168256521225\n",
      "Iteration 4220, Loss: 0.054171524941921234\n",
      "Iteration 4221, Loss: 0.05398925393819809\n",
      "Iteration 4222, Loss: 0.05417132377624512\n",
      "Iteration 4223, Loss: 0.053989291191101074\n",
      "Iteration 4224, Loss: 0.05417132377624512\n",
      "Iteration 4225, Loss: 0.053989291191101074\n",
      "Iteration 4226, Loss: 0.054171204566955566\n",
      "Iteration 4227, Loss: 0.05398944020271301\n",
      "Iteration 4228, Loss: 0.054171204566955566\n",
      "Iteration 4229, Loss: 0.053989410400390625\n",
      "Iteration 4230, Loss: 0.05417132005095482\n",
      "Iteration 4231, Loss: 0.05398932099342346\n",
      "Iteration 4232, Loss: 0.05417148023843765\n",
      "Iteration 4233, Loss: 0.053989432752132416\n",
      "Iteration 4234, Loss: 0.05417148023843765\n",
      "Iteration 4235, Loss: 0.05398940294981003\n",
      "Iteration 4236, Loss: 0.05417144298553467\n",
      "Iteration 4237, Loss: 0.053989212960004807\n",
      "Iteration 4238, Loss: 0.05417155846953392\n",
      "Iteration 4239, Loss: 0.05398917198181152\n",
      "Iteration 4240, Loss: 0.054171450436115265\n",
      "Iteration 4241, Loss: 0.05398920178413391\n",
      "Iteration 4242, Loss: 0.05417156219482422\n",
      "Iteration 4243, Loss: 0.05398912355303764\n",
      "Iteration 4244, Loss: 0.0541716031730175\n",
      "Iteration 4245, Loss: 0.05398920178413391\n",
      "Iteration 4246, Loss: 0.05417156219482422\n",
      "Iteration 4247, Loss: 0.05398900806903839\n",
      "Iteration 4248, Loss: 0.05417171120643616\n",
      "Iteration 4249, Loss: 0.05398893356323242\n",
      "Iteration 4250, Loss: 0.054171644151210785\n",
      "Iteration 4251, Loss: 0.053988978266716\n",
      "Iteration 4252, Loss: 0.0541716031730175\n",
      "Iteration 4253, Loss: 0.05398913472890854\n",
      "Iteration 4254, Loss: 0.05417148396372795\n",
      "Iteration 4255, Loss: 0.05398924648761749\n",
      "Iteration 4256, Loss: 0.05417148396372795\n",
      "Iteration 4257, Loss: 0.05398928374052048\n",
      "Iteration 4258, Loss: 0.0541715994477272\n",
      "Iteration 4259, Loss: 0.05398912727832794\n",
      "Iteration 4260, Loss: 0.054171763360500336\n",
      "Iteration 4261, Loss: 0.05398901551961899\n",
      "Iteration 4262, Loss: 0.054171763360500336\n",
      "Iteration 4263, Loss: 0.05398892983794212\n",
      "Iteration 4264, Loss: 0.05417187511920929\n",
      "Iteration 4265, Loss: 0.05398900434374809\n",
      "Iteration 4266, Loss: 0.05417179688811302\n",
      "Iteration 4267, Loss: 0.053988855332136154\n",
      "Iteration 4268, Loss: 0.05417179316282272\n",
      "Iteration 4269, Loss: 0.05398900806903839\n",
      "Iteration 4270, Loss: 0.054171644151210785\n",
      "Iteration 4271, Loss: 0.053989045321941376\n",
      "Iteration 4272, Loss: 0.054171644151210785\n",
      "Iteration 4273, Loss: 0.053989119827747345\n",
      "Iteration 4274, Loss: 0.05417168140411377\n",
      "Iteration 4275, Loss: 0.053989045321941376\n",
      "Iteration 4276, Loss: 0.05417168140411377\n",
      "Iteration 4277, Loss: 0.05398900806903839\n",
      "Iteration 4278, Loss: 0.05417168140411377\n",
      "Iteration 4279, Loss: 0.053988974541425705\n",
      "Iteration 4280, Loss: 0.0541718415915966\n",
      "Iteration 4281, Loss: 0.05398892983794212\n",
      "Iteration 4282, Loss: 0.05417203530669212\n",
      "Iteration 4283, Loss: 0.05398854240775108\n",
      "Iteration 4284, Loss: 0.05417210981249809\n",
      "Iteration 4285, Loss: 0.05398862063884735\n",
      "Iteration 4286, Loss: 0.05417194962501526\n",
      "Iteration 4287, Loss: 0.05398882180452347\n",
      "Iteration 4288, Loss: 0.05417167767882347\n",
      "Iteration 4289, Loss: 0.05398912355303764\n",
      "Iteration 4290, Loss: 0.054171524941921234\n",
      "Iteration 4291, Loss: 0.05398925393819809\n",
      "Iteration 4292, Loss: 0.05417143926024437\n",
      "Iteration 4293, Loss: 0.05398933216929436\n",
      "Iteration 4294, Loss: 0.05417143926024437\n",
      "Iteration 4295, Loss: 0.053989287465810776\n",
      "Iteration 4296, Loss: 0.0541713684797287\n",
      "Iteration 4297, Loss: 0.05398920178413391\n",
      "Iteration 4298, Loss: 0.054171644151210785\n",
      "Iteration 4299, Loss: 0.053989049047231674\n",
      "Iteration 4300, Loss: 0.05417175218462944\n",
      "Iteration 4301, Loss: 0.05398901551961899\n",
      "Iteration 4302, Loss: 0.05417191982269287\n",
      "Iteration 4303, Loss: 0.053988926112651825\n",
      "Iteration 4304, Loss: 0.05417206883430481\n",
      "Iteration 4305, Loss: 0.05398869514465332\n",
      "Iteration 4306, Loss: 0.05417199432849884\n",
      "Iteration 4307, Loss: 0.05398881435394287\n",
      "Iteration 4308, Loss: 0.054171763360500336\n",
      "Iteration 4309, Loss: 0.05398900806903839\n",
      "Iteration 4310, Loss: 0.05417148396372795\n",
      "Iteration 4311, Loss: 0.05398920178413391\n",
      "Iteration 4312, Loss: 0.05417144298553467\n",
      "Iteration 4313, Loss: 0.05398925393819809\n",
      "Iteration 4314, Loss: 0.0541713647544384\n",
      "Iteration 4315, Loss: 0.053989287465810776\n",
      "Iteration 4316, Loss: 0.05417156219482422\n",
      "Iteration 4317, Loss: 0.05398905277252197\n",
      "Iteration 4318, Loss: 0.054171763360500336\n",
      "Iteration 4319, Loss: 0.05398882180452347\n",
      "Iteration 4320, Loss: 0.05417187139391899\n",
      "Iteration 4321, Loss: 0.05398940667510033\n",
      "Iteration 4322, Loss: 0.054171763360500336\n",
      "Iteration 4323, Loss: 0.05398949235677719\n",
      "Iteration 4324, Loss: 0.05417215824127197\n",
      "Iteration 4325, Loss: 0.053989604115486145\n",
      "Iteration 4326, Loss: 0.05417203903198242\n",
      "Iteration 4327, Loss: 0.05398957431316376\n",
      "Iteration 4328, Loss: 0.0541718415915966\n",
      "Iteration 4329, Loss: 0.05398973077535629\n",
      "Iteration 4330, Loss: 0.054171882569789886\n",
      "Iteration 4331, Loss: 0.05398983880877495\n",
      "Iteration 4332, Loss: 0.054171882569789886\n",
      "Iteration 4333, Loss: 0.05398973077535629\n",
      "Iteration 4334, Loss: 0.05417212098836899\n",
      "Iteration 4335, Loss: 0.05398960039019585\n",
      "Iteration 4336, Loss: 0.05417227745056152\n",
      "Iteration 4337, Loss: 0.053989335894584656\n",
      "Iteration 4338, Loss: 0.054172322154045105\n",
      "Iteration 4339, Loss: 0.053989216685295105\n",
      "Iteration 4340, Loss: 0.054172348231077194\n",
      "Iteration 4341, Loss: 0.05398925766348839\n",
      "Iteration 4342, Loss: 0.05417224019765854\n",
      "Iteration 4343, Loss: 0.0539894625544548\n",
      "Iteration 4344, Loss: 0.054172154515981674\n",
      "Iteration 4345, Loss: 0.05398956686258316\n",
      "Iteration 4346, Loss: 0.05417218804359436\n",
      "Iteration 4347, Loss: 0.05398957431316376\n",
      "Iteration 4348, Loss: 0.05417222902178764\n",
      "Iteration 4349, Loss: 0.053989604115486145\n",
      "Iteration 4350, Loss: 0.05417211353778839\n",
      "Iteration 4351, Loss: 0.053989604115486145\n",
      "Iteration 4352, Loss: 0.054172080010175705\n",
      "Iteration 4353, Loss: 0.053989529609680176\n",
      "Iteration 4354, Loss: 0.05417215824127197\n",
      "Iteration 4355, Loss: 0.05398945137858391\n",
      "Iteration 4356, Loss: 0.05417211353778839\n",
      "Iteration 4357, Loss: 0.053989529609680176\n",
      "Iteration 4358, Loss: 0.05417200177907944\n",
      "Iteration 4359, Loss: 0.05398961156606674\n",
      "Iteration 4360, Loss: 0.054171960800886154\n",
      "Iteration 4361, Loss: 0.05398976802825928\n",
      "Iteration 4362, Loss: 0.054171882569789886\n",
      "Iteration 4363, Loss: 0.05398976802825928\n",
      "Iteration 4364, Loss: 0.0541718527674675\n",
      "Iteration 4365, Loss: 0.05398983880877495\n",
      "Iteration 4366, Loss: 0.05417203903198242\n",
      "Iteration 4367, Loss: 0.05398961156606674\n",
      "Iteration 4368, Loss: 0.05417223274707794\n",
      "Iteration 4369, Loss: 0.05398945510387421\n",
      "Iteration 4370, Loss: 0.054172318428754807\n",
      "Iteration 4371, Loss: 0.053989291191101074\n",
      "Iteration 4372, Loss: 0.05417247116565704\n",
      "Iteration 4373, Loss: 0.053989291191101074\n",
      "Iteration 4374, Loss: 0.05417243763804436\n",
      "Iteration 4375, Loss: 0.053989291191101074\n",
      "Iteration 4376, Loss: 0.054172273725271225\n",
      "Iteration 4377, Loss: 0.05398949235677719\n",
      "Iteration 4378, Loss: 0.054172150790691376\n",
      "Iteration 4379, Loss: 0.05398968979716301\n",
      "Iteration 4380, Loss: 0.054171886295080185\n",
      "Iteration 4381, Loss: 0.05398969352245331\n",
      "Iteration 4382, Loss: 0.054171960800886154\n",
      "Iteration 4383, Loss: 0.05398968979716301\n",
      "Iteration 4384, Loss: 0.054172005504369736\n",
      "Iteration 4385, Loss: 0.05398964509367943\n",
      "Iteration 4386, Loss: 0.05417203903198242\n",
      "Iteration 4387, Loss: 0.0539897195994854\n",
      "Iteration 4388, Loss: 0.05417212098836899\n",
      "Iteration 4389, Loss: 0.05398964509367943\n",
      "Iteration 4390, Loss: 0.05417230725288391\n",
      "Iteration 4391, Loss: 0.05398945137858391\n",
      "Iteration 4392, Loss: 0.05417230725288391\n",
      "Iteration 4393, Loss: 0.05398934334516525\n",
      "Iteration 4394, Loss: 0.05417230725288391\n",
      "Iteration 4395, Loss: 0.05398938059806824\n",
      "Iteration 4396, Loss: 0.054172150790691376\n",
      "Iteration 4397, Loss: 0.05398949608206749\n",
      "Iteration 4398, Loss: 0.054171960800886154\n",
      "Iteration 4399, Loss: 0.05398964881896973\n",
      "Iteration 4400, Loss: 0.05417191982269287\n",
      "Iteration 4401, Loss: 0.05398976802825928\n",
      "Iteration 4402, Loss: 0.05417210981249809\n",
      "Iteration 4403, Loss: 0.053989656269550323\n",
      "Iteration 4404, Loss: 0.054172080010175705\n",
      "Iteration 4405, Loss: 0.05398960039019585\n",
      "Iteration 4406, Loss: 0.05417238920927048\n",
      "Iteration 4407, Loss: 0.05398925393819809\n",
      "Iteration 4408, Loss: 0.05417242646217346\n",
      "Iteration 4409, Loss: 0.05398937314748764\n",
      "Iteration 4410, Loss: 0.05417243763804436\n",
      "Iteration 4411, Loss: 0.053989291191101074\n",
      "Iteration 4412, Loss: 0.05417238920927048\n",
      "Iteration 4413, Loss: 0.05398933216929436\n",
      "Iteration 4414, Loss: 0.054172273725271225\n",
      "Iteration 4415, Loss: 0.05398938059806824\n",
      "Iteration 4416, Loss: 0.054172076284885406\n",
      "Iteration 4417, Loss: 0.05398949608206749\n",
      "Iteration 4418, Loss: 0.05417210981249809\n",
      "Iteration 4419, Loss: 0.05398968607187271\n",
      "Iteration 4420, Loss: 0.05417215824127197\n",
      "Iteration 4421, Loss: 0.05398949980735779\n",
      "Iteration 4422, Loss: 0.05417231470346451\n",
      "Iteration 4423, Loss: 0.053989261388778687\n",
      "Iteration 4424, Loss: 0.05417250841856003\n",
      "Iteration 4425, Loss: 0.053989291191101074\n",
      "Iteration 4426, Loss: 0.05417242646217346\n",
      "Iteration 4427, Loss: 0.0539892241358757\n",
      "Iteration 4428, Loss: 0.05417222902178764\n",
      "Iteration 4429, Loss: 0.05398938059806824\n",
      "Iteration 4430, Loss: 0.05417200177907944\n",
      "Iteration 4431, Loss: 0.05398984253406525\n",
      "Iteration 4432, Loss: 0.05417191982269287\n",
      "Iteration 4433, Loss: 0.05398987978696823\n",
      "Iteration 4434, Loss: 0.054171882569789886\n",
      "Iteration 4435, Loss: 0.053989723324775696\n",
      "Iteration 4436, Loss: 0.054172076284885406\n",
      "Iteration 4437, Loss: 0.053989604115486145\n",
      "Iteration 4438, Loss: 0.05417212098836899\n",
      "Iteration 4439, Loss: 0.05398956686258316\n",
      "Iteration 4440, Loss: 0.05417222902178764\n",
      "Iteration 4441, Loss: 0.053989529609680176\n",
      "Iteration 4442, Loss: 0.054172199219465256\n",
      "Iteration 4443, Loss: 0.053989335894584656\n",
      "Iteration 4444, Loss: 0.054172348231077194\n",
      "Iteration 4445, Loss: 0.05398933216929436\n",
      "Iteration 4446, Loss: 0.05417235195636749\n",
      "Iteration 4447, Loss: 0.05398933216929436\n",
      "Iteration 4448, Loss: 0.054172199219465256\n",
      "Iteration 4449, Loss: 0.05398934334516525\n",
      "Iteration 4450, Loss: 0.05417219549417496\n",
      "Iteration 4451, Loss: 0.05398949608206749\n",
      "Iteration 4452, Loss: 0.054171960800886154\n",
      "Iteration 4453, Loss: 0.05398965999484062\n",
      "Iteration 4454, Loss: 0.05417203903198242\n",
      "Iteration 4455, Loss: 0.05398964881896973\n",
      "Iteration 4456, Loss: 0.054172080010175705\n",
      "Iteration 4457, Loss: 0.053989604115486145\n",
      "Iteration 4458, Loss: 0.05417212098836899\n",
      "Iteration 4459, Loss: 0.05398945510387421\n",
      "Iteration 4460, Loss: 0.05417206883430481\n",
      "Iteration 4461, Loss: 0.05398961156606674\n",
      "Iteration 4462, Loss: 0.05417199432849884\n",
      "Iteration 4463, Loss: 0.05398961529135704\n",
      "Iteration 4464, Loss: 0.054171960800886154\n",
      "Iteration 4465, Loss: 0.05398973450064659\n",
      "Iteration 4466, Loss: 0.054171811789274216\n",
      "Iteration 4467, Loss: 0.053989797830581665\n",
      "Iteration 4468, Loss: 0.0541718415915966\n",
      "Iteration 4469, Loss: 0.05398969352245331\n",
      "Iteration 4470, Loss: 0.054171767085790634\n",
      "Iteration 4471, Loss: 0.053989849984645844\n",
      "Iteration 4472, Loss: 0.05417194962501526\n",
      "Iteration 4473, Loss: 0.05398976802825928\n",
      "Iteration 4474, Loss: 0.054171886295080185\n",
      "Iteration 4475, Loss: 0.053989656269550323\n",
      "Iteration 4476, Loss: 0.05417205020785332\n",
      "Iteration 4477, Loss: 0.053989559412002563\n",
      "Iteration 4478, Loss: 0.054172396659851074\n",
      "Iteration 4479, Loss: 0.05398925393819809\n",
      "Iteration 4480, Loss: 0.05417255684733391\n",
      "Iteration 4481, Loss: 0.053989093750715256\n",
      "Iteration 4482, Loss: 0.05417255312204361\n",
      "Iteration 4483, Loss: 0.05398917198181152\n",
      "Iteration 4484, Loss: 0.05417238920927048\n",
      "Iteration 4485, Loss: 0.053989291191101074\n",
      "Iteration 4486, Loss: 0.05417215824127197\n",
      "Iteration 4487, Loss: 0.05398961156606674\n",
      "Iteration 4488, Loss: 0.05417199060320854\n",
      "Iteration 4489, Loss: 0.05398976802825928\n",
      "Iteration 4490, Loss: 0.05417179688811302\n",
      "Iteration 4491, Loss: 0.05398992821574211\n",
      "Iteration 4492, Loss: 0.05417172238230705\n",
      "Iteration 4493, Loss: 0.053989917039871216\n",
      "Iteration 4494, Loss: 0.05417177081108093\n",
      "Iteration 4495, Loss: 0.05398973077535629\n",
      "Iteration 4496, Loss: 0.05417206883430481\n",
      "Iteration 4497, Loss: 0.05398961529135704\n",
      "Iteration 4498, Loss: 0.05417212098836899\n",
      "Iteration 4499, Loss: 0.05398945510387421\n",
      "Iteration 4500, Loss: 0.05417224019765854\n",
      "Iteration 4501, Loss: 0.05398937314748764\n",
      "Iteration 4502, Loss: 0.054172199219465256\n",
      "Iteration 4503, Loss: 0.05398937687277794\n",
      "Iteration 4504, Loss: 0.054172154515981674\n",
      "Iteration 4505, Loss: 0.05398949608206749\n",
      "Iteration 4506, Loss: 0.05417203903198242\n",
      "Iteration 4507, Loss: 0.05398949980735779\n",
      "Iteration 4508, Loss: 0.054172150790691376\n",
      "Iteration 4509, Loss: 0.05398961156606674\n",
      "Iteration 4510, Loss: 0.05417211353778839\n",
      "Iteration 4511, Loss: 0.05398968607187271\n",
      "Iteration 4512, Loss: 0.05417218804359436\n",
      "Iteration 4513, Loss: 0.053989604115486145\n",
      "Iteration 4514, Loss: 0.05417212098836899\n",
      "Iteration 4515, Loss: 0.05398957058787346\n",
      "Iteration 4516, Loss: 0.05417215824127197\n",
      "Iteration 4517, Loss: 0.05398949235677719\n",
      "Iteration 4518, Loss: 0.05417215824127197\n",
      "Iteration 4519, Loss: 0.05398964136838913\n",
      "Iteration 4520, Loss: 0.054172199219465256\n",
      "Iteration 4521, Loss: 0.053989529609680176\n",
      "Iteration 4522, Loss: 0.05417227745056152\n",
      "Iteration 4523, Loss: 0.05398944765329361\n",
      "Iteration 4524, Loss: 0.05417223274707794\n",
      "Iteration 4525, Loss: 0.05398941785097122\n",
      "Iteration 4526, Loss: 0.05417212098836899\n",
      "Iteration 4527, Loss: 0.05398949608206749\n",
      "Iteration 4528, Loss: 0.05417196452617645\n",
      "Iteration 4529, Loss: 0.05398954078555107\n",
      "Iteration 4530, Loss: 0.054172150790691376\n",
      "Iteration 4531, Loss: 0.05398961156606674\n",
      "Iteration 4532, Loss: 0.054172150790691376\n",
      "Iteration 4533, Loss: 0.05398957431316376\n",
      "Iteration 4534, Loss: 0.05417218804359436\n",
      "Iteration 4535, Loss: 0.05398949980735779\n",
      "Iteration 4536, Loss: 0.05417199432849884\n",
      "Iteration 4537, Loss: 0.05398964881896973\n",
      "Iteration 4538, Loss: 0.054171960800886154\n",
      "Iteration 4539, Loss: 0.053989797830581665\n",
      "Iteration 4540, Loss: 0.054171882569789886\n",
      "Iteration 4541, Loss: 0.05398984253406525\n",
      "Iteration 4542, Loss: 0.05417189002037048\n",
      "Iteration 4543, Loss: 0.05398983880877495\n",
      "Iteration 4544, Loss: 0.054171960800886154\n",
      "Iteration 4545, Loss: 0.053989797830581665\n",
      "Iteration 4546, Loss: 0.05417203903198242\n",
      "Iteration 4547, Loss: 0.05398964509367943\n",
      "Iteration 4548, Loss: 0.054172273725271225\n",
      "Iteration 4549, Loss: 0.05398936569690704\n",
      "Iteration 4550, Loss: 0.054172348231077194\n",
      "Iteration 4551, Loss: 0.05398933216929436\n",
      "Iteration 4552, Loss: 0.05417230725288391\n",
      "Iteration 4553, Loss: 0.05398938059806824\n",
      "Iteration 4554, Loss: 0.054172150790691376\n",
      "Iteration 4555, Loss: 0.05398961156606674\n",
      "Iteration 4556, Loss: 0.054171960800886154\n",
      "Iteration 4557, Loss: 0.05398968979716301\n",
      "Iteration 4558, Loss: 0.054171763360500336\n",
      "Iteration 4559, Loss: 0.053989820182323456\n",
      "Iteration 4560, Loss: 0.054171763360500336\n",
      "Iteration 4561, Loss: 0.05398980900645256\n",
      "Iteration 4562, Loss: 0.0541718527674675\n",
      "Iteration 4563, Loss: 0.05398976802825928\n",
      "Iteration 4564, Loss: 0.054172005504369736\n",
      "Iteration 4565, Loss: 0.053989678621292114\n",
      "Iteration 4566, Loss: 0.05417227745056152\n",
      "Iteration 4567, Loss: 0.05398933216929436\n",
      "Iteration 4568, Loss: 0.054172515869140625\n",
      "Iteration 4569, Loss: 0.053989212960004807\n",
      "Iteration 4570, Loss: 0.054172586649656296\n",
      "Iteration 4571, Loss: 0.05398917943239212\n",
      "Iteration 4572, Loss: 0.054172318428754807\n",
      "Iteration 4573, Loss: 0.05398933216929436\n",
      "Iteration 4574, Loss: 0.054172080010175705\n",
      "Iteration 4575, Loss: 0.05398961156606674\n",
      "Iteration 4576, Loss: 0.0541718527674675\n",
      "Iteration 4577, Loss: 0.05398976802825928\n",
      "Iteration 4578, Loss: 0.05417172610759735\n",
      "Iteration 4579, Loss: 0.053989775478839874\n",
      "Iteration 4580, Loss: 0.05417191982269287\n",
      "Iteration 4581, Loss: 0.053989656269550323\n",
      "Iteration 4582, Loss: 0.054172009229660034\n",
      "Iteration 4583, Loss: 0.053989529609680176\n",
      "Iteration 4584, Loss: 0.054172247648239136\n",
      "Iteration 4585, Loss: 0.0539892241358757\n",
      "Iteration 4586, Loss: 0.054172515869140625\n",
      "Iteration 4587, Loss: 0.05398917943239212\n",
      "Iteration 4588, Loss: 0.05417235940694809\n",
      "Iteration 4589, Loss: 0.053989291191101074\n",
      "Iteration 4590, Loss: 0.05417215824127197\n",
      "Iteration 4591, Loss: 0.053989529609680176\n",
      "Iteration 4592, Loss: 0.0541718527674675\n",
      "Iteration 4593, Loss: 0.053989700973033905\n",
      "Iteration 4594, Loss: 0.05417172238230705\n",
      "Iteration 4595, Loss: 0.05398988723754883\n",
      "Iteration 4596, Loss: 0.054171763360500336\n",
      "Iteration 4597, Loss: 0.053989849984645844\n",
      "Iteration 4598, Loss: 0.05417191982269287\n",
      "Iteration 4599, Loss: 0.0539897195994854\n",
      "Iteration 4600, Loss: 0.054172128438949585\n",
      "Iteration 4601, Loss: 0.05398937687277794\n",
      "Iteration 4602, Loss: 0.05417240783572197\n",
      "Iteration 4603, Loss: 0.05398924648761749\n",
      "Iteration 4604, Loss: 0.05417255684733391\n",
      "Iteration 4605, Loss: 0.05398913472890854\n",
      "Iteration 4606, Loss: 0.054172515869140625\n",
      "Iteration 4607, Loss: 0.05398913845419884\n",
      "Iteration 4608, Loss: 0.054172318428754807\n",
      "Iteration 4609, Loss: 0.05398949235677719\n",
      "Iteration 4610, Loss: 0.054172080010175705\n",
      "Iteration 4611, Loss: 0.05398949235677719\n",
      "Iteration 4612, Loss: 0.05417203530669212\n",
      "Iteration 4613, Loss: 0.05398964881896973\n",
      "Iteration 4614, Loss: 0.05417191982269287\n",
      "Iteration 4615, Loss: 0.05398968979716301\n",
      "Iteration 4616, Loss: 0.054171960800886154\n",
      "Iteration 4617, Loss: 0.053990088403224945\n",
      "Iteration 4618, Loss: 0.054172080010175705\n",
      "Iteration 4619, Loss: 0.05399000644683838\n",
      "Iteration 4620, Loss: 0.05417263135313988\n",
      "Iteration 4621, Loss: 0.053989820182323456\n",
      "Iteration 4622, Loss: 0.05417262762784958\n",
      "Iteration 4623, Loss: 0.05399000644683838\n",
      "Iteration 4624, Loss: 0.05417235940694809\n",
      "Iteration 4625, Loss: 0.05399024486541748\n",
      "Iteration 4626, Loss: 0.05417215824127197\n",
      "Iteration 4627, Loss: 0.053990475833415985\n",
      "Iteration 4628, Loss: 0.05417200177907944\n",
      "Iteration 4629, Loss: 0.05399055778980255\n",
      "Iteration 4630, Loss: 0.0541720911860466\n",
      "Iteration 4631, Loss: 0.05399036034941673\n",
      "Iteration 4632, Loss: 0.054172173142433167\n",
      "Iteration 4633, Loss: 0.05399012193083763\n",
      "Iteration 4634, Loss: 0.05417260527610779\n",
      "Iteration 4635, Loss: 0.05398987978696823\n",
      "Iteration 4636, Loss: 0.05417299270629883\n",
      "Iteration 4637, Loss: 0.05398949980735779\n",
      "Iteration 4638, Loss: 0.0541730672121048\n",
      "Iteration 4639, Loss: 0.05398938059806824\n",
      "Iteration 4640, Loss: 0.05417291447520256\n",
      "Iteration 4641, Loss: 0.05398973450064659\n",
      "Iteration 4642, Loss: 0.05417267233133316\n",
      "Iteration 4643, Loss: 0.05398993194103241\n",
      "Iteration 4644, Loss: 0.05417235940694809\n",
      "Iteration 4645, Loss: 0.05399024486541748\n",
      "Iteration 4646, Loss: 0.054172124713659286\n",
      "Iteration 4647, Loss: 0.053990475833415985\n",
      "Iteration 4648, Loss: 0.054172005504369736\n",
      "Iteration 4649, Loss: 0.05399051308631897\n",
      "Iteration 4650, Loss: 0.054172154515981674\n",
      "Iteration 4651, Loss: 0.05399051308631897\n",
      "Iteration 4652, Loss: 0.05417213588953018\n",
      "Iteration 4653, Loss: 0.05399027466773987\n",
      "Iteration 4654, Loss: 0.0541725680232048\n",
      "Iteration 4655, Loss: 0.05398976802825928\n",
      "Iteration 4656, Loss: 0.05417299270629883\n",
      "Iteration 4657, Loss: 0.05398961156606674\n",
      "Iteration 4658, Loss: 0.05417299270629883\n",
      "Iteration 4659, Loss: 0.05398957431316376\n",
      "Iteration 4660, Loss: 0.05417283624410629\n",
      "Iteration 4661, Loss: 0.05398968979716301\n",
      "Iteration 4662, Loss: 0.05417275428771973\n",
      "Iteration 4663, Loss: 0.0539899617433548\n",
      "Iteration 4664, Loss: 0.05417259782552719\n",
      "Iteration 4665, Loss: 0.053989969193935394\n",
      "Iteration 4666, Loss: 0.05417255684733391\n",
      "Iteration 4667, Loss: 0.05399004742503166\n",
      "Iteration 4668, Loss: 0.05417260155081749\n",
      "Iteration 4669, Loss: 0.05398988723754883\n",
      "Iteration 4670, Loss: 0.05417272076010704\n",
      "Iteration 4671, Loss: 0.053989775478839874\n",
      "Iteration 4672, Loss: 0.05417275428771973\n",
      "Iteration 4673, Loss: 0.053989849984645844\n",
      "Iteration 4674, Loss: 0.05417279899120331\n",
      "Iteration 4675, Loss: 0.05398976802825928\n",
      "Iteration 4676, Loss: 0.05417287349700928\n",
      "Iteration 4677, Loss: 0.05398973077535629\n",
      "Iteration 4678, Loss: 0.05417286604642868\n",
      "Iteration 4679, Loss: 0.05398969352245331\n",
      "Iteration 4680, Loss: 0.0541728250682354\n",
      "Iteration 4681, Loss: 0.053989969193935394\n",
      "Iteration 4682, Loss: 0.05417255312204361\n",
      "Iteration 4683, Loss: 0.053989969193935394\n",
      "Iteration 4684, Loss: 0.054172441363334656\n",
      "Iteration 4685, Loss: 0.05399012565612793\n",
      "Iteration 4686, Loss: 0.05417247861623764\n",
      "Iteration 4687, Loss: 0.053990088403224945\n",
      "Iteration 4688, Loss: 0.05417244881391525\n",
      "Iteration 4689, Loss: 0.05399000644683838\n",
      "Iteration 4690, Loss: 0.054172635078430176\n",
      "Iteration 4691, Loss: 0.05398992821574211\n",
      "Iteration 4692, Loss: 0.054172635078430176\n",
      "Iteration 4693, Loss: 0.05398977920413017\n",
      "Iteration 4694, Loss: 0.05417259782552719\n",
      "Iteration 4695, Loss: 0.05399004742503166\n",
      "Iteration 4696, Loss: 0.05417247861623764\n",
      "Iteration 4697, Loss: 0.05399012565612793\n",
      "Iteration 4698, Loss: 0.05417235940694809\n",
      "Iteration 4699, Loss: 0.05399016663432121\n",
      "Iteration 4700, Loss: 0.054172396659851074\n",
      "Iteration 4701, Loss: 0.05399012565612793\n",
      "Iteration 4702, Loss: 0.05417247861623764\n",
      "Iteration 4703, Loss: 0.05399012565612793\n",
      "Iteration 4704, Loss: 0.05417255684733391\n",
      "Iteration 4705, Loss: 0.05399004742503166\n",
      "Iteration 4706, Loss: 0.05417267233133316\n",
      "Iteration 4707, Loss: 0.05398980900645256\n",
      "Iteration 4708, Loss: 0.054172784090042114\n",
      "Iteration 4709, Loss: 0.053989849984645844\n",
      "Iteration 4710, Loss: 0.05417275056242943\n",
      "Iteration 4711, Loss: 0.053989775478839874\n",
      "Iteration 4712, Loss: 0.054172635078430176\n",
      "Iteration 4713, Loss: 0.05398988723754883\n",
      "Iteration 4714, Loss: 0.05417255684733391\n",
      "Iteration 4715, Loss: 0.05399000272154808\n",
      "Iteration 4716, Loss: 0.05417251214385033\n",
      "Iteration 4717, Loss: 0.0539902001619339\n",
      "Iteration 4718, Loss: 0.054172322154045105\n",
      "Iteration 4719, Loss: 0.053990356624126434\n",
      "Iteration 4720, Loss: 0.05417243763804436\n",
      "Iteration 4721, Loss: 0.05399012565612793\n",
      "Iteration 4722, Loss: 0.054172515869140625\n",
      "Iteration 4723, Loss: 0.053989969193935394\n",
      "Iteration 4724, Loss: 0.05417272076010704\n",
      "Iteration 4725, Loss: 0.05398961901664734\n",
      "Iteration 4726, Loss: 0.054172955453395844\n",
      "Iteration 4727, Loss: 0.053989581763744354\n",
      "Iteration 4728, Loss: 0.05417298898100853\n",
      "Iteration 4729, Loss: 0.05398957431316376\n",
      "Iteration 4730, Loss: 0.05417291074991226\n",
      "Iteration 4731, Loss: 0.05398968979716301\n",
      "Iteration 4732, Loss: 0.05417259782552719\n",
      "Iteration 4733, Loss: 0.05399015545845032\n",
      "Iteration 4734, Loss: 0.054172366857528687\n",
      "Iteration 4735, Loss: 0.05399027466773987\n",
      "Iteration 4736, Loss: 0.05417224019765854\n",
      "Iteration 4737, Loss: 0.05399032682180405\n",
      "Iteration 4738, Loss: 0.05417216941714287\n",
      "Iteration 4739, Loss: 0.05399039387702942\n",
      "Iteration 4740, Loss: 0.054172247648239136\n",
      "Iteration 4741, Loss: 0.05399027094244957\n",
      "Iteration 4742, Loss: 0.05417264997959137\n",
      "Iteration 4743, Loss: 0.05398976802825928\n",
      "Iteration 4744, Loss: 0.054172955453395844\n",
      "Iteration 4745, Loss: 0.05398957058787346\n",
      "Iteration 4746, Loss: 0.054173074662685394\n",
      "Iteration 4747, Loss: 0.05398957431316376\n",
      "Iteration 4748, Loss: 0.05417299270629883\n",
      "Iteration 4749, Loss: 0.05398968979716301\n",
      "Iteration 4750, Loss: 0.05417271703481674\n",
      "Iteration 4751, Loss: 0.05398992821574211\n",
      "Iteration 4752, Loss: 0.05417247861623764\n",
      "Iteration 4753, Loss: 0.053990088403224945\n",
      "Iteration 4754, Loss: 0.054172247648239136\n",
      "Iteration 4755, Loss: 0.053990285843610764\n",
      "Iteration 4756, Loss: 0.054172202944755554\n",
      "Iteration 4757, Loss: 0.05399031937122345\n",
      "Iteration 4758, Loss: 0.05417235940694809\n",
      "Iteration 4759, Loss: 0.0539901964366436\n",
      "Iteration 4760, Loss: 0.054172687232494354\n",
      "Iteration 4761, Loss: 0.05398980900645256\n",
      "Iteration 4762, Loss: 0.054172955453395844\n",
      "Iteration 4763, Loss: 0.05398964881896973\n",
      "Iteration 4764, Loss: 0.05417279899120331\n",
      "Iteration 4765, Loss: 0.05398964881896973\n",
      "Iteration 4766, Loss: 0.05417275056242943\n",
      "Iteration 4767, Loss: 0.05398992821574211\n",
      "Iteration 4768, Loss: 0.05417255684733391\n",
      "Iteration 4769, Loss: 0.053990088403224945\n",
      "Iteration 4770, Loss: 0.0541723296046257\n",
      "Iteration 4771, Loss: 0.05399027466773987\n",
      "Iteration 4772, Loss: 0.05417228490114212\n",
      "Iteration 4773, Loss: 0.053990207612514496\n",
      "Iteration 4774, Loss: 0.05417235940694809\n",
      "Iteration 4775, Loss: 0.05399024486541748\n",
      "Iteration 4776, Loss: 0.054172322154045105\n",
      "Iteration 4777, Loss: 0.053990088403224945\n",
      "Iteration 4778, Loss: 0.054172635078430176\n",
      "Iteration 4779, Loss: 0.05399004742503166\n",
      "Iteration 4780, Loss: 0.05417267605662346\n",
      "Iteration 4781, Loss: 0.05398985370993614\n",
      "Iteration 4782, Loss: 0.05417279154062271\n",
      "Iteration 4783, Loss: 0.053989775478839874\n",
      "Iteration 4784, Loss: 0.05417264625430107\n",
      "Iteration 4785, Loss: 0.05398976802825928\n",
      "Iteration 4786, Loss: 0.05417267605662346\n",
      "Iteration 4787, Loss: 0.05398988723754883\n",
      "Iteration 4788, Loss: 0.054172784090042114\n",
      "Iteration 4789, Loss: 0.05398992821574211\n",
      "Iteration 4790, Loss: 0.054172709584236145\n",
      "Iteration 4791, Loss: 0.05398981273174286\n",
      "Iteration 4792, Loss: 0.05417267233133316\n",
      "Iteration 4793, Loss: 0.05398992821574211\n",
      "Iteration 4794, Loss: 0.054172664880752563\n",
      "Iteration 4795, Loss: 0.05399000272154808\n",
      "Iteration 4796, Loss: 0.05417263135313988\n",
      "Iteration 4797, Loss: 0.05398988723754883\n",
      "Iteration 4798, Loss: 0.054172515869140625\n",
      "Iteration 4799, Loss: 0.053989969193935394\n",
      "Iteration 4800, Loss: 0.054172396659851074\n",
      "Iteration 4801, Loss: 0.05399004742503166\n",
      "Iteration 4802, Loss: 0.05417228862643242\n",
      "Iteration 4803, Loss: 0.053990356624126434\n",
      "Iteration 4804, Loss: 0.05417235940694809\n",
      "Iteration 4805, Loss: 0.053990285843610764\n",
      "Iteration 4806, Loss: 0.05417235940694809\n",
      "Iteration 4807, Loss: 0.05399012565612793\n",
      "Iteration 4808, Loss: 0.054172396659851074\n",
      "Iteration 4809, Loss: 0.05399027466773987\n",
      "Iteration 4810, Loss: 0.05417255312204361\n",
      "Iteration 4811, Loss: 0.05399004742503166\n",
      "Iteration 4812, Loss: 0.054172515869140625\n",
      "Iteration 4813, Loss: 0.053990043699741364\n",
      "Iteration 4814, Loss: 0.05417271703481674\n",
      "Iteration 4815, Loss: 0.05398980900645256\n",
      "Iteration 4816, Loss: 0.05417291447520256\n",
      "Iteration 4817, Loss: 0.05398968979716301\n",
      "Iteration 4818, Loss: 0.05417291447520256\n",
      "Iteration 4819, Loss: 0.05398968979716301\n",
      "Iteration 4820, Loss: 0.054172828793525696\n",
      "Iteration 4821, Loss: 0.05398968979716301\n",
      "Iteration 4822, Loss: 0.05417259782552719\n",
      "Iteration 4823, Loss: 0.053989969193935394\n",
      "Iteration 4824, Loss: 0.05417229235172272\n",
      "Iteration 4825, Loss: 0.053990207612514496\n",
      "Iteration 4826, Loss: 0.05417224019765854\n",
      "Iteration 4827, Loss: 0.05399032682180405\n",
      "Iteration 4828, Loss: 0.05417221039533615\n",
      "Iteration 4829, Loss: 0.05399031564593315\n",
      "Iteration 4830, Loss: 0.05417240411043167\n",
      "Iteration 4831, Loss: 0.05399000644683838\n",
      "Iteration 4832, Loss: 0.054172635078430176\n",
      "Iteration 4833, Loss: 0.05398988351225853\n",
      "Iteration 4834, Loss: 0.05417267605662346\n",
      "Iteration 4835, Loss: 0.053989849984645844\n",
      "Iteration 4836, Loss: 0.054172709584236145\n",
      "Iteration 4837, Loss: 0.05398992821574211\n",
      "Iteration 4838, Loss: 0.05417259782552719\n",
      "Iteration 4839, Loss: 0.053990043699741364\n",
      "Iteration 4840, Loss: 0.05417254567146301\n",
      "Iteration 4841, Loss: 0.05399000644683838\n",
      "Iteration 4842, Loss: 0.054172366857528687\n",
      "Iteration 4843, Loss: 0.053990207612514496\n",
      "Iteration 4844, Loss: 0.054172322154045105\n",
      "Iteration 4845, Loss: 0.05399024486541748\n",
      "Iteration 4846, Loss: 0.054172396659851074\n",
      "Iteration 4847, Loss: 0.05399031564593315\n",
      "Iteration 4848, Loss: 0.05417255684733391\n",
      "Iteration 4849, Loss: 0.053989969193935394\n",
      "Iteration 4850, Loss: 0.05417275428771973\n",
      "Iteration 4851, Loss: 0.05398973077535629\n",
      "Iteration 4852, Loss: 0.05417275428771973\n",
      "Iteration 4853, Loss: 0.05398973077535629\n",
      "Iteration 4854, Loss: 0.054172635078430176\n",
      "Iteration 4855, Loss: 0.05399011820554733\n",
      "Iteration 4856, Loss: 0.05417247861623764\n",
      "Iteration 4857, Loss: 0.05399024114012718\n",
      "Iteration 4858, Loss: 0.05417228490114212\n",
      "Iteration 4859, Loss: 0.053990356624126434\n",
      "Iteration 4860, Loss: 0.054172396659851074\n",
      "Iteration 4861, Loss: 0.053990207612514496\n",
      "Iteration 4862, Loss: 0.05417240783572197\n",
      "Iteration 4863, Loss: 0.053989969193935394\n",
      "Iteration 4864, Loss: 0.05417267978191376\n",
      "Iteration 4865, Loss: 0.05398973077535629\n",
      "Iteration 4866, Loss: 0.054172955453395844\n",
      "Iteration 4867, Loss: 0.05398961156606674\n",
      "Iteration 4868, Loss: 0.05417299270629883\n",
      "Iteration 4869, Loss: 0.05398961901664734\n",
      "Iteration 4870, Loss: 0.05417291447520256\n",
      "Iteration 4871, Loss: 0.053989581763744354\n",
      "Iteration 4872, Loss: 0.05417279154062271\n",
      "Iteration 4873, Loss: 0.05398976802825928\n",
      "Iteration 4874, Loss: 0.05417259782552719\n",
      "Iteration 4875, Loss: 0.05399004742503166\n",
      "Iteration 4876, Loss: 0.0541723296046257\n",
      "Iteration 4877, Loss: 0.05399024114012718\n",
      "Iteration 4878, Loss: 0.054172318428754807\n",
      "Iteration 4879, Loss: 0.05399039387702942\n",
      "Iteration 4880, Loss: 0.05417216569185257\n",
      "Iteration 4881, Loss: 0.05399032682180405\n",
      "Iteration 4882, Loss: 0.05417224019765854\n",
      "Iteration 4883, Loss: 0.053990356624126434\n",
      "Iteration 4884, Loss: 0.05417247116565704\n",
      "Iteration 4885, Loss: 0.05399004742503166\n",
      "Iteration 4886, Loss: 0.05417259782552719\n",
      "Iteration 4887, Loss: 0.05399000644683838\n",
      "Iteration 4888, Loss: 0.054172635078430176\n",
      "Iteration 4889, Loss: 0.05398981273174286\n",
      "Iteration 4890, Loss: 0.05417279154062271\n",
      "Iteration 4891, Loss: 0.05398988723754883\n",
      "Iteration 4892, Loss: 0.05417267605662346\n",
      "Iteration 4893, Loss: 0.05398988723754883\n",
      "Iteration 4894, Loss: 0.05417255684733391\n",
      "Iteration 4895, Loss: 0.05398988723754883\n",
      "Iteration 4896, Loss: 0.05417255684733391\n",
      "Iteration 4897, Loss: 0.053989894688129425\n",
      "Iteration 4898, Loss: 0.05417259782552719\n",
      "Iteration 4899, Loss: 0.05399000272154808\n",
      "Iteration 4900, Loss: 0.05417263135313988\n",
      "Iteration 4901, Loss: 0.053989969193935394\n",
      "Iteration 4902, Loss: 0.05417263135313988\n",
      "Iteration 4903, Loss: 0.053989969193935394\n",
      "Iteration 4904, Loss: 0.05417262762784958\n",
      "Iteration 4905, Loss: 0.053989969193935394\n",
      "Iteration 4906, Loss: 0.05417262762784958\n",
      "Iteration 4907, Loss: 0.053989969193935394\n",
      "Iteration 4908, Loss: 0.05417262762784958\n",
      "Iteration 4909, Loss: 0.053989969193935394\n",
      "Iteration 4910, Loss: 0.054172590374946594\n",
      "Iteration 4911, Loss: 0.053989969193935394\n",
      "Iteration 4912, Loss: 0.05417255684733391\n",
      "Iteration 4913, Loss: 0.053990088403224945\n",
      "Iteration 4914, Loss: 0.0541725680232048\n",
      "Iteration 4915, Loss: 0.05398992821574211\n",
      "Iteration 4916, Loss: 0.054172687232494354\n",
      "Iteration 4917, Loss: 0.053989656269550323\n",
      "Iteration 4918, Loss: 0.054172880947589874\n",
      "Iteration 4919, Loss: 0.05398949980735779\n",
      "Iteration 4920, Loss: 0.054172955453395844\n",
      "Iteration 4921, Loss: 0.05398957431316376\n",
      "Iteration 4922, Loss: 0.05417275428771973\n",
      "Iteration 4923, Loss: 0.05398980900645256\n",
      "Iteration 4924, Loss: 0.054172664880752563\n",
      "Iteration 4925, Loss: 0.053989969193935394\n",
      "Iteration 4926, Loss: 0.0541723296046257\n",
      "Iteration 4927, Loss: 0.05399024114012718\n",
      "Iteration 4928, Loss: 0.05417227745056152\n",
      "Iteration 4929, Loss: 0.053990401327610016\n",
      "Iteration 4930, Loss: 0.054172199219465256\n",
      "Iteration 4931, Loss: 0.05399024486541748\n",
      "Iteration 4932, Loss: 0.05417235940694809\n",
      "Iteration 4933, Loss: 0.053990282118320465\n",
      "Iteration 4934, Loss: 0.05417236313223839\n",
      "Iteration 4935, Loss: 0.053990088403224945\n",
      "Iteration 4936, Loss: 0.0541725680232048\n",
      "Iteration 4937, Loss: 0.05398980900645256\n",
      "Iteration 4938, Loss: 0.05417279526591301\n",
      "Iteration 4939, Loss: 0.05398968979716301\n",
      "Iteration 4940, Loss: 0.05417279154062271\n",
      "Iteration 4941, Loss: 0.05398973822593689\n",
      "Iteration 4942, Loss: 0.05417255684733391\n",
      "Iteration 4943, Loss: 0.053990043699741364\n",
      "Iteration 4944, Loss: 0.05417255312204361\n",
      "Iteration 4945, Loss: 0.05399011820554733\n",
      "Iteration 4946, Loss: 0.05417236313223839\n",
      "Iteration 4947, Loss: 0.053990088403224945\n",
      "Iteration 4948, Loss: 0.05417235940694809\n",
      "Iteration 4949, Loss: 0.053990282118320465\n",
      "Iteration 4950, Loss: 0.05417247861623764\n",
      "Iteration 4951, Loss: 0.05399016663432121\n",
      "Iteration 4952, Loss: 0.054172709584236145\n",
      "Iteration 4953, Loss: 0.053989849984645844\n",
      "Iteration 4954, Loss: 0.05417279526591301\n",
      "Iteration 4955, Loss: 0.05398976802825928\n",
      "Iteration 4956, Loss: 0.05417286977171898\n",
      "Iteration 4957, Loss: 0.05398973822593689\n",
      "Iteration 4958, Loss: 0.05417275428771973\n",
      "Iteration 4959, Loss: 0.05398988723754883\n",
      "Iteration 4960, Loss: 0.054172709584236145\n",
      "Iteration 4961, Loss: 0.0539899617433548\n",
      "Iteration 4962, Loss: 0.05417240783572197\n",
      "Iteration 4963, Loss: 0.05399007722735405\n",
      "Iteration 4964, Loss: 0.0541723296046257\n",
      "Iteration 4965, Loss: 0.053990088403224945\n",
      "Iteration 4966, Loss: 0.05417243763804436\n",
      "Iteration 4967, Loss: 0.05399012565612793\n",
      "Iteration 4968, Loss: 0.05417243763804436\n",
      "Iteration 4969, Loss: 0.053990092128515244\n",
      "Iteration 4970, Loss: 0.05417248234152794\n",
      "Iteration 4971, Loss: 0.05399004742503166\n",
      "Iteration 4972, Loss: 0.05417260155081749\n",
      "Iteration 4973, Loss: 0.0539892241358757\n",
      "Iteration 4974, Loss: 0.0541725680232048\n",
      "Iteration 4975, Loss: 0.053989119827747345\n",
      "Iteration 4976, Loss: 0.05417267605662346\n",
      "Iteration 4977, Loss: 0.05398915708065033\n",
      "Iteration 4978, Loss: 0.05417194217443466\n",
      "Iteration 4979, Loss: 0.053989261388778687\n",
      "Iteration 4980, Loss: 0.05417194217443466\n",
      "Iteration 4981, Loss: 0.05398930236697197\n",
      "Iteration 4982, Loss: 0.054171934723854065\n",
      "Iteration 4983, Loss: 0.05398930236697197\n",
      "Iteration 4984, Loss: 0.05417182669043541\n",
      "Iteration 4985, Loss: 0.0539892315864563\n",
      "Iteration 4986, Loss: 0.05417190119624138\n",
      "Iteration 4987, Loss: 0.053989261388778687\n",
      "Iteration 4988, Loss: 0.05417190119624138\n",
      "Iteration 4989, Loss: 0.05398930236697197\n",
      "Iteration 4990, Loss: 0.05417182296514511\n",
      "Iteration 4991, Loss: 0.053989261388778687\n",
      "Iteration 4992, Loss: 0.054171785712242126\n",
      "Iteration 4993, Loss: 0.053989261388778687\n",
      "Iteration 4994, Loss: 0.05417182296514511\n",
      "Iteration 4995, Loss: 0.0539892241358757\n",
      "Iteration 4996, Loss: 0.0541718564927578\n",
      "Iteration 4997, Loss: 0.05398938059806824\n",
      "Iteration 4998, Loss: 0.05417170375585556\n",
      "Iteration 4999, Loss: 0.05398930609226227\n",
      "Iteration 5000, Loss: 0.05417166277766228\n",
      "Iteration 5001, Loss: 0.053989432752132416\n",
      "Iteration 5002, Loss: 0.05417158827185631\n",
      "Iteration 5003, Loss: 0.0539894662797451\n",
      "Iteration 5004, Loss: 0.054171547293663025\n",
      "Iteration 5005, Loss: 0.053989510983228683\n",
      "Iteration 5006, Loss: 0.05417170375585556\n",
      "Iteration 5007, Loss: 0.05398949608206749\n",
      "Iteration 5008, Loss: 0.05417179316282272\n",
      "Iteration 5009, Loss: 0.053989142179489136\n",
      "Iteration 5010, Loss: 0.05417221784591675\n",
      "Iteration 5011, Loss: 0.05398891493678093\n",
      "Iteration 5012, Loss: 0.05417225882411003\n",
      "Iteration 5013, Loss: 0.05398891493678093\n",
      "Iteration 5014, Loss: 0.05417206138372421\n",
      "Iteration 5015, Loss: 0.053989067673683167\n",
      "Iteration 5016, Loss: 0.05417190119624138\n",
      "Iteration 5017, Loss: 0.05398934707045555\n",
      "Iteration 5018, Loss: 0.054171621799468994\n",
      "Iteration 5019, Loss: 0.05398954078555107\n",
      "Iteration 5020, Loss: 0.05417146533727646\n",
      "Iteration 5021, Loss: 0.053989704698324203\n",
      "Iteration 5022, Loss: 0.05417127534747124\n",
      "Iteration 5023, Loss: 0.053989820182323456\n",
      "Iteration 5024, Loss: 0.054171472787857056\n",
      "Iteration 5025, Loss: 0.05398954078555107\n",
      "Iteration 5026, Loss: 0.054171860218048096\n",
      "Iteration 5027, Loss: 0.05398911237716675\n",
      "Iteration 5028, Loss: 0.05417213961482048\n",
      "Iteration 5029, Loss: 0.05398891493678093\n",
      "Iteration 5030, Loss: 0.05417225882411003\n",
      "Iteration 5031, Loss: 0.05398883670568466\n",
      "Iteration 5032, Loss: 0.05417221784591675\n",
      "Iteration 5033, Loss: 0.053989022970199585\n",
      "Iteration 5034, Loss: 0.05417213961482048\n",
      "Iteration 5035, Loss: 0.053989142179489136\n",
      "Iteration 5036, Loss: 0.05417194217443466\n",
      "Iteration 5037, Loss: 0.05398930236697197\n",
      "Iteration 5038, Loss: 0.0541718527674675\n",
      "Iteration 5039, Loss: 0.05398942157626152\n",
      "Iteration 5040, Loss: 0.05417178198695183\n",
      "Iteration 5041, Loss: 0.05398938059806824\n",
      "Iteration 5042, Loss: 0.05417182296514511\n",
      "Iteration 5043, Loss: 0.053989261388778687\n",
      "Iteration 5044, Loss: 0.05417194217443466\n",
      "Iteration 5045, Loss: 0.05398918315768242\n",
      "Iteration 5046, Loss: 0.05417210981249809\n",
      "Iteration 5047, Loss: 0.05398895591497421\n",
      "Iteration 5048, Loss: 0.05417218804359436\n",
      "Iteration 5049, Loss: 0.05398886650800705\n",
      "Iteration 5050, Loss: 0.05417226254940033\n",
      "Iteration 5051, Loss: 0.053988825529813766\n",
      "Iteration 5052, Loss: 0.05417225882411003\n",
      "Iteration 5053, Loss: 0.05398883670568466\n",
      "Iteration 5054, Loss: 0.0541720949113369\n",
      "Iteration 5055, Loss: 0.05398911237716675\n",
      "Iteration 5056, Loss: 0.05417162925004959\n",
      "Iteration 5057, Loss: 0.05398954078555107\n",
      "Iteration 5058, Loss: 0.05417146533727646\n",
      "Iteration 5059, Loss: 0.05398965999484062\n",
      "Iteration 5060, Loss: 0.05417146533727646\n",
      "Iteration 5061, Loss: 0.05398965999484062\n",
      "Iteration 5062, Loss: 0.05417158454656601\n",
      "Iteration 5063, Loss: 0.053989581763744354\n",
      "Iteration 5064, Loss: 0.054171591997146606\n",
      "Iteration 5065, Loss: 0.0539894625544548\n",
      "Iteration 5066, Loss: 0.054171741008758545\n",
      "Iteration 5067, Loss: 0.05398942530155182\n",
      "Iteration 5068, Loss: 0.054171860218048096\n",
      "Iteration 5069, Loss: 0.0539892315864563\n",
      "Iteration 5070, Loss: 0.05417194217443466\n",
      "Iteration 5071, Loss: 0.05398910492658615\n",
      "Iteration 5072, Loss: 0.054172031581401825\n",
      "Iteration 5073, Loss: 0.0539889894425869\n",
      "Iteration 5074, Loss: 0.05417210981249809\n",
      "Iteration 5075, Loss: 0.05398883670568466\n",
      "Iteration 5076, Loss: 0.05417225882411003\n",
      "Iteration 5077, Loss: 0.053988873958587646\n",
      "Iteration 5078, Loss: 0.05417221784591675\n",
      "Iteration 5079, Loss: 0.05398903042078018\n",
      "Iteration 5080, Loss: 0.05417194217443466\n",
      "Iteration 5081, Loss: 0.05398915708065033\n",
      "Iteration 5082, Loss: 0.054171741008758545\n",
      "Iteration 5083, Loss: 0.053989432752132416\n",
      "Iteration 5084, Loss: 0.054171543568372726\n",
      "Iteration 5085, Loss: 0.05398961901664734\n",
      "Iteration 5086, Loss: 0.05417134612798691\n",
      "Iteration 5087, Loss: 0.05398966372013092\n",
      "Iteration 5088, Loss: 0.05417134612798691\n",
      "Iteration 5089, Loss: 0.05398977920413017\n",
      "Iteration 5090, Loss: 0.054171428084373474\n",
      "Iteration 5091, Loss: 0.05398961901664734\n",
      "Iteration 5092, Loss: 0.05417155846953392\n",
      "Iteration 5093, Loss: 0.053989313542842865\n",
      "Iteration 5094, Loss: 0.05417183041572571\n",
      "Iteration 5095, Loss: 0.05398895591497421\n",
      "Iteration 5096, Loss: 0.05417218059301376\n",
      "Iteration 5097, Loss: 0.05398891121149063\n",
      "Iteration 5098, Loss: 0.054172299802303314\n",
      "Iteration 5099, Loss: 0.053988754749298096\n",
      "Iteration 5100, Loss: 0.05417221784591675\n",
      "Iteration 5101, Loss: 0.053988873958587646\n",
      "Iteration 5102, Loss: 0.05417202040553093\n",
      "Iteration 5103, Loss: 0.05398915335536003\n",
      "Iteration 5104, Loss: 0.05417170748114586\n",
      "Iteration 5105, Loss: 0.05398939177393913\n",
      "Iteration 5106, Loss: 0.05417150259017944\n",
      "Iteration 5107, Loss: 0.05398973822593689\n",
      "Iteration 5108, Loss: 0.05417130887508392\n",
      "Iteration 5109, Loss: 0.053989704698324203\n",
      "Iteration 5110, Loss: 0.054171230643987656\n",
      "Iteration 5111, Loss: 0.05398967117071152\n",
      "Iteration 5112, Loss: 0.05417146906256676\n",
      "Iteration 5113, Loss: 0.053989432752132416\n",
      "Iteration 5114, Loss: 0.0541715994477272\n",
      "Iteration 5115, Loss: 0.05398903787136078\n",
      "Iteration 5116, Loss: 0.054172106087207794\n",
      "Iteration 5117, Loss: 0.05398883670568466\n",
      "Iteration 5118, Loss: 0.05417218059301376\n",
      "Iteration 5119, Loss: 0.05398883670568466\n",
      "Iteration 5120, Loss: 0.05417225882411003\n",
      "Iteration 5121, Loss: 0.05398903414607048\n",
      "Iteration 5122, Loss: 0.0541720949113369\n",
      "Iteration 5123, Loss: 0.05398911237716675\n",
      "Iteration 5124, Loss: 0.054171930998563766\n",
      "Iteration 5125, Loss: 0.05398927256464958\n",
      "Iteration 5126, Loss: 0.05417182296514511\n",
      "Iteration 5127, Loss: 0.05398934707045555\n",
      "Iteration 5128, Loss: 0.05417170748114586\n",
      "Iteration 5129, Loss: 0.053989388048648834\n",
      "Iteration 5130, Loss: 0.05417182296514511\n",
      "Iteration 5131, Loss: 0.053989313542842865\n",
      "Iteration 5132, Loss: 0.054171860218048096\n",
      "Iteration 5133, Loss: 0.0539892315864563\n",
      "Iteration 5134, Loss: 0.05417186766862869\n",
      "Iteration 5135, Loss: 0.053989119827747345\n",
      "Iteration 5136, Loss: 0.05417190492153168\n",
      "Iteration 5137, Loss: 0.05398907884955406\n",
      "Iteration 5138, Loss: 0.054171934723854065\n",
      "Iteration 5139, Loss: 0.05398915335536003\n",
      "Iteration 5140, Loss: 0.05417189747095108\n",
      "Iteration 5141, Loss: 0.05398930236697197\n",
      "Iteration 5142, Loss: 0.05417178198695183\n",
      "Iteration 5143, Loss: 0.0539892315864563\n",
      "Iteration 5144, Loss: 0.054171741008758545\n",
      "Iteration 5145, Loss: 0.05398942157626152\n",
      "Iteration 5146, Loss: 0.054171785712242126\n",
      "Iteration 5147, Loss: 0.05398915708065033\n",
      "Iteration 5148, Loss: 0.05417182669043541\n",
      "Iteration 5149, Loss: 0.05398911237716675\n",
      "Iteration 5150, Loss: 0.05417194217443466\n",
      "Iteration 5151, Loss: 0.05398911237716675\n",
      "Iteration 5152, Loss: 0.054171979427337646\n",
      "Iteration 5153, Loss: 0.05398896336555481\n",
      "Iteration 5154, Loss: 0.05417190119624138\n",
      "Iteration 5155, Loss: 0.0539892315864563\n",
      "Iteration 5156, Loss: 0.05417182296514511\n",
      "Iteration 5157, Loss: 0.05398942157626152\n",
      "Iteration 5158, Loss: 0.054171666502952576\n",
      "Iteration 5159, Loss: 0.05398938059806824\n",
      "Iteration 5160, Loss: 0.05417170748114586\n",
      "Iteration 5161, Loss: 0.05398927256464958\n",
      "Iteration 5162, Loss: 0.05417175218462944\n",
      "Iteration 5163, Loss: 0.0539892315864563\n",
      "Iteration 5164, Loss: 0.05417179316282272\n",
      "Iteration 5165, Loss: 0.053989261388778687\n",
      "Iteration 5166, Loss: 0.05417182669043541\n",
      "Iteration 5167, Loss: 0.053989119827747345\n",
      "Iteration 5168, Loss: 0.05417201668024063\n",
      "Iteration 5169, Loss: 0.05398907884955406\n",
      "Iteration 5170, Loss: 0.05417205020785332\n",
      "Iteration 5171, Loss: 0.05398907884955406\n",
      "Iteration 5172, Loss: 0.054171934723854065\n",
      "Iteration 5173, Loss: 0.0539892241358757\n",
      "Iteration 5174, Loss: 0.054171860218048096\n",
      "Iteration 5175, Loss: 0.05398930236697197\n",
      "Iteration 5176, Loss: 0.05417178198695183\n",
      "Iteration 5177, Loss: 0.05398930609226227\n",
      "Iteration 5178, Loss: 0.05417182296514511\n",
      "Iteration 5179, Loss: 0.05398935079574585\n",
      "Iteration 5180, Loss: 0.05417194217443466\n",
      "Iteration 5181, Loss: 0.05398911237716675\n",
      "Iteration 5182, Loss: 0.05417194217443466\n",
      "Iteration 5183, Loss: 0.05398903787136078\n",
      "Iteration 5184, Loss: 0.05417202040553093\n",
      "Iteration 5185, Loss: 0.05398903042078018\n",
      "Iteration 5186, Loss: 0.05417206138372421\n",
      "Iteration 5187, Loss: 0.05398903042078018\n",
      "Iteration 5188, Loss: 0.05417194217443466\n",
      "Iteration 5189, Loss: 0.0539892315864563\n",
      "Iteration 5190, Loss: 0.05417182296514511\n",
      "Iteration 5191, Loss: 0.05398938059806824\n",
      "Iteration 5192, Loss: 0.05417166277766228\n",
      "Iteration 5193, Loss: 0.0539894625544548\n",
      "Iteration 5194, Loss: 0.054171591997146606\n",
      "Iteration 5195, Loss: 0.053989388048648834\n",
      "Iteration 5196, Loss: 0.054171666502952576\n",
      "Iteration 5197, Loss: 0.053989388048648834\n",
      "Iteration 5198, Loss: 0.05417170375585556\n",
      "Iteration 5199, Loss: 0.05398935079574585\n",
      "Iteration 5200, Loss: 0.05417162925004959\n",
      "Iteration 5201, Loss: 0.05398939177393913\n",
      "Iteration 5202, Loss: 0.05417162925004959\n",
      "Iteration 5203, Loss: 0.05398927256464958\n",
      "Iteration 5204, Loss: 0.054171621799468994\n",
      "Iteration 5205, Loss: 0.053989313542842865\n",
      "Iteration 5206, Loss: 0.054171621799468994\n",
      "Iteration 5207, Loss: 0.05398954078555107\n",
      "Iteration 5208, Loss: 0.054171349853277206\n",
      "Iteration 5209, Loss: 0.05398977920413017\n",
      "Iteration 5210, Loss: 0.05417126417160034\n",
      "Iteration 5211, Loss: 0.053989820182323456\n",
      "Iteration 5212, Loss: 0.05417122691869736\n",
      "Iteration 5213, Loss: 0.05398977920413017\n",
      "Iteration 5214, Loss: 0.05417138338088989\n",
      "Iteration 5215, Loss: 0.053989700973033905\n",
      "Iteration 5216, Loss: 0.05417143553495407\n",
      "Iteration 5217, Loss: 0.053989581763744354\n",
      "Iteration 5218, Loss: 0.05417163297533989\n",
      "Iteration 5219, Loss: 0.05398934334516525\n",
      "Iteration 5220, Loss: 0.05417186766862869\n",
      "Iteration 5221, Loss: 0.05398910492658615\n",
      "Iteration 5222, Loss: 0.0541720986366272\n",
      "Iteration 5223, Loss: 0.053988806903362274\n",
      "Iteration 5224, Loss: 0.05417202413082123\n",
      "Iteration 5225, Loss: 0.05398888513445854\n",
      "Iteration 5226, Loss: 0.05417194217443466\n",
      "Iteration 5227, Loss: 0.053989164531230927\n",
      "Iteration 5228, Loss: 0.05417169630527496\n",
      "Iteration 5229, Loss: 0.05398954078555107\n",
      "Iteration 5230, Loss: 0.054171353578567505\n",
      "Iteration 5231, Loss: 0.053989700973033905\n",
      "Iteration 5232, Loss: 0.054171230643987656\n",
      "Iteration 5233, Loss: 0.053989749401807785\n",
      "Iteration 5234, Loss: 0.054171185940504074\n",
      "Iteration 5235, Loss: 0.053989749401807785\n",
      "Iteration 5236, Loss: 0.054171230643987656\n",
      "Iteration 5237, Loss: 0.05398973822593689\n",
      "Iteration 5238, Loss: 0.054171424359083176\n",
      "Iteration 5239, Loss: 0.053989626467227936\n",
      "Iteration 5240, Loss: 0.054171543568372726\n",
      "Iteration 5241, Loss: 0.0539894700050354\n",
      "Iteration 5242, Loss: 0.05417155474424362\n",
      "Iteration 5243, Loss: 0.05398935079574585\n",
      "Iteration 5244, Loss: 0.05417162925004959\n",
      "Iteration 5245, Loss: 0.05398938059806824\n",
      "Iteration 5246, Loss: 0.054171472787857056\n",
      "Iteration 5247, Loss: 0.05398939177393913\n",
      "Iteration 5248, Loss: 0.05417143553495407\n",
      "Iteration 5249, Loss: 0.05398954451084137\n",
      "Iteration 5250, Loss: 0.05417139455676079\n",
      "Iteration 5251, Loss: 0.0539894700050354\n",
      "Iteration 5252, Loss: 0.054171543568372726\n",
      "Iteration 5253, Loss: 0.05398954078555107\n",
      "Iteration 5254, Loss: 0.054171543568372726\n",
      "Iteration 5255, Loss: 0.05398942530155182\n",
      "Iteration 5256, Loss: 0.05417162925004959\n",
      "Iteration 5257, Loss: 0.05398935079574585\n",
      "Iteration 5258, Loss: 0.054171591997146606\n",
      "Iteration 5259, Loss: 0.053989313542842865\n",
      "Iteration 5260, Loss: 0.054171621799468994\n",
      "Iteration 5261, Loss: 0.053989507257938385\n",
      "Iteration 5262, Loss: 0.05417151004076004\n",
      "Iteration 5263, Loss: 0.05398949980735779\n",
      "Iteration 5264, Loss: 0.054171543568372726\n",
      "Iteration 5265, Loss: 0.05398954078555107\n",
      "Iteration 5266, Loss: 0.05417143553495407\n",
      "Iteration 5267, Loss: 0.0539894662797451\n",
      "Iteration 5268, Loss: 0.054171472787857056\n",
      "Iteration 5269, Loss: 0.053989432752132416\n",
      "Iteration 5270, Loss: 0.054171591997146606\n",
      "Iteration 5271, Loss: 0.05398942157626152\n",
      "Iteration 5272, Loss: 0.054171591997146606\n",
      "Iteration 5273, Loss: 0.05398942157626152\n",
      "Iteration 5274, Loss: 0.05417158454656601\n",
      "Iteration 5275, Loss: 0.05398939177393913\n",
      "Iteration 5276, Loss: 0.054171543568372726\n",
      "Iteration 5277, Loss: 0.05398954451084137\n",
      "Iteration 5278, Loss: 0.054171543568372726\n",
      "Iteration 5279, Loss: 0.053989581763744354\n",
      "Iteration 5280, Loss: 0.054171428084373474\n",
      "Iteration 5281, Loss: 0.05398949980735779\n",
      "Iteration 5282, Loss: 0.054171621799468994\n",
      "Iteration 5283, Loss: 0.053989432752132416\n",
      "Iteration 5284, Loss: 0.05417151376605034\n",
      "Iteration 5285, Loss: 0.05398935079574585\n",
      "Iteration 5286, Loss: 0.054171591997146606\n",
      "Iteration 5287, Loss: 0.053989432752132416\n",
      "Iteration 5288, Loss: 0.05417170748114586\n",
      "Iteration 5289, Loss: 0.05398919805884361\n",
      "Iteration 5290, Loss: 0.05417182669043541\n",
      "Iteration 5291, Loss: 0.05398911237716675\n",
      "Iteration 5292, Loss: 0.05417190119624138\n",
      "Iteration 5293, Loss: 0.053989194333553314\n",
      "Iteration 5294, Loss: 0.05417170375585556\n",
      "Iteration 5295, Loss: 0.053989313542842865\n",
      "Iteration 5296, Loss: 0.05417139455676079\n",
      "Iteration 5297, Loss: 0.05398955196142197\n",
      "Iteration 5298, Loss: 0.054171424359083176\n",
      "Iteration 5299, Loss: 0.05398961901664734\n",
      "Iteration 5300, Loss: 0.05417133495211601\n",
      "Iteration 5301, Loss: 0.053989700973033905\n",
      "Iteration 5302, Loss: 0.054171305149793625\n",
      "Iteration 5303, Loss: 0.05398973822593689\n",
      "Iteration 5304, Loss: 0.054171498864889145\n",
      "Iteration 5305, Loss: 0.05398973450064659\n",
      "Iteration 5306, Loss: 0.05417143553495407\n",
      "Iteration 5307, Loss: 0.0539894700050354\n",
      "Iteration 5308, Loss: 0.05417178198695183\n",
      "Iteration 5309, Loss: 0.053989313542842865\n",
      "Iteration 5310, Loss: 0.05417197197675705\n",
      "Iteration 5311, Loss: 0.05398907512426376\n",
      "Iteration 5312, Loss: 0.054172053933143616\n",
      "Iteration 5313, Loss: 0.05398903414607048\n",
      "Iteration 5314, Loss: 0.054171930998563766\n",
      "Iteration 5315, Loss: 0.05398915335536003\n",
      "Iteration 5316, Loss: 0.054171741008758545\n",
      "Iteration 5317, Loss: 0.0539894625544548\n",
      "Iteration 5318, Loss: 0.05417146533727646\n",
      "Iteration 5319, Loss: 0.053989820182323456\n",
      "Iteration 5320, Loss: 0.054171305149793625\n",
      "Iteration 5321, Loss: 0.053989894688129425\n",
      "Iteration 5322, Loss: 0.05417130887508392\n",
      "Iteration 5323, Loss: 0.053989849984645844\n",
      "Iteration 5324, Loss: 0.05417155474424362\n",
      "Iteration 5325, Loss: 0.053989529609680176\n",
      "Iteration 5326, Loss: 0.05417190119624138\n",
      "Iteration 5327, Loss: 0.0539892241358757\n",
      "Iteration 5328, Loss: 0.05417206138372421\n",
      "Iteration 5329, Loss: 0.05398911237716675\n",
      "Iteration 5330, Loss: 0.0541720986366272\n",
      "Iteration 5331, Loss: 0.053988926112651825\n",
      "Iteration 5332, Loss: 0.05417218059301376\n",
      "Iteration 5333, Loss: 0.05398883670568466\n",
      "Iteration 5334, Loss: 0.05417225882411003\n",
      "Iteration 5335, Loss: 0.05398883670568466\n",
      "Iteration 5336, Loss: 0.0541720986366272\n",
      "Iteration 5337, Loss: 0.05398903414607048\n",
      "Iteration 5338, Loss: 0.054171979427337646\n",
      "Iteration 5339, Loss: 0.05398927256464958\n",
      "Iteration 5340, Loss: 0.054171741008758545\n",
      "Iteration 5341, Loss: 0.05398942157626152\n",
      "Iteration 5342, Loss: 0.05417177826166153\n",
      "Iteration 5343, Loss: 0.05398938059806824\n",
      "Iteration 5344, Loss: 0.05417182296514511\n",
      "Iteration 5345, Loss: 0.05398927256464958\n",
      "Iteration 5346, Loss: 0.05417197570204735\n",
      "Iteration 5347, Loss: 0.05398915335536003\n",
      "Iteration 5348, Loss: 0.054172009229660034\n",
      "Iteration 5349, Loss: 0.053989261388778687\n",
      "Iteration 5350, Loss: 0.05417182669043541\n",
      "Iteration 5351, Loss: 0.05398930236697197\n",
      "Iteration 5352, Loss: 0.05417178198695183\n",
      "Iteration 5353, Loss: 0.05398938059806824\n",
      "Iteration 5354, Loss: 0.05417170375585556\n",
      "Iteration 5355, Loss: 0.053989388048648834\n",
      "Iteration 5356, Loss: 0.054171741008758545\n",
      "Iteration 5357, Loss: 0.05398938059806824\n",
      "Iteration 5358, Loss: 0.05417178198695183\n",
      "Iteration 5359, Loss: 0.05398939177393913\n",
      "Iteration 5360, Loss: 0.054171860218048096\n",
      "Iteration 5361, Loss: 0.05398915335536003\n",
      "Iteration 5362, Loss: 0.05417190119624138\n",
      "Iteration 5363, Loss: 0.053989194333553314\n",
      "Iteration 5364, Loss: 0.05417194217443466\n",
      "Iteration 5365, Loss: 0.05398915335536003\n",
      "Iteration 5366, Loss: 0.054171930998563766\n",
      "Iteration 5367, Loss: 0.05398927256464958\n",
      "Iteration 5368, Loss: 0.05417178198695183\n",
      "Iteration 5369, Loss: 0.05398927256464958\n",
      "Iteration 5370, Loss: 0.05417182296514511\n",
      "Iteration 5371, Loss: 0.05398938059806824\n",
      "Iteration 5372, Loss: 0.05417177081108093\n",
      "Iteration 5373, Loss: 0.05398942530155182\n",
      "Iteration 5374, Loss: 0.05417177081108093\n",
      "Iteration 5375, Loss: 0.05398939177393913\n",
      "Iteration 5376, Loss: 0.05417182296514511\n",
      "Iteration 5377, Loss: 0.05398927256464958\n",
      "Iteration 5378, Loss: 0.05417183041572571\n",
      "Iteration 5379, Loss: 0.05398918688297272\n",
      "Iteration 5380, Loss: 0.05417202040553093\n",
      "Iteration 5381, Loss: 0.05398895591497421\n",
      "Iteration 5382, Loss: 0.05417218059301376\n",
      "Iteration 5383, Loss: 0.05398891493678093\n",
      "Iteration 5384, Loss: 0.054172106087207794\n",
      "Iteration 5385, Loss: 0.053989432752132416\n",
      "Iteration 5386, Loss: 0.054172009229660034\n",
      "Iteration 5387, Loss: 0.05398977920413017\n",
      "Iteration 5388, Loss: 0.05417138338088989\n",
      "Iteration 5389, Loss: 0.053990334272384644\n",
      "Iteration 5390, Loss: 0.05417056009173393\n",
      "Iteration 5391, Loss: 0.05399053543806076\n",
      "Iteration 5392, Loss: 0.05417070910334587\n",
      "Iteration 5393, Loss: 0.0539904460310936\n",
      "Iteration 5394, Loss: 0.05417099595069885\n",
      "Iteration 5395, Loss: 0.053989898413419724\n",
      "Iteration 5396, Loss: 0.054171860218048096\n",
      "Iteration 5397, Loss: 0.05398911237716675\n",
      "Iteration 5398, Loss: 0.054172269999980927\n",
      "Iteration 5399, Loss: 0.05398871749639511\n",
      "Iteration 5400, Loss: 0.05417269095778465\n",
      "Iteration 5401, Loss: 0.05398837476968765\n",
      "Iteration 5402, Loss: 0.054172616451978683\n",
      "Iteration 5403, Loss: 0.053988516330718994\n",
      "Iteration 5404, Loss: 0.054172419011592865\n",
      "Iteration 5405, Loss: 0.053988873958587646\n",
      "Iteration 5406, Loss: 0.054171979427337646\n",
      "Iteration 5407, Loss: 0.05398930236697197\n",
      "Iteration 5408, Loss: 0.05417155474424362\n",
      "Iteration 5409, Loss: 0.05398958921432495\n",
      "Iteration 5410, Loss: 0.05417138338088989\n",
      "Iteration 5411, Loss: 0.0539897084236145\n",
      "Iteration 5412, Loss: 0.054171424359083176\n",
      "Iteration 5413, Loss: 0.053989820182323456\n",
      "Iteration 5414, Loss: 0.05417150259017944\n",
      "Iteration 5415, Loss: 0.053989581763744354\n",
      "Iteration 5416, Loss: 0.054171741008758545\n",
      "Iteration 5417, Loss: 0.05398935079574585\n",
      "Iteration 5418, Loss: 0.054171815514564514\n",
      "Iteration 5419, Loss: 0.05398935079574585\n",
      "Iteration 5420, Loss: 0.05417189002037048\n",
      "Iteration 5421, Loss: 0.05398935079574585\n",
      "Iteration 5422, Loss: 0.05417190119624138\n",
      "Iteration 5423, Loss: 0.053988754749298096\n",
      "Iteration 5424, Loss: 0.05417179316282272\n",
      "Iteration 5425, Loss: 0.053988516330718994\n",
      "Iteration 5426, Loss: 0.05417262762784958\n",
      "Iteration 5427, Loss: 0.05398839712142944\n",
      "Iteration 5428, Loss: 0.05417269468307495\n",
      "Iteration 5429, Loss: 0.053988441824913025\n",
      "Iteration 5430, Loss: 0.05417237803339958\n",
      "Iteration 5431, Loss: 0.053988903760910034\n",
      "Iteration 5432, Loss: 0.05417212098836899\n",
      "Iteration 5433, Loss: 0.05398937687277794\n",
      "Iteration 5434, Loss: 0.054171621799468994\n",
      "Iteration 5435, Loss: 0.053989507257938385\n",
      "Iteration 5436, Loss: 0.05417130887508392\n",
      "Iteration 5437, Loss: 0.05398973822593689\n",
      "Iteration 5438, Loss: 0.05417134612798691\n",
      "Iteration 5439, Loss: 0.053989700973033905\n",
      "Iteration 5440, Loss: 0.05417143553495407\n",
      "Iteration 5441, Loss: 0.05398954078555107\n",
      "Iteration 5442, Loss: 0.05417155474424362\n",
      "Iteration 5443, Loss: 0.05398927256464958\n",
      "Iteration 5444, Loss: 0.05417194217443466\n",
      "Iteration 5445, Loss: 0.05398911237716675\n",
      "Iteration 5446, Loss: 0.05417206138372421\n",
      "Iteration 5447, Loss: 0.05398910492658615\n",
      "Iteration 5448, Loss: 0.054172173142433167\n",
      "Iteration 5449, Loss: 0.05398891493678093\n",
      "Iteration 5450, Loss: 0.05417213588953018\n",
      "Iteration 5451, Loss: 0.0539889931678772\n",
      "Iteration 5452, Loss: 0.05417202040553093\n",
      "Iteration 5453, Loss: 0.05398910865187645\n",
      "Iteration 5454, Loss: 0.05417182296514511\n",
      "Iteration 5455, Loss: 0.0539892315864563\n",
      "Iteration 5456, Loss: 0.0541718527674675\n",
      "Iteration 5457, Loss: 0.05398930609226227\n",
      "Iteration 5458, Loss: 0.05417178198695183\n",
      "Iteration 5459, Loss: 0.05398927256464958\n",
      "Iteration 5460, Loss: 0.05417170375585556\n",
      "Iteration 5461, Loss: 0.053989313542842865\n",
      "Iteration 5462, Loss: 0.05417174845933914\n",
      "Iteration 5463, Loss: 0.05398926883935928\n",
      "Iteration 5464, Loss: 0.05417179316282272\n",
      "Iteration 5465, Loss: 0.0539892241358757\n",
      "Iteration 5466, Loss: 0.05417194217443466\n",
      "Iteration 5467, Loss: 0.053989142179489136\n",
      "Iteration 5468, Loss: 0.054171979427337646\n",
      "Iteration 5469, Loss: 0.05398907512426376\n",
      "Iteration 5470, Loss: 0.05417190119624138\n",
      "Iteration 5471, Loss: 0.05398911237716675\n",
      "Iteration 5472, Loss: 0.0541718527674675\n",
      "Iteration 5473, Loss: 0.05398926883935928\n",
      "Iteration 5474, Loss: 0.05417165905237198\n",
      "Iteration 5475, Loss: 0.05398949980735779\n",
      "Iteration 5476, Loss: 0.054171618074178696\n",
      "Iteration 5477, Loss: 0.05398961901664734\n",
      "Iteration 5478, Loss: 0.054171618074178696\n",
      "Iteration 5479, Loss: 0.053989510983228683\n",
      "Iteration 5480, Loss: 0.05417166277766228\n",
      "Iteration 5481, Loss: 0.0539894625544548\n",
      "Iteration 5482, Loss: 0.054171815514564514\n",
      "Iteration 5483, Loss: 0.05398938059806824\n",
      "Iteration 5484, Loss: 0.05417190119624138\n",
      "Iteration 5485, Loss: 0.05398907512426376\n",
      "Iteration 5486, Loss: 0.0541720986366272\n",
      "Iteration 5487, Loss: 0.05398879945278168\n",
      "Iteration 5488, Loss: 0.0541723296046257\n",
      "Iteration 5489, Loss: 0.05398879572749138\n",
      "Iteration 5490, Loss: 0.054172247648239136\n",
      "Iteration 5491, Loss: 0.05398891493678093\n",
      "Iteration 5492, Loss: 0.054172009229660034\n",
      "Iteration 5493, Loss: 0.053989227861166\n",
      "Iteration 5494, Loss: 0.05417166277766228\n",
      "Iteration 5495, Loss: 0.05398957431316376\n",
      "Iteration 5496, Loss: 0.054171424359083176\n",
      "Iteration 5497, Loss: 0.05398977920413017\n",
      "Iteration 5498, Loss: 0.05417133495211601\n",
      "Iteration 5499, Loss: 0.05398993939161301\n",
      "Iteration 5500, Loss: 0.054171305149793625\n",
      "Iteration 5501, Loss: 0.05398977920413017\n",
      "Iteration 5502, Loss: 0.05417151376605034\n",
      "Iteration 5503, Loss: 0.05398954078555107\n",
      "Iteration 5504, Loss: 0.05417174845933914\n",
      "Iteration 5505, Loss: 0.0539892315864563\n",
      "Iteration 5506, Loss: 0.05417194589972496\n",
      "Iteration 5507, Loss: 0.0539889931678772\n",
      "Iteration 5508, Loss: 0.05417218059301376\n",
      "Iteration 5509, Loss: 0.05398887023329735\n",
      "Iteration 5510, Loss: 0.0541723296046257\n",
      "Iteration 5511, Loss: 0.05398883670568466\n",
      "Iteration 5512, Loss: 0.05417221039533615\n",
      "Iteration 5513, Loss: 0.05398891493678093\n",
      "Iteration 5514, Loss: 0.054172128438949585\n",
      "Iteration 5515, Loss: 0.053989194333553314\n",
      "Iteration 5516, Loss: 0.05417177081108093\n",
      "Iteration 5517, Loss: 0.05398949980735779\n",
      "Iteration 5518, Loss: 0.05417158827185631\n",
      "Iteration 5519, Loss: 0.05398961901664734\n",
      "Iteration 5520, Loss: 0.05417158454656601\n",
      "Iteration 5521, Loss: 0.05398955196142197\n",
      "Iteration 5522, Loss: 0.054171621799468994\n",
      "Iteration 5523, Loss: 0.053989388048648834\n",
      "Iteration 5524, Loss: 0.05417190119624138\n",
      "Iteration 5525, Loss: 0.05398914963006973\n",
      "Iteration 5526, Loss: 0.05417206138372421\n",
      "Iteration 5527, Loss: 0.053988873958587646\n",
      "Iteration 5528, Loss: 0.05417221784591675\n",
      "Iteration 5529, Loss: 0.05398883670568466\n",
      "Iteration 5530, Loss: 0.05417221039533615\n",
      "Iteration 5531, Loss: 0.05398891493678093\n",
      "Iteration 5532, Loss: 0.05417221039533615\n",
      "Iteration 5533, Loss: 0.0539889931678772\n",
      "Iteration 5534, Loss: 0.054171860218048096\n",
      "Iteration 5535, Loss: 0.053989227861166\n",
      "Iteration 5536, Loss: 0.05417177081108093\n",
      "Iteration 5537, Loss: 0.05398942530155182\n",
      "Iteration 5538, Loss: 0.054171621799468994\n",
      "Iteration 5539, Loss: 0.05398954078555107\n",
      "Iteration 5540, Loss: 0.054171621799468994\n",
      "Iteration 5541, Loss: 0.053989581763744354\n",
      "Iteration 5542, Loss: 0.054171621799468994\n",
      "Iteration 5543, Loss: 0.05398942530155182\n",
      "Iteration 5544, Loss: 0.05417158454656601\n",
      "Iteration 5545, Loss: 0.05398961529135704\n",
      "Iteration 5546, Loss: 0.05417150259017944\n",
      "Iteration 5547, Loss: 0.053989581763744354\n",
      "Iteration 5548, Loss: 0.05417150259017944\n",
      "Iteration 5549, Loss: 0.05398961901664734\n",
      "Iteration 5550, Loss: 0.054171621799468994\n",
      "Iteration 5551, Loss: 0.05398954078555107\n",
      "Iteration 5552, Loss: 0.05417158454656601\n",
      "Iteration 5553, Loss: 0.05398938059806824\n",
      "Iteration 5554, Loss: 0.05417174845933914\n",
      "Iteration 5555, Loss: 0.053989194333553314\n",
      "Iteration 5556, Loss: 0.05417202040553093\n",
      "Iteration 5557, Loss: 0.0539889931678772\n",
      "Iteration 5558, Loss: 0.054172247648239136\n",
      "Iteration 5559, Loss: 0.05398888140916824\n",
      "Iteration 5560, Loss: 0.05417213588953018\n",
      "Iteration 5561, Loss: 0.05398903042078018\n",
      "Iteration 5562, Loss: 0.05417182296514511\n",
      "Iteration 5563, Loss: 0.053989227861166\n",
      "Iteration 5564, Loss: 0.054171811789274216\n",
      "Iteration 5565, Loss: 0.05398934707045555\n",
      "Iteration 5566, Loss: 0.05417158454656601\n",
      "Iteration 5567, Loss: 0.053989581763744354\n",
      "Iteration 5568, Loss: 0.054171543568372726\n",
      "Iteration 5569, Loss: 0.05398965999484062\n",
      "Iteration 5570, Loss: 0.054171621799468994\n",
      "Iteration 5571, Loss: 0.0539894625544548\n",
      "Iteration 5572, Loss: 0.05417178198695183\n",
      "Iteration 5573, Loss: 0.053989194333553314\n",
      "Iteration 5574, Loss: 0.054172031581401825\n",
      "Iteration 5575, Loss: 0.053988873958587646\n",
      "Iteration 5576, Loss: 0.05417221784591675\n",
      "Iteration 5577, Loss: 0.05398879200220108\n",
      "Iteration 5578, Loss: 0.05417244881391525\n",
      "Iteration 5579, Loss: 0.05398871749639511\n",
      "Iteration 5580, Loss: 0.054172173142433167\n",
      "Iteration 5581, Loss: 0.05398891493678093\n",
      "Iteration 5582, Loss: 0.054172009229660034\n",
      "Iteration 5583, Loss: 0.05398918315768242\n",
      "Iteration 5584, Loss: 0.05417189002037048\n",
      "Iteration 5585, Loss: 0.05398930609226227\n",
      "Iteration 5586, Loss: 0.05417166277766228\n",
      "Iteration 5587, Loss: 0.053989507257938385\n",
      "Iteration 5588, Loss: 0.05417166277766228\n",
      "Iteration 5589, Loss: 0.05398949980735779\n",
      "Iteration 5590, Loss: 0.054171741008758545\n",
      "Iteration 5591, Loss: 0.05398942157626152\n",
      "Iteration 5592, Loss: 0.054171934723854065\n",
      "Iteration 5593, Loss: 0.05398915335536003\n",
      "Iteration 5594, Loss: 0.0541720986366272\n",
      "Iteration 5595, Loss: 0.05398884415626526\n",
      "Iteration 5596, Loss: 0.054172299802303314\n",
      "Iteration 5597, Loss: 0.05398871749639511\n",
      "Iteration 5598, Loss: 0.05417244881391525\n",
      "Iteration 5599, Loss: 0.053988754749298096\n",
      "Iteration 5600, Loss: 0.05417213961482048\n",
      "Iteration 5601, Loss: 0.05398891493678093\n",
      "Iteration 5602, Loss: 0.05417190119624138\n",
      "Iteration 5603, Loss: 0.05398927256464958\n",
      "Iteration 5604, Loss: 0.05417158454656601\n",
      "Iteration 5605, Loss: 0.05398965999484062\n",
      "Iteration 5606, Loss: 0.05417138338088989\n",
      "Iteration 5607, Loss: 0.05398977920413017\n",
      "Iteration 5608, Loss: 0.054171424359083176\n",
      "Iteration 5609, Loss: 0.05398961901664734\n",
      "Iteration 5610, Loss: 0.05417155474424362\n",
      "Iteration 5611, Loss: 0.05398934707045555\n",
      "Iteration 5612, Loss: 0.054171860218048096\n",
      "Iteration 5613, Loss: 0.0539892241358757\n",
      "Iteration 5614, Loss: 0.054172009229660034\n",
      "Iteration 5615, Loss: 0.05398915708065033\n",
      "Iteration 5616, Loss: 0.054171930998563766\n",
      "Iteration 5617, Loss: 0.0539892315864563\n",
      "Iteration 5618, Loss: 0.0541718527674675\n",
      "Iteration 5619, Loss: 0.05398930609226227\n",
      "Iteration 5620, Loss: 0.05417166277766228\n",
      "Iteration 5621, Loss: 0.05398949980735779\n",
      "Iteration 5622, Loss: 0.054171621799468994\n",
      "Iteration 5623, Loss: 0.053989432752132416\n",
      "Iteration 5624, Loss: 0.05417170375585556\n",
      "Iteration 5625, Loss: 0.053989388048648834\n",
      "Iteration 5626, Loss: 0.0541718527674675\n",
      "Iteration 5627, Loss: 0.05398938059806824\n",
      "Iteration 5628, Loss: 0.05417182296514511\n",
      "Iteration 5629, Loss: 0.053989261388778687\n",
      "Iteration 5630, Loss: 0.05417189747095108\n",
      "Iteration 5631, Loss: 0.0539892315864563\n",
      "Iteration 5632, Loss: 0.0541718527674675\n",
      "Iteration 5633, Loss: 0.05398949235677719\n",
      "Iteration 5634, Loss: 0.05417170375585556\n",
      "Iteration 5635, Loss: 0.05398945510387421\n",
      "Iteration 5636, Loss: 0.05417158454656601\n",
      "Iteration 5637, Loss: 0.05398954078555107\n",
      "Iteration 5638, Loss: 0.0541716143488884\n",
      "Iteration 5639, Loss: 0.05398969352245331\n",
      "Iteration 5640, Loss: 0.05417157709598541\n",
      "Iteration 5641, Loss: 0.05398961901664734\n",
      "Iteration 5642, Loss: 0.05417166277766228\n",
      "Iteration 5643, Loss: 0.05398938059806824\n",
      "Iteration 5644, Loss: 0.05417182296514511\n",
      "Iteration 5645, Loss: 0.05398914963006973\n",
      "Iteration 5646, Loss: 0.05417190492153168\n",
      "Iteration 5647, Loss: 0.05398891493678093\n",
      "Iteration 5648, Loss: 0.05417202040553093\n",
      "Iteration 5649, Loss: 0.05398915335536003\n",
      "Iteration 5650, Loss: 0.05417194217443466\n",
      "Iteration 5651, Loss: 0.053989261388778687\n",
      "Iteration 5652, Loss: 0.05417189002037048\n",
      "Iteration 5653, Loss: 0.05398945510387421\n",
      "Iteration 5654, Loss: 0.05417166277766228\n",
      "Iteration 5655, Loss: 0.05398949980735779\n",
      "Iteration 5656, Loss: 0.054171737283468246\n",
      "Iteration 5657, Loss: 0.05398949980735779\n",
      "Iteration 5658, Loss: 0.05417166277766228\n",
      "Iteration 5659, Loss: 0.0539894625544548\n",
      "Iteration 5660, Loss: 0.05417182296514511\n",
      "Iteration 5661, Loss: 0.05398934334516525\n",
      "Iteration 5662, Loss: 0.05417190119624138\n",
      "Iteration 5663, Loss: 0.05398910865187645\n",
      "Iteration 5664, Loss: 0.05417194217443466\n",
      "Iteration 5665, Loss: 0.05398903414607048\n",
      "Iteration 5666, Loss: 0.05417201668024063\n",
      "Iteration 5667, Loss: 0.05398907512426376\n",
      "Iteration 5668, Loss: 0.054171815514564514\n",
      "Iteration 5669, Loss: 0.05398930236697197\n",
      "Iteration 5670, Loss: 0.05417165905237198\n",
      "Iteration 5671, Loss: 0.0539894625544548\n",
      "Iteration 5672, Loss: 0.05417151004076004\n",
      "Iteration 5673, Loss: 0.05398958548903465\n",
      "Iteration 5674, Loss: 0.054171621799468994\n",
      "Iteration 5675, Loss: 0.05398881062865257\n",
      "Iteration 5676, Loss: 0.05417170375585556\n",
      "Iteration 5677, Loss: 0.05398872494697571\n",
      "Iteration 5678, Loss: 0.054171159863471985\n",
      "Iteration 5679, Loss: 0.05398876592516899\n",
      "Iteration 5680, Loss: 0.054171353578567505\n",
      "Iteration 5681, Loss: 0.05398841202259064\n",
      "Iteration 5682, Loss: 0.05417144298553467\n",
      "Iteration 5683, Loss: 0.05398828908801079\n",
      "Iteration 5684, Loss: 0.05417155474424362\n",
      "Iteration 5685, Loss: 0.05398821830749512\n",
      "Iteration 5686, Loss: 0.054171591997146606\n",
      "Iteration 5687, Loss: 0.053988367319107056\n",
      "Iteration 5688, Loss: 0.05417143553495407\n",
      "Iteration 5689, Loss: 0.05398837849497795\n",
      "Iteration 5690, Loss: 0.054171156138181686\n",
      "Iteration 5691, Loss: 0.05398865044116974\n",
      "Iteration 5692, Loss: 0.05417100712656975\n",
      "Iteration 5693, Loss: 0.053988732397556305\n",
      "Iteration 5694, Loss: 0.0541711263358593\n",
      "Iteration 5695, Loss: 0.053988657891750336\n",
      "Iteration 5696, Loss: 0.0541711263358593\n",
      "Iteration 5697, Loss: 0.05398860573768616\n",
      "Iteration 5698, Loss: 0.05417131632566452\n",
      "Iteration 5699, Loss: 0.05398860573768616\n",
      "Iteration 5700, Loss: 0.054171234369277954\n",
      "Iteration 5701, Loss: 0.053988657891750336\n",
      "Iteration 5702, Loss: 0.05417127162218094\n",
      "Iteration 5703, Loss: 0.05398861691355705\n",
      "Iteration 5704, Loss: 0.05417100340127945\n",
      "Iteration 5705, Loss: 0.05398876592516899\n",
      "Iteration 5706, Loss: 0.05417099595069885\n",
      "Iteration 5707, Loss: 0.053988926112651825\n",
      "Iteration 5708, Loss: 0.05417095869779587\n",
      "Iteration 5709, Loss: 0.05398900434374809\n",
      "Iteration 5710, Loss: 0.0541708879172802\n",
      "Iteration 5711, Loss: 0.05398903414607048\n",
      "Iteration 5712, Loss: 0.05417093634605408\n",
      "Iteration 5713, Loss: 0.053988613188266754\n",
      "Iteration 5714, Loss: 0.05417121201753616\n",
      "Iteration 5715, Loss: 0.05398837476968765\n",
      "Iteration 5716, Loss: 0.05417140945792198\n",
      "Iteration 5717, Loss: 0.05398821830749512\n",
      "Iteration 5718, Loss: 0.0541715994477272\n",
      "Iteration 5719, Loss: 0.05398814007639885\n",
      "Iteration 5720, Loss: 0.05417151004076004\n",
      "Iteration 5721, Loss: 0.05398845300078392\n",
      "Iteration 5722, Loss: 0.05417119711637497\n",
      "Iteration 5723, Loss: 0.05398872494697571\n",
      "Iteration 5724, Loss: 0.054171156138181686\n",
      "Iteration 5725, Loss: 0.05398876592516899\n",
      "Iteration 5726, Loss: 0.05417104810476303\n",
      "Iteration 5727, Loss: 0.05398876592516899\n",
      "Iteration 5728, Loss: 0.05417127534747124\n",
      "Iteration 5729, Loss: 0.053988538682460785\n",
      "Iteration 5730, Loss: 0.05417127534747124\n",
      "Iteration 5731, Loss: 0.05398856848478317\n",
      "Iteration 5732, Loss: 0.054171204566955566\n",
      "Iteration 5733, Loss: 0.0539884939789772\n",
      "Iteration 5734, Loss: 0.05417139455676079\n",
      "Iteration 5735, Loss: 0.05398833751678467\n",
      "Iteration 5736, Loss: 0.05417139455676079\n",
      "Iteration 5737, Loss: 0.053988419473171234\n",
      "Iteration 5738, Loss: 0.054171156138181686\n",
      "Iteration 5739, Loss: 0.05398872494697571\n",
      "Iteration 5740, Loss: 0.05417085811495781\n",
      "Iteration 5741, Loss: 0.05398888513445854\n",
      "Iteration 5742, Loss: 0.05417092889547348\n",
      "Iteration 5743, Loss: 0.053988851606845856\n",
      "Iteration 5744, Loss: 0.05417092889547348\n",
      "Iteration 5745, Loss: 0.05398900434374809\n",
      "Iteration 5746, Loss: 0.054170966148376465\n",
      "Iteration 5747, Loss: 0.053988732397556305\n",
      "Iteration 5748, Loss: 0.054171085357666016\n",
      "Iteration 5749, Loss: 0.053988538682460785\n",
      "Iteration 5750, Loss: 0.05417124554514885\n",
      "Iteration 5751, Loss: 0.053988419473171234\n",
      "Iteration 5752, Loss: 0.0541713647544384\n",
      "Iteration 5753, Loss: 0.0539882592856884\n",
      "Iteration 5754, Loss: 0.054171331226825714\n",
      "Iteration 5755, Loss: 0.05398822948336601\n",
      "Iteration 5756, Loss: 0.0541713647544384\n",
      "Iteration 5757, Loss: 0.05398845672607422\n",
      "Iteration 5758, Loss: 0.054171279072761536\n",
      "Iteration 5759, Loss: 0.0539884977042675\n",
      "Iteration 5760, Loss: 0.05417116731405258\n",
      "Iteration 5761, Loss: 0.05398864671587944\n",
      "Iteration 5762, Loss: 0.0541711263358593\n",
      "Iteration 5763, Loss: 0.05398869514465332\n",
      "Iteration 5764, Loss: 0.054171156138181686\n",
      "Iteration 5765, Loss: 0.05398869141936302\n",
      "Iteration 5766, Loss: 0.05417100712656975\n",
      "Iteration 5767, Loss: 0.05398876965045929\n",
      "Iteration 5768, Loss: 0.05417104810476303\n",
      "Iteration 5769, Loss: 0.05398868769407272\n",
      "Iteration 5770, Loss: 0.05417120084166527\n",
      "Iteration 5771, Loss: 0.053988613188266754\n",
      "Iteration 5772, Loss: 0.05417124554514885\n",
      "Iteration 5773, Loss: 0.053988419473171234\n",
      "Iteration 5774, Loss: 0.054171279072761536\n",
      "Iteration 5775, Loss: 0.05398845672607422\n",
      "Iteration 5776, Loss: 0.054171085357666016\n",
      "Iteration 5777, Loss: 0.053988538682460785\n",
      "Iteration 5778, Loss: 0.05417104810476303\n",
      "Iteration 5779, Loss: 0.05398868769407272\n",
      "Iteration 5780, Loss: 0.05417092889547348\n",
      "Iteration 5781, Loss: 0.05398888885974884\n",
      "Iteration 5782, Loss: 0.0541708879172802\n",
      "Iteration 5783, Loss: 0.05398884415626526\n",
      "Iteration 5784, Loss: 0.05417093634605408\n",
      "Iteration 5785, Loss: 0.053988806903362274\n",
      "Iteration 5786, Loss: 0.05417124181985855\n",
      "Iteration 5787, Loss: 0.05398845672607422\n",
      "Iteration 5788, Loss: 0.05417139455676079\n",
      "Iteration 5789, Loss: 0.05398837849497795\n",
      "Iteration 5790, Loss: 0.05417140573263168\n",
      "Iteration 5791, Loss: 0.05398833751678467\n",
      "Iteration 5792, Loss: 0.05417132377624512\n",
      "Iteration 5793, Loss: 0.05398833751678467\n",
      "Iteration 5794, Loss: 0.05417124554514885\n",
      "Iteration 5795, Loss: 0.0539884977042675\n",
      "Iteration 5796, Loss: 0.0541711263358593\n",
      "Iteration 5797, Loss: 0.05398868769407272\n",
      "Iteration 5798, Loss: 0.05417100712656975\n",
      "Iteration 5799, Loss: 0.053988806903362274\n",
      "Iteration 5800, Loss: 0.054170966148376465\n",
      "Iteration 5801, Loss: 0.053988777101039886\n",
      "Iteration 5802, Loss: 0.054170966148376465\n",
      "Iteration 5803, Loss: 0.053988657891750336\n",
      "Iteration 5804, Loss: 0.05417104810476303\n",
      "Iteration 5805, Loss: 0.05398865044116974\n",
      "Iteration 5806, Loss: 0.054171204566955566\n",
      "Iteration 5807, Loss: 0.053988419473171234\n",
      "Iteration 5808, Loss: 0.0541713647544384\n",
      "Iteration 5809, Loss: 0.05398821830749512\n",
      "Iteration 5810, Loss: 0.05417148396372795\n",
      "Iteration 5811, Loss: 0.05398821830749512\n",
      "Iteration 5812, Loss: 0.05417156219482422\n",
      "Iteration 5813, Loss: 0.05398830026388168\n",
      "Iteration 5814, Loss: 0.05417151749134064\n",
      "Iteration 5815, Loss: 0.05398821830749512\n",
      "Iteration 5816, Loss: 0.0541713610291481\n",
      "Iteration 5817, Loss: 0.05398845672607422\n",
      "Iteration 5818, Loss: 0.05417116731405258\n",
      "Iteration 5819, Loss: 0.05398857593536377\n",
      "Iteration 5820, Loss: 0.05417116731405258\n",
      "Iteration 5821, Loss: 0.053988538682460785\n",
      "Iteration 5822, Loss: 0.05417119711637497\n",
      "Iteration 5823, Loss: 0.05398857593536377\n",
      "Iteration 5824, Loss: 0.05417100712656975\n",
      "Iteration 5825, Loss: 0.053988657891750336\n",
      "Iteration 5826, Loss: 0.0541708879172802\n",
      "Iteration 5827, Loss: 0.053988851606845856\n",
      "Iteration 5828, Loss: 0.054170846939086914\n",
      "Iteration 5829, Loss: 0.05398896336555481\n",
      "Iteration 5830, Loss: 0.05417092144489288\n",
      "Iteration 5831, Loss: 0.053989000618457794\n",
      "Iteration 5832, Loss: 0.05417100712656975\n",
      "Iteration 5833, Loss: 0.05398876592516899\n",
      "Iteration 5834, Loss: 0.05417117103934288\n",
      "Iteration 5835, Loss: 0.05398845672607422\n",
      "Iteration 5836, Loss: 0.05417140945792198\n",
      "Iteration 5837, Loss: 0.053988292813301086\n",
      "Iteration 5838, Loss: 0.05417148768901825\n",
      "Iteration 5839, Loss: 0.05398810654878616\n",
      "Iteration 5840, Loss: 0.05417156219482422\n",
      "Iteration 5841, Loss: 0.05398821830749512\n",
      "Iteration 5842, Loss: 0.05417143553495407\n",
      "Iteration 5843, Loss: 0.053988486528396606\n",
      "Iteration 5844, Loss: 0.0541711151599884\n",
      "Iteration 5845, Loss: 0.05398876965045929\n",
      "Iteration 5846, Loss: 0.0541708841919899\n",
      "Iteration 5847, Loss: 0.05398888513445854\n",
      "Iteration 5848, Loss: 0.054170768707990646\n",
      "Iteration 5849, Loss: 0.05398900434374809\n",
      "Iteration 5850, Loss: 0.054170768707990646\n",
      "Iteration 5851, Loss: 0.05398892983794212\n",
      "Iteration 5852, Loss: 0.0541708879172802\n",
      "Iteration 5853, Loss: 0.05398891493678093\n",
      "Iteration 5854, Loss: 0.05417092889547348\n",
      "Iteration 5855, Loss: 0.05398876592516899\n",
      "Iteration 5856, Loss: 0.054171085357666016\n",
      "Iteration 5857, Loss: 0.05398864671587944\n",
      "Iteration 5858, Loss: 0.05417124554514885\n",
      "Iteration 5859, Loss: 0.053988419473171234\n",
      "Iteration 5860, Loss: 0.0541713647544384\n",
      "Iteration 5861, Loss: 0.05398830398917198\n",
      "Iteration 5862, Loss: 0.05417124554514885\n",
      "Iteration 5863, Loss: 0.05398845672607422\n",
      "Iteration 5864, Loss: 0.05417124554514885\n",
      "Iteration 5865, Loss: 0.05398845672607422\n",
      "Iteration 5866, Loss: 0.0541711263358593\n",
      "Iteration 5867, Loss: 0.05398861691355705\n",
      "Iteration 5868, Loss: 0.05417100712656975\n",
      "Iteration 5869, Loss: 0.053988806903362274\n",
      "Iteration 5870, Loss: 0.05417092889547348\n",
      "Iteration 5871, Loss: 0.05398876592516899\n",
      "Iteration 5872, Loss: 0.05417104810476303\n",
      "Iteration 5873, Loss: 0.05398864671587944\n",
      "Iteration 5874, Loss: 0.054171279072761536\n",
      "Iteration 5875, Loss: 0.053988486528396606\n",
      "Iteration 5876, Loss: 0.05417131632566452\n",
      "Iteration 5877, Loss: 0.05398901551961899\n",
      "Iteration 5878, Loss: 0.05417120084166527\n",
      "Iteration 5879, Loss: 0.05398900806903839\n",
      "Iteration 5880, Loss: 0.054171644151210785\n",
      "Iteration 5881, Loss: 0.053988974541425705\n",
      "Iteration 5882, Loss: 0.05417168140411377\n",
      "Iteration 5883, Loss: 0.05398905277252197\n",
      "Iteration 5884, Loss: 0.0541716031730175\n",
      "Iteration 5885, Loss: 0.053989093750715256\n",
      "Iteration 5886, Loss: 0.05417148396372795\n",
      "Iteration 5887, Loss: 0.05398924648761749\n",
      "Iteration 5888, Loss: 0.05417140573263168\n",
      "Iteration 5889, Loss: 0.05398929864168167\n",
      "Iteration 5890, Loss: 0.05417129397392273\n",
      "Iteration 5891, Loss: 0.05398976802825928\n",
      "Iteration 5892, Loss: 0.05417144298553467\n",
      "Iteration 5893, Loss: 0.05398961156606674\n",
      "Iteration 5894, Loss: 0.05417200177907944\n",
      "Iteration 5895, Loss: 0.05398961156606674\n",
      "Iteration 5896, Loss: 0.054172076284885406\n",
      "Iteration 5897, Loss: 0.05398956686258316\n",
      "Iteration 5898, Loss: 0.05417210981249809\n",
      "Iteration 5899, Loss: 0.05398961156606674\n",
      "Iteration 5900, Loss: 0.05417212098836899\n",
      "Iteration 5901, Loss: 0.05398952588438988\n",
      "Iteration 5902, Loss: 0.05417215824127197\n",
      "Iteration 5903, Loss: 0.053989484906196594\n",
      "Iteration 5904, Loss: 0.054172202944755554\n",
      "Iteration 5905, Loss: 0.05398940667510033\n",
      "Iteration 5906, Loss: 0.05417224019765854\n",
      "Iteration 5907, Loss: 0.05398933216929436\n",
      "Iteration 5908, Loss: 0.05417216941714287\n",
      "Iteration 5909, Loss: 0.05398932844400406\n",
      "Iteration 5910, Loss: 0.05417227745056152\n",
      "Iteration 5911, Loss: 0.05398929864168167\n",
      "Iteration 5912, Loss: 0.05417224019765854\n",
      "Iteration 5913, Loss: 0.05398945137858391\n",
      "Iteration 5914, Loss: 0.05417218804359436\n",
      "Iteration 5915, Loss: 0.05398957058787346\n",
      "Iteration 5916, Loss: 0.054172080010175705\n",
      "Iteration 5917, Loss: 0.05398964136838913\n",
      "Iteration 5918, Loss: 0.05417210981249809\n",
      "Iteration 5919, Loss: 0.0539897195994854\n",
      "Iteration 5920, Loss: 0.054171960800886154\n",
      "Iteration 5921, Loss: 0.05398983508348465\n",
      "Iteration 5922, Loss: 0.05417199060320854\n",
      "Iteration 5923, Loss: 0.05398968979716301\n",
      "Iteration 5924, Loss: 0.05417200177907944\n",
      "Iteration 5925, Loss: 0.05398957058787346\n",
      "Iteration 5926, Loss: 0.05417211353778839\n",
      "Iteration 5927, Loss: 0.053989529609680176\n",
      "Iteration 5928, Loss: 0.05417215824127197\n",
      "Iteration 5929, Loss: 0.053989484906196594\n",
      "Iteration 5930, Loss: 0.05417223274707794\n",
      "Iteration 5931, Loss: 0.05398933216929436\n",
      "Iteration 5932, Loss: 0.05417223274707794\n",
      "Iteration 5933, Loss: 0.053989410400390625\n",
      "Iteration 5934, Loss: 0.05417218804359436\n",
      "Iteration 5935, Loss: 0.053989674896001816\n",
      "Iteration 5936, Loss: 0.05417200177907944\n",
      "Iteration 5937, Loss: 0.053989678621292114\n",
      "Iteration 5938, Loss: 0.054171886295080185\n",
      "Iteration 5939, Loss: 0.053989678621292114\n",
      "Iteration 5940, Loss: 0.05417191982269287\n",
      "Iteration 5941, Loss: 0.05398968607187271\n",
      "Iteration 5942, Loss: 0.054171960800886154\n",
      "Iteration 5943, Loss: 0.05398961156606674\n",
      "Iteration 5944, Loss: 0.054172009229660034\n",
      "Iteration 5945, Loss: 0.05398941785097122\n",
      "Iteration 5946, Loss: 0.05417228862643242\n",
      "Iteration 5947, Loss: 0.05398917198181152\n",
      "Iteration 5948, Loss: 0.05417247861623764\n",
      "Iteration 5949, Loss: 0.05398905277252197\n",
      "Iteration 5950, Loss: 0.05417262762784958\n",
      "Iteration 5951, Loss: 0.053989093750715256\n",
      "Iteration 5952, Loss: 0.05417235940694809\n",
      "Iteration 5953, Loss: 0.053989291191101074\n",
      "Iteration 5954, Loss: 0.05417219549417496\n",
      "Iteration 5955, Loss: 0.053989559412002563\n",
      "Iteration 5956, Loss: 0.054172076284885406\n",
      "Iteration 5957, Loss: 0.05398961156606674\n",
      "Iteration 5958, Loss: 0.05417200177907944\n",
      "Iteration 5959, Loss: 0.053989723324775696\n",
      "Iteration 5960, Loss: 0.054171886295080185\n",
      "Iteration 5961, Loss: 0.05398964509367943\n",
      "Iteration 5962, Loss: 0.05417196452617645\n",
      "Iteration 5963, Loss: 0.05398960039019585\n",
      "Iteration 5964, Loss: 0.0541720911860466\n",
      "Iteration 5965, Loss: 0.05398933216929436\n",
      "Iteration 5966, Loss: 0.054172318428754807\n",
      "Iteration 5967, Loss: 0.053989287465810776\n",
      "Iteration 5968, Loss: 0.054172396659851074\n",
      "Iteration 5969, Loss: 0.05398924648761749\n",
      "Iteration 5970, Loss: 0.054172396659851074\n",
      "Iteration 5971, Loss: 0.053989291191101074\n",
      "Iteration 5972, Loss: 0.05417219549417496\n",
      "Iteration 5973, Loss: 0.053989559412002563\n",
      "Iteration 5974, Loss: 0.05417203903198242\n",
      "Iteration 5975, Loss: 0.05398961156606674\n",
      "Iteration 5976, Loss: 0.05417203903198242\n",
      "Iteration 5977, Loss: 0.05398961156606674\n",
      "Iteration 5978, Loss: 0.054172009229660034\n",
      "Iteration 5979, Loss: 0.05398956686258316\n",
      "Iteration 5980, Loss: 0.05417212098836899\n",
      "Iteration 5981, Loss: 0.05398937314748764\n",
      "Iteration 5982, Loss: 0.05417223274707794\n",
      "Iteration 5983, Loss: 0.05398937314748764\n",
      "Iteration 5984, Loss: 0.05417223274707794\n",
      "Iteration 5985, Loss: 0.05398940667510033\n",
      "Iteration 5986, Loss: 0.05417230725288391\n",
      "Iteration 5987, Loss: 0.053989484906196594\n",
      "Iteration 5988, Loss: 0.05417224019765854\n",
      "Iteration 5989, Loss: 0.05398940294981003\n",
      "Iteration 5990, Loss: 0.05417215824127197\n",
      "Iteration 5991, Loss: 0.053989410400390625\n",
      "Iteration 5992, Loss: 0.05417224019765854\n",
      "Iteration 5993, Loss: 0.053989559412002563\n",
      "Iteration 5994, Loss: 0.05417203903198242\n",
      "Iteration 5995, Loss: 0.053989678621292114\n",
      "Iteration 5996, Loss: 0.05417200177907944\n",
      "Iteration 5997, Loss: 0.05398964509367943\n",
      "Iteration 5998, Loss: 0.05417200177907944\n",
      "Iteration 5999, Loss: 0.053989723324775696\n",
      "Iteration 6000, Loss: 0.05417191982269287\n",
      "Iteration 6001, Loss: 0.05398957058787346\n",
      "Iteration 6002, Loss: 0.05417200177907944\n",
      "Iteration 6003, Loss: 0.05398957058787346\n",
      "Iteration 6004, Loss: 0.05417203903198242\n",
      "Iteration 6005, Loss: 0.053989604115486145\n",
      "Iteration 6006, Loss: 0.05417211353778839\n",
      "Iteration 6007, Loss: 0.05398960039019585\n",
      "Iteration 6008, Loss: 0.05417211353778839\n",
      "Iteration 6009, Loss: 0.05398960039019585\n",
      "Iteration 6010, Loss: 0.05417205020785332\n",
      "Iteration 6011, Loss: 0.05398949235677719\n",
      "Iteration 6012, Loss: 0.054172199219465256\n",
      "Iteration 6013, Loss: 0.05398937314748764\n",
      "Iteration 6014, Loss: 0.05417227745056152\n",
      "Iteration 6015, Loss: 0.053989291191101074\n",
      "Iteration 6016, Loss: 0.054172318428754807\n",
      "Iteration 6017, Loss: 0.05398933216929436\n",
      "Iteration 6018, Loss: 0.05417224019765854\n",
      "Iteration 6019, Loss: 0.05398945137858391\n",
      "Iteration 6020, Loss: 0.054172080010175705\n",
      "Iteration 6021, Loss: 0.053989529609680176\n",
      "Iteration 6022, Loss: 0.054171960800886154\n",
      "Iteration 6023, Loss: 0.0539897195994854\n",
      "Iteration 6024, Loss: 0.0541718415915966\n",
      "Iteration 6025, Loss: 0.053989723324775696\n",
      "Iteration 6026, Loss: 0.054171767085790634\n",
      "Iteration 6027, Loss: 0.05398964881896973\n",
      "Iteration 6028, Loss: 0.05417192727327347\n",
      "Iteration 6029, Loss: 0.05398964136838913\n",
      "Iteration 6030, Loss: 0.05417212098836899\n",
      "Iteration 6031, Loss: 0.05398944765329361\n",
      "Iteration 6032, Loss: 0.0541720911860466\n",
      "Iteration 6033, Loss: 0.05398937314748764\n",
      "Iteration 6034, Loss: 0.054172318428754807\n",
      "Iteration 6035, Loss: 0.053989212960004807\n",
      "Iteration 6036, Loss: 0.05417228862643242\n",
      "Iteration 6037, Loss: 0.05398910492658615\n",
      "Iteration 6038, Loss: 0.05417243391275406\n",
      "Iteration 6039, Loss: 0.05398925393819809\n",
      "Iteration 6040, Loss: 0.05417242646217346\n",
      "Iteration 6041, Loss: 0.053989361971616745\n",
      "Iteration 6042, Loss: 0.05417230352759361\n",
      "Iteration 6043, Loss: 0.053989559412002563\n",
      "Iteration 6044, Loss: 0.05417189002037048\n",
      "Iteration 6045, Loss: 0.05398976057767868\n",
      "Iteration 6046, Loss: 0.05417191982269287\n",
      "Iteration 6047, Loss: 0.05398983880877495\n",
      "Iteration 6048, Loss: 0.05417180806398392\n",
      "Iteration 6049, Loss: 0.05398976057767868\n",
      "Iteration 6050, Loss: 0.0541718527674675\n",
      "Iteration 6051, Loss: 0.05398964509367943\n",
      "Iteration 6052, Loss: 0.05417203903198242\n",
      "Iteration 6053, Loss: 0.05398957058787346\n",
      "Iteration 6054, Loss: 0.05417197197675705\n",
      "Iteration 6055, Loss: 0.05398956686258316\n",
      "Iteration 6056, Loss: 0.054172009229660034\n",
      "Iteration 6057, Loss: 0.05398949235677719\n",
      "Iteration 6058, Loss: 0.054172080010175705\n",
      "Iteration 6059, Loss: 0.053989529609680176\n",
      "Iteration 6060, Loss: 0.05417203903198242\n",
      "Iteration 6061, Loss: 0.053989678621292114\n",
      "Iteration 6062, Loss: 0.05417200177907944\n",
      "Iteration 6063, Loss: 0.05398957058787346\n",
      "Iteration 6064, Loss: 0.05417200177907944\n",
      "Iteration 6065, Loss: 0.05398961156606674\n",
      "Iteration 6066, Loss: 0.05417196452617645\n",
      "Iteration 6067, Loss: 0.05398957058787346\n",
      "Iteration 6068, Loss: 0.054172009229660034\n",
      "Iteration 6069, Loss: 0.05398956686258316\n",
      "Iteration 6070, Loss: 0.05417212098836899\n",
      "Iteration 6071, Loss: 0.05398940667510033\n",
      "Iteration 6072, Loss: 0.05417212098836899\n",
      "Iteration 6073, Loss: 0.05398940667510033\n",
      "Iteration 6074, Loss: 0.05417215824127197\n",
      "Iteration 6075, Loss: 0.053989484906196594\n",
      "Iteration 6076, Loss: 0.05417216569185257\n",
      "Iteration 6077, Loss: 0.05398940667510033\n",
      "Iteration 6078, Loss: 0.05417215824127197\n",
      "Iteration 6079, Loss: 0.053989410400390625\n",
      "Iteration 6080, Loss: 0.05417197197675705\n",
      "Iteration 6081, Loss: 0.053989559412002563\n",
      "Iteration 6082, Loss: 0.05417203903198242\n",
      "Iteration 6083, Loss: 0.05398961156606674\n",
      "Iteration 6084, Loss: 0.05417203903198242\n",
      "Iteration 6085, Loss: 0.05398961156606674\n",
      "Iteration 6086, Loss: 0.05417203903198242\n",
      "Iteration 6087, Loss: 0.05398957058787346\n",
      "Iteration 6088, Loss: 0.05417191982269287\n",
      "Iteration 6089, Loss: 0.05398949980735779\n",
      "Iteration 6090, Loss: 0.054171960800886154\n",
      "Iteration 6091, Loss: 0.05398968607187271\n",
      "Iteration 6092, Loss: 0.054171882569789886\n",
      "Iteration 6093, Loss: 0.05398976057767868\n",
      "Iteration 6094, Loss: 0.05417191982269287\n",
      "Iteration 6095, Loss: 0.05398991331458092\n",
      "Iteration 6096, Loss: 0.0541718415915966\n",
      "Iteration 6097, Loss: 0.053989917039871216\n",
      "Iteration 6098, Loss: 0.054171767085790634\n",
      "Iteration 6099, Loss: 0.05398987978696823\n",
      "Iteration 6100, Loss: 0.054171737283468246\n",
      "Iteration 6101, Loss: 0.05398976057767868\n",
      "Iteration 6102, Loss: 0.05417196452617645\n",
      "Iteration 6103, Loss: 0.053989674896001816\n",
      "Iteration 6104, Loss: 0.0541720911860466\n",
      "Iteration 6105, Loss: 0.05398940294981003\n",
      "Iteration 6106, Loss: 0.05417228862643242\n",
      "Iteration 6107, Loss: 0.05398917198181152\n",
      "Iteration 6108, Loss: 0.054172396659851074\n",
      "Iteration 6109, Loss: 0.05398917943239212\n",
      "Iteration 6110, Loss: 0.05417215824127197\n",
      "Iteration 6111, Loss: 0.05398952215909958\n",
      "Iteration 6112, Loss: 0.05417200177907944\n",
      "Iteration 6113, Loss: 0.05398964509367943\n",
      "Iteration 6114, Loss: 0.054171811789274216\n",
      "Iteration 6115, Loss: 0.053989797830581665\n",
      "Iteration 6116, Loss: 0.05417177081108093\n",
      "Iteration 6117, Loss: 0.05398991331458092\n",
      "Iteration 6118, Loss: 0.05417177081108093\n",
      "Iteration 6119, Loss: 0.053989917039871216\n",
      "Iteration 6120, Loss: 0.054171882569789886\n",
      "Iteration 6121, Loss: 0.05398987978696823\n",
      "Iteration 6122, Loss: 0.054171811789274216\n",
      "Iteration 6123, Loss: 0.05398964136838913\n",
      "Iteration 6124, Loss: 0.05417212098836899\n",
      "Iteration 6125, Loss: 0.05398933216929436\n",
      "Iteration 6126, Loss: 0.0541720911860466\n",
      "Iteration 6127, Loss: 0.05398933216929436\n",
      "Iteration 6128, Loss: 0.05417216569185257\n",
      "Iteration 6129, Loss: 0.05398944765329361\n",
      "Iteration 6130, Loss: 0.05417197197675705\n",
      "Iteration 6131, Loss: 0.05398961156606674\n",
      "Iteration 6132, Loss: 0.05417191982269287\n",
      "Iteration 6133, Loss: 0.05398976057767868\n",
      "Iteration 6134, Loss: 0.0541718527674675\n",
      "Iteration 6135, Loss: 0.0539897195994854\n",
      "Iteration 6136, Loss: 0.054171930998563766\n",
      "Iteration 6137, Loss: 0.053989604115486145\n",
      "Iteration 6138, Loss: 0.05417197197675705\n",
      "Iteration 6139, Loss: 0.053989484906196594\n",
      "Iteration 6140, Loss: 0.054172202944755554\n",
      "Iteration 6141, Loss: 0.05398936569690704\n",
      "Iteration 6142, Loss: 0.05417216569185257\n",
      "Iteration 6143, Loss: 0.053989410400390625\n",
      "Iteration 6144, Loss: 0.05417224019765854\n",
      "Iteration 6145, Loss: 0.053989484906196594\n",
      "Iteration 6146, Loss: 0.054172199219465256\n",
      "Iteration 6147, Loss: 0.053989484906196594\n",
      "Iteration 6148, Loss: 0.05417212098836899\n",
      "Iteration 6149, Loss: 0.05398949235677719\n",
      "Iteration 6150, Loss: 0.05417200177907944\n",
      "Iteration 6151, Loss: 0.0539897195994854\n",
      "Iteration 6152, Loss: 0.05417191982269287\n",
      "Iteration 6153, Loss: 0.05398987978696823\n",
      "Iteration 6154, Loss: 0.0541718527674675\n",
      "Iteration 6155, Loss: 0.05398964881896973\n",
      "Iteration 6156, Loss: 0.054171930998563766\n",
      "Iteration 6157, Loss: 0.05398964136838913\n",
      "Iteration 6158, Loss: 0.05417204648256302\n",
      "Iteration 6159, Loss: 0.05398944765329361\n",
      "Iteration 6160, Loss: 0.05417215824127197\n",
      "Iteration 6161, Loss: 0.05398942157626152\n",
      "Iteration 6162, Loss: 0.054172154515981674\n",
      "Iteration 6163, Loss: 0.05398949235677719\n",
      "Iteration 6164, Loss: 0.054172080010175705\n",
      "Iteration 6165, Loss: 0.05398949235677719\n",
      "Iteration 6166, Loss: 0.05417203903198242\n",
      "Iteration 6167, Loss: 0.053989604115486145\n",
      "Iteration 6168, Loss: 0.05417191982269287\n",
      "Iteration 6169, Loss: 0.05398968979716301\n",
      "Iteration 6170, Loss: 0.054171882569789886\n",
      "Iteration 6171, Loss: 0.05398976057767868\n",
      "Iteration 6172, Loss: 0.05417199432849884\n",
      "Iteration 6173, Loss: 0.05398964881896973\n",
      "Iteration 6174, Loss: 0.054171960800886154\n",
      "Iteration 6175, Loss: 0.05398968607187271\n",
      "Iteration 6176, Loss: 0.05417199432849884\n",
      "Iteration 6177, Loss: 0.05398968607187271\n",
      "Iteration 6178, Loss: 0.05417200177907944\n",
      "Iteration 6179, Loss: 0.05398953706026077\n",
      "Iteration 6180, Loss: 0.054171930998563766\n",
      "Iteration 6181, Loss: 0.05398956686258316\n",
      "Iteration 6182, Loss: 0.05417205020785332\n",
      "Iteration 6183, Loss: 0.053989484906196594\n",
      "Iteration 6184, Loss: 0.05417205020785332\n",
      "Iteration 6185, Loss: 0.05398945137858391\n",
      "Iteration 6186, Loss: 0.054172128438949585\n",
      "Iteration 6187, Loss: 0.05398952215909958\n",
      "Iteration 6188, Loss: 0.05417215824127197\n",
      "Iteration 6189, Loss: 0.05398944765329361\n",
      "Iteration 6190, Loss: 0.054172154515981674\n",
      "Iteration 6191, Loss: 0.05398957058787346\n",
      "Iteration 6192, Loss: 0.05417192727327347\n",
      "Iteration 6193, Loss: 0.05398961156606674\n",
      "Iteration 6194, Loss: 0.05417191982269287\n",
      "Iteration 6195, Loss: 0.053989797830581665\n",
      "Iteration 6196, Loss: 0.054171886295080185\n",
      "Iteration 6197, Loss: 0.05398964881896973\n",
      "Iteration 6198, Loss: 0.054171886295080185\n",
      "Iteration 6199, Loss: 0.05398964881896973\n",
      "Iteration 6200, Loss: 0.05417199432849884\n",
      "Iteration 6201, Loss: 0.053989678621292114\n",
      "Iteration 6202, Loss: 0.05417196452617645\n",
      "Iteration 6203, Loss: 0.05398952588438988\n",
      "Iteration 6204, Loss: 0.054172009229660034\n",
      "Iteration 6205, Loss: 0.053989410400390625\n",
      "Iteration 6206, Loss: 0.05417224019765854\n",
      "Iteration 6207, Loss: 0.053989410400390625\n",
      "Iteration 6208, Loss: 0.054172199219465256\n",
      "Iteration 6209, Loss: 0.05398937314748764\n",
      "Iteration 6210, Loss: 0.05417213588953018\n",
      "Iteration 6211, Loss: 0.05398933216929436\n",
      "Iteration 6212, Loss: 0.05417227745056152\n",
      "Iteration 6213, Loss: 0.05398933216929436\n",
      "Iteration 6214, Loss: 0.05417212098836899\n",
      "Iteration 6215, Loss: 0.053989484906196594\n",
      "Iteration 6216, Loss: 0.05417200177907944\n",
      "Iteration 6217, Loss: 0.05398976057767868\n",
      "Iteration 6218, Loss: 0.0541718415915966\n",
      "Iteration 6219, Loss: 0.05398984253406525\n",
      "Iteration 6220, Loss: 0.05417172238230705\n",
      "Iteration 6221, Loss: 0.05398980900645256\n",
      "Iteration 6222, Loss: 0.05417180806398392\n",
      "Iteration 6223, Loss: 0.05398964881896973\n",
      "Iteration 6224, Loss: 0.0541718527674675\n",
      "Iteration 6225, Loss: 0.053989529609680176\n",
      "Iteration 6226, Loss: 0.0541720911860466\n",
      "Iteration 6227, Loss: 0.05398937314748764\n",
      "Iteration 6228, Loss: 0.0541723296046257\n",
      "Iteration 6229, Loss: 0.05398917198181152\n",
      "Iteration 6230, Loss: 0.05417247861623764\n",
      "Iteration 6231, Loss: 0.05398913472890854\n",
      "Iteration 6232, Loss: 0.05417255312204361\n",
      "Iteration 6233, Loss: 0.053989093750715256\n",
      "Iteration 6234, Loss: 0.054172396659851074\n",
      "Iteration 6235, Loss: 0.053989291191101074\n",
      "Iteration 6236, Loss: 0.054172154515981674\n",
      "Iteration 6237, Loss: 0.05398957058787346\n",
      "Iteration 6238, Loss: 0.05417192727327347\n",
      "Iteration 6239, Loss: 0.05398973077535629\n",
      "Iteration 6240, Loss: 0.05417173355817795\n",
      "Iteration 6241, Loss: 0.053989797830581665\n",
      "Iteration 6242, Loss: 0.05417192727327347\n",
      "Iteration 6243, Loss: 0.05398960039019585\n",
      "Iteration 6244, Loss: 0.0541720911860466\n",
      "Iteration 6245, Loss: 0.05398937314748764\n",
      "Iteration 6246, Loss: 0.054172247648239136\n",
      "Iteration 6247, Loss: 0.05398917198181152\n",
      "Iteration 6248, Loss: 0.05417243763804436\n",
      "Iteration 6249, Loss: 0.05398925393819809\n",
      "Iteration 6250, Loss: 0.05417235940694809\n",
      "Iteration 6251, Loss: 0.0539892241358757\n",
      "Iteration 6252, Loss: 0.05417203903198242\n",
      "Iteration 6253, Loss: 0.05398964136838913\n",
      "Iteration 6254, Loss: 0.054171882569789886\n",
      "Iteration 6255, Loss: 0.05398987978696823\n",
      "Iteration 6256, Loss: 0.05417180061340332\n",
      "Iteration 6257, Loss: 0.053989917039871216\n",
      "Iteration 6258, Loss: 0.05417180061340332\n",
      "Iteration 6259, Loss: 0.053989849984645844\n",
      "Iteration 6260, Loss: 0.05417180061340332\n",
      "Iteration 6261, Loss: 0.05398984253406525\n",
      "Iteration 6262, Loss: 0.05417189002037048\n",
      "Iteration 6263, Loss: 0.05398956686258316\n",
      "Iteration 6264, Loss: 0.054172199219465256\n",
      "Iteration 6265, Loss: 0.053989410400390625\n",
      "Iteration 6266, Loss: 0.05417221039533615\n",
      "Iteration 6267, Loss: 0.05398918315768242\n",
      "Iteration 6268, Loss: 0.05417221039533615\n",
      "Iteration 6269, Loss: 0.053989291191101074\n",
      "Iteration 6270, Loss: 0.054172202944755554\n",
      "Iteration 6271, Loss: 0.053989559412002563\n",
      "Iteration 6272, Loss: 0.05417212098836899\n",
      "Iteration 6273, Loss: 0.05398960039019585\n",
      "Iteration 6274, Loss: 0.05417191982269287\n",
      "Iteration 6275, Loss: 0.05398968607187271\n",
      "Iteration 6276, Loss: 0.05417191982269287\n",
      "Iteration 6277, Loss: 0.05398961156606674\n",
      "Iteration 6278, Loss: 0.05417191982269287\n",
      "Iteration 6279, Loss: 0.05398968979716301\n",
      "Iteration 6280, Loss: 0.054171811789274216\n",
      "Iteration 6281, Loss: 0.05398957058787346\n",
      "Iteration 6282, Loss: 0.054171960800886154\n",
      "Iteration 6283, Loss: 0.053989529609680176\n",
      "Iteration 6284, Loss: 0.054171960800886154\n",
      "Iteration 6285, Loss: 0.05398973077535629\n",
      "Iteration 6286, Loss: 0.054171763360500336\n",
      "Iteration 6287, Loss: 0.05398980900645256\n",
      "Iteration 6288, Loss: 0.05417179316282272\n",
      "Iteration 6289, Loss: 0.053989917039871216\n",
      "Iteration 6290, Loss: 0.05417175218462944\n",
      "Iteration 6291, Loss: 0.053989849984645844\n",
      "Iteration 6292, Loss: 0.05417175590991974\n",
      "Iteration 6293, Loss: 0.05398999899625778\n",
      "Iteration 6294, Loss: 0.05417165160179138\n",
      "Iteration 6295, Loss: 0.05398987978696823\n",
      "Iteration 6296, Loss: 0.054171811789274216\n",
      "Iteration 6297, Loss: 0.05398964509367943\n",
      "Iteration 6298, Loss: 0.054171960800886154\n",
      "Iteration 6299, Loss: 0.05398964136838913\n",
      "Iteration 6300, Loss: 0.054172080010175705\n",
      "Iteration 6301, Loss: 0.053989410400390625\n",
      "Iteration 6302, Loss: 0.05417210981249809\n",
      "Iteration 6303, Loss: 0.05398957058787346\n",
      "Iteration 6304, Loss: 0.05417177081108093\n",
      "Iteration 6305, Loss: 0.05398976802825928\n",
      "Iteration 6306, Loss: 0.05417172238230705\n",
      "Iteration 6307, Loss: 0.05398988723754883\n",
      "Iteration 6308, Loss: 0.05417148396372795\n",
      "Iteration 6309, Loss: 0.05399007722735405\n",
      "Iteration 6310, Loss: 0.05417140573263168\n",
      "Iteration 6311, Loss: 0.05399015545845032\n",
      "Iteration 6312, Loss: 0.05417140573263168\n",
      "Iteration 6313, Loss: 0.05399000644683838\n",
      "Iteration 6314, Loss: 0.05417144298553467\n",
      "Iteration 6315, Loss: 0.05399011820554733\n",
      "Iteration 6316, Loss: 0.05417165160179138\n",
      "Iteration 6317, Loss: 0.05398983880877495\n",
      "Iteration 6318, Loss: 0.054171886295080185\n",
      "Iteration 6319, Loss: 0.05398961156606674\n",
      "Iteration 6320, Loss: 0.054172076284885406\n",
      "Iteration 6321, Loss: 0.05398945510387421\n",
      "Iteration 6322, Loss: 0.05417210981249809\n",
      "Iteration 6323, Loss: 0.0539897195994854\n",
      "Iteration 6324, Loss: 0.054171692579984665\n",
      "Iteration 6325, Loss: 0.05398987978696823\n",
      "Iteration 6326, Loss: 0.054171524941921234\n",
      "Iteration 6327, Loss: 0.05398992821574211\n",
      "Iteration 6328, Loss: 0.054171450436115265\n",
      "Iteration 6329, Loss: 0.05399007722735405\n",
      "Iteration 6330, Loss: 0.054171450436115265\n",
      "Iteration 6331, Loss: 0.05399000272154808\n",
      "Iteration 6332, Loss: 0.05417145416140556\n",
      "Iteration 6333, Loss: 0.05399000272154808\n",
      "Iteration 6334, Loss: 0.0541716143488884\n",
      "Iteration 6335, Loss: 0.05398976802825928\n",
      "Iteration 6336, Loss: 0.054171811789274216\n",
      "Iteration 6337, Loss: 0.05398964509367943\n",
      "Iteration 6338, Loss: 0.054171930998563766\n",
      "Iteration 6339, Loss: 0.05398953706026077\n",
      "Iteration 6340, Loss: 0.05417203903198242\n",
      "Iteration 6341, Loss: 0.053989559412002563\n",
      "Iteration 6342, Loss: 0.05417192727327347\n",
      "Iteration 6343, Loss: 0.05398964136838913\n",
      "Iteration 6344, Loss: 0.05417199432849884\n",
      "Iteration 6345, Loss: 0.053989723324775696\n",
      "Iteration 6346, Loss: 0.0541718415915966\n",
      "Iteration 6347, Loss: 0.05398976057767868\n",
      "Iteration 6348, Loss: 0.05417168140411377\n",
      "Iteration 6349, Loss: 0.05398984253406525\n",
      "Iteration 6350, Loss: 0.05417164787650108\n",
      "Iteration 6351, Loss: 0.0539899580180645\n",
      "Iteration 6352, Loss: 0.05417172610759735\n",
      "Iteration 6353, Loss: 0.05398968979716301\n",
      "Iteration 6354, Loss: 0.0541718415915966\n",
      "Iteration 6355, Loss: 0.05398968979716301\n",
      "Iteration 6356, Loss: 0.05417180061340332\n",
      "Iteration 6357, Loss: 0.05398973077535629\n",
      "Iteration 6358, Loss: 0.0541716068983078\n",
      "Iteration 6359, Loss: 0.05398980900645256\n",
      "Iteration 6360, Loss: 0.05417171120643616\n",
      "Iteration 6361, Loss: 0.05399003252387047\n",
      "Iteration 6362, Loss: 0.05417164787650108\n",
      "Iteration 6363, Loss: 0.05398980528116226\n",
      "Iteration 6364, Loss: 0.05417180061340332\n",
      "Iteration 6365, Loss: 0.05398968979716301\n",
      "Iteration 6366, Loss: 0.054171882569789886\n",
      "Iteration 6367, Loss: 0.05398976057767868\n",
      "Iteration 6368, Loss: 0.0541718453168869\n",
      "Iteration 6369, Loss: 0.053989723324775696\n",
      "Iteration 6370, Loss: 0.0541718415915966\n",
      "Iteration 6371, Loss: 0.05398973077535629\n",
      "Iteration 6372, Loss: 0.05417179316282272\n",
      "Iteration 6373, Loss: 0.053989917039871216\n",
      "Iteration 6374, Loss: 0.05417179316282272\n",
      "Iteration 6375, Loss: 0.05398988351225853\n",
      "Iteration 6376, Loss: 0.0541716068983078\n",
      "Iteration 6377, Loss: 0.05398988723754883\n",
      "Iteration 6378, Loss: 0.05417168140411377\n",
      "Iteration 6379, Loss: 0.05398999899625778\n",
      "Iteration 6380, Loss: 0.054171495139598846\n",
      "Iteration 6381, Loss: 0.0539899617433548\n",
      "Iteration 6382, Loss: 0.0541716143488884\n",
      "Iteration 6383, Loss: 0.053989849984645844\n",
      "Iteration 6384, Loss: 0.054171767085790634\n",
      "Iteration 6385, Loss: 0.05398968979716301\n",
      "Iteration 6386, Loss: 0.054171960800886154\n",
      "Iteration 6387, Loss: 0.053989529609680176\n",
      "Iteration 6388, Loss: 0.05417212098836899\n",
      "Iteration 6389, Loss: 0.05398933216929436\n",
      "Iteration 6390, Loss: 0.054172199219465256\n",
      "Iteration 6391, Loss: 0.05398937314748764\n",
      "Iteration 6392, Loss: 0.05417218804359436\n",
      "Iteration 6393, Loss: 0.05398937314748764\n",
      "Iteration 6394, Loss: 0.054172150790691376\n",
      "Iteration 6395, Loss: 0.05398964136838913\n",
      "Iteration 6396, Loss: 0.0541718415915966\n",
      "Iteration 6397, Loss: 0.053989797830581665\n",
      "Iteration 6398, Loss: 0.054171644151210785\n",
      "Iteration 6399, Loss: 0.05398988723754883\n",
      "Iteration 6400, Loss: 0.0541716031730175\n",
      "Iteration 6401, Loss: 0.05398999899625778\n",
      "Iteration 6402, Loss: 0.054171495139598846\n",
      "Iteration 6403, Loss: 0.05399007722735405\n",
      "Iteration 6404, Loss: 0.054171621799468994\n",
      "Iteration 6405, Loss: 0.0539897195994854\n",
      "Iteration 6406, Loss: 0.054172128438949585\n",
      "Iteration 6407, Loss: 0.05398918315768242\n",
      "Iteration 6408, Loss: 0.054172441363334656\n",
      "Iteration 6409, Loss: 0.053989019244909286\n",
      "Iteration 6410, Loss: 0.05417244881391525\n",
      "Iteration 6411, Loss: 0.05398909002542496\n",
      "Iteration 6412, Loss: 0.05417243763804436\n",
      "Iteration 6413, Loss: 0.05398913472890854\n",
      "Iteration 6414, Loss: 0.05417227745056152\n",
      "Iteration 6415, Loss: 0.05398933216929436\n",
      "Iteration 6416, Loss: 0.05417200177907944\n",
      "Iteration 6417, Loss: 0.05398961156606674\n",
      "Iteration 6418, Loss: 0.05417191609740257\n",
      "Iteration 6419, Loss: 0.05398987978696823\n",
      "Iteration 6420, Loss: 0.05417172238230705\n",
      "Iteration 6421, Loss: 0.053989917039871216\n",
      "Iteration 6422, Loss: 0.054171573370695114\n",
      "Iteration 6423, Loss: 0.05398984253406525\n",
      "Iteration 6424, Loss: 0.0541718527674675\n",
      "Iteration 6425, Loss: 0.05398968979716301\n",
      "Iteration 6426, Loss: 0.05417191982269287\n",
      "Iteration 6427, Loss: 0.05398964881896973\n",
      "Iteration 6428, Loss: 0.054171882569789886\n",
      "Iteration 6429, Loss: 0.05398964136838913\n",
      "Iteration 6430, Loss: 0.05417203903198242\n",
      "Iteration 6431, Loss: 0.05398956686258316\n",
      "Iteration 6432, Loss: 0.05417197197675705\n",
      "Iteration 6433, Loss: 0.053989559412002563\n",
      "Iteration 6434, Loss: 0.05417203530669212\n",
      "Iteration 6435, Loss: 0.05398961156606674\n",
      "Iteration 6436, Loss: 0.054171930998563766\n",
      "Iteration 6437, Loss: 0.05398964136838913\n",
      "Iteration 6438, Loss: 0.05417197197675705\n",
      "Iteration 6439, Loss: 0.05398964136838913\n",
      "Iteration 6440, Loss: 0.05417189002037048\n",
      "Iteration 6441, Loss: 0.05398942157626152\n",
      "Iteration 6442, Loss: 0.054172080010175705\n",
      "Iteration 6443, Loss: 0.05398945510387421\n",
      "Iteration 6444, Loss: 0.054171960800886154\n",
      "Iteration 6445, Loss: 0.053989529609680176\n",
      "Iteration 6446, Loss: 0.05417200177907944\n",
      "Iteration 6447, Loss: 0.053989529609680176\n",
      "Iteration 6448, Loss: 0.05417189002037048\n",
      "Iteration 6449, Loss: 0.05398964136838913\n",
      "Iteration 6450, Loss: 0.05417210981249809\n",
      "Iteration 6451, Loss: 0.053989529609680176\n",
      "Iteration 6452, Loss: 0.054172080010175705\n",
      "Iteration 6453, Loss: 0.05398945137858391\n",
      "Iteration 6454, Loss: 0.054172199219465256\n",
      "Iteration 6455, Loss: 0.05398945137858391\n",
      "Iteration 6456, Loss: 0.05417212098836899\n",
      "Iteration 6457, Loss: 0.05398956686258316\n",
      "Iteration 6458, Loss: 0.05417197197675705\n",
      "Iteration 6459, Loss: 0.05398957058787346\n",
      "Iteration 6460, Loss: 0.054171930998563766\n",
      "Iteration 6461, Loss: 0.05398956686258316\n",
      "Iteration 6462, Loss: 0.054172076284885406\n",
      "Iteration 6463, Loss: 0.05398941785097122\n",
      "Iteration 6464, Loss: 0.05417199432849884\n",
      "Iteration 6465, Loss: 0.05398957058787346\n",
      "Iteration 6466, Loss: 0.05417191982269287\n",
      "Iteration 6467, Loss: 0.05398976057767868\n",
      "Iteration 6468, Loss: 0.05417180806398392\n",
      "Iteration 6469, Loss: 0.05398973077535629\n",
      "Iteration 6470, Loss: 0.05417177081108093\n",
      "Iteration 6471, Loss: 0.05398964881896973\n",
      "Iteration 6472, Loss: 0.0541718527674675\n",
      "Iteration 6473, Loss: 0.053989678621292114\n",
      "Iteration 6474, Loss: 0.054171960800886154\n",
      "Iteration 6475, Loss: 0.05398964136838913\n",
      "Iteration 6476, Loss: 0.054172080010175705\n",
      "Iteration 6477, Loss: 0.05398949235677719\n",
      "Iteration 6478, Loss: 0.05417215824127197\n",
      "Iteration 6479, Loss: 0.05398944765329361\n",
      "Iteration 6480, Loss: 0.054172080010175705\n",
      "Iteration 6481, Loss: 0.05398961156606674\n",
      "Iteration 6482, Loss: 0.05417191982269287\n",
      "Iteration 6483, Loss: 0.05398976057767868\n",
      "Iteration 6484, Loss: 0.05417180061340332\n",
      "Iteration 6485, Loss: 0.05398976057767868\n",
      "Iteration 6486, Loss: 0.05417180061340332\n",
      "Iteration 6487, Loss: 0.05398980528116226\n",
      "Iteration 6488, Loss: 0.054171763360500336\n",
      "Iteration 6489, Loss: 0.05398983880877495\n",
      "Iteration 6490, Loss: 0.05417173355817795\n",
      "Iteration 6491, Loss: 0.053989872336387634\n",
      "Iteration 6492, Loss: 0.0541718527674675\n",
      "Iteration 6493, Loss: 0.05398976057767868\n",
      "Iteration 6494, Loss: 0.0541720911860466\n",
      "Iteration 6495, Loss: 0.05398944020271301\n",
      "Iteration 6496, Loss: 0.05417221039533615\n",
      "Iteration 6497, Loss: 0.053989291191101074\n",
      "Iteration 6498, Loss: 0.05417227745056152\n",
      "Iteration 6499, Loss: 0.05398918315768242\n",
      "Iteration 6500, Loss: 0.054172269999980927\n",
      "Iteration 6501, Loss: 0.053989529609680176\n",
      "Iteration 6502, Loss: 0.05417206883430481\n",
      "Iteration 6503, Loss: 0.0539897195994854\n",
      "Iteration 6504, Loss: 0.05417180061340332\n",
      "Iteration 6505, Loss: 0.05398976057767868\n",
      "Iteration 6506, Loss: 0.05417194962501526\n",
      "Iteration 6507, Loss: 0.05398976802825928\n",
      "Iteration 6508, Loss: 0.0541718453168869\n",
      "Iteration 6509, Loss: 0.053989797830581665\n",
      "Iteration 6510, Loss: 0.054171960800886154\n",
      "Iteration 6511, Loss: 0.05398961156606674\n",
      "Iteration 6512, Loss: 0.05417203903198242\n",
      "Iteration 6513, Loss: 0.05398957058787346\n",
      "Iteration 6514, Loss: 0.05417200177907944\n",
      "Iteration 6515, Loss: 0.05398960039019585\n",
      "Iteration 6516, Loss: 0.054172080010175705\n",
      "Iteration 6517, Loss: 0.05398964136838913\n",
      "Iteration 6518, Loss: 0.054172080010175705\n",
      "Iteration 6519, Loss: 0.05398952588438988\n",
      "Iteration 6520, Loss: 0.05417212098836899\n",
      "Iteration 6521, Loss: 0.053989484906196594\n",
      "Iteration 6522, Loss: 0.054172154515981674\n",
      "Iteration 6523, Loss: 0.053989559412002563\n",
      "Iteration 6524, Loss: 0.05417204648256302\n",
      "Iteration 6525, Loss: 0.05398957058787346\n",
      "Iteration 6526, Loss: 0.0541720911860466\n",
      "Iteration 6527, Loss: 0.05398941785097122\n",
      "Iteration 6528, Loss: 0.05417221039533615\n",
      "Iteration 6529, Loss: 0.05398933216929436\n",
      "Iteration 6530, Loss: 0.05417235940694809\n",
      "Iteration 6531, Loss: 0.053989242762327194\n",
      "Iteration 6532, Loss: 0.05417247861623764\n",
      "Iteration 6533, Loss: 0.0539889857172966\n",
      "Iteration 6534, Loss: 0.05417247861623764\n",
      "Iteration 6535, Loss: 0.05398917198181152\n",
      "Iteration 6536, Loss: 0.05417235940694809\n",
      "Iteration 6537, Loss: 0.05398939177393913\n",
      "Iteration 6538, Loss: 0.054172199219465256\n",
      "Iteration 6539, Loss: 0.05398944020271301\n",
      "Iteration 6540, Loss: 0.05417224019765854\n",
      "Iteration 6541, Loss: 0.053989484906196594\n",
      "Iteration 6542, Loss: 0.05417215824127197\n",
      "Iteration 6543, Loss: 0.05398952588438988\n",
      "Iteration 6544, Loss: 0.054172124713659286\n",
      "Iteration 6545, Loss: 0.053989559412002563\n",
      "Iteration 6546, Loss: 0.0541720911860466\n",
      "Iteration 6547, Loss: 0.053989559412002563\n",
      "Iteration 6548, Loss: 0.05417215824127197\n",
      "Iteration 6549, Loss: 0.05398944765329361\n",
      "Iteration 6550, Loss: 0.054172199219465256\n",
      "Iteration 6551, Loss: 0.053989410400390625\n",
      "Iteration 6552, Loss: 0.05417218804359436\n",
      "Iteration 6553, Loss: 0.05398949235677719\n",
      "Iteration 6554, Loss: 0.05417191982269287\n",
      "Iteration 6555, Loss: 0.05398957058787346\n",
      "Iteration 6556, Loss: 0.05417199432849884\n",
      "Iteration 6557, Loss: 0.05398964881896973\n",
      "Iteration 6558, Loss: 0.05417192727327347\n",
      "Iteration 6559, Loss: 0.053989678621292114\n",
      "Iteration 6560, Loss: 0.054172083735466\n",
      "Iteration 6561, Loss: 0.053989559412002563\n",
      "Iteration 6562, Loss: 0.054172396659851074\n",
      "Iteration 6563, Loss: 0.05398933216929436\n",
      "Iteration 6564, Loss: 0.05417247861623764\n",
      "Iteration 6565, Loss: 0.053989212960004807\n",
      "Iteration 6566, Loss: 0.0541725754737854\n",
      "Iteration 6567, Loss: 0.053989361971616745\n",
      "Iteration 6568, Loss: 0.05417237803339958\n",
      "Iteration 6569, Loss: 0.053989559412002563\n",
      "Iteration 6570, Loss: 0.054172080010175705\n",
      "Iteration 6571, Loss: 0.0539897195994854\n",
      "Iteration 6572, Loss: 0.0541718415915966\n",
      "Iteration 6573, Loss: 0.05398987978696823\n",
      "Iteration 6574, Loss: 0.05417180061340332\n",
      "Iteration 6575, Loss: 0.05398987978696823\n",
      "Iteration 6576, Loss: 0.0541718415915966\n",
      "Iteration 6577, Loss: 0.05398983880877495\n",
      "Iteration 6578, Loss: 0.05417177081108093\n",
      "Iteration 6579, Loss: 0.05398976057767868\n",
      "Iteration 6580, Loss: 0.05417196452617645\n",
      "Iteration 6581, Loss: 0.05398961156606674\n",
      "Iteration 6582, Loss: 0.05417215824127197\n",
      "Iteration 6583, Loss: 0.053989410400390625\n",
      "Iteration 6584, Loss: 0.054172318428754807\n",
      "Iteration 6585, Loss: 0.05398925393819809\n",
      "Iteration 6586, Loss: 0.054172392934560776\n",
      "Iteration 6587, Loss: 0.05398936569690704\n",
      "Iteration 6588, Loss: 0.054172348231077194\n",
      "Iteration 6589, Loss: 0.05398940294981003\n",
      "Iteration 6590, Loss: 0.054172269999980927\n",
      "Iteration 6591, Loss: 0.05398992449045181\n",
      "Iteration 6592, Loss: 0.05417210981249809\n",
      "Iteration 6593, Loss: 0.05399015545845032\n",
      "Iteration 6594, Loss: 0.05417128652334213\n",
      "Iteration 6595, Loss: 0.0539904348552227\n",
      "Iteration 6596, Loss: 0.05417131632566452\n",
      "Iteration 6597, Loss: 0.05399039387702942\n",
      "Iteration 6598, Loss: 0.05417148396372795\n",
      "Iteration 6599, Loss: 0.05399011820554733\n",
      "Iteration 6600, Loss: 0.054171811789274216\n",
      "Iteration 6601, Loss: 0.053989678621292114\n",
      "Iteration 6602, Loss: 0.05417227745056152\n",
      "Iteration 6603, Loss: 0.05398936569690704\n",
      "Iteration 6604, Loss: 0.054172590374946594\n",
      "Iteration 6605, Loss: 0.05398917198181152\n",
      "Iteration 6606, Loss: 0.054172586649656296\n",
      "Iteration 6607, Loss: 0.053989212960004807\n",
      "Iteration 6608, Loss: 0.05417250841856003\n",
      "Iteration 6609, Loss: 0.05398937314748764\n",
      "Iteration 6610, Loss: 0.05417218804359436\n",
      "Iteration 6611, Loss: 0.05398964509367943\n",
      "Iteration 6612, Loss: 0.05417199060320854\n",
      "Iteration 6613, Loss: 0.05398987978696823\n",
      "Iteration 6614, Loss: 0.054171882569789886\n",
      "Iteration 6615, Loss: 0.05398992449045181\n",
      "Iteration 6616, Loss: 0.05417191982269287\n",
      "Iteration 6617, Loss: 0.05398976430296898\n",
      "Iteration 6618, Loss: 0.05417200177907944\n",
      "Iteration 6619, Loss: 0.053989581763744354\n",
      "Iteration 6620, Loss: 0.05417212098836899\n",
      "Iteration 6621, Loss: 0.05398945137858391\n",
      "Iteration 6622, Loss: 0.05417238920927048\n",
      "Iteration 6623, Loss: 0.053989484906196594\n",
      "Iteration 6624, Loss: 0.05417242646217346\n",
      "Iteration 6625, Loss: 0.05398940294981003\n",
      "Iteration 6626, Loss: 0.05417235940694809\n",
      "Iteration 6627, Loss: 0.05398940667510033\n",
      "Iteration 6628, Loss: 0.05417238920927048\n",
      "Iteration 6629, Loss: 0.053989410400390625\n",
      "Iteration 6630, Loss: 0.054172348231077194\n",
      "Iteration 6631, Loss: 0.05398952215909958\n",
      "Iteration 6632, Loss: 0.05417230725288391\n",
      "Iteration 6633, Loss: 0.05398952588438988\n",
      "Iteration 6634, Loss: 0.05417223274707794\n",
      "Iteration 6635, Loss: 0.053989529609680176\n",
      "Iteration 6636, Loss: 0.05417222902178764\n",
      "Iteration 6637, Loss: 0.05398949235677719\n",
      "Iteration 6638, Loss: 0.054172269999980927\n",
      "Iteration 6639, Loss: 0.05398957058787346\n",
      "Iteration 6640, Loss: 0.054172150790691376\n",
      "Iteration 6641, Loss: 0.05398961156606674\n",
      "Iteration 6642, Loss: 0.05417210981249809\n",
      "Iteration 6643, Loss: 0.05398968607187271\n",
      "Iteration 6644, Loss: 0.05417204648256302\n",
      "Iteration 6645, Loss: 0.05398961156606674\n",
      "Iteration 6646, Loss: 0.05417203903198242\n",
      "Iteration 6647, Loss: 0.05398976057767868\n",
      "Iteration 6648, Loss: 0.05417203903198242\n",
      "Iteration 6649, Loss: 0.05398968607187271\n",
      "Iteration 6650, Loss: 0.054172150790691376\n",
      "Iteration 6651, Loss: 0.05398968607187271\n",
      "Iteration 6652, Loss: 0.054172225296497345\n",
      "Iteration 6653, Loss: 0.05398964881896973\n",
      "Iteration 6654, Loss: 0.05417203903198242\n",
      "Iteration 6655, Loss: 0.0539897195994854\n",
      "Iteration 6656, Loss: 0.05417203903198242\n",
      "Iteration 6657, Loss: 0.05398961156606674\n",
      "Iteration 6658, Loss: 0.05417210981249809\n",
      "Iteration 6659, Loss: 0.05398961156606674\n",
      "Iteration 6660, Loss: 0.05417210981249809\n",
      "Iteration 6661, Loss: 0.053989678621292114\n",
      "Iteration 6662, Loss: 0.054172080010175705\n",
      "Iteration 6663, Loss: 0.053989678621292114\n",
      "Iteration 6664, Loss: 0.054172080010175705\n",
      "Iteration 6665, Loss: 0.0539897195994854\n",
      "Iteration 6666, Loss: 0.054172124713659286\n",
      "Iteration 6667, Loss: 0.05398957058787346\n",
      "Iteration 6668, Loss: 0.054172199219465256\n",
      "Iteration 6669, Loss: 0.053989484906196594\n",
      "Iteration 6670, Loss: 0.054172199219465256\n",
      "Iteration 6671, Loss: 0.05398937314748764\n",
      "Iteration 6672, Loss: 0.05417247116565704\n",
      "Iteration 6673, Loss: 0.05398933216929436\n",
      "Iteration 6674, Loss: 0.05417242646217346\n",
      "Iteration 6675, Loss: 0.05398933216929436\n",
      "Iteration 6676, Loss: 0.05417237803339958\n",
      "Iteration 6677, Loss: 0.053989529609680176\n",
      "Iteration 6678, Loss: 0.054172031581401825\n",
      "Iteration 6679, Loss: 0.05398980900645256\n",
      "Iteration 6680, Loss: 0.05417187139391899\n",
      "Iteration 6681, Loss: 0.053989969193935394\n",
      "Iteration 6682, Loss: 0.05417187139391899\n",
      "Iteration 6683, Loss: 0.0539899580180645\n",
      "Iteration 6684, Loss: 0.0541718527674675\n",
      "Iteration 6685, Loss: 0.05398968979716301\n",
      "Iteration 6686, Loss: 0.05417203903198242\n",
      "Iteration 6687, Loss: 0.05398953706026077\n",
      "Iteration 6688, Loss: 0.05417227745056152\n",
      "Iteration 6689, Loss: 0.05398932844400406\n",
      "Iteration 6690, Loss: 0.054172396659851074\n",
      "Iteration 6691, Loss: 0.05398913845419884\n",
      "Iteration 6692, Loss: 0.054172538220882416\n",
      "Iteration 6693, Loss: 0.05398933216929436\n",
      "Iteration 6694, Loss: 0.05417226254940033\n",
      "Iteration 6695, Loss: 0.05398964509367943\n",
      "Iteration 6696, Loss: 0.05417199060320854\n",
      "Iteration 6697, Loss: 0.053989849984645844\n",
      "Iteration 6698, Loss: 0.05417187511920929\n",
      "Iteration 6699, Loss: 0.0539899580180645\n",
      "Iteration 6700, Loss: 0.05417194962501526\n",
      "Iteration 6701, Loss: 0.05398992449045181\n",
      "Iteration 6702, Loss: 0.054171960800886154\n",
      "Iteration 6703, Loss: 0.05398976057767868\n",
      "Iteration 6704, Loss: 0.05417224019765854\n",
      "Iteration 6705, Loss: 0.05398944020271301\n",
      "Iteration 6706, Loss: 0.05417240411043167\n",
      "Iteration 6707, Loss: 0.053989212960004807\n",
      "Iteration 6708, Loss: 0.05417259782552719\n",
      "Iteration 6709, Loss: 0.05398913472890854\n",
      "Iteration 6710, Loss: 0.05417251214385033\n",
      "Iteration 6711, Loss: 0.053989212960004807\n",
      "Iteration 6712, Loss: 0.05417238920927048\n",
      "Iteration 6713, Loss: 0.053989481180906296\n",
      "Iteration 6714, Loss: 0.05417215824127197\n",
      "Iteration 6715, Loss: 0.05398964136838913\n",
      "Iteration 6716, Loss: 0.05417199432849884\n",
      "Iteration 6717, Loss: 0.05398982763290405\n",
      "Iteration 6718, Loss: 0.05417187139391899\n",
      "Iteration 6719, Loss: 0.053989917039871216\n",
      "Iteration 6720, Loss: 0.05417187139391899\n",
      "Iteration 6721, Loss: 0.05398988351225853\n",
      "Iteration 6722, Loss: 0.0541718415915966\n",
      "Iteration 6723, Loss: 0.053989849984645844\n",
      "Iteration 6724, Loss: 0.054172031581401825\n",
      "Iteration 6725, Loss: 0.05398976430296898\n",
      "Iteration 6726, Loss: 0.05417191982269287\n",
      "Iteration 6727, Loss: 0.05398968979716301\n",
      "Iteration 6728, Loss: 0.05417196452617645\n",
      "Iteration 6729, Loss: 0.05398968607187271\n",
      "Iteration 6730, Loss: 0.05417203530669212\n",
      "Iteration 6731, Loss: 0.05398964881896973\n",
      "Iteration 6732, Loss: 0.054172076284885406\n",
      "Iteration 6733, Loss: 0.053989797830581665\n",
      "Iteration 6734, Loss: 0.05417211353778839\n",
      "Iteration 6735, Loss: 0.053989604115486145\n",
      "Iteration 6736, Loss: 0.05417215824127197\n",
      "Iteration 6737, Loss: 0.05398964136838913\n",
      "Iteration 6738, Loss: 0.05417224019765854\n",
      "Iteration 6739, Loss: 0.05398960039019585\n",
      "Iteration 6740, Loss: 0.05417215824127197\n",
      "Iteration 6741, Loss: 0.05398952215909958\n",
      "Iteration 6742, Loss: 0.05417231470346451\n",
      "Iteration 6743, Loss: 0.05398933216929436\n",
      "Iteration 6744, Loss: 0.05417227745056152\n",
      "Iteration 6745, Loss: 0.05398952215909958\n",
      "Iteration 6746, Loss: 0.05417222902178764\n",
      "Iteration 6747, Loss: 0.053989529609680176\n",
      "Iteration 6748, Loss: 0.05417210981249809\n",
      "Iteration 6749, Loss: 0.05398968979716301\n",
      "Iteration 6750, Loss: 0.054172031581401825\n",
      "Iteration 6751, Loss: 0.05398976802825928\n",
      "Iteration 6752, Loss: 0.05417199060320854\n",
      "Iteration 6753, Loss: 0.053989849984645844\n",
      "Iteration 6754, Loss: 0.054171960800886154\n",
      "Iteration 6755, Loss: 0.05398980528116226\n",
      "Iteration 6756, Loss: 0.054172005504369736\n",
      "Iteration 6757, Loss: 0.05398957058787346\n",
      "Iteration 6758, Loss: 0.054172247648239136\n",
      "Iteration 6759, Loss: 0.05398936569690704\n",
      "Iteration 6760, Loss: 0.05417251214385033\n",
      "Iteration 6761, Loss: 0.05398928374052048\n",
      "Iteration 6762, Loss: 0.05417247116565704\n",
      "Iteration 6763, Loss: 0.05398932844400406\n",
      "Iteration 6764, Loss: 0.05417238920927048\n",
      "Iteration 6765, Loss: 0.053989410400390625\n",
      "Iteration 6766, Loss: 0.05417227745056152\n",
      "Iteration 6767, Loss: 0.053989674896001816\n",
      "Iteration 6768, Loss: 0.05417210981249809\n",
      "Iteration 6769, Loss: 0.0539897195994854\n",
      "Iteration 6770, Loss: 0.054171960800886154\n",
      "Iteration 6771, Loss: 0.05398983880877495\n",
      "Iteration 6772, Loss: 0.05417200177907944\n",
      "Iteration 6773, Loss: 0.05398980528116226\n",
      "Iteration 6774, Loss: 0.05417200177907944\n",
      "Iteration 6775, Loss: 0.05398976430296898\n",
      "Iteration 6776, Loss: 0.05417212098836899\n",
      "Iteration 6777, Loss: 0.05398960039019585\n",
      "Iteration 6778, Loss: 0.05417215824127197\n",
      "Iteration 6779, Loss: 0.05398949235677719\n",
      "Iteration 6780, Loss: 0.05417227745056152\n",
      "Iteration 6781, Loss: 0.05398929864168167\n",
      "Iteration 6782, Loss: 0.054172318428754807\n",
      "Iteration 6783, Loss: 0.05398937314748764\n",
      "Iteration 6784, Loss: 0.054172344505786896\n",
      "Iteration 6785, Loss: 0.05398952215909958\n",
      "Iteration 6786, Loss: 0.054172150790691376\n",
      "Iteration 6787, Loss: 0.05398968607187271\n",
      "Iteration 6788, Loss: 0.054171957075595856\n",
      "Iteration 6789, Loss: 0.05398987978696823\n",
      "Iteration 6790, Loss: 0.05417194962501526\n",
      "Iteration 6791, Loss: 0.05398987978696823\n",
      "Iteration 6792, Loss: 0.0541718527674675\n",
      "Iteration 6793, Loss: 0.0539897195994854\n",
      "Iteration 6794, Loss: 0.054172009229660034\n",
      "Iteration 6795, Loss: 0.05398960039019585\n",
      "Iteration 6796, Loss: 0.054172273725271225\n",
      "Iteration 6797, Loss: 0.05398944020271301\n",
      "Iteration 6798, Loss: 0.05417228490114212\n",
      "Iteration 6799, Loss: 0.053989291191101074\n",
      "Iteration 6800, Loss: 0.05417224019765854\n",
      "Iteration 6801, Loss: 0.05398949235677719\n",
      "Iteration 6802, Loss: 0.05417219549417496\n",
      "Iteration 6803, Loss: 0.053989604115486145\n",
      "Iteration 6804, Loss: 0.054172076284885406\n",
      "Iteration 6805, Loss: 0.05398968607187271\n",
      "Iteration 6806, Loss: 0.05417203903198242\n",
      "Iteration 6807, Loss: 0.05398968607187271\n",
      "Iteration 6808, Loss: 0.054172154515981674\n",
      "Iteration 6809, Loss: 0.05398960039019585\n",
      "Iteration 6810, Loss: 0.05417224019765854\n",
      "Iteration 6811, Loss: 0.053989410400390625\n",
      "Iteration 6812, Loss: 0.054172467440366745\n",
      "Iteration 6813, Loss: 0.05398936569690704\n",
      "Iteration 6814, Loss: 0.05417243763804436\n",
      "Iteration 6815, Loss: 0.053989291191101074\n",
      "Iteration 6816, Loss: 0.05417246371507645\n",
      "Iteration 6817, Loss: 0.05398944765329361\n",
      "Iteration 6818, Loss: 0.05417230725288391\n",
      "Iteration 6819, Loss: 0.053989529609680176\n",
      "Iteration 6820, Loss: 0.05417212098836899\n",
      "Iteration 6821, Loss: 0.05398957058787346\n",
      "Iteration 6822, Loss: 0.05417203903198242\n",
      "Iteration 6823, Loss: 0.05398968979716301\n",
      "Iteration 6824, Loss: 0.054172031581401825\n",
      "Iteration 6825, Loss: 0.05398976057767868\n",
      "Iteration 6826, Loss: 0.05417191982269287\n",
      "Iteration 6827, Loss: 0.053989917039871216\n",
      "Iteration 6828, Loss: 0.054171882569789886\n",
      "Iteration 6829, Loss: 0.05398976802825928\n",
      "Iteration 6830, Loss: 0.05417206883430481\n",
      "Iteration 6831, Loss: 0.05398968607187271\n",
      "Iteration 6832, Loss: 0.054172199219465256\n",
      "Iteration 6833, Loss: 0.05398945137858391\n",
      "Iteration 6834, Loss: 0.054172348231077194\n",
      "Iteration 6835, Loss: 0.05398933216929436\n",
      "Iteration 6836, Loss: 0.054172348231077194\n",
      "Iteration 6837, Loss: 0.053989484906196594\n",
      "Iteration 6838, Loss: 0.054172150790691376\n",
      "Iteration 6839, Loss: 0.053989604115486145\n",
      "Iteration 6840, Loss: 0.05417206883430481\n",
      "Iteration 6841, Loss: 0.05398987978696823\n",
      "Iteration 6842, Loss: 0.054171882569789886\n",
      "Iteration 6843, Loss: 0.05398980528116226\n",
      "Iteration 6844, Loss: 0.05417203530669212\n",
      "Iteration 6845, Loss: 0.053989678621292114\n",
      "Iteration 6846, Loss: 0.054172199219465256\n",
      "Iteration 6847, Loss: 0.05398959666490555\n",
      "Iteration 6848, Loss: 0.05417227745056152\n",
      "Iteration 6849, Loss: 0.053989477455616\n",
      "Iteration 6850, Loss: 0.05417238920927048\n",
      "Iteration 6851, Loss: 0.053989481180906296\n",
      "Iteration 6852, Loss: 0.05417227745056152\n",
      "Iteration 6853, Loss: 0.05398952215909958\n",
      "Iteration 6854, Loss: 0.05417206883430481\n",
      "Iteration 6855, Loss: 0.053989723324775696\n",
      "Iteration 6856, Loss: 0.05417194962501526\n",
      "Iteration 6857, Loss: 0.05398987978696823\n",
      "Iteration 6858, Loss: 0.05417183041572571\n",
      "Iteration 6859, Loss: 0.05398999899625778\n",
      "Iteration 6860, Loss: 0.054171763360500336\n",
      "Iteration 6861, Loss: 0.05398999899625778\n",
      "Iteration 6862, Loss: 0.054171763360500336\n",
      "Iteration 6863, Loss: 0.05398987978696823\n",
      "Iteration 6864, Loss: 0.054171882569789886\n",
      "Iteration 6865, Loss: 0.053989797830581665\n",
      "Iteration 6866, Loss: 0.05417204648256302\n",
      "Iteration 6867, Loss: 0.05398949235677719\n",
      "Iteration 6868, Loss: 0.054172348231077194\n",
      "Iteration 6869, Loss: 0.053989481180906296\n",
      "Iteration 6870, Loss: 0.05417231470346451\n",
      "Iteration 6871, Loss: 0.05398952215909958\n",
      "Iteration 6872, Loss: 0.054172269999980927\n",
      "Iteration 6873, Loss: 0.05398964136838913\n",
      "Iteration 6874, Loss: 0.05417230352759361\n",
      "Iteration 6875, Loss: 0.05398968607187271\n",
      "Iteration 6876, Loss: 0.054172031581401825\n",
      "Iteration 6877, Loss: 0.05398983880877495\n",
      "Iteration 6878, Loss: 0.054171960800886154\n",
      "Iteration 6879, Loss: 0.053989723324775696\n",
      "Iteration 6880, Loss: 0.054171960800886154\n",
      "Iteration 6881, Loss: 0.053989723324775696\n",
      "Iteration 6882, Loss: 0.054171960800886154\n",
      "Iteration 6883, Loss: 0.05398964881896973\n",
      "Iteration 6884, Loss: 0.054172009229660034\n",
      "Iteration 6885, Loss: 0.05398957058787346\n",
      "Iteration 6886, Loss: 0.054172080010175705\n",
      "Iteration 6887, Loss: 0.053989604115486145\n",
      "Iteration 6888, Loss: 0.054172080010175705\n",
      "Iteration 6889, Loss: 0.05398954078555107\n",
      "Iteration 6890, Loss: 0.05417203903198242\n",
      "Iteration 6891, Loss: 0.05398964881896973\n",
      "Iteration 6892, Loss: 0.054172080010175705\n",
      "Iteration 6893, Loss: 0.05398964881896973\n",
      "Iteration 6894, Loss: 0.054171960800886154\n",
      "Iteration 6895, Loss: 0.053989723324775696\n",
      "Iteration 6896, Loss: 0.054172031581401825\n",
      "Iteration 6897, Loss: 0.05398984253406525\n",
      "Iteration 6898, Loss: 0.0541718453168869\n",
      "Iteration 6899, Loss: 0.053989723324775696\n",
      "Iteration 6900, Loss: 0.05417200177907944\n",
      "Iteration 6901, Loss: 0.05398968607187271\n",
      "Iteration 6902, Loss: 0.05417206883430481\n",
      "Iteration 6903, Loss: 0.0539897195994854\n",
      "Iteration 6904, Loss: 0.054171930998563766\n",
      "Iteration 6905, Loss: 0.053989678621292114\n",
      "Iteration 6906, Loss: 0.05417203903198242\n",
      "Iteration 6907, Loss: 0.053989678621292114\n",
      "Iteration 6908, Loss: 0.05417212098836899\n",
      "Iteration 6909, Loss: 0.053989678621292114\n",
      "Iteration 6910, Loss: 0.05417212098836899\n",
      "Iteration 6911, Loss: 0.05398960039019585\n",
      "Iteration 6912, Loss: 0.054172199219465256\n",
      "Iteration 6913, Loss: 0.053989559412002563\n",
      "Iteration 6914, Loss: 0.05417224019765854\n",
      "Iteration 6915, Loss: 0.053989410400390625\n",
      "Iteration 6916, Loss: 0.05417222902178764\n",
      "Iteration 6917, Loss: 0.053989529609680176\n",
      "Iteration 6918, Loss: 0.05417222902178764\n",
      "Iteration 6919, Loss: 0.05398949980735779\n",
      "Iteration 6920, Loss: 0.054172076284885406\n",
      "Iteration 6921, Loss: 0.05398957058787346\n",
      "Iteration 6922, Loss: 0.05417199432849884\n",
      "Iteration 6923, Loss: 0.05398964881896973\n",
      "Iteration 6924, Loss: 0.05417206883430481\n",
      "Iteration 6925, Loss: 0.05398976802825928\n",
      "Iteration 6926, Loss: 0.05417191609740257\n",
      "Iteration 6927, Loss: 0.053989849984645844\n",
      "Iteration 6928, Loss: 0.0541718415915966\n",
      "Iteration 6929, Loss: 0.05398992449045181\n",
      "Iteration 6930, Loss: 0.0541718527674675\n",
      "Iteration 6931, Loss: 0.05398968979716301\n",
      "Iteration 6932, Loss: 0.0541720911860466\n",
      "Iteration 6933, Loss: 0.05398937314748764\n",
      "Iteration 6934, Loss: 0.05417240783572197\n",
      "Iteration 6935, Loss: 0.05398928374052048\n",
      "Iteration 6936, Loss: 0.05417255684733391\n",
      "Iteration 6937, Loss: 0.05398917198181152\n",
      "Iteration 6938, Loss: 0.054172515869140625\n",
      "Iteration 6939, Loss: 0.05398910492658615\n",
      "Iteration 6940, Loss: 0.054172392934560776\n",
      "Iteration 6941, Loss: 0.053989291191101074\n",
      "Iteration 6942, Loss: 0.05417218804359436\n",
      "Iteration 6943, Loss: 0.05398961156606674\n",
      "Iteration 6944, Loss: 0.054171882569789886\n",
      "Iteration 6945, Loss: 0.05398976802825928\n",
      "Iteration 6946, Loss: 0.054171763360500336\n",
      "Iteration 6947, Loss: 0.053989969193935394\n",
      "Iteration 6948, Loss: 0.05417173355817795\n",
      "Iteration 6949, Loss: 0.05398988723754883\n",
      "Iteration 6950, Loss: 0.05417180061340332\n",
      "Iteration 6951, Loss: 0.05398984253406525\n",
      "Iteration 6952, Loss: 0.054171930998563766\n",
      "Iteration 6953, Loss: 0.05398964136838913\n",
      "Iteration 6954, Loss: 0.054172202944755554\n",
      "Iteration 6955, Loss: 0.053989291191101074\n",
      "Iteration 6956, Loss: 0.05417228862643242\n",
      "Iteration 6957, Loss: 0.05398933216929436\n",
      "Iteration 6958, Loss: 0.05417228862643242\n",
      "Iteration 6959, Loss: 0.05398940294981003\n",
      "Iteration 6960, Loss: 0.05417227745056152\n",
      "Iteration 6961, Loss: 0.05398945137858391\n",
      "Iteration 6962, Loss: 0.05417215824127197\n",
      "Iteration 6963, Loss: 0.05398964136838913\n",
      "Iteration 6964, Loss: 0.054171960800886154\n",
      "Iteration 6965, Loss: 0.05398973077535629\n",
      "Iteration 6966, Loss: 0.05417191982269287\n",
      "Iteration 6967, Loss: 0.05398980900645256\n",
      "Iteration 6968, Loss: 0.054171882569789886\n",
      "Iteration 6969, Loss: 0.053989581763744354\n",
      "Iteration 6970, Loss: 0.054172009229660034\n",
      "Iteration 6971, Loss: 0.05398941785097122\n",
      "Iteration 6972, Loss: 0.05417216941714287\n",
      "Iteration 6973, Loss: 0.05398937314748764\n",
      "Iteration 6974, Loss: 0.05417236313223839\n",
      "Iteration 6975, Loss: 0.053989291191101074\n",
      "Iteration 6976, Loss: 0.054172318428754807\n",
      "Iteration 6977, Loss: 0.053989291191101074\n",
      "Iteration 6978, Loss: 0.054172273725271225\n",
      "Iteration 6979, Loss: 0.05398945137858391\n",
      "Iteration 6980, Loss: 0.05417215824127197\n",
      "Iteration 6981, Loss: 0.05398961156606674\n",
      "Iteration 6982, Loss: 0.054172031581401825\n",
      "Iteration 6983, Loss: 0.05398968979716301\n",
      "Iteration 6984, Loss: 0.054171957075595856\n",
      "Iteration 6985, Loss: 0.053989775478839874\n",
      "Iteration 6986, Loss: 0.0541718527674675\n",
      "Iteration 6987, Loss: 0.05398976802825928\n",
      "Iteration 6988, Loss: 0.0541718527674675\n",
      "Iteration 6989, Loss: 0.05398976057767868\n",
      "Iteration 6990, Loss: 0.054171960800886154\n",
      "Iteration 6991, Loss: 0.05398961156606674\n",
      "Iteration 6992, Loss: 0.054172124713659286\n",
      "Iteration 6993, Loss: 0.05398944765329361\n",
      "Iteration 6994, Loss: 0.05417224392294884\n",
      "Iteration 6995, Loss: 0.0539892241358757\n",
      "Iteration 6996, Loss: 0.0541723296046257\n",
      "Iteration 6997, Loss: 0.05398929864168167\n",
      "Iteration 6998, Loss: 0.054172318428754807\n",
      "Iteration 6999, Loss: 0.05398937314748764\n",
      "Iteration 7000, Loss: 0.05417216941714287\n",
      "Iteration 7001, Loss: 0.05398934334516525\n",
      "Iteration 7002, Loss: 0.05417211353778839\n",
      "Iteration 7003, Loss: 0.05398961156606674\n",
      "Iteration 7004, Loss: 0.05417200177907944\n",
      "Iteration 7005, Loss: 0.05398968979716301\n",
      "Iteration 7006, Loss: 0.05417189002037048\n",
      "Iteration 7007, Loss: 0.05398964881896973\n",
      "Iteration 7008, Loss: 0.05417203903198242\n",
      "Iteration 7009, Loss: 0.05398964881896973\n",
      "Iteration 7010, Loss: 0.05417215824127197\n",
      "Iteration 7011, Loss: 0.05398949235677719\n",
      "Iteration 7012, Loss: 0.054172199219465256\n",
      "Iteration 7013, Loss: 0.053989410400390625\n",
      "Iteration 7014, Loss: 0.05417216569185257\n",
      "Iteration 7015, Loss: 0.053989410400390625\n",
      "Iteration 7016, Loss: 0.054172199219465256\n",
      "Iteration 7017, Loss: 0.05398957058787346\n",
      "Iteration 7018, Loss: 0.054171960800886154\n",
      "Iteration 7019, Loss: 0.05398973077535629\n",
      "Iteration 7020, Loss: 0.0541718527674675\n",
      "Iteration 7021, Loss: 0.05398973077535629\n",
      "Iteration 7022, Loss: 0.05417189002037048\n",
      "Iteration 7023, Loss: 0.05398957058787346\n",
      "Iteration 7024, Loss: 0.054172080010175705\n",
      "Iteration 7025, Loss: 0.05398941785097122\n",
      "Iteration 7026, Loss: 0.05417215824127197\n",
      "Iteration 7027, Loss: 0.05398949235677719\n",
      "Iteration 7028, Loss: 0.054172199219465256\n",
      "Iteration 7029, Loss: 0.053989410400390625\n",
      "Iteration 7030, Loss: 0.05417222902178764\n",
      "Iteration 7031, Loss: 0.05398957058787346\n",
      "Iteration 7032, Loss: 0.05417203903198242\n",
      "Iteration 7033, Loss: 0.05398968979716301\n",
      "Iteration 7034, Loss: 0.054172076284885406\n",
      "Iteration 7035, Loss: 0.05398964881896973\n",
      "Iteration 7036, Loss: 0.05417200177907944\n",
      "Iteration 7037, Loss: 0.05398961156606674\n",
      "Iteration 7038, Loss: 0.05417203903198242\n",
      "Iteration 7039, Loss: 0.05398961156606674\n",
      "Iteration 7040, Loss: 0.054172080010175705\n",
      "Iteration 7041, Loss: 0.05398957058787346\n",
      "Iteration 7042, Loss: 0.054172009229660034\n",
      "Iteration 7043, Loss: 0.05398945137858391\n",
      "Iteration 7044, Loss: 0.054172199219465256\n",
      "Iteration 7045, Loss: 0.05398949235677719\n",
      "Iteration 7046, Loss: 0.05417212098836899\n",
      "Iteration 7047, Loss: 0.05398953706026077\n",
      "Iteration 7048, Loss: 0.05417204648256302\n",
      "Iteration 7049, Loss: 0.053989604115486145\n",
      "Iteration 7050, Loss: 0.054172080010175705\n",
      "Iteration 7051, Loss: 0.053989604115486145\n",
      "Iteration 7052, Loss: 0.05417203530669212\n",
      "Iteration 7053, Loss: 0.05398961156606674\n",
      "Iteration 7054, Loss: 0.05417203530669212\n",
      "Iteration 7055, Loss: 0.05398968979716301\n",
      "Iteration 7056, Loss: 0.054172080010175705\n",
      "Iteration 7057, Loss: 0.05398949235677719\n",
      "Iteration 7058, Loss: 0.05417216569185257\n",
      "Iteration 7059, Loss: 0.05398949235677719\n",
      "Iteration 7060, Loss: 0.054172318428754807\n",
      "Iteration 7061, Loss: 0.053989410400390625\n",
      "Iteration 7062, Loss: 0.054172396659851074\n",
      "Iteration 7063, Loss: 0.05398917943239212\n",
      "Iteration 7064, Loss: 0.054172396659851074\n",
      "Iteration 7065, Loss: 0.05398918315768242\n",
      "Iteration 7066, Loss: 0.05417243763804436\n",
      "Iteration 7067, Loss: 0.05398933216929436\n",
      "Iteration 7068, Loss: 0.05417224019765854\n",
      "Iteration 7069, Loss: 0.05398956686258316\n",
      "Iteration 7070, Loss: 0.05417203530669212\n",
      "Iteration 7071, Loss: 0.05398964881896973\n",
      "Iteration 7072, Loss: 0.05417200177907944\n",
      "Iteration 7073, Loss: 0.05398928374052048\n",
      "Iteration 7074, Loss: 0.05417192727327347\n",
      "Iteration 7075, Loss: 0.05398900434374809\n",
      "Iteration 7076, Loss: 0.05417276546359062\n",
      "Iteration 7077, Loss: 0.053988777101039886\n",
      "Iteration 7078, Loss: 0.05417283624410629\n",
      "Iteration 7079, Loss: 0.05398881435394287\n",
      "Iteration 7080, Loss: 0.054172664880752563\n",
      "Iteration 7081, Loss: 0.05398905277252197\n",
      "Iteration 7082, Loss: 0.054172348231077194\n",
      "Iteration 7083, Loss: 0.05398937314748764\n",
      "Iteration 7084, Loss: 0.05417199432849884\n",
      "Iteration 7085, Loss: 0.05398960039019585\n",
      "Iteration 7086, Loss: 0.0541718415915966\n",
      "Iteration 7087, Loss: 0.05398976802825928\n",
      "Iteration 7088, Loss: 0.05417163670063019\n",
      "Iteration 7089, Loss: 0.05399011820554733\n",
      "Iteration 7090, Loss: 0.05417141318321228\n",
      "Iteration 7091, Loss: 0.05399015173316002\n",
      "Iteration 7092, Loss: 0.05417138338088989\n",
      "Iteration 7093, Loss: 0.05398999899625778\n",
      "Iteration 7094, Loss: 0.054171882569789886\n",
      "Iteration 7095, Loss: 0.0539897195994854\n",
      "Iteration 7096, Loss: 0.05417223274707794\n",
      "Iteration 7097, Loss: 0.053989291191101074\n",
      "Iteration 7098, Loss: 0.05417247861623764\n",
      "Iteration 7099, Loss: 0.05398901551961899\n",
      "Iteration 7100, Loss: 0.05417244881391525\n",
      "Iteration 7101, Loss: 0.05398905277252197\n",
      "Iteration 7102, Loss: 0.05417240783572197\n",
      "Iteration 7103, Loss: 0.05398917198181152\n",
      "Iteration 7104, Loss: 0.05417215824127197\n",
      "Iteration 7105, Loss: 0.053989481180906296\n",
      "Iteration 7106, Loss: 0.054172080010175705\n",
      "Iteration 7107, Loss: 0.05398964136838913\n",
      "Iteration 7108, Loss: 0.054171767085790634\n",
      "Iteration 7109, Loss: 0.05398964881896973\n",
      "Iteration 7110, Loss: 0.054171692579984665\n",
      "Iteration 7111, Loss: 0.05398973077535629\n",
      "Iteration 7112, Loss: 0.0541718527674675\n",
      "Iteration 7113, Loss: 0.053989529609680176\n",
      "Iteration 7114, Loss: 0.05417197197675705\n",
      "Iteration 7115, Loss: 0.05398945137858391\n",
      "Iteration 7116, Loss: 0.05417212098836899\n",
      "Iteration 7117, Loss: 0.05398937314748764\n",
      "Iteration 7118, Loss: 0.054172199219465256\n",
      "Iteration 7119, Loss: 0.05398936569690704\n",
      "Iteration 7120, Loss: 0.054172199219465256\n",
      "Iteration 7121, Loss: 0.05398937314748764\n",
      "Iteration 7122, Loss: 0.05417219549417496\n",
      "Iteration 7123, Loss: 0.053989529609680176\n",
      "Iteration 7124, Loss: 0.054171960800886154\n",
      "Iteration 7125, Loss: 0.05398964881896973\n",
      "Iteration 7126, Loss: 0.054171811789274216\n",
      "Iteration 7127, Loss: 0.05398957058787346\n",
      "Iteration 7128, Loss: 0.054172009229660034\n",
      "Iteration 7129, Loss: 0.053989484906196594\n",
      "Iteration 7130, Loss: 0.05417216941714287\n",
      "Iteration 7131, Loss: 0.053989212960004807\n",
      "Iteration 7132, Loss: 0.05417228862643242\n",
      "Iteration 7133, Loss: 0.05398932099342346\n",
      "Iteration 7134, Loss: 0.05417216941714287\n",
      "Iteration 7135, Loss: 0.053989291191101074\n",
      "Iteration 7136, Loss: 0.05417203903198242\n",
      "Iteration 7137, Loss: 0.05398964136838913\n",
      "Iteration 7138, Loss: 0.05417191982269287\n",
      "Iteration 7139, Loss: 0.053989797830581665\n",
      "Iteration 7140, Loss: 0.054171767085790634\n",
      "Iteration 7141, Loss: 0.053989797830581665\n",
      "Iteration 7142, Loss: 0.054171882569789886\n",
      "Iteration 7143, Loss: 0.05398976430296898\n",
      "Iteration 7144, Loss: 0.054171811789274216\n",
      "Iteration 7145, Loss: 0.053989604115486145\n",
      "Iteration 7146, Loss: 0.054172009229660034\n",
      "Iteration 7147, Loss: 0.053989484906196594\n",
      "Iteration 7148, Loss: 0.05417216941714287\n",
      "Iteration 7149, Loss: 0.05398933216929436\n",
      "Iteration 7150, Loss: 0.05417227745056152\n",
      "Iteration 7151, Loss: 0.053989361971616745\n",
      "Iteration 7152, Loss: 0.054172128438949585\n",
      "Iteration 7153, Loss: 0.053989212960004807\n",
      "Iteration 7154, Loss: 0.05417205020785332\n",
      "Iteration 7155, Loss: 0.05398945137858391\n",
      "Iteration 7156, Loss: 0.0541718527674675\n",
      "Iteration 7157, Loss: 0.05398957058787346\n",
      "Iteration 7158, Loss: 0.0541718527674675\n",
      "Iteration 7159, Loss: 0.05398964881896973\n",
      "Iteration 7160, Loss: 0.054171741008758545\n",
      "Iteration 7161, Loss: 0.05398976430296898\n",
      "Iteration 7162, Loss: 0.054171737283468246\n",
      "Iteration 7163, Loss: 0.05398976057767868\n",
      "Iteration 7164, Loss: 0.0541718453168869\n",
      "Iteration 7165, Loss: 0.05399007722735405\n",
      "Iteration 7166, Loss: 0.054172009229660034\n",
      "Iteration 7167, Loss: 0.05398987978696823\n",
      "Iteration 7168, Loss: 0.05417260527610779\n",
      "Iteration 7169, Loss: 0.05398964881896973\n",
      "Iteration 7170, Loss: 0.054172687232494354\n",
      "Iteration 7171, Loss: 0.05398987978696823\n",
      "Iteration 7172, Loss: 0.05417264252901077\n",
      "Iteration 7173, Loss: 0.05398991331458092\n",
      "Iteration 7174, Loss: 0.05417260527610779\n",
      "Iteration 7175, Loss: 0.05398983880877495\n",
      "Iteration 7176, Loss: 0.0541725680232048\n",
      "Iteration 7177, Loss: 0.05398976802825928\n",
      "Iteration 7178, Loss: 0.05417264625430107\n",
      "Iteration 7179, Loss: 0.05398987978696823\n",
      "Iteration 7180, Loss: 0.05417248234152794\n",
      "Iteration 7181, Loss: 0.05399003624916077\n",
      "Iteration 7182, Loss: 0.05417228862643242\n",
      "Iteration 7183, Loss: 0.05399012565612793\n",
      "Iteration 7184, Loss: 0.054172322154045105\n",
      "Iteration 7185, Loss: 0.05399015545845032\n",
      "Iteration 7186, Loss: 0.0541723296046257\n",
      "Iteration 7187, Loss: 0.05399000272154808\n",
      "Iteration 7188, Loss: 0.05417252331972122\n",
      "Iteration 7189, Loss: 0.053989849984645844\n",
      "Iteration 7190, Loss: 0.05417260527610779\n",
      "Iteration 7191, Loss: 0.05398983880877495\n",
      "Iteration 7192, Loss: 0.054172761738300323\n",
      "Iteration 7193, Loss: 0.05398968607187271\n",
      "Iteration 7194, Loss: 0.05417272448539734\n",
      "Iteration 7195, Loss: 0.05398964509367943\n",
      "Iteration 7196, Loss: 0.05417272448539734\n",
      "Iteration 7197, Loss: 0.05398961529135704\n",
      "Iteration 7198, Loss: 0.05417267978191376\n",
      "Iteration 7199, Loss: 0.053989700973033905\n",
      "Iteration 7200, Loss: 0.05417255684733391\n",
      "Iteration 7201, Loss: 0.05399007350206375\n",
      "Iteration 7202, Loss: 0.05417247861623764\n",
      "Iteration 7203, Loss: 0.053990043699741364\n",
      "Iteration 7204, Loss: 0.05417228862643242\n",
      "Iteration 7205, Loss: 0.05399011820554733\n",
      "Iteration 7206, Loss: 0.05417243763804436\n",
      "Iteration 7207, Loss: 0.05399007722735405\n",
      "Iteration 7208, Loss: 0.05417240411043167\n",
      "Iteration 7209, Loss: 0.05399015173316002\n",
      "Iteration 7210, Loss: 0.054172366857528687\n",
      "Iteration 7211, Loss: 0.053990110754966736\n",
      "Iteration 7212, Loss: 0.054172366857528687\n",
      "Iteration 7213, Loss: 0.05399007722735405\n",
      "Iteration 7214, Loss: 0.05417252704501152\n",
      "Iteration 7215, Loss: 0.053989849984645844\n",
      "Iteration 7216, Loss: 0.05417260527610779\n",
      "Iteration 7217, Loss: 0.05398983880877495\n",
      "Iteration 7218, Loss: 0.0541725717484951\n",
      "Iteration 7219, Loss: 0.05398976430296898\n",
      "Iteration 7220, Loss: 0.05417264625430107\n",
      "Iteration 7221, Loss: 0.05398976802825928\n",
      "Iteration 7222, Loss: 0.054172635078430176\n",
      "Iteration 7223, Loss: 0.053989849984645844\n",
      "Iteration 7224, Loss: 0.05417236313223839\n",
      "Iteration 7225, Loss: 0.0539901964366436\n",
      "Iteration 7226, Loss: 0.05417224392294884\n",
      "Iteration 7227, Loss: 0.05399024114012718\n",
      "Iteration 7228, Loss: 0.05417227745056152\n",
      "Iteration 7229, Loss: 0.05399027466773987\n",
      "Iteration 7230, Loss: 0.05417228862643242\n",
      "Iteration 7231, Loss: 0.05398992821574211\n",
      "Iteration 7232, Loss: 0.05417255684733391\n",
      "Iteration 7233, Loss: 0.05398987978696823\n",
      "Iteration 7234, Loss: 0.054172687232494354\n",
      "Iteration 7235, Loss: 0.053989797830581665\n",
      "Iteration 7236, Loss: 0.054172806441783905\n",
      "Iteration 7237, Loss: 0.05398961156606674\n",
      "Iteration 7238, Loss: 0.05417276546359062\n",
      "Iteration 7239, Loss: 0.05398964509367943\n",
      "Iteration 7240, Loss: 0.05417275428771973\n",
      "Iteration 7241, Loss: 0.05398983880877495\n",
      "Iteration 7242, Loss: 0.054172515869140625\n",
      "Iteration 7243, Loss: 0.053989969193935394\n",
      "Iteration 7244, Loss: 0.054172247648239136\n",
      "Iteration 7245, Loss: 0.05399027466773987\n",
      "Iteration 7246, Loss: 0.054172128438949585\n",
      "Iteration 7247, Loss: 0.053990237414836884\n",
      "Iteration 7248, Loss: 0.05417221039533615\n",
      "Iteration 7249, Loss: 0.05399024114012718\n",
      "Iteration 7250, Loss: 0.0541723296046257\n",
      "Iteration 7251, Loss: 0.053990043699741364\n",
      "Iteration 7252, Loss: 0.05417249724268913\n",
      "Iteration 7253, Loss: 0.05398968979716301\n",
      "Iteration 7254, Loss: 0.054172806441783905\n",
      "Iteration 7255, Loss: 0.05398956686258316\n",
      "Iteration 7256, Loss: 0.05417287349700928\n",
      "Iteration 7257, Loss: 0.05398964881896973\n",
      "Iteration 7258, Loss: 0.05417267605662346\n",
      "Iteration 7259, Loss: 0.053989261388778687\n",
      "Iteration 7260, Loss: 0.05417235940694809\n",
      "Iteration 7261, Loss: 0.05398938059806824\n",
      "Iteration 7262, Loss: 0.05417158454656601\n",
      "Iteration 7263, Loss: 0.05398935079574585\n",
      "Iteration 7264, Loss: 0.05417143553495407\n",
      "Iteration 7265, Loss: 0.05398949980735779\n",
      "Iteration 7266, Loss: 0.054171472787857056\n",
      "Iteration 7267, Loss: 0.05398954078555107\n",
      "Iteration 7268, Loss: 0.054171472787857056\n",
      "Iteration 7269, Loss: 0.05398949608206749\n",
      "Iteration 7270, Loss: 0.05417163297533989\n",
      "Iteration 7271, Loss: 0.05398930236697197\n",
      "Iteration 7272, Loss: 0.05417182669043541\n",
      "Iteration 7273, Loss: 0.05398911237716675\n",
      "Iteration 7274, Loss: 0.05417194217443466\n",
      "Iteration 7275, Loss: 0.05398903042078018\n",
      "Iteration 7276, Loss: 0.054171979427337646\n",
      "Iteration 7277, Loss: 0.053989022970199585\n",
      "Iteration 7278, Loss: 0.05417205020785332\n",
      "Iteration 7279, Loss: 0.05398915335536003\n",
      "Iteration 7280, Loss: 0.05417182669043541\n",
      "Iteration 7281, Loss: 0.05398930236697197\n",
      "Iteration 7282, Loss: 0.05417182296514511\n",
      "Iteration 7283, Loss: 0.0539892241358757\n",
      "Iteration 7284, Loss: 0.05417171120643616\n",
      "Iteration 7285, Loss: 0.05398914963006973\n",
      "Iteration 7286, Loss: 0.05417179316282272\n",
      "Iteration 7287, Loss: 0.05398925393819809\n",
      "Iteration 7288, Loss: 0.05417190492153168\n",
      "Iteration 7289, Loss: 0.05398910492658615\n",
      "Iteration 7290, Loss: 0.05417202040553093\n",
      "Iteration 7291, Loss: 0.05398903414607048\n",
      "Iteration 7292, Loss: 0.054171912372112274\n",
      "Iteration 7293, Loss: 0.05398910492658615\n",
      "Iteration 7294, Loss: 0.054171860218048096\n",
      "Iteration 7295, Loss: 0.0539892241358757\n",
      "Iteration 7296, Loss: 0.05417166277766228\n",
      "Iteration 7297, Loss: 0.05398938059806824\n",
      "Iteration 7298, Loss: 0.054171543568372726\n",
      "Iteration 7299, Loss: 0.0539894625544548\n",
      "Iteration 7300, Loss: 0.05417151004076004\n",
      "Iteration 7301, Loss: 0.0539894700050354\n",
      "Iteration 7302, Loss: 0.054171547293663025\n",
      "Iteration 7303, Loss: 0.05398941785097122\n",
      "Iteration 7304, Loss: 0.05417182296514511\n",
      "Iteration 7305, Loss: 0.053989142179489136\n",
      "Iteration 7306, Loss: 0.05417199060320854\n",
      "Iteration 7307, Loss: 0.053989022970199585\n",
      "Iteration 7308, Loss: 0.0541720986366272\n",
      "Iteration 7309, Loss: 0.053988903760910034\n",
      "Iteration 7310, Loss: 0.0541720949113369\n",
      "Iteration 7311, Loss: 0.0539889931678772\n",
      "Iteration 7312, Loss: 0.05417182296514511\n",
      "Iteration 7313, Loss: 0.053989142179489136\n",
      "Iteration 7314, Loss: 0.05417177826166153\n",
      "Iteration 7315, Loss: 0.053989410400390625\n",
      "Iteration 7316, Loss: 0.054171737283468246\n",
      "Iteration 7317, Loss: 0.05398942157626152\n",
      "Iteration 7318, Loss: 0.054171472787857056\n",
      "Iteration 7319, Loss: 0.0539894625544548\n",
      "Iteration 7320, Loss: 0.05417155474424362\n",
      "Iteration 7321, Loss: 0.05398945137858391\n",
      "Iteration 7322, Loss: 0.05417163297533989\n",
      "Iteration 7323, Loss: 0.05398934334516525\n",
      "Iteration 7324, Loss: 0.05417175218462944\n",
      "Iteration 7325, Loss: 0.05398918315768242\n",
      "Iteration 7326, Loss: 0.05417206138372421\n",
      "Iteration 7327, Loss: 0.05398891493678093\n",
      "Iteration 7328, Loss: 0.05417218059301376\n",
      "Iteration 7329, Loss: 0.05398879572749138\n",
      "Iteration 7330, Loss: 0.05417213961482048\n",
      "Iteration 7331, Loss: 0.05398879572749138\n",
      "Iteration 7332, Loss: 0.05417206138372421\n",
      "Iteration 7333, Loss: 0.0539889857172966\n",
      "Iteration 7334, Loss: 0.05417182296514511\n",
      "Iteration 7335, Loss: 0.05398930236697197\n",
      "Iteration 7336, Loss: 0.05417169630527496\n",
      "Iteration 7337, Loss: 0.05398949980735779\n",
      "Iteration 7338, Loss: 0.05417150259017944\n",
      "Iteration 7339, Loss: 0.05398954078555107\n",
      "Iteration 7340, Loss: 0.054171498864889145\n",
      "Iteration 7341, Loss: 0.053989581763744354\n",
      "Iteration 7342, Loss: 0.05417150259017944\n",
      "Iteration 7343, Loss: 0.05398949980735779\n",
      "Iteration 7344, Loss: 0.054171543568372726\n",
      "Iteration 7345, Loss: 0.05398949608206749\n",
      "Iteration 7346, Loss: 0.054171741008758545\n",
      "Iteration 7347, Loss: 0.053989291191101074\n",
      "Iteration 7348, Loss: 0.05417183041572571\n",
      "Iteration 7349, Loss: 0.05398903042078018\n",
      "Iteration 7350, Loss: 0.05417190492153168\n",
      "Iteration 7351, Loss: 0.053989022970199585\n",
      "Iteration 7352, Loss: 0.054171860218048096\n",
      "Iteration 7353, Loss: 0.05398910492658615\n",
      "Iteration 7354, Loss: 0.05417182669043541\n",
      "Iteration 7355, Loss: 0.05398910865187645\n",
      "Iteration 7356, Loss: 0.05417167395353317\n",
      "Iteration 7357, Loss: 0.05398938059806824\n",
      "Iteration 7358, Loss: 0.05417163297533989\n",
      "Iteration 7359, Loss: 0.053989388048648834\n",
      "Iteration 7360, Loss: 0.05417170748114586\n",
      "Iteration 7361, Loss: 0.05398930236697197\n",
      "Iteration 7362, Loss: 0.054171860218048096\n",
      "Iteration 7363, Loss: 0.0539892241358757\n",
      "Iteration 7364, Loss: 0.054171860218048096\n",
      "Iteration 7365, Loss: 0.053989142179489136\n",
      "Iteration 7366, Loss: 0.05417197197675705\n",
      "Iteration 7367, Loss: 0.0539892241358757\n",
      "Iteration 7368, Loss: 0.054171737283468246\n",
      "Iteration 7369, Loss: 0.05398938059806824\n",
      "Iteration 7370, Loss: 0.05417146533727646\n",
      "Iteration 7371, Loss: 0.05398939177393913\n",
      "Iteration 7372, Loss: 0.05417134612798691\n",
      "Iteration 7373, Loss: 0.05398973822593689\n",
      "Iteration 7374, Loss: 0.054171111434698105\n",
      "Iteration 7375, Loss: 0.05398977920413017\n",
      "Iteration 7376, Loss: 0.05417107790708542\n",
      "Iteration 7377, Loss: 0.05398973822593689\n",
      "Iteration 7378, Loss: 0.05417139455676079\n",
      "Iteration 7379, Loss: 0.05398938059806824\n",
      "Iteration 7380, Loss: 0.05417158827185631\n",
      "Iteration 7381, Loss: 0.05398930236697197\n",
      "Iteration 7382, Loss: 0.05417170375585556\n",
      "Iteration 7383, Loss: 0.053989261388778687\n",
      "Iteration 7384, Loss: 0.05417158827185631\n",
      "Iteration 7385, Loss: 0.053989388048648834\n",
      "Iteration 7386, Loss: 0.054171498864889145\n",
      "Iteration 7387, Loss: 0.0539894700050354\n",
      "Iteration 7388, Loss: 0.05417114496231079\n",
      "Iteration 7389, Loss: 0.05398974567651749\n",
      "Iteration 7390, Loss: 0.05417114496231079\n",
      "Iteration 7391, Loss: 0.05398997291922569\n",
      "Iteration 7392, Loss: 0.05417107790708542\n",
      "Iteration 7393, Loss: 0.05398965999484062\n",
      "Iteration 7394, Loss: 0.05417143553495407\n",
      "Iteration 7395, Loss: 0.05398926883935928\n",
      "Iteration 7396, Loss: 0.05417171120643616\n",
      "Iteration 7397, Loss: 0.053989142179489136\n",
      "Iteration 7398, Loss: 0.05417194962501526\n",
      "Iteration 7399, Loss: 0.05398891493678093\n",
      "Iteration 7400, Loss: 0.05417198687791824\n",
      "Iteration 7401, Loss: 0.053988873958587646\n",
      "Iteration 7402, Loss: 0.05417179316282272\n",
      "Iteration 7403, Loss: 0.05398907512426376\n",
      "Iteration 7404, Loss: 0.05417170375585556\n",
      "Iteration 7405, Loss: 0.0539894625544548\n",
      "Iteration 7406, Loss: 0.054171543568372726\n",
      "Iteration 7407, Loss: 0.05398949980735779\n",
      "Iteration 7408, Loss: 0.054171353578567505\n",
      "Iteration 7409, Loss: 0.05398954078555107\n",
      "Iteration 7410, Loss: 0.054171472787857056\n",
      "Iteration 7411, Loss: 0.05398954078555107\n",
      "Iteration 7412, Loss: 0.054171472787857056\n",
      "Iteration 7413, Loss: 0.05398930609226227\n",
      "Iteration 7414, Loss: 0.05417170375585556\n",
      "Iteration 7415, Loss: 0.053989194333553314\n",
      "Iteration 7416, Loss: 0.05417163297533989\n",
      "Iteration 7417, Loss: 0.05398911237716675\n",
      "Iteration 7418, Loss: 0.05417158827185631\n",
      "Iteration 7419, Loss: 0.053989261388778687\n",
      "Iteration 7420, Loss: 0.054171543568372726\n",
      "Iteration 7421, Loss: 0.05398942157626152\n",
      "Iteration 7422, Loss: 0.05417134612798691\n",
      "Iteration 7423, Loss: 0.0539894700050354\n",
      "Iteration 7424, Loss: 0.054171185940504074\n",
      "Iteration 7425, Loss: 0.05398985743522644\n",
      "Iteration 7426, Loss: 0.05417114123702049\n",
      "Iteration 7427, Loss: 0.05398992821574211\n",
      "Iteration 7428, Loss: 0.054171111434698105\n",
      "Iteration 7429, Loss: 0.053989849984645844\n",
      "Iteration 7430, Loss: 0.054171353578567505\n",
      "Iteration 7431, Loss: 0.05398928374052048\n",
      "Iteration 7432, Loss: 0.05417148023843765\n",
      "Iteration 7433, Loss: 0.053989164531230927\n",
      "Iteration 7434, Loss: 0.05417104810476303\n",
      "Iteration 7435, Loss: 0.053989045321941376\n",
      "Iteration 7436, Loss: 0.054171524941921234\n",
      "Iteration 7437, Loss: 0.05398908257484436\n",
      "Iteration 7438, Loss: 0.05417145416140556\n",
      "Iteration 7439, Loss: 0.053989093750715256\n",
      "Iteration 7440, Loss: 0.0541713610291481\n",
      "Iteration 7441, Loss: 0.05398933216929436\n",
      "Iteration 7442, Loss: 0.0541711263358593\n",
      "Iteration 7443, Loss: 0.053989559412002563\n",
      "Iteration 7444, Loss: 0.054170966148376465\n",
      "Iteration 7445, Loss: 0.053989559412002563\n",
      "Iteration 7446, Loss: 0.05417089909315109\n",
      "Iteration 7447, Loss: 0.053989484906196594\n",
      "Iteration 7448, Loss: 0.05417117103934288\n",
      "Iteration 7449, Loss: 0.05398940294981003\n",
      "Iteration 7450, Loss: 0.0541713684797287\n",
      "Iteration 7451, Loss: 0.05398912727832794\n",
      "Iteration 7452, Loss: 0.05417148768901825\n",
      "Iteration 7453, Loss: 0.05398900806903839\n",
      "Iteration 7454, Loss: 0.054171569645404816\n",
      "Iteration 7455, Loss: 0.05398900806903839\n",
      "Iteration 7456, Loss: 0.05417172238230705\n",
      "Iteration 7457, Loss: 0.053988970816135406\n",
      "Iteration 7458, Loss: 0.054171573370695114\n",
      "Iteration 7459, Loss: 0.05398889631032944\n",
      "Iteration 7460, Loss: 0.054171573370695114\n",
      "Iteration 7461, Loss: 0.05398900434374809\n",
      "Iteration 7462, Loss: 0.05417145416140556\n",
      "Iteration 7463, Loss: 0.05398912727832794\n",
      "Iteration 7464, Loss: 0.054171256721019745\n",
      "Iteration 7465, Loss: 0.05398920178413391\n",
      "Iteration 7466, Loss: 0.05417129397392273\n",
      "Iteration 7467, Loss: 0.05398917198181152\n",
      "Iteration 7468, Loss: 0.05417129397392273\n",
      "Iteration 7469, Loss: 0.05398932099342346\n",
      "Iteration 7470, Loss: 0.05417121201753616\n",
      "Iteration 7471, Loss: 0.05398932844400406\n",
      "Iteration 7472, Loss: 0.05417128652334213\n",
      "Iteration 7473, Loss: 0.05398925393819809\n",
      "Iteration 7474, Loss: 0.05417121201753616\n",
      "Iteration 7475, Loss: 0.05398932844400406\n",
      "Iteration 7476, Loss: 0.05417121201753616\n",
      "Iteration 7477, Loss: 0.05398932844400406\n",
      "Iteration 7478, Loss: 0.054171137511730194\n",
      "Iteration 7479, Loss: 0.05398932844400406\n",
      "Iteration 7480, Loss: 0.05417132377624512\n",
      "Iteration 7481, Loss: 0.05398932099342346\n",
      "Iteration 7482, Loss: 0.05417132377624512\n",
      "Iteration 7483, Loss: 0.05398925393819809\n",
      "Iteration 7484, Loss: 0.05417124554514885\n",
      "Iteration 7485, Loss: 0.05398932099342346\n",
      "Iteration 7486, Loss: 0.05417116731405258\n",
      "Iteration 7487, Loss: 0.05398936569690704\n",
      "Iteration 7488, Loss: 0.05417105555534363\n",
      "Iteration 7489, Loss: 0.053989481180906296\n",
      "Iteration 7490, Loss: 0.05417124554514885\n",
      "Iteration 7491, Loss: 0.053989510983228683\n",
      "Iteration 7492, Loss: 0.05417117476463318\n",
      "Iteration 7493, Loss: 0.05398932099342346\n",
      "Iteration 7494, Loss: 0.05417129024863243\n",
      "Iteration 7495, Loss: 0.05398925393819809\n",
      "Iteration 7496, Loss: 0.05417129397392273\n",
      "Iteration 7497, Loss: 0.053989242762327194\n",
      "Iteration 7498, Loss: 0.05417156219482422\n",
      "Iteration 7499, Loss: 0.05398905277252197\n",
      "Iteration 7500, Loss: 0.054171767085790634\n",
      "Iteration 7501, Loss: 0.0539887361228466\n",
      "Iteration 7502, Loss: 0.05417203903198242\n",
      "Iteration 7503, Loss: 0.0539885014295578\n",
      "Iteration 7504, Loss: 0.05417200177907944\n",
      "Iteration 7505, Loss: 0.053988583385944366\n",
      "Iteration 7506, Loss: 0.05417187511920929\n",
      "Iteration 7507, Loss: 0.05398882180452347\n",
      "Iteration 7508, Loss: 0.05417148396372795\n",
      "Iteration 7509, Loss: 0.05398913472890854\n",
      "Iteration 7510, Loss: 0.05417127534747124\n",
      "Iteration 7511, Loss: 0.05398952215909958\n",
      "Iteration 7512, Loss: 0.05417104810476303\n",
      "Iteration 7513, Loss: 0.053989630192518234\n",
      "Iteration 7514, Loss: 0.054171010851860046\n",
      "Iteration 7515, Loss: 0.053989630192518234\n",
      "Iteration 7516, Loss: 0.05417124927043915\n",
      "Iteration 7517, Loss: 0.05398928374052048\n",
      "Iteration 7518, Loss: 0.05417141318321228\n",
      "Iteration 7519, Loss: 0.05398900806903839\n",
      "Iteration 7520, Loss: 0.05417173355817795\n",
      "Iteration 7521, Loss: 0.05398884415626526\n",
      "Iteration 7522, Loss: 0.05417191982269287\n",
      "Iteration 7523, Loss: 0.05398869514465332\n",
      "Iteration 7524, Loss: 0.05417191982269287\n",
      "Iteration 7525, Loss: 0.053988732397556305\n",
      "Iteration 7526, Loss: 0.054171882569789886\n",
      "Iteration 7527, Loss: 0.05398884415626526\n",
      "Iteration 7528, Loss: 0.054171644151210785\n",
      "Iteration 7529, Loss: 0.05398901551961899\n",
      "Iteration 7530, Loss: 0.054171524941921234\n",
      "Iteration 7531, Loss: 0.05398920923471451\n",
      "Iteration 7532, Loss: 0.05417129397392273\n",
      "Iteration 7533, Loss: 0.05398928374052048\n",
      "Iteration 7534, Loss: 0.05417133495211601\n",
      "Iteration 7535, Loss: 0.053989361971616745\n",
      "Iteration 7536, Loss: 0.054171524941921234\n",
      "Iteration 7537, Loss: 0.053989045321941376\n",
      "Iteration 7538, Loss: 0.054171763360500336\n",
      "Iteration 7539, Loss: 0.05398881435394287\n",
      "Iteration 7540, Loss: 0.05417200177907944\n",
      "Iteration 7541, Loss: 0.05398869514465332\n",
      "Iteration 7542, Loss: 0.05417200177907944\n",
      "Iteration 7543, Loss: 0.05398865044116974\n",
      "Iteration 7544, Loss: 0.05417189002037048\n",
      "Iteration 7545, Loss: 0.053988657891750336\n",
      "Iteration 7546, Loss: 0.054171692579984665\n",
      "Iteration 7547, Loss: 0.05398892983794212\n",
      "Iteration 7548, Loss: 0.054171495139598846\n",
      "Iteration 7549, Loss: 0.05398912727832794\n",
      "Iteration 7550, Loss: 0.05417141318321228\n",
      "Iteration 7551, Loss: 0.05398920178413391\n",
      "Iteration 7552, Loss: 0.054171256721019745\n",
      "Iteration 7553, Loss: 0.053989287465810776\n",
      "Iteration 7554, Loss: 0.054171331226825714\n",
      "Iteration 7555, Loss: 0.053989164531230927\n",
      "Iteration 7556, Loss: 0.054171524941921234\n",
      "Iteration 7557, Loss: 0.053989049047231674\n",
      "Iteration 7558, Loss: 0.0541716068983078\n",
      "Iteration 7559, Loss: 0.05398900434374809\n",
      "Iteration 7560, Loss: 0.05417168140411377\n",
      "Iteration 7561, Loss: 0.05398893356323242\n",
      "Iteration 7562, Loss: 0.054171644151210785\n",
      "Iteration 7563, Loss: 0.05398919805884361\n",
      "Iteration 7564, Loss: 0.054171591997146606\n",
      "Iteration 7565, Loss: 0.05398912727832794\n",
      "Iteration 7566, Loss: 0.05417148396372795\n",
      "Iteration 7567, Loss: 0.053989164531230927\n",
      "Iteration 7568, Loss: 0.05417140945792198\n",
      "Iteration 7569, Loss: 0.053989242762327194\n",
      "Iteration 7570, Loss: 0.05417133495211601\n",
      "Iteration 7571, Loss: 0.053989168256521225\n",
      "Iteration 7572, Loss: 0.05417148396372795\n",
      "Iteration 7573, Loss: 0.053989093750715256\n",
      "Iteration 7574, Loss: 0.054171375930309296\n",
      "Iteration 7575, Loss: 0.05398912727832794\n",
      "Iteration 7576, Loss: 0.054171331226825714\n",
      "Iteration 7577, Loss: 0.05398913472890854\n",
      "Iteration 7578, Loss: 0.05417132377624512\n",
      "Iteration 7579, Loss: 0.053989212960004807\n",
      "Iteration 7580, Loss: 0.0541713647544384\n",
      "Iteration 7581, Loss: 0.053989242762327194\n",
      "Iteration 7582, Loss: 0.05417132377624512\n",
      "Iteration 7583, Loss: 0.05398932099342346\n",
      "Iteration 7584, Loss: 0.0541713684797287\n",
      "Iteration 7585, Loss: 0.05398928374052048\n",
      "Iteration 7586, Loss: 0.05417153239250183\n",
      "Iteration 7587, Loss: 0.053989045321941376\n",
      "Iteration 7588, Loss: 0.054171763360500336\n",
      "Iteration 7589, Loss: 0.05398881062865257\n",
      "Iteration 7590, Loss: 0.05417177081108093\n",
      "Iteration 7591, Loss: 0.05398869514465332\n",
      "Iteration 7592, Loss: 0.05417187511920929\n",
      "Iteration 7593, Loss: 0.05398881435394287\n",
      "Iteration 7594, Loss: 0.05417168140411377\n",
      "Iteration 7595, Loss: 0.05398905277252197\n",
      "Iteration 7596, Loss: 0.05417133495211601\n",
      "Iteration 7597, Loss: 0.053989168256521225\n",
      "Iteration 7598, Loss: 0.054171256721019745\n",
      "Iteration 7599, Loss: 0.053989361971616745\n",
      "Iteration 7600, Loss: 0.05417121574282646\n",
      "Iteration 7601, Loss: 0.053989481180906296\n",
      "Iteration 7602, Loss: 0.05417116731405258\n",
      "Iteration 7603, Loss: 0.053989481180906296\n",
      "Iteration 7604, Loss: 0.05417117476463318\n",
      "Iteration 7605, Loss: 0.05398944020271301\n",
      "Iteration 7606, Loss: 0.05417126044631004\n",
      "Iteration 7607, Loss: 0.053989361971616745\n",
      "Iteration 7608, Loss: 0.054171495139598846\n",
      "Iteration 7609, Loss: 0.05398900434374809\n",
      "Iteration 7610, Loss: 0.05417172238230705\n",
      "Iteration 7611, Loss: 0.05398881435394287\n",
      "Iteration 7612, Loss: 0.054171882569789886\n",
      "Iteration 7613, Loss: 0.05398876965045929\n",
      "Iteration 7614, Loss: 0.05417180061340332\n",
      "Iteration 7615, Loss: 0.05398888885974884\n",
      "Iteration 7616, Loss: 0.054171573370695114\n",
      "Iteration 7617, Loss: 0.053988974541425705\n",
      "Iteration 7618, Loss: 0.05417145416140556\n",
      "Iteration 7619, Loss: 0.05398909002542496\n",
      "Iteration 7620, Loss: 0.05417140945792198\n",
      "Iteration 7621, Loss: 0.053989164531230927\n",
      "Iteration 7622, Loss: 0.05417141318321228\n",
      "Iteration 7623, Loss: 0.05398920178413391\n",
      "Iteration 7624, Loss: 0.05417148396372795\n",
      "Iteration 7625, Loss: 0.053989164531230927\n",
      "Iteration 7626, Loss: 0.054171495139598846\n",
      "Iteration 7627, Loss: 0.05398908257484436\n",
      "Iteration 7628, Loss: 0.054171644151210785\n",
      "Iteration 7629, Loss: 0.053988974541425705\n",
      "Iteration 7630, Loss: 0.054171644151210785\n",
      "Iteration 7631, Loss: 0.053989049047231674\n",
      "Iteration 7632, Loss: 0.05417168140411377\n",
      "Iteration 7633, Loss: 0.05398889631032944\n",
      "Iteration 7634, Loss: 0.05417168140411377\n",
      "Iteration 7635, Loss: 0.05398889631032944\n",
      "Iteration 7636, Loss: 0.054171569645404816\n",
      "Iteration 7637, Loss: 0.05398901551961899\n",
      "Iteration 7638, Loss: 0.054171524941921234\n",
      "Iteration 7639, Loss: 0.053989093750715256\n",
      "Iteration 7640, Loss: 0.05417140573263168\n",
      "Iteration 7641, Loss: 0.05398917198181152\n",
      "Iteration 7642, Loss: 0.05417148396372795\n",
      "Iteration 7643, Loss: 0.053989093750715256\n",
      "Iteration 7644, Loss: 0.05417156219482422\n",
      "Iteration 7645, Loss: 0.05398901551961899\n",
      "Iteration 7646, Loss: 0.05417148768901825\n",
      "Iteration 7647, Loss: 0.053989164531230927\n",
      "Iteration 7648, Loss: 0.05417156219482422\n",
      "Iteration 7649, Loss: 0.05398920178413391\n",
      "Iteration 7650, Loss: 0.05417129397392273\n",
      "Iteration 7651, Loss: 0.053989510983228683\n",
      "Iteration 7652, Loss: 0.05417132377624512\n",
      "Iteration 7653, Loss: 0.05398940294981003\n",
      "Iteration 7654, Loss: 0.054171256721019745\n",
      "Iteration 7655, Loss: 0.05398932099342346\n",
      "Iteration 7656, Loss: 0.05417133495211601\n",
      "Iteration 7657, Loss: 0.05398932099342346\n",
      "Iteration 7658, Loss: 0.0541715994477272\n",
      "Iteration 7659, Loss: 0.05398909002542496\n",
      "Iteration 7660, Loss: 0.05417168140411377\n",
      "Iteration 7661, Loss: 0.05398888885974884\n",
      "Iteration 7662, Loss: 0.054171763360500336\n",
      "Iteration 7663, Loss: 0.05398881062865257\n",
      "Iteration 7664, Loss: 0.05417180061340332\n",
      "Iteration 7665, Loss: 0.05398884415626526\n",
      "Iteration 7666, Loss: 0.05417172238230705\n",
      "Iteration 7667, Loss: 0.053988926112651825\n",
      "Iteration 7668, Loss: 0.05417171120643616\n",
      "Iteration 7669, Loss: 0.05398912355303764\n",
      "Iteration 7670, Loss: 0.054171591997146606\n",
      "Iteration 7671, Loss: 0.05398932099342346\n",
      "Iteration 7672, Loss: 0.05417139455676079\n",
      "Iteration 7673, Loss: 0.05398944020271301\n",
      "Iteration 7674, Loss: 0.05417128652334213\n",
      "Iteration 7675, Loss: 0.05398940294981003\n",
      "Iteration 7676, Loss: 0.05417148396372795\n",
      "Iteration 7677, Loss: 0.05398912355303764\n",
      "Iteration 7678, Loss: 0.05417168140411377\n",
      "Iteration 7679, Loss: 0.053988855332136154\n",
      "Iteration 7680, Loss: 0.05417199060320854\n",
      "Iteration 7681, Loss: 0.05398884415626526\n",
      "Iteration 7682, Loss: 0.05417191982269287\n",
      "Iteration 7683, Loss: 0.05398888140916824\n",
      "Iteration 7684, Loss: 0.05417175590991974\n",
      "Iteration 7685, Loss: 0.053988970816135406\n",
      "Iteration 7686, Loss: 0.054171591997146606\n",
      "Iteration 7687, Loss: 0.053989242762327194\n",
      "Iteration 7688, Loss: 0.0541713647544384\n",
      "Iteration 7689, Loss: 0.05398932844400406\n",
      "Iteration 7690, Loss: 0.0541711263358593\n",
      "Iteration 7691, Loss: 0.05398955196142197\n",
      "Iteration 7692, Loss: 0.05417124554514885\n",
      "Iteration 7693, Loss: 0.053989481180906296\n",
      "Iteration 7694, Loss: 0.05417124554514885\n",
      "Iteration 7695, Loss: 0.053989361971616745\n",
      "Iteration 7696, Loss: 0.05417152866721153\n",
      "Iteration 7697, Loss: 0.053989045321941376\n",
      "Iteration 7698, Loss: 0.05417180061340332\n",
      "Iteration 7699, Loss: 0.05398881062865257\n",
      "Iteration 7700, Loss: 0.05417191982269287\n",
      "Iteration 7701, Loss: 0.0539887361228466\n",
      "Iteration 7702, Loss: 0.05417194962501526\n",
      "Iteration 7703, Loss: 0.05398888513445854\n",
      "Iteration 7704, Loss: 0.054171763360500336\n",
      "Iteration 7705, Loss: 0.05398900434374809\n",
      "Iteration 7706, Loss: 0.0541716031730175\n",
      "Iteration 7707, Loss: 0.05398908257484436\n",
      "Iteration 7708, Loss: 0.05417152866721153\n",
      "Iteration 7709, Loss: 0.053989164531230927\n",
      "Iteration 7710, Loss: 0.054171524941921234\n",
      "Iteration 7711, Loss: 0.05398905277252197\n",
      "Iteration 7712, Loss: 0.054171524941921234\n",
      "Iteration 7713, Loss: 0.05398912355303764\n",
      "Iteration 7714, Loss: 0.0541716068983078\n",
      "Iteration 7715, Loss: 0.05398900806903839\n",
      "Iteration 7716, Loss: 0.05417172238230705\n",
      "Iteration 7717, Loss: 0.053988974541425705\n",
      "Iteration 7718, Loss: 0.05417179316282272\n",
      "Iteration 7719, Loss: 0.05398889631032944\n",
      "Iteration 7720, Loss: 0.05417168140411377\n",
      "Iteration 7721, Loss: 0.05398900434374809\n",
      "Iteration 7722, Loss: 0.0541716031730175\n",
      "Iteration 7723, Loss: 0.053989049047231674\n",
      "Iteration 7724, Loss: 0.05417155846953392\n",
      "Iteration 7725, Loss: 0.053989164531230927\n",
      "Iteration 7726, Loss: 0.054171524941921234\n",
      "Iteration 7727, Loss: 0.053989242762327194\n",
      "Iteration 7728, Loss: 0.0541716031730175\n",
      "Iteration 7729, Loss: 0.053989164531230927\n",
      "Iteration 7730, Loss: 0.054171718657016754\n",
      "Iteration 7731, Loss: 0.05398900434374809\n",
      "Iteration 7732, Loss: 0.05417187511920929\n",
      "Iteration 7733, Loss: 0.053988851606845856\n",
      "Iteration 7734, Loss: 0.05417183041572571\n",
      "Iteration 7735, Loss: 0.05398889631032944\n",
      "Iteration 7736, Loss: 0.05417171120643616\n",
      "Iteration 7737, Loss: 0.05398905277252197\n",
      "Iteration 7738, Loss: 0.054171524941921234\n",
      "Iteration 7739, Loss: 0.053989361971616745\n",
      "Iteration 7740, Loss: 0.05417140573263168\n",
      "Iteration 7741, Loss: 0.05398939177393913\n",
      "Iteration 7742, Loss: 0.054171591997146606\n",
      "Iteration 7743, Loss: 0.05398920178413391\n",
      "Iteration 7744, Loss: 0.054171718657016754\n",
      "Iteration 7745, Loss: 0.053988974541425705\n",
      "Iteration 7746, Loss: 0.05417187139391899\n",
      "Iteration 7747, Loss: 0.053988855332136154\n",
      "Iteration 7748, Loss: 0.054171960800886154\n",
      "Iteration 7749, Loss: 0.053988732397556305\n",
      "Iteration 7750, Loss: 0.054171957075595856\n",
      "Iteration 7751, Loss: 0.05398869141936302\n",
      "Iteration 7752, Loss: 0.054171882569789886\n",
      "Iteration 7753, Loss: 0.05398884415626526\n",
      "Iteration 7754, Loss: 0.05417179688811302\n",
      "Iteration 7755, Loss: 0.05398896336555481\n",
      "Iteration 7756, Loss: 0.05417163297533989\n",
      "Iteration 7757, Loss: 0.053989242762327194\n",
      "Iteration 7758, Loss: 0.054171472787857056\n",
      "Iteration 7759, Loss: 0.05398944020271301\n",
      "Iteration 7760, Loss: 0.05417116731405258\n",
      "Iteration 7761, Loss: 0.05398959666490555\n",
      "Iteration 7762, Loss: 0.05417132005095482\n",
      "Iteration 7763, Loss: 0.05398944020271301\n",
      "Iteration 7764, Loss: 0.05417155846953392\n",
      "Iteration 7765, Loss: 0.053989045321941376\n",
      "Iteration 7766, Loss: 0.054171811789274216\n",
      "Iteration 7767, Loss: 0.05398884415626526\n",
      "Iteration 7768, Loss: 0.054172080010175705\n",
      "Iteration 7769, Loss: 0.05398861691355705\n",
      "Iteration 7770, Loss: 0.05417218804359436\n",
      "Iteration 7771, Loss: 0.05398857593536377\n",
      "Iteration 7772, Loss: 0.05417206883430481\n",
      "Iteration 7773, Loss: 0.05398869514465332\n",
      "Iteration 7774, Loss: 0.05417187139391899\n",
      "Iteration 7775, Loss: 0.05398889631032944\n",
      "Iteration 7776, Loss: 0.05417171120643616\n",
      "Iteration 7777, Loss: 0.053989164531230927\n",
      "Iteration 7778, Loss: 0.054171331226825714\n",
      "Iteration 7779, Loss: 0.05398939549922943\n",
      "Iteration 7780, Loss: 0.0541713610291481\n",
      "Iteration 7781, Loss: 0.053989477455616\n",
      "Iteration 7782, Loss: 0.05417132377624512\n",
      "Iteration 7783, Loss: 0.05398955196142197\n",
      "Iteration 7784, Loss: 0.0541715994477272\n",
      "Iteration 7785, Loss: 0.053989164531230927\n",
      "Iteration 7786, Loss: 0.05417187511920929\n",
      "Iteration 7787, Loss: 0.05398884043097496\n",
      "Iteration 7788, Loss: 0.05417215824127197\n",
      "Iteration 7789, Loss: 0.05398856848478317\n",
      "Iteration 7790, Loss: 0.05417215824127197\n",
      "Iteration 7791, Loss: 0.05398860573768616\n",
      "Iteration 7792, Loss: 0.054171960800886154\n",
      "Iteration 7793, Loss: 0.053988806903362274\n",
      "Iteration 7794, Loss: 0.05417175218462944\n",
      "Iteration 7795, Loss: 0.05398957058787346\n",
      "Iteration 7796, Loss: 0.05417124554514885\n",
      "Iteration 7797, Loss: 0.0539899580180645\n",
      "Iteration 7798, Loss: 0.05417068302631378\n",
      "Iteration 7799, Loss: 0.05399022623896599\n",
      "Iteration 7800, Loss: 0.05417054146528244\n",
      "Iteration 7801, Loss: 0.053990066051483154\n",
      "Iteration 7802, Loss: 0.05417104810476303\n",
      "Iteration 7803, Loss: 0.053989559412002563\n",
      "Iteration 7804, Loss: 0.05417144298553467\n",
      "Iteration 7805, Loss: 0.05398928374052048\n",
      "Iteration 7806, Loss: 0.05417194962501526\n",
      "Iteration 7807, Loss: 0.05398884415626526\n",
      "Iteration 7808, Loss: 0.05417215824127197\n",
      "Iteration 7809, Loss: 0.05398857593536377\n",
      "Iteration 7810, Loss: 0.05417224019765854\n",
      "Iteration 7811, Loss: 0.05398864671587944\n",
      "Iteration 7812, Loss: 0.054172150790691376\n",
      "Iteration 7813, Loss: 0.05398881062865257\n",
      "Iteration 7814, Loss: 0.05417187139391899\n",
      "Iteration 7815, Loss: 0.05398908257484436\n",
      "Iteration 7816, Loss: 0.0541716031730175\n",
      "Iteration 7817, Loss: 0.05398917198181152\n",
      "Iteration 7818, Loss: 0.054171591997146606\n",
      "Iteration 7819, Loss: 0.053989287465810776\n",
      "Iteration 7820, Loss: 0.05417143926024437\n",
      "Iteration 7821, Loss: 0.053989481180906296\n",
      "Iteration 7822, Loss: 0.05417132005095482\n",
      "Iteration 7823, Loss: 0.05398967117071152\n",
      "Iteration 7824, Loss: 0.05417132377624512\n",
      "Iteration 7825, Loss: 0.05398955196142197\n",
      "Iteration 7826, Loss: 0.054171398282051086\n",
      "Iteration 7827, Loss: 0.05398932099342346\n",
      "Iteration 7828, Loss: 0.054171524941921234\n",
      "Iteration 7829, Loss: 0.05398932099342346\n",
      "Iteration 7830, Loss: 0.05417175218462944\n",
      "Iteration 7831, Loss: 0.05398908257484436\n",
      "Iteration 7832, Loss: 0.05417187511920929\n",
      "Iteration 7833, Loss: 0.05398896336555481\n",
      "Iteration 7834, Loss: 0.0541718415915966\n",
      "Iteration 7835, Loss: 0.053988851606845856\n",
      "Iteration 7836, Loss: 0.054171763360500336\n",
      "Iteration 7837, Loss: 0.053988970816135406\n",
      "Iteration 7838, Loss: 0.054171763360500336\n",
      "Iteration 7839, Loss: 0.05398905277252197\n",
      "Iteration 7840, Loss: 0.0541715994477272\n",
      "Iteration 7841, Loss: 0.05398924648761749\n",
      "Iteration 7842, Loss: 0.05417144298553467\n",
      "Iteration 7843, Loss: 0.053989361971616745\n",
      "Iteration 7844, Loss: 0.05417143553495407\n",
      "Iteration 7845, Loss: 0.05398967117071152\n",
      "Iteration 7846, Loss: 0.05417124181985855\n",
      "Iteration 7847, Loss: 0.05398967117071152\n",
      "Iteration 7848, Loss: 0.05417132005095482\n",
      "Iteration 7849, Loss: 0.05398952215909958\n",
      "Iteration 7850, Loss: 0.05417140573263168\n",
      "Iteration 7851, Loss: 0.05398940294981003\n",
      "Iteration 7852, Loss: 0.054171644151210785\n",
      "Iteration 7853, Loss: 0.05398920178413391\n",
      "Iteration 7854, Loss: 0.05417191982269287\n",
      "Iteration 7855, Loss: 0.053988926112651825\n",
      "Iteration 7856, Loss: 0.054172083735466\n",
      "Iteration 7857, Loss: 0.05398872494697571\n",
      "Iteration 7858, Loss: 0.05417215824127197\n",
      "Iteration 7859, Loss: 0.053988657891750336\n",
      "Iteration 7860, Loss: 0.054172076284885406\n",
      "Iteration 7861, Loss: 0.05398870259523392\n",
      "Iteration 7862, Loss: 0.05417183041572571\n",
      "Iteration 7863, Loss: 0.05398912355303764\n",
      "Iteration 7864, Loss: 0.05417155474424362\n",
      "Iteration 7865, Loss: 0.05398940294981003\n",
      "Iteration 7866, Loss: 0.054171234369277954\n",
      "Iteration 7867, Loss: 0.05398979038000107\n",
      "Iteration 7868, Loss: 0.05417107790708542\n",
      "Iteration 7869, Loss: 0.05398990958929062\n",
      "Iteration 7870, Loss: 0.05417100712656975\n",
      "Iteration 7871, Loss: 0.05398982763290405\n",
      "Iteration 7872, Loss: 0.05417129024863243\n",
      "Iteration 7873, Loss: 0.05398932099342346\n",
      "Iteration 7874, Loss: 0.054171718657016754\n",
      "Iteration 7875, Loss: 0.05398896336555481\n",
      "Iteration 7876, Loss: 0.054172080010175705\n",
      "Iteration 7877, Loss: 0.05398876965045929\n",
      "Iteration 7878, Loss: 0.054172273725271225\n",
      "Iteration 7879, Loss: 0.05398865044116974\n",
      "Iteration 7880, Loss: 0.05417230725288391\n",
      "Iteration 7881, Loss: 0.05398857221007347\n",
      "Iteration 7882, Loss: 0.05417203903198242\n",
      "Iteration 7883, Loss: 0.0539887361228466\n",
      "Iteration 7884, Loss: 0.05417191609740257\n",
      "Iteration 7885, Loss: 0.053988974541425705\n",
      "Iteration 7886, Loss: 0.05417175218462944\n",
      "Iteration 7887, Loss: 0.05398913472890854\n",
      "Iteration 7888, Loss: 0.05417156219482422\n",
      "Iteration 7889, Loss: 0.05398925393819809\n",
      "Iteration 7890, Loss: 0.05417148396372795\n",
      "Iteration 7891, Loss: 0.05398940294981003\n",
      "Iteration 7892, Loss: 0.05417143926024437\n",
      "Iteration 7893, Loss: 0.053989481180906296\n",
      "Iteration 7894, Loss: 0.05417148396372795\n",
      "Iteration 7895, Loss: 0.05398932099342346\n",
      "Iteration 7896, Loss: 0.05417155846953392\n",
      "Iteration 7897, Loss: 0.053989242762327194\n",
      "Iteration 7898, Loss: 0.05417179316282272\n",
      "Iteration 7899, Loss: 0.053989119827747345\n",
      "Iteration 7900, Loss: 0.05417199060320854\n",
      "Iteration 7901, Loss: 0.05398884415626526\n",
      "Iteration 7902, Loss: 0.0541718415915966\n",
      "Iteration 7903, Loss: 0.05398889631032944\n",
      "Iteration 7904, Loss: 0.054171763360500336\n",
      "Iteration 7905, Loss: 0.05398905277252197\n",
      "Iteration 7906, Loss: 0.05417156219482422\n",
      "Iteration 7907, Loss: 0.05398920923471451\n",
      "Iteration 7908, Loss: 0.05417140573263168\n",
      "Iteration 7909, Loss: 0.05398932099342346\n",
      "Iteration 7910, Loss: 0.05417140573263168\n",
      "Iteration 7911, Loss: 0.053989287465810776\n",
      "Iteration 7912, Loss: 0.054171524941921234\n",
      "Iteration 7913, Loss: 0.053989287465810776\n",
      "Iteration 7914, Loss: 0.05417148396372795\n",
      "Iteration 7915, Loss: 0.05398932844400406\n",
      "Iteration 7916, Loss: 0.054171524941921234\n",
      "Iteration 7917, Loss: 0.05398935079574585\n",
      "Iteration 7918, Loss: 0.0541715994477272\n",
      "Iteration 7919, Loss: 0.053989212960004807\n",
      "Iteration 7920, Loss: 0.05417148396372795\n",
      "Iteration 7921, Loss: 0.053989242762327194\n",
      "Iteration 7922, Loss: 0.05417175590991974\n",
      "Iteration 7923, Loss: 0.053988974541425705\n",
      "Iteration 7924, Loss: 0.05417187511920929\n",
      "Iteration 7925, Loss: 0.05398892983794212\n",
      "Iteration 7926, Loss: 0.054171882569789886\n",
      "Iteration 7927, Loss: 0.05398892983794212\n",
      "Iteration 7928, Loss: 0.05417187139391899\n",
      "Iteration 7929, Loss: 0.05398888885974884\n",
      "Iteration 7930, Loss: 0.054171763360500336\n",
      "Iteration 7931, Loss: 0.05398901551961899\n",
      "Iteration 7932, Loss: 0.05417167395353317\n",
      "Iteration 7933, Loss: 0.053989242762327194\n",
      "Iteration 7934, Loss: 0.05417148396372795\n",
      "Iteration 7935, Loss: 0.053989242762327194\n",
      "Iteration 7936, Loss: 0.05417148396372795\n",
      "Iteration 7937, Loss: 0.05398940294981003\n",
      "Iteration 7938, Loss: 0.054171524941921234\n",
      "Iteration 7939, Loss: 0.05398928374052048\n",
      "Iteration 7940, Loss: 0.05417152866721153\n",
      "Iteration 7941, Loss: 0.053989164531230927\n",
      "Iteration 7942, Loss: 0.0541718453168869\n",
      "Iteration 7943, Loss: 0.05398888885974884\n",
      "Iteration 7944, Loss: 0.05417203903198242\n",
      "Iteration 7945, Loss: 0.05398868769407272\n",
      "Iteration 7946, Loss: 0.05417200177907944\n",
      "Iteration 7947, Loss: 0.0539887361228466\n",
      "Iteration 7948, Loss: 0.05417194962501526\n",
      "Iteration 7949, Loss: 0.05398892983794212\n",
      "Iteration 7950, Loss: 0.05417167395353317\n",
      "Iteration 7951, Loss: 0.05398924648761749\n",
      "Iteration 7952, Loss: 0.05417143553495407\n",
      "Iteration 7953, Loss: 0.053989630192518234\n",
      "Iteration 7954, Loss: 0.05417116731405258\n",
      "Iteration 7955, Loss: 0.0539897084236145\n",
      "Iteration 7956, Loss: 0.05417127534747124\n",
      "Iteration 7957, Loss: 0.05398958921432495\n",
      "Iteration 7958, Loss: 0.05417144298553467\n",
      "Iteration 7959, Loss: 0.053989361971616745\n",
      "Iteration 7960, Loss: 0.05417152866721153\n",
      "Iteration 7961, Loss: 0.053989049047231674\n",
      "Iteration 7962, Loss: 0.054171912372112274\n",
      "Iteration 7963, Loss: 0.05398895964026451\n",
      "Iteration 7964, Loss: 0.05417199432849884\n",
      "Iteration 7965, Loss: 0.053988777101039886\n",
      "Iteration 7966, Loss: 0.05417200177907944\n",
      "Iteration 7967, Loss: 0.053988657891750336\n",
      "Iteration 7968, Loss: 0.054171960800886154\n",
      "Iteration 7969, Loss: 0.053988926112651825\n",
      "Iteration 7970, Loss: 0.05417187139391899\n",
      "Iteration 7971, Loss: 0.053989093750715256\n",
      "Iteration 7972, Loss: 0.05417156219482422\n",
      "Iteration 7973, Loss: 0.053989242762327194\n",
      "Iteration 7974, Loss: 0.05417143926024437\n",
      "Iteration 7975, Loss: 0.05398944020271301\n",
      "Iteration 7976, Loss: 0.054171256721019745\n",
      "Iteration 7977, Loss: 0.05398955196142197\n",
      "Iteration 7978, Loss: 0.05417129397392273\n",
      "Iteration 7979, Loss: 0.05398940294981003\n",
      "Iteration 7980, Loss: 0.05417155474424362\n",
      "Iteration 7981, Loss: 0.05398928374052048\n",
      "Iteration 7982, Loss: 0.054171718657016754\n",
      "Iteration 7983, Loss: 0.05398900434374809\n",
      "Iteration 7984, Loss: 0.05417180061340332\n",
      "Iteration 7985, Loss: 0.05398896336555481\n",
      "Iteration 7986, Loss: 0.05417183041572571\n",
      "Iteration 7987, Loss: 0.05398912355303764\n",
      "Iteration 7988, Loss: 0.05417163670063019\n",
      "Iteration 7989, Loss: 0.05398913472890854\n",
      "Iteration 7990, Loss: 0.05417148396372795\n",
      "Iteration 7991, Loss: 0.053989287465810776\n",
      "Iteration 7992, Loss: 0.05417144298553467\n",
      "Iteration 7993, Loss: 0.05398932844400406\n",
      "Iteration 7994, Loss: 0.054171524941921234\n",
      "Iteration 7995, Loss: 0.05398928374052048\n",
      "Iteration 7996, Loss: 0.05417153239250183\n",
      "Iteration 7997, Loss: 0.05398909002542496\n",
      "Iteration 7998, Loss: 0.05417172238230705\n",
      "Iteration 7999, Loss: 0.05398903787136078\n",
      "Iteration 8000, Loss: 0.05417194962501526\n",
      "Iteration 8001, Loss: 0.05398896336555481\n",
      "Iteration 8002, Loss: 0.05417191982269287\n",
      "Iteration 8003, Loss: 0.05398888513445854\n",
      "Iteration 8004, Loss: 0.054171957075595856\n",
      "Iteration 8005, Loss: 0.053988851606845856\n",
      "Iteration 8006, Loss: 0.05417187511920929\n",
      "Iteration 8007, Loss: 0.05398892983794212\n",
      "Iteration 8008, Loss: 0.05417183041572571\n",
      "Iteration 8009, Loss: 0.05398912355303764\n",
      "Iteration 8010, Loss: 0.05417155846953392\n",
      "Iteration 8011, Loss: 0.05398932844400406\n",
      "Iteration 8012, Loss: 0.05417140573263168\n",
      "Iteration 8013, Loss: 0.053989481180906296\n",
      "Iteration 8014, Loss: 0.05417129397392273\n",
      "Iteration 8015, Loss: 0.0539894700050354\n",
      "Iteration 8016, Loss: 0.05417148396372795\n",
      "Iteration 8017, Loss: 0.053989242762327194\n",
      "Iteration 8018, Loss: 0.05417168140411377\n",
      "Iteration 8019, Loss: 0.053988974541425705\n",
      "Iteration 8020, Loss: 0.0541718415915966\n",
      "Iteration 8021, Loss: 0.05398888885974884\n",
      "Iteration 8022, Loss: 0.05417191982269287\n",
      "Iteration 8023, Loss: 0.05398896336555481\n",
      "Iteration 8024, Loss: 0.05417191982269287\n",
      "Iteration 8025, Loss: 0.053988851606845856\n",
      "Iteration 8026, Loss: 0.05417187511920929\n",
      "Iteration 8027, Loss: 0.05398896336555481\n",
      "Iteration 8028, Loss: 0.05417172238230705\n",
      "Iteration 8029, Loss: 0.05398909002542496\n",
      "Iteration 8030, Loss: 0.05417163670063019\n",
      "Iteration 8031, Loss: 0.053989242762327194\n",
      "Iteration 8032, Loss: 0.05417148023843765\n",
      "Iteration 8033, Loss: 0.05398933216929436\n",
      "Iteration 8034, Loss: 0.05417143553495407\n",
      "Iteration 8035, Loss: 0.05398933216929436\n",
      "Iteration 8036, Loss: 0.05417133495211601\n",
      "Iteration 8037, Loss: 0.05398928374052048\n",
      "Iteration 8038, Loss: 0.05417163670063019\n",
      "Iteration 8039, Loss: 0.05398912727832794\n",
      "Iteration 8040, Loss: 0.05417172238230705\n",
      "Iteration 8041, Loss: 0.05398900434374809\n",
      "Iteration 8042, Loss: 0.0541718415915966\n",
      "Iteration 8043, Loss: 0.05398895591497421\n",
      "Iteration 8044, Loss: 0.0541718415915966\n",
      "Iteration 8045, Loss: 0.05398907884955406\n",
      "Iteration 8046, Loss: 0.054171960800886154\n",
      "Iteration 8047, Loss: 0.05398896336555481\n",
      "Iteration 8048, Loss: 0.054171957075595856\n",
      "Iteration 8049, Loss: 0.05398881062865257\n",
      "Iteration 8050, Loss: 0.054171960800886154\n",
      "Iteration 8051, Loss: 0.053988806903362274\n",
      "Iteration 8052, Loss: 0.054171960800886154\n",
      "Iteration 8053, Loss: 0.05398884415626526\n",
      "Iteration 8054, Loss: 0.0541718415915966\n",
      "Iteration 8055, Loss: 0.053989045321941376\n",
      "Iteration 8056, Loss: 0.05417163297533989\n",
      "Iteration 8057, Loss: 0.053989168256521225\n",
      "Iteration 8058, Loss: 0.0541713647544384\n",
      "Iteration 8059, Loss: 0.05398936569690704\n",
      "Iteration 8060, Loss: 0.05417121574282646\n",
      "Iteration 8061, Loss: 0.05398944020271301\n",
      "Iteration 8062, Loss: 0.05417132377624512\n",
      "Iteration 8063, Loss: 0.05398951470851898\n",
      "Iteration 8064, Loss: 0.05417129024863243\n",
      "Iteration 8065, Loss: 0.05398935824632645\n",
      "Iteration 8066, Loss: 0.05417155846953392\n",
      "Iteration 8067, Loss: 0.05398927628993988\n",
      "Iteration 8068, Loss: 0.05417172238230705\n",
      "Iteration 8069, Loss: 0.053989164531230927\n",
      "Iteration 8070, Loss: 0.05417183041572571\n",
      "Iteration 8071, Loss: 0.053988926112651825\n",
      "Iteration 8072, Loss: 0.054171837866306305\n",
      "Iteration 8073, Loss: 0.05398896336555481\n",
      "Iteration 8074, Loss: 0.054171644151210785\n",
      "Iteration 8075, Loss: 0.05398927628993988\n",
      "Iteration 8076, Loss: 0.05417148396372795\n",
      "Iteration 8077, Loss: 0.05398940294981003\n",
      "Iteration 8078, Loss: 0.0541713610291481\n",
      "Iteration 8079, Loss: 0.053989481180906296\n",
      "Iteration 8080, Loss: 0.05417124554514885\n",
      "Iteration 8081, Loss: 0.05398952215909958\n",
      "Iteration 8082, Loss: 0.05417124554514885\n",
      "Iteration 8083, Loss: 0.053989481180906296\n",
      "Iteration 8084, Loss: 0.05417124554514885\n",
      "Iteration 8085, Loss: 0.05398940294981003\n",
      "Iteration 8086, Loss: 0.05417148396372795\n",
      "Iteration 8087, Loss: 0.053989242762327194\n",
      "Iteration 8088, Loss: 0.05417175218462944\n",
      "Iteration 8089, Loss: 0.05398912355303764\n",
      "Iteration 8090, Loss: 0.05417194962501526\n",
      "Iteration 8091, Loss: 0.05398896336555481\n",
      "Iteration 8092, Loss: 0.05417191609740257\n",
      "Iteration 8093, Loss: 0.05398896336555481\n",
      "Iteration 8094, Loss: 0.0541718415915966\n",
      "Iteration 8095, Loss: 0.05398893356323242\n",
      "Iteration 8096, Loss: 0.054171644151210785\n",
      "Iteration 8097, Loss: 0.053989093750715256\n",
      "Iteration 8098, Loss: 0.05417156219482422\n",
      "Iteration 8099, Loss: 0.05398913472890854\n",
      "Iteration 8100, Loss: 0.05417148396372795\n",
      "Iteration 8101, Loss: 0.05398935079574585\n",
      "Iteration 8102, Loss: 0.054171450436115265\n",
      "Iteration 8103, Loss: 0.05398927256464958\n",
      "Iteration 8104, Loss: 0.054171569645404816\n",
      "Iteration 8105, Loss: 0.05398901551961899\n",
      "Iteration 8106, Loss: 0.0541716031730175\n",
      "Iteration 8107, Loss: 0.053989093750715256\n",
      "Iteration 8108, Loss: 0.05417141318321228\n",
      "Iteration 8109, Loss: 0.05398925393819809\n",
      "Iteration 8110, Loss: 0.05417124927043915\n",
      "Iteration 8111, Loss: 0.05398937314748764\n",
      "Iteration 8112, Loss: 0.05417128652334213\n",
      "Iteration 8113, Loss: 0.05398944020271301\n",
      "Iteration 8114, Loss: 0.05417132377624512\n",
      "Iteration 8115, Loss: 0.053989291191101074\n",
      "Iteration 8116, Loss: 0.05417148396372795\n",
      "Iteration 8117, Loss: 0.05398928374052048\n",
      "Iteration 8118, Loss: 0.054171644151210785\n",
      "Iteration 8119, Loss: 0.05398908257484436\n",
      "Iteration 8120, Loss: 0.05417183041572571\n",
      "Iteration 8121, Loss: 0.05398889631032944\n",
      "Iteration 8122, Loss: 0.05417191982269287\n",
      "Iteration 8123, Loss: 0.0539887361228466\n",
      "Iteration 8124, Loss: 0.054171960800886154\n",
      "Iteration 8125, Loss: 0.05398881435394287\n",
      "Iteration 8126, Loss: 0.054171763360500336\n",
      "Iteration 8127, Loss: 0.05398901551961899\n",
      "Iteration 8128, Loss: 0.05417156219482422\n",
      "Iteration 8129, Loss: 0.053989242762327194\n",
      "Iteration 8130, Loss: 0.05417140573263168\n",
      "Iteration 8131, Loss: 0.053989481180906296\n",
      "Iteration 8132, Loss: 0.05417124181985855\n",
      "Iteration 8133, Loss: 0.0539897084236145\n",
      "Iteration 8134, Loss: 0.05417109280824661\n",
      "Iteration 8135, Loss: 0.053989481180906296\n",
      "Iteration 8136, Loss: 0.05417122691869736\n",
      "Iteration 8137, Loss: 0.05398932844400406\n",
      "Iteration 8138, Loss: 0.05417152866721153\n",
      "Iteration 8139, Loss: 0.05398901551961899\n",
      "Iteration 8140, Loss: 0.05417180061340332\n",
      "Iteration 8141, Loss: 0.05398888885974884\n",
      "Iteration 8142, Loss: 0.05417203530669212\n",
      "Iteration 8143, Loss: 0.05398888513445854\n",
      "Iteration 8144, Loss: 0.05417191982269287\n",
      "Iteration 8145, Loss: 0.05398889631032944\n",
      "Iteration 8146, Loss: 0.054171763360500336\n",
      "Iteration 8147, Loss: 0.053988978266716\n",
      "Iteration 8148, Loss: 0.05417168140411377\n",
      "Iteration 8149, Loss: 0.053989168256521225\n",
      "Iteration 8150, Loss: 0.05417155846953392\n",
      "Iteration 8151, Loss: 0.05398925393819809\n",
      "Iteration 8152, Loss: 0.054171256721019745\n",
      "Iteration 8153, Loss: 0.053989361971616745\n",
      "Iteration 8154, Loss: 0.054171375930309296\n",
      "Iteration 8155, Loss: 0.05398928374052048\n",
      "Iteration 8156, Loss: 0.054171569645404816\n",
      "Iteration 8157, Loss: 0.05398905277252197\n",
      "Iteration 8158, Loss: 0.05417168140411377\n",
      "Iteration 8159, Loss: 0.05398892983794212\n",
      "Iteration 8160, Loss: 0.054171882569789886\n",
      "Iteration 8161, Loss: 0.053988855332136154\n",
      "Iteration 8162, Loss: 0.054171837866306305\n",
      "Iteration 8163, Loss: 0.053988855332136154\n",
      "Iteration 8164, Loss: 0.054171644151210785\n",
      "Iteration 8165, Loss: 0.05398913472890854\n",
      "Iteration 8166, Loss: 0.0541715994477272\n",
      "Iteration 8167, Loss: 0.053989291191101074\n",
      "Iteration 8168, Loss: 0.05417144298553467\n",
      "Iteration 8169, Loss: 0.053989287465810776\n",
      "Iteration 8170, Loss: 0.05417133495211601\n",
      "Iteration 8171, Loss: 0.05398928374052048\n",
      "Iteration 8172, Loss: 0.05417148768901825\n",
      "Iteration 8173, Loss: 0.053989242762327194\n",
      "Iteration 8174, Loss: 0.05417148768901825\n",
      "Iteration 8175, Loss: 0.05398920178413391\n",
      "Iteration 8176, Loss: 0.05417156219482422\n",
      "Iteration 8177, Loss: 0.05398920178413391\n",
      "Iteration 8178, Loss: 0.054171644151210785\n",
      "Iteration 8179, Loss: 0.053989164531230927\n",
      "Iteration 8180, Loss: 0.05417156219482422\n",
      "Iteration 8181, Loss: 0.053989093750715256\n",
      "Iteration 8182, Loss: 0.054171375930309296\n",
      "Iteration 8183, Loss: 0.053989291191101074\n",
      "Iteration 8184, Loss: 0.05417141318321228\n",
      "Iteration 8185, Loss: 0.053989361971616745\n",
      "Iteration 8186, Loss: 0.05417148768901825\n",
      "Iteration 8187, Loss: 0.05398912727832794\n",
      "Iteration 8188, Loss: 0.05417175218462944\n",
      "Iteration 8189, Loss: 0.053989049047231674\n",
      "Iteration 8190, Loss: 0.054171882569789886\n",
      "Iteration 8191, Loss: 0.05398888885974884\n",
      "Iteration 8192, Loss: 0.05417197197675705\n",
      "Iteration 8193, Loss: 0.05398857593536377\n",
      "Iteration 8194, Loss: 0.054171960800886154\n",
      "Iteration 8195, Loss: 0.053988657891750336\n",
      "Iteration 8196, Loss: 0.054171957075595856\n",
      "Iteration 8197, Loss: 0.053988855332136154\n",
      "Iteration 8198, Loss: 0.054171718657016754\n",
      "Iteration 8199, Loss: 0.05398928374052048\n",
      "Iteration 8200, Loss: 0.054171450436115265\n",
      "Iteration 8201, Loss: 0.05398932844400406\n",
      "Iteration 8202, Loss: 0.05417140573263168\n",
      "Iteration 8203, Loss: 0.05398932099342346\n",
      "Iteration 8204, Loss: 0.05417148396372795\n",
      "Iteration 8205, Loss: 0.05398928374052048\n",
      "Iteration 8206, Loss: 0.054171569645404816\n",
      "Iteration 8207, Loss: 0.053989093750715256\n",
      "Iteration 8208, Loss: 0.05417164787650108\n",
      "Iteration 8209, Loss: 0.05398900434374809\n",
      "Iteration 8210, Loss: 0.054171767085790634\n",
      "Iteration 8211, Loss: 0.05398892983794212\n",
      "Iteration 8212, Loss: 0.05417172238230705\n",
      "Iteration 8213, Loss: 0.05398893356323242\n",
      "Iteration 8214, Loss: 0.054171644151210785\n",
      "Iteration 8215, Loss: 0.05398909002542496\n",
      "Iteration 8216, Loss: 0.05417141318321228\n",
      "Iteration 8217, Loss: 0.053989291191101074\n",
      "Iteration 8218, Loss: 0.054171331226825714\n",
      "Iteration 8219, Loss: 0.053989216685295105\n",
      "Iteration 8220, Loss: 0.05417129397392273\n",
      "Iteration 8221, Loss: 0.05398933216929436\n",
      "Iteration 8222, Loss: 0.05417141318321228\n",
      "Iteration 8223, Loss: 0.05398920923471451\n",
      "Iteration 8224, Loss: 0.054171644151210785\n",
      "Iteration 8225, Loss: 0.05398909002542496\n",
      "Iteration 8226, Loss: 0.05417180061340332\n",
      "Iteration 8227, Loss: 0.05398881435394287\n",
      "Iteration 8228, Loss: 0.05417191982269287\n",
      "Iteration 8229, Loss: 0.0539887361228466\n",
      "Iteration 8230, Loss: 0.05417191982269287\n",
      "Iteration 8231, Loss: 0.053988855332136154\n",
      "Iteration 8232, Loss: 0.05417172238230705\n",
      "Iteration 8233, Loss: 0.05398901551961899\n",
      "Iteration 8234, Loss: 0.05417148396372795\n",
      "Iteration 8235, Loss: 0.053989168256521225\n",
      "Iteration 8236, Loss: 0.0541713647544384\n",
      "Iteration 8237, Loss: 0.053989410400390625\n",
      "Iteration 8238, Loss: 0.05417105555534363\n",
      "Iteration 8239, Loss: 0.05398952215909958\n",
      "Iteration 8240, Loss: 0.054171107709407806\n",
      "Iteration 8241, Loss: 0.05398940294981003\n",
      "Iteration 8242, Loss: 0.054171256721019745\n",
      "Iteration 8243, Loss: 0.05398924648761749\n",
      "Iteration 8244, Loss: 0.054171424359083176\n",
      "Iteration 8245, Loss: 0.05398909002542496\n",
      "Iteration 8246, Loss: 0.05417173355817795\n",
      "Iteration 8247, Loss: 0.053988777101039886\n",
      "Iteration 8248, Loss: 0.05417191982269287\n",
      "Iteration 8249, Loss: 0.05398881435394287\n",
      "Iteration 8250, Loss: 0.0541718415915966\n",
      "Iteration 8251, Loss: 0.053988780826330185\n",
      "Iteration 8252, Loss: 0.054171763360500336\n",
      "Iteration 8253, Loss: 0.05398908257484436\n",
      "Iteration 8254, Loss: 0.05417145416140556\n",
      "Iteration 8255, Loss: 0.05398924648761749\n",
      "Iteration 8256, Loss: 0.05417129397392273\n",
      "Iteration 8257, Loss: 0.05398936569690704\n",
      "Iteration 8258, Loss: 0.05417124927043915\n",
      "Iteration 8259, Loss: 0.05398933216929436\n",
      "Iteration 8260, Loss: 0.05417122691869736\n",
      "Iteration 8261, Loss: 0.053989361971616745\n",
      "Iteration 8262, Loss: 0.05417126417160034\n",
      "Iteration 8263, Loss: 0.05398913472890854\n",
      "Iteration 8264, Loss: 0.054171495139598846\n",
      "Iteration 8265, Loss: 0.053989093750715256\n",
      "Iteration 8266, Loss: 0.0541716143488884\n",
      "Iteration 8267, Loss: 0.05398892983794212\n",
      "Iteration 8268, Loss: 0.05417173355817795\n",
      "Iteration 8269, Loss: 0.053988926112651825\n",
      "Iteration 8270, Loss: 0.05417172238230705\n",
      "Iteration 8271, Loss: 0.05398893356323242\n",
      "Iteration 8272, Loss: 0.054171573370695114\n",
      "Iteration 8273, Loss: 0.05398908257484436\n",
      "Iteration 8274, Loss: 0.054171450436115265\n",
      "Iteration 8275, Loss: 0.053989287465810776\n",
      "Iteration 8276, Loss: 0.0541713684797287\n",
      "Iteration 8277, Loss: 0.05398925393819809\n",
      "Iteration 8278, Loss: 0.054171375930309296\n",
      "Iteration 8279, Loss: 0.05398917198181152\n",
      "Iteration 8280, Loss: 0.054171379655599594\n",
      "Iteration 8281, Loss: 0.05398909002542496\n",
      "Iteration 8282, Loss: 0.054171450436115265\n",
      "Iteration 8283, Loss: 0.05398913472890854\n",
      "Iteration 8284, Loss: 0.054171450436115265\n",
      "Iteration 8285, Loss: 0.053989093750715256\n",
      "Iteration 8286, Loss: 0.05417144298553467\n",
      "Iteration 8287, Loss: 0.05398920178413391\n",
      "Iteration 8288, Loss: 0.05417152866721153\n",
      "Iteration 8289, Loss: 0.05398912355303764\n",
      "Iteration 8290, Loss: 0.05417152866721153\n",
      "Iteration 8291, Loss: 0.053989239037036896\n",
      "Iteration 8292, Loss: 0.054171495139598846\n",
      "Iteration 8293, Loss: 0.05398919805884361\n",
      "Iteration 8294, Loss: 0.054171495139598846\n",
      "Iteration 8295, Loss: 0.053989164531230927\n",
      "Iteration 8296, Loss: 0.054171573370695114\n",
      "Iteration 8297, Loss: 0.053989045321941376\n",
      "Iteration 8298, Loss: 0.05417165160179138\n",
      "Iteration 8299, Loss: 0.05398889631032944\n",
      "Iteration 8300, Loss: 0.0541716143488884\n",
      "Iteration 8301, Loss: 0.053988900035619736\n",
      "Iteration 8302, Loss: 0.0541716143488884\n",
      "Iteration 8303, Loss: 0.053988978266716\n",
      "Iteration 8304, Loss: 0.05417156219482422\n",
      "Iteration 8305, Loss: 0.05398912355303764\n",
      "Iteration 8306, Loss: 0.05417141318321228\n",
      "Iteration 8307, Loss: 0.05398905277252197\n",
      "Iteration 8308, Loss: 0.05417141318321228\n",
      "Iteration 8309, Loss: 0.05398924648761749\n",
      "Iteration 8310, Loss: 0.05417133867740631\n",
      "Iteration 8311, Loss: 0.05398928374052048\n",
      "Iteration 8312, Loss: 0.054171375930309296\n",
      "Iteration 8313, Loss: 0.05398920178413391\n",
      "Iteration 8314, Loss: 0.05417152866721153\n",
      "Iteration 8315, Loss: 0.05398912727832794\n",
      "Iteration 8316, Loss: 0.0541716068983078\n",
      "Iteration 8317, Loss: 0.05398908257484436\n",
      "Iteration 8318, Loss: 0.054171573370695114\n",
      "Iteration 8319, Loss: 0.05398900806903839\n",
      "Iteration 8320, Loss: 0.054171573370695114\n",
      "Iteration 8321, Loss: 0.05398900806903839\n",
      "Iteration 8322, Loss: 0.0541716143488884\n",
      "Iteration 8323, Loss: 0.05398912355303764\n",
      "Iteration 8324, Loss: 0.0541716143488884\n",
      "Iteration 8325, Loss: 0.05398909002542496\n",
      "Iteration 8326, Loss: 0.054171573370695114\n",
      "Iteration 8327, Loss: 0.05398909002542496\n",
      "Iteration 8328, Loss: 0.054171573370695114\n",
      "Iteration 8329, Loss: 0.05398900806903839\n",
      "Iteration 8330, Loss: 0.0541716143488884\n",
      "Iteration 8331, Loss: 0.05398900806903839\n",
      "Iteration 8332, Loss: 0.05417165160179138\n",
      "Iteration 8333, Loss: 0.05398908257484436\n",
      "Iteration 8334, Loss: 0.054171882569789886\n",
      "Iteration 8335, Loss: 0.0539887361228466\n",
      "Iteration 8336, Loss: 0.054171882569789886\n",
      "Iteration 8337, Loss: 0.05398870259523392\n",
      "Iteration 8338, Loss: 0.054171763360500336\n",
      "Iteration 8339, Loss: 0.05398889631032944\n",
      "Iteration 8340, Loss: 0.0541716031730175\n",
      "Iteration 8341, Loss: 0.05398913472890854\n",
      "Iteration 8342, Loss: 0.05417133495211601\n",
      "Iteration 8343, Loss: 0.05398932099342346\n",
      "Iteration 8344, Loss: 0.05417117476463318\n",
      "Iteration 8345, Loss: 0.05398925766348839\n",
      "Iteration 8346, Loss: 0.05417122691869736\n",
      "Iteration 8347, Loss: 0.053989361971616745\n",
      "Iteration 8348, Loss: 0.05417122691869736\n",
      "Iteration 8349, Loss: 0.05398917198181152\n",
      "Iteration 8350, Loss: 0.05417133495211601\n",
      "Iteration 8351, Loss: 0.05398913472890854\n",
      "Iteration 8352, Loss: 0.054171644151210785\n",
      "Iteration 8353, Loss: 0.053988970816135406\n",
      "Iteration 8354, Loss: 0.05417173355817795\n",
      "Iteration 8355, Loss: 0.05398881435394287\n",
      "Iteration 8356, Loss: 0.05417177081108093\n",
      "Iteration 8357, Loss: 0.05398882180452347\n",
      "Iteration 8358, Loss: 0.054171882569789886\n",
      "Iteration 8359, Loss: 0.053988855332136154\n",
      "Iteration 8360, Loss: 0.054171811789274216\n",
      "Iteration 8361, Loss: 0.05398881435394287\n",
      "Iteration 8362, Loss: 0.054171811789274216\n",
      "Iteration 8363, Loss: 0.053988780826330185\n",
      "Iteration 8364, Loss: 0.054171886295080185\n",
      "Iteration 8365, Loss: 0.05398881435394287\n",
      "Iteration 8366, Loss: 0.05417177081108093\n",
      "Iteration 8367, Loss: 0.05398881435394287\n",
      "Iteration 8368, Loss: 0.05417173355817795\n",
      "Iteration 8369, Loss: 0.05398882180452347\n",
      "Iteration 8370, Loss: 0.054171763360500336\n",
      "Iteration 8371, Loss: 0.05398901551961899\n",
      "Iteration 8372, Loss: 0.054171524941921234\n",
      "Iteration 8373, Loss: 0.05398913472890854\n",
      "Iteration 8374, Loss: 0.05417133495211601\n",
      "Iteration 8375, Loss: 0.05398937314748764\n",
      "Iteration 8376, Loss: 0.05417129397392273\n",
      "Iteration 8377, Loss: 0.053989212960004807\n",
      "Iteration 8378, Loss: 0.05417152866721153\n",
      "Iteration 8379, Loss: 0.053989093750715256\n",
      "Iteration 8380, Loss: 0.05417164787650108\n",
      "Iteration 8381, Loss: 0.053989045321941376\n",
      "Iteration 8382, Loss: 0.0541716143488884\n",
      "Iteration 8383, Loss: 0.053988900035619736\n",
      "Iteration 8384, Loss: 0.05417153984308243\n",
      "Iteration 8385, Loss: 0.053988978266716\n",
      "Iteration 8386, Loss: 0.05417145788669586\n",
      "Iteration 8387, Loss: 0.053988978266716\n",
      "Iteration 8388, Loss: 0.0541716031730175\n",
      "Iteration 8389, Loss: 0.053989093750715256\n",
      "Iteration 8390, Loss: 0.05417148396372795\n",
      "Iteration 8391, Loss: 0.053989216685295105\n",
      "Iteration 8392, Loss: 0.05417121574282646\n",
      "Iteration 8393, Loss: 0.053989142179489136\n",
      "Iteration 8394, Loss: 0.054171256721019745\n",
      "Iteration 8395, Loss: 0.05398933216929436\n",
      "Iteration 8396, Loss: 0.054171331226825714\n",
      "Iteration 8397, Loss: 0.053989291191101074\n",
      "Iteration 8398, Loss: 0.054171331226825714\n",
      "Iteration 8399, Loss: 0.05398933216929436\n",
      "Iteration 8400, Loss: 0.05417133495211601\n",
      "Iteration 8401, Loss: 0.05398933216929436\n",
      "Iteration 8402, Loss: 0.05417129397392273\n",
      "Iteration 8403, Loss: 0.053989242762327194\n",
      "Iteration 8404, Loss: 0.05417133867740631\n",
      "Iteration 8405, Loss: 0.05398912727832794\n",
      "Iteration 8406, Loss: 0.05417148768901825\n",
      "Iteration 8407, Loss: 0.053989093750715256\n",
      "Iteration 8408, Loss: 0.05417148768901825\n",
      "Iteration 8409, Loss: 0.053989093750715256\n",
      "Iteration 8410, Loss: 0.054171450436115265\n",
      "Iteration 8411, Loss: 0.053989022970199585\n",
      "Iteration 8412, Loss: 0.05417144298553467\n",
      "Iteration 8413, Loss: 0.053989212960004807\n",
      "Iteration 8414, Loss: 0.054171256721019745\n",
      "Iteration 8415, Loss: 0.05398925393819809\n",
      "Iteration 8416, Loss: 0.05417133495211601\n",
      "Iteration 8417, Loss: 0.05398925766348839\n",
      "Iteration 8418, Loss: 0.05417129397392273\n",
      "Iteration 8419, Loss: 0.05398925393819809\n",
      "Iteration 8420, Loss: 0.05417133495211601\n",
      "Iteration 8421, Loss: 0.053989168256521225\n",
      "Iteration 8422, Loss: 0.054171495139598846\n",
      "Iteration 8423, Loss: 0.05398905277252197\n",
      "Iteration 8424, Loss: 0.05417172238230705\n",
      "Iteration 8425, Loss: 0.05398889631032944\n",
      "Iteration 8426, Loss: 0.054171692579984665\n",
      "Iteration 8427, Loss: 0.053988825529813766\n",
      "Iteration 8428, Loss: 0.054171644151210785\n",
      "Iteration 8429, Loss: 0.053989093750715256\n",
      "Iteration 8430, Loss: 0.05417141318321228\n",
      "Iteration 8431, Loss: 0.05398925393819809\n",
      "Iteration 8432, Loss: 0.054171256721019745\n",
      "Iteration 8433, Loss: 0.053989361971616745\n",
      "Iteration 8434, Loss: 0.05417117476463318\n",
      "Iteration 8435, Loss: 0.05398937314748764\n",
      "Iteration 8436, Loss: 0.05417121574282646\n",
      "Iteration 8437, Loss: 0.053989291191101074\n",
      "Iteration 8438, Loss: 0.05417133495211601\n",
      "Iteration 8439, Loss: 0.05398976430296898\n",
      "Iteration 8440, Loss: 0.054171573370695114\n",
      "Iteration 8441, Loss: 0.05398945137858391\n",
      "Iteration 8442, Loss: 0.054172247648239136\n",
      "Iteration 8443, Loss: 0.05398913845419884\n",
      "Iteration 8444, Loss: 0.05417243763804436\n",
      "Iteration 8445, Loss: 0.05398913472890854\n",
      "Iteration 8446, Loss: 0.054172366857528687\n",
      "Iteration 8447, Loss: 0.05398917198181152\n",
      "Iteration 8448, Loss: 0.05417228490114212\n",
      "Iteration 8449, Loss: 0.053989291191101074\n",
      "Iteration 8450, Loss: 0.05417204648256302\n",
      "Iteration 8451, Loss: 0.05398949235677719\n",
      "Iteration 8452, Loss: 0.054171960800886154\n",
      "Iteration 8453, Loss: 0.05398968979716301\n",
      "Iteration 8454, Loss: 0.054171644151210785\n",
      "Iteration 8455, Loss: 0.05398992821574211\n",
      "Iteration 8456, Loss: 0.05417153239250183\n",
      "Iteration 8457, Loss: 0.05398992821574211\n",
      "Iteration 8458, Loss: 0.05417148768901825\n",
      "Iteration 8459, Loss: 0.05398988723754883\n",
      "Iteration 8460, Loss: 0.05417148768901825\n",
      "Iteration 8461, Loss: 0.05398992821574211\n",
      "Iteration 8462, Loss: 0.054171573370695114\n",
      "Iteration 8463, Loss: 0.05398992821574211\n",
      "Iteration 8464, Loss: 0.054171495139598846\n",
      "Iteration 8465, Loss: 0.05398980900645256\n",
      "Iteration 8466, Loss: 0.054171495139598846\n",
      "Iteration 8467, Loss: 0.0539899617433548\n",
      "Iteration 8468, Loss: 0.05417145416140556\n",
      "Iteration 8469, Loss: 0.05398999899625778\n",
      "Iteration 8470, Loss: 0.05417145416140556\n",
      "Iteration 8471, Loss: 0.05398992821574211\n",
      "Iteration 8472, Loss: 0.054171573370695114\n",
      "Iteration 8473, Loss: 0.05398987978696823\n",
      "Iteration 8474, Loss: 0.0541718415915966\n",
      "Iteration 8475, Loss: 0.053989678621292114\n",
      "Iteration 8476, Loss: 0.05417200177907944\n",
      "Iteration 8477, Loss: 0.05398952588438988\n",
      "Iteration 8478, Loss: 0.054172080010175705\n",
      "Iteration 8479, Loss: 0.05398949235677719\n",
      "Iteration 8480, Loss: 0.054171960800886154\n",
      "Iteration 8481, Loss: 0.05398957058787346\n",
      "Iteration 8482, Loss: 0.05417175590991974\n",
      "Iteration 8483, Loss: 0.05398973822593689\n",
      "Iteration 8484, Loss: 0.054171375930309296\n",
      "Iteration 8485, Loss: 0.0539901927113533\n",
      "Iteration 8486, Loss: 0.054171256721019745\n",
      "Iteration 8487, Loss: 0.05399015545845032\n",
      "Iteration 8488, Loss: 0.05417133867740631\n",
      "Iteration 8489, Loss: 0.05398999899625778\n",
      "Iteration 8490, Loss: 0.05417164787650108\n",
      "Iteration 8491, Loss: 0.05398987978696823\n",
      "Iteration 8492, Loss: 0.05417173355817795\n",
      "Iteration 8493, Loss: 0.05398964509367943\n",
      "Iteration 8494, Loss: 0.05417191982269287\n",
      "Iteration 8495, Loss: 0.05398945510387421\n",
      "Iteration 8496, Loss: 0.05417177081108093\n",
      "Iteration 8497, Loss: 0.05398964881896973\n",
      "Iteration 8498, Loss: 0.05417172610759735\n",
      "Iteration 8499, Loss: 0.05398973077535629\n",
      "Iteration 8500, Loss: 0.054171573370695114\n",
      "Iteration 8501, Loss: 0.05398988723754883\n",
      "Iteration 8502, Loss: 0.05417153239250183\n",
      "Iteration 8503, Loss: 0.0539899580180645\n",
      "Iteration 8504, Loss: 0.054171692579984665\n",
      "Iteration 8505, Loss: 0.05398968979716301\n",
      "Iteration 8506, Loss: 0.054171960800886154\n",
      "Iteration 8507, Loss: 0.053989529609680176\n",
      "Iteration 8508, Loss: 0.054172083735466\n",
      "Iteration 8509, Loss: 0.05398940667510033\n",
      "Iteration 8510, Loss: 0.0541720911860466\n",
      "Iteration 8511, Loss: 0.05398937314748764\n",
      "Iteration 8512, Loss: 0.05417203903198242\n",
      "Iteration 8513, Loss: 0.053989410400390625\n",
      "Iteration 8514, Loss: 0.05417180806398392\n",
      "Iteration 8515, Loss: 0.05398973077535629\n",
      "Iteration 8516, Loss: 0.054171573370695114\n",
      "Iteration 8517, Loss: 0.05398988351225853\n",
      "Iteration 8518, Loss: 0.054171375930309296\n",
      "Iteration 8519, Loss: 0.05399003624916077\n",
      "Iteration 8520, Loss: 0.05417141318321228\n",
      "Iteration 8521, Loss: 0.05399004742503166\n",
      "Iteration 8522, Loss: 0.05417152866721153\n",
      "Iteration 8523, Loss: 0.0539899617433548\n",
      "Iteration 8524, Loss: 0.054171543568372726\n",
      "Iteration 8525, Loss: 0.05398964881896973\n",
      "Iteration 8526, Loss: 0.054171886295080185\n",
      "Iteration 8527, Loss: 0.05398957058787346\n",
      "Iteration 8528, Loss: 0.054172083735466\n",
      "Iteration 8529, Loss: 0.05398925766348839\n",
      "Iteration 8530, Loss: 0.05417224392294884\n",
      "Iteration 8531, Loss: 0.053989291191101074\n",
      "Iteration 8532, Loss: 0.05417216941714287\n",
      "Iteration 8533, Loss: 0.053989287465810776\n",
      "Iteration 8534, Loss: 0.05417215824127197\n",
      "Iteration 8535, Loss: 0.053989484906196594\n",
      "Iteration 8536, Loss: 0.05417191982269287\n",
      "Iteration 8537, Loss: 0.05398961156606674\n",
      "Iteration 8538, Loss: 0.054171763360500336\n",
      "Iteration 8539, Loss: 0.05398980900645256\n",
      "Iteration 8540, Loss: 0.05417153239250183\n",
      "Iteration 8541, Loss: 0.0539899580180645\n",
      "Iteration 8542, Loss: 0.054171573370695114\n",
      "Iteration 8543, Loss: 0.05398988723754883\n",
      "Iteration 8544, Loss: 0.05417138338088989\n",
      "Iteration 8545, Loss: 0.0539899580180645\n",
      "Iteration 8546, Loss: 0.05417165160179138\n",
      "Iteration 8547, Loss: 0.05398983880877495\n",
      "Iteration 8548, Loss: 0.05417177081108093\n",
      "Iteration 8549, Loss: 0.05398961901664734\n",
      "Iteration 8550, Loss: 0.05417166277766228\n",
      "Iteration 8551, Loss: 0.05398965999484062\n",
      "Iteration 8552, Loss: 0.05417177826166153\n",
      "Iteration 8553, Loss: 0.05398964509367943\n",
      "Iteration 8554, Loss: 0.054171811789274216\n",
      "Iteration 8555, Loss: 0.05398968979716301\n",
      "Iteration 8556, Loss: 0.054171882569789886\n",
      "Iteration 8557, Loss: 0.05398968979716301\n",
      "Iteration 8558, Loss: 0.05417191982269287\n",
      "Iteration 8559, Loss: 0.05398964881896973\n",
      "Iteration 8560, Loss: 0.054171811789274216\n",
      "Iteration 8561, Loss: 0.05398957058787346\n",
      "Iteration 8562, Loss: 0.0541718453168869\n",
      "Iteration 8563, Loss: 0.05398961156606674\n",
      "Iteration 8564, Loss: 0.054171882569789886\n",
      "Iteration 8565, Loss: 0.05398961156606674\n",
      "Iteration 8566, Loss: 0.05417180061340332\n",
      "Iteration 8567, Loss: 0.05398968979716301\n",
      "Iteration 8568, Loss: 0.054171692579984665\n",
      "Iteration 8569, Loss: 0.05398988351225853\n",
      "Iteration 8570, Loss: 0.054171573370695114\n",
      "Iteration 8571, Loss: 0.05398988723754883\n",
      "Iteration 8572, Loss: 0.05417173355817795\n",
      "Iteration 8573, Loss: 0.0539897195994854\n",
      "Iteration 8574, Loss: 0.0541718527674675\n",
      "Iteration 8575, Loss: 0.053989604115486145\n",
      "Iteration 8576, Loss: 0.054172009229660034\n",
      "Iteration 8577, Loss: 0.05398940667510033\n",
      "Iteration 8578, Loss: 0.054172247648239136\n",
      "Iteration 8579, Loss: 0.053989291191101074\n",
      "Iteration 8580, Loss: 0.054172322154045105\n",
      "Iteration 8581, Loss: 0.05398917198181152\n",
      "Iteration 8582, Loss: 0.05417228490114212\n",
      "Iteration 8583, Loss: 0.0539892241358757\n",
      "Iteration 8584, Loss: 0.054172083735466\n",
      "Iteration 8585, Loss: 0.05398941785097122\n",
      "Iteration 8586, Loss: 0.0541718527674675\n",
      "Iteration 8587, Loss: 0.05398965999484062\n",
      "Iteration 8588, Loss: 0.05417172610759735\n",
      "Iteration 8589, Loss: 0.05398987978696823\n",
      "Iteration 8590, Loss: 0.05417168140411377\n",
      "Iteration 8591, Loss: 0.05398988723754883\n",
      "Iteration 8592, Loss: 0.05417172238230705\n",
      "Iteration 8593, Loss: 0.05398988351225853\n",
      "Iteration 8594, Loss: 0.0541718527674675\n",
      "Iteration 8595, Loss: 0.05398957058787346\n",
      "Iteration 8596, Loss: 0.05417205020785332\n",
      "Iteration 8597, Loss: 0.053989361971616745\n",
      "Iteration 8598, Loss: 0.054172366857528687\n",
      "Iteration 8599, Loss: 0.05398912727832794\n",
      "Iteration 8600, Loss: 0.05417248606681824\n",
      "Iteration 8601, Loss: 0.053988978266716\n",
      "Iteration 8602, Loss: 0.05417252331972122\n",
      "Iteration 8603, Loss: 0.05398906022310257\n",
      "Iteration 8604, Loss: 0.05417224019765854\n",
      "Iteration 8605, Loss: 0.05398930236697197\n",
      "Iteration 8606, Loss: 0.05417191982269287\n",
      "Iteration 8607, Loss: 0.05398965999484062\n",
      "Iteration 8608, Loss: 0.0541716143488884\n",
      "Iteration 8609, Loss: 0.05398987978696823\n",
      "Iteration 8610, Loss: 0.054171573370695114\n",
      "Iteration 8611, Loss: 0.05398988723754883\n",
      "Iteration 8612, Loss: 0.054171767085790634\n",
      "Iteration 8613, Loss: 0.05398973077535629\n",
      "Iteration 8614, Loss: 0.054171886295080185\n",
      "Iteration 8615, Loss: 0.053989529609680176\n",
      "Iteration 8616, Loss: 0.05417201668024063\n",
      "Iteration 8617, Loss: 0.05398925393819809\n",
      "Iteration 8618, Loss: 0.054172441363334656\n",
      "Iteration 8619, Loss: 0.053989022970199585\n",
      "Iteration 8620, Loss: 0.05417255684733391\n",
      "Iteration 8621, Loss: 0.053988974541425705\n",
      "Iteration 8622, Loss: 0.05417247861623764\n",
      "Iteration 8623, Loss: 0.05398910492658615\n",
      "Iteration 8624, Loss: 0.05417221039533615\n",
      "Iteration 8625, Loss: 0.05398929864168167\n",
      "Iteration 8626, Loss: 0.054172005504369736\n",
      "Iteration 8627, Loss: 0.0539894625544548\n",
      "Iteration 8628, Loss: 0.054171811789274216\n",
      "Iteration 8629, Loss: 0.05398980528116226\n",
      "Iteration 8630, Loss: 0.054171692579984665\n",
      "Iteration 8631, Loss: 0.05398968979716301\n",
      "Iteration 8632, Loss: 0.05417189002037048\n",
      "Iteration 8633, Loss: 0.05398945510387421\n",
      "Iteration 8634, Loss: 0.0541720911860466\n",
      "Iteration 8635, Loss: 0.053989291191101074\n",
      "Iteration 8636, Loss: 0.05417224392294884\n",
      "Iteration 8637, Loss: 0.053989216685295105\n",
      "Iteration 8638, Loss: 0.05417235940694809\n",
      "Iteration 8639, Loss: 0.053989216685295105\n",
      "Iteration 8640, Loss: 0.05417221039533615\n",
      "Iteration 8641, Loss: 0.053989142179489136\n",
      "Iteration 8642, Loss: 0.05417224019765854\n",
      "Iteration 8643, Loss: 0.05398929864168167\n",
      "Iteration 8644, Loss: 0.05417205020785332\n",
      "Iteration 8645, Loss: 0.0539894625544548\n",
      "Iteration 8646, Loss: 0.05417192727327347\n",
      "Iteration 8647, Loss: 0.05398964881896973\n",
      "Iteration 8648, Loss: 0.05417189002037048\n",
      "Iteration 8649, Loss: 0.053989604115486145\n",
      "Iteration 8650, Loss: 0.05417189002037048\n",
      "Iteration 8651, Loss: 0.05398953706026077\n",
      "Iteration 8652, Loss: 0.05417189002037048\n",
      "Iteration 8653, Loss: 0.05398942157626152\n",
      "Iteration 8654, Loss: 0.05417200177907944\n",
      "Iteration 8655, Loss: 0.053989604115486145\n",
      "Iteration 8656, Loss: 0.054171811789274216\n",
      "Iteration 8657, Loss: 0.05398964881896973\n",
      "Iteration 8658, Loss: 0.05417173355817795\n",
      "Iteration 8659, Loss: 0.05398965999484062\n",
      "Iteration 8660, Loss: 0.05417166277766228\n",
      "Iteration 8661, Loss: 0.053989700973033905\n",
      "Iteration 8662, Loss: 0.054171741008758545\n",
      "Iteration 8663, Loss: 0.053989700973033905\n",
      "Iteration 8664, Loss: 0.0541718527674675\n",
      "Iteration 8665, Loss: 0.05398954078555107\n",
      "Iteration 8666, Loss: 0.05417189002037048\n",
      "Iteration 8667, Loss: 0.053989529609680176\n",
      "Iteration 8668, Loss: 0.05417189002037048\n",
      "Iteration 8669, Loss: 0.053989529609680176\n",
      "Iteration 8670, Loss: 0.05417197197675705\n",
      "Iteration 8671, Loss: 0.05398949235677719\n",
      "Iteration 8672, Loss: 0.054172005504369736\n",
      "Iteration 8673, Loss: 0.05398949608206749\n",
      "Iteration 8674, Loss: 0.05417189002037048\n",
      "Iteration 8675, Loss: 0.05398957058787346\n",
      "Iteration 8676, Loss: 0.054171882569789886\n",
      "Iteration 8677, Loss: 0.05398968979716301\n",
      "Iteration 8678, Loss: 0.054171811789274216\n",
      "Iteration 8679, Loss: 0.053989529609680176\n",
      "Iteration 8680, Loss: 0.054171811789274216\n",
      "Iteration 8681, Loss: 0.05398953706026077\n",
      "Iteration 8682, Loss: 0.05417190119624138\n",
      "Iteration 8683, Loss: 0.05398949235677719\n",
      "Iteration 8684, Loss: 0.05417205020785332\n",
      "Iteration 8685, Loss: 0.053989410400390625\n",
      "Iteration 8686, Loss: 0.05417224392294884\n",
      "Iteration 8687, Loss: 0.053989142179489136\n",
      "Iteration 8688, Loss: 0.054172318428754807\n",
      "Iteration 8689, Loss: 0.05398906394839287\n",
      "Iteration 8690, Loss: 0.05417228862643242\n",
      "Iteration 8691, Loss: 0.05398918315768242\n",
      "Iteration 8692, Loss: 0.054172083735466\n",
      "Iteration 8693, Loss: 0.05398930236697197\n",
      "Iteration 8694, Loss: 0.05417203903198242\n",
      "Iteration 8695, Loss: 0.053989529609680176\n",
      "Iteration 8696, Loss: 0.05417192727327347\n",
      "Iteration 8697, Loss: 0.05398957058787346\n",
      "Iteration 8698, Loss: 0.05417180061340332\n",
      "Iteration 8699, Loss: 0.053989581763744354\n",
      "Iteration 8700, Loss: 0.05417177081108093\n",
      "Iteration 8701, Loss: 0.05398973450064659\n",
      "Iteration 8702, Loss: 0.054171621799468994\n",
      "Iteration 8703, Loss: 0.053989849984645844\n",
      "Iteration 8704, Loss: 0.05417180806398392\n",
      "Iteration 8705, Loss: 0.05398961156606674\n",
      "Iteration 8706, Loss: 0.054171930998563766\n",
      "Iteration 8707, Loss: 0.05398945137858391\n",
      "Iteration 8708, Loss: 0.05417205020785332\n",
      "Iteration 8709, Loss: 0.05398933216929436\n",
      "Iteration 8710, Loss: 0.054172124713659286\n",
      "Iteration 8711, Loss: 0.05398937314748764\n",
      "Iteration 8712, Loss: 0.05417203903198242\n",
      "Iteration 8713, Loss: 0.05398949235677719\n",
      "Iteration 8714, Loss: 0.054171930998563766\n",
      "Iteration 8715, Loss: 0.05398949608206749\n",
      "Iteration 8716, Loss: 0.05417189002037048\n",
      "Iteration 8717, Loss: 0.05398957058787346\n",
      "Iteration 8718, Loss: 0.05417189002037048\n",
      "Iteration 8719, Loss: 0.05398964881896973\n",
      "Iteration 8720, Loss: 0.05417192727327347\n",
      "Iteration 8721, Loss: 0.05398894101381302\n",
      "Iteration 8722, Loss: 0.0541720911860466\n",
      "Iteration 8723, Loss: 0.053988587111234665\n",
      "Iteration 8724, Loss: 0.05417259782552719\n",
      "Iteration 8725, Loss: 0.05398818850517273\n",
      "Iteration 8726, Loss: 0.054173510521650314\n",
      "Iteration 8727, Loss: 0.05398784205317497\n",
      "Iteration 8728, Loss: 0.05417346954345703\n",
      "Iteration 8729, Loss: 0.053988002240657806\n",
      "Iteration 8730, Loss: 0.05417303368449211\n",
      "Iteration 8731, Loss: 0.0539885088801384\n",
      "Iteration 8732, Loss: 0.05417262762784958\n",
      "Iteration 8733, Loss: 0.05398906022310257\n",
      "Iteration 8734, Loss: 0.054171960800886154\n",
      "Iteration 8735, Loss: 0.05398949608206749\n",
      "Iteration 8736, Loss: 0.05417163670063019\n",
      "Iteration 8737, Loss: 0.053989849984645844\n",
      "Iteration 8738, Loss: 0.05417124927043915\n",
      "Iteration 8739, Loss: 0.053990043699741364\n",
      "Iteration 8740, Loss: 0.0541713684797287\n",
      "Iteration 8741, Loss: 0.05398999899625778\n",
      "Iteration 8742, Loss: 0.05417150259017944\n",
      "Iteration 8743, Loss: 0.05398961156606674\n",
      "Iteration 8744, Loss: 0.05417200177907944\n",
      "Iteration 8745, Loss: 0.053989291191101074\n",
      "Iteration 8746, Loss: 0.05417228862643242\n",
      "Iteration 8747, Loss: 0.053988903760910034\n",
      "Iteration 8748, Loss: 0.05417252704501152\n",
      "Iteration 8749, Loss: 0.05398886650800705\n",
      "Iteration 8750, Loss: 0.05417256057262421\n",
      "Iteration 8751, Loss: 0.053988710045814514\n",
      "Iteration 8752, Loss: 0.054172515869140625\n",
      "Iteration 8753, Loss: 0.053989019244909286\n",
      "Iteration 8754, Loss: 0.054172318428754807\n",
      "Iteration 8755, Loss: 0.05398913472890854\n",
      "Iteration 8756, Loss: 0.05417215824127197\n",
      "Iteration 8757, Loss: 0.053989142179489136\n",
      "Iteration 8758, Loss: 0.05417212098836899\n",
      "Iteration 8759, Loss: 0.053989291191101074\n",
      "Iteration 8760, Loss: 0.05417215824127197\n",
      "Iteration 8761, Loss: 0.0539892241358757\n",
      "Iteration 8762, Loss: 0.054172080010175705\n",
      "Iteration 8763, Loss: 0.053989261388778687\n",
      "Iteration 8764, Loss: 0.054171930998563766\n",
      "Iteration 8765, Loss: 0.053989410400390625\n",
      "Iteration 8766, Loss: 0.0541718527674675\n",
      "Iteration 8767, Loss: 0.05398957058787346\n",
      "Iteration 8768, Loss: 0.05417165160179138\n",
      "Iteration 8769, Loss: 0.05398968979716301\n",
      "Iteration 8770, Loss: 0.0541718527674675\n",
      "Iteration 8771, Loss: 0.053989529609680176\n",
      "Iteration 8772, Loss: 0.05417189002037048\n",
      "Iteration 8773, Loss: 0.05398937314748764\n",
      "Iteration 8774, Loss: 0.05417216941714287\n",
      "Iteration 8775, Loss: 0.05398913472890854\n",
      "Iteration 8776, Loss: 0.054172173142433167\n",
      "Iteration 8777, Loss: 0.053989022970199585\n",
      "Iteration 8778, Loss: 0.05417231470346451\n",
      "Iteration 8779, Loss: 0.05398910492658615\n",
      "Iteration 8780, Loss: 0.05417215824127197\n",
      "Iteration 8781, Loss: 0.053989212960004807\n",
      "Iteration 8782, Loss: 0.054171960800886154\n",
      "Iteration 8783, Loss: 0.05398945137858391\n",
      "Iteration 8784, Loss: 0.05417180061340332\n",
      "Iteration 8785, Loss: 0.05398968979716301\n",
      "Iteration 8786, Loss: 0.05417164787650108\n",
      "Iteration 8787, Loss: 0.05398968979716301\n",
      "Iteration 8788, Loss: 0.05417164787650108\n",
      "Iteration 8789, Loss: 0.05398973077535629\n",
      "Iteration 8790, Loss: 0.05417177081108093\n",
      "Iteration 8791, Loss: 0.053989529609680176\n",
      "Iteration 8792, Loss: 0.054171960800886154\n",
      "Iteration 8793, Loss: 0.05398952215909958\n",
      "Iteration 8794, Loss: 0.054172124713659286\n",
      "Iteration 8795, Loss: 0.05398924648761749\n",
      "Iteration 8796, Loss: 0.054172247648239136\n",
      "Iteration 8797, Loss: 0.05398905277252197\n",
      "Iteration 8798, Loss: 0.05417228490114212\n",
      "Iteration 8799, Loss: 0.05398894473910332\n",
      "Iteration 8800, Loss: 0.0541720911860466\n",
      "Iteration 8801, Loss: 0.053989261388778687\n",
      "Iteration 8802, Loss: 0.054171767085790634\n",
      "Iteration 8803, Loss: 0.05398949608206749\n",
      "Iteration 8804, Loss: 0.05417168140411377\n",
      "Iteration 8805, Loss: 0.05398976802825928\n",
      "Iteration 8806, Loss: 0.054171524941921234\n",
      "Iteration 8807, Loss: 0.05398984253406525\n",
      "Iteration 8808, Loss: 0.05417141318321228\n",
      "Iteration 8809, Loss: 0.053989775478839874\n",
      "Iteration 8810, Loss: 0.05417153239250183\n",
      "Iteration 8811, Loss: 0.05398965999484062\n",
      "Iteration 8812, Loss: 0.05417180806398392\n",
      "Iteration 8813, Loss: 0.05398956686258316\n",
      "Iteration 8814, Loss: 0.05417203903198242\n",
      "Iteration 8815, Loss: 0.05398937687277794\n",
      "Iteration 8816, Loss: 0.054172124713659286\n",
      "Iteration 8817, Loss: 0.05398917943239212\n",
      "Iteration 8818, Loss: 0.054172322154045105\n",
      "Iteration 8819, Loss: 0.05398906022310257\n",
      "Iteration 8820, Loss: 0.05417225882411003\n",
      "Iteration 8821, Loss: 0.05398901551961899\n",
      "Iteration 8822, Loss: 0.05417228490114212\n",
      "Iteration 8823, Loss: 0.05398910492658615\n",
      "Iteration 8824, Loss: 0.05417203903198242\n",
      "Iteration 8825, Loss: 0.053989410400390625\n",
      "Iteration 8826, Loss: 0.05417180806398392\n",
      "Iteration 8827, Loss: 0.05398954078555107\n",
      "Iteration 8828, Loss: 0.054171692579984665\n",
      "Iteration 8829, Loss: 0.05398949980735779\n",
      "Iteration 8830, Loss: 0.05417173355817795\n",
      "Iteration 8831, Loss: 0.053989507257938385\n",
      "Iteration 8832, Loss: 0.05417180061340332\n",
      "Iteration 8833, Loss: 0.05398961156606674\n",
      "Iteration 8834, Loss: 0.05417191982269287\n",
      "Iteration 8835, Loss: 0.05398945137858391\n",
      "Iteration 8836, Loss: 0.05417196452617645\n",
      "Iteration 8837, Loss: 0.05398933216929436\n",
      "Iteration 8838, Loss: 0.05417204648256302\n",
      "Iteration 8839, Loss: 0.05398925766348839\n",
      "Iteration 8840, Loss: 0.05417203903198242\n",
      "Iteration 8841, Loss: 0.053989410400390625\n",
      "Iteration 8842, Loss: 0.05417197197675705\n",
      "Iteration 8843, Loss: 0.05398956686258316\n",
      "Iteration 8844, Loss: 0.05417200177907944\n",
      "Iteration 8845, Loss: 0.05398934334516525\n",
      "Iteration 8846, Loss: 0.054172031581401825\n",
      "Iteration 8847, Loss: 0.05398941785097122\n",
      "Iteration 8848, Loss: 0.05417191982269287\n",
      "Iteration 8849, Loss: 0.05398949235677719\n",
      "Iteration 8850, Loss: 0.054171882569789886\n",
      "Iteration 8851, Loss: 0.053989529609680176\n",
      "Iteration 8852, Loss: 0.05417191982269287\n",
      "Iteration 8853, Loss: 0.05398953706026077\n",
      "Iteration 8854, Loss: 0.054171882569789886\n",
      "Iteration 8855, Loss: 0.05398945510387421\n",
      "Iteration 8856, Loss: 0.0541718453168869\n",
      "Iteration 8857, Loss: 0.0539894625544548\n",
      "Iteration 8858, Loss: 0.054171811789274216\n",
      "Iteration 8859, Loss: 0.05398949235677719\n",
      "Iteration 8860, Loss: 0.054172009229660034\n",
      "Iteration 8861, Loss: 0.053989410400390625\n",
      "Iteration 8862, Loss: 0.054172273725271225\n",
      "Iteration 8863, Loss: 0.053989291191101074\n",
      "Iteration 8864, Loss: 0.05417235940694809\n",
      "Iteration 8865, Loss: 0.05398913472890854\n",
      "Iteration 8866, Loss: 0.05417255312204361\n",
      "Iteration 8867, Loss: 0.053988900035619736\n",
      "Iteration 8868, Loss: 0.054172586649656296\n",
      "Iteration 8869, Loss: 0.053989093750715256\n",
      "Iteration 8870, Loss: 0.054172318428754807\n",
      "Iteration 8871, Loss: 0.053989212960004807\n",
      "Iteration 8872, Loss: 0.054172080010175705\n",
      "Iteration 8873, Loss: 0.05398944020271301\n",
      "Iteration 8874, Loss: 0.05417192727327347\n",
      "Iteration 8875, Loss: 0.05398960039019585\n",
      "Iteration 8876, Loss: 0.0541718453168869\n",
      "Iteration 8877, Loss: 0.05398964509367943\n",
      "Iteration 8878, Loss: 0.054171886295080185\n",
      "Iteration 8879, Loss: 0.05398957058787346\n",
      "Iteration 8880, Loss: 0.05417196452617645\n",
      "Iteration 8881, Loss: 0.05398937314748764\n",
      "Iteration 8882, Loss: 0.054172080010175705\n",
      "Iteration 8883, Loss: 0.053989261388778687\n",
      "Iteration 8884, Loss: 0.054171960800886154\n",
      "Iteration 8885, Loss: 0.05398945137858391\n",
      "Iteration 8886, Loss: 0.05417177826166153\n",
      "Iteration 8887, Loss: 0.05398964509367943\n",
      "Iteration 8888, Loss: 0.05417180061340332\n",
      "Iteration 8889, Loss: 0.05398976430296898\n",
      "Iteration 8890, Loss: 0.05417191609740257\n",
      "Iteration 8891, Loss: 0.053989723324775696\n",
      "Iteration 8892, Loss: 0.054171957075595856\n",
      "Iteration 8893, Loss: 0.05398960039019585\n",
      "Iteration 8894, Loss: 0.05417215824127197\n",
      "Iteration 8895, Loss: 0.053989287465810776\n",
      "Iteration 8896, Loss: 0.05417247861623764\n",
      "Iteration 8897, Loss: 0.053988974541425705\n",
      "Iteration 8898, Loss: 0.05417244881391525\n",
      "Iteration 8899, Loss: 0.053988903760910034\n",
      "Iteration 8900, Loss: 0.054172299802303314\n",
      "Iteration 8901, Loss: 0.05398913472890854\n",
      "Iteration 8902, Loss: 0.05417216941714287\n",
      "Iteration 8903, Loss: 0.05398924648761749\n",
      "Iteration 8904, Loss: 0.054172005504369736\n",
      "Iteration 8905, Loss: 0.05398940294981003\n",
      "Iteration 8906, Loss: 0.0541718527674675\n",
      "Iteration 8907, Loss: 0.05398960039019585\n",
      "Iteration 8908, Loss: 0.05417169630527496\n",
      "Iteration 8909, Loss: 0.053989559412002563\n",
      "Iteration 8910, Loss: 0.054171811789274216\n",
      "Iteration 8911, Loss: 0.05398964881896973\n",
      "Iteration 8912, Loss: 0.05417172610759735\n",
      "Iteration 8913, Loss: 0.05398961156606674\n",
      "Iteration 8914, Loss: 0.05417189002037048\n",
      "Iteration 8915, Loss: 0.05398960039019585\n",
      "Iteration 8916, Loss: 0.05417205020785332\n",
      "Iteration 8917, Loss: 0.05398917198181152\n",
      "Iteration 8918, Loss: 0.054172396659851074\n",
      "Iteration 8919, Loss: 0.05398893356323242\n",
      "Iteration 8920, Loss: 0.0541725680232048\n",
      "Iteration 8921, Loss: 0.05398894101381302\n",
      "Iteration 8922, Loss: 0.05417259782552719\n",
      "Iteration 8923, Loss: 0.053988974541425705\n",
      "Iteration 8924, Loss: 0.05417243763804436\n",
      "Iteration 8925, Loss: 0.05398905277252197\n",
      "Iteration 8926, Loss: 0.054172318428754807\n",
      "Iteration 8927, Loss: 0.053989097476005554\n",
      "Iteration 8928, Loss: 0.054172053933143616\n",
      "Iteration 8929, Loss: 0.053989216685295105\n",
      "Iteration 8930, Loss: 0.05417192727327347\n",
      "Iteration 8931, Loss: 0.05398960039019585\n",
      "Iteration 8932, Loss: 0.054171767085790634\n",
      "Iteration 8933, Loss: 0.05398968979716301\n",
      "Iteration 8934, Loss: 0.054171692579984665\n",
      "Iteration 8935, Loss: 0.0539897195994854\n",
      "Iteration 8936, Loss: 0.054171882569789886\n",
      "Iteration 8937, Loss: 0.05398949235677719\n",
      "Iteration 8938, Loss: 0.0541718527674675\n",
      "Iteration 8939, Loss: 0.05398945137858391\n",
      "Iteration 8940, Loss: 0.054171886295080185\n",
      "Iteration 8941, Loss: 0.05398949608206749\n",
      "Iteration 8942, Loss: 0.0541718453168869\n",
      "Iteration 8943, Loss: 0.05398964881896973\n",
      "Iteration 8944, Loss: 0.054171811789274216\n",
      "Iteration 8945, Loss: 0.053989529609680176\n",
      "Iteration 8946, Loss: 0.054172005504369736\n",
      "Iteration 8947, Loss: 0.05398944765329361\n",
      "Iteration 8948, Loss: 0.0541720911860466\n",
      "Iteration 8949, Loss: 0.05398925393819809\n",
      "Iteration 8950, Loss: 0.054172247648239136\n",
      "Iteration 8951, Loss: 0.05398906394839287\n",
      "Iteration 8952, Loss: 0.05417224019765854\n",
      "Iteration 8953, Loss: 0.05398917943239212\n",
      "Iteration 8954, Loss: 0.05417224019765854\n",
      "Iteration 8955, Loss: 0.053989212960004807\n",
      "Iteration 8956, Loss: 0.05417205020785332\n",
      "Iteration 8957, Loss: 0.05398940294981003\n",
      "Iteration 8958, Loss: 0.054172005504369736\n",
      "Iteration 8959, Loss: 0.05398944765329361\n",
      "Iteration 8960, Loss: 0.054171811789274216\n",
      "Iteration 8961, Loss: 0.05398952588438988\n",
      "Iteration 8962, Loss: 0.054171811789274216\n",
      "Iteration 8963, Loss: 0.053989604115486145\n",
      "Iteration 8964, Loss: 0.05417165160179138\n",
      "Iteration 8965, Loss: 0.05398973077535629\n",
      "Iteration 8966, Loss: 0.054171692579984665\n",
      "Iteration 8967, Loss: 0.05398976430296898\n",
      "Iteration 8968, Loss: 0.054171882569789886\n",
      "Iteration 8969, Loss: 0.05398949235677719\n",
      "Iteration 8970, Loss: 0.0541720911860466\n",
      "Iteration 8971, Loss: 0.05398925393819809\n",
      "Iteration 8972, Loss: 0.05417243391275406\n",
      "Iteration 8973, Loss: 0.05398905277252197\n",
      "Iteration 8974, Loss: 0.054172322154045105\n",
      "Iteration 8975, Loss: 0.05398906022310257\n",
      "Iteration 8976, Loss: 0.05417216569185257\n",
      "Iteration 8977, Loss: 0.0539892241358757\n",
      "Iteration 8978, Loss: 0.05417192727327347\n",
      "Iteration 8979, Loss: 0.05398957058787346\n",
      "Iteration 8980, Loss: 0.05417172238230705\n",
      "Iteration 8981, Loss: 0.05398964881896973\n",
      "Iteration 8982, Loss: 0.05417153239250183\n",
      "Iteration 8983, Loss: 0.05398988351225853\n",
      "Iteration 8984, Loss: 0.054171573370695114\n",
      "Iteration 8985, Loss: 0.05398983880877495\n",
      "Iteration 8986, Loss: 0.05417165160179138\n",
      "Iteration 8987, Loss: 0.0539901964366436\n",
      "Iteration 8988, Loss: 0.054171930998563766\n",
      "Iteration 8989, Loss: 0.053989849984645844\n",
      "Iteration 8990, Loss: 0.054172687232494354\n",
      "Iteration 8991, Loss: 0.0539897195994854\n",
      "Iteration 8992, Loss: 0.054172955453395844\n",
      "Iteration 8993, Loss: 0.05398937687277794\n",
      "Iteration 8994, Loss: 0.05417291447520256\n",
      "Iteration 8995, Loss: 0.05398957431316376\n",
      "Iteration 8996, Loss: 0.05417260527610779\n",
      "Iteration 8997, Loss: 0.05398976802825928\n",
      "Iteration 8998, Loss: 0.05417248234152794\n",
      "Iteration 8999, Loss: 0.05399029701948166\n",
      "Iteration 9000, Loss: 0.05417224392294884\n",
      "Iteration 9001, Loss: 0.05399087071418762\n",
      "Iteration 9002, Loss: 0.054171882569789886\n",
      "Iteration 9003, Loss: 0.053991034626960754\n",
      "Iteration 9004, Loss: 0.054171256721019745\n",
      "Iteration 9005, Loss: 0.05399115011096001\n",
      "Iteration 9006, Loss: 0.05417153239250183\n",
      "Iteration 9007, Loss: 0.053990673273801804\n",
      "Iteration 9008, Loss: 0.054172009229660034\n",
      "Iteration 9009, Loss: 0.053990285843610764\n",
      "Iteration 9010, Loss: 0.05417252704501152\n",
      "Iteration 9011, Loss: 0.053989849984645844\n",
      "Iteration 9012, Loss: 0.05417291820049286\n",
      "Iteration 9013, Loss: 0.05398960039019585\n",
      "Iteration 9014, Loss: 0.054172929376363754\n",
      "Iteration 9015, Loss: 0.05398957058787346\n",
      "Iteration 9016, Loss: 0.05417285114526749\n",
      "Iteration 9017, Loss: 0.05398954078555107\n",
      "Iteration 9018, Loss: 0.05417260527610779\n",
      "Iteration 9019, Loss: 0.053989820182323456\n",
      "Iteration 9020, Loss: 0.05417244881391525\n",
      "Iteration 9021, Loss: 0.05399012565612793\n",
      "Iteration 9022, Loss: 0.054172318428754807\n",
      "Iteration 9023, Loss: 0.05399013310670853\n",
      "Iteration 9024, Loss: 0.0541723296046257\n",
      "Iteration 9025, Loss: 0.053990207612514496\n",
      "Iteration 9026, Loss: 0.05417235940694809\n",
      "Iteration 9027, Loss: 0.053990017622709274\n",
      "Iteration 9028, Loss: 0.05417254567146301\n",
      "Iteration 9029, Loss: 0.05399000644683838\n",
      "Iteration 9030, Loss: 0.05417248234152794\n",
      "Iteration 9031, Loss: 0.05399011820554733\n",
      "Iteration 9032, Loss: 0.05417240783572197\n",
      "Iteration 9033, Loss: 0.05399004742503166\n",
      "Iteration 9034, Loss: 0.05417252331972122\n",
      "Iteration 9035, Loss: 0.05398999899625778\n",
      "Iteration 9036, Loss: 0.05417267605662346\n",
      "Iteration 9037, Loss: 0.05398999899625778\n",
      "Iteration 9038, Loss: 0.0541725680232048\n",
      "Iteration 9039, Loss: 0.05399003624916077\n",
      "Iteration 9040, Loss: 0.054172635078430176\n",
      "Iteration 9041, Loss: 0.05398992821574211\n",
      "Iteration 9042, Loss: 0.05417260155081749\n",
      "Iteration 9043, Loss: 0.05398992449045181\n",
      "Iteration 9044, Loss: 0.05417252704501152\n",
      "Iteration 9045, Loss: 0.053989969193935394\n",
      "Iteration 9046, Loss: 0.05417240783572197\n",
      "Iteration 9047, Loss: 0.053989969193935394\n",
      "Iteration 9048, Loss: 0.054172441363334656\n",
      "Iteration 9049, Loss: 0.05399000644683838\n",
      "Iteration 9050, Loss: 0.05417235940694809\n",
      "Iteration 9051, Loss: 0.05399013310670853\n",
      "Iteration 9052, Loss: 0.054172247648239136\n",
      "Iteration 9053, Loss: 0.053990136831998825\n",
      "Iteration 9054, Loss: 0.05417213961482048\n",
      "Iteration 9055, Loss: 0.05399024486541748\n",
      "Iteration 9056, Loss: 0.05417228862643242\n",
      "Iteration 9057, Loss: 0.05399012565612793\n",
      "Iteration 9058, Loss: 0.05417244881391525\n",
      "Iteration 9059, Loss: 0.053989917039871216\n",
      "Iteration 9060, Loss: 0.05417260527610779\n",
      "Iteration 9061, Loss: 0.05398968979716301\n",
      "Iteration 9062, Loss: 0.05417276546359062\n",
      "Iteration 9063, Loss: 0.05398968979716301\n",
      "Iteration 9064, Loss: 0.05417275428771973\n",
      "Iteration 9065, Loss: 0.05398973822593689\n",
      "Iteration 9066, Loss: 0.05417267605662346\n",
      "Iteration 9067, Loss: 0.053989969193935394\n",
      "Iteration 9068, Loss: 0.05417252704501152\n",
      "Iteration 9069, Loss: 0.053989969193935394\n",
      "Iteration 9070, Loss: 0.054172366857528687\n",
      "Iteration 9071, Loss: 0.053990088403224945\n",
      "Iteration 9072, Loss: 0.0541723296046257\n",
      "Iteration 9073, Loss: 0.05399015545845032\n",
      "Iteration 9074, Loss: 0.0541723296046257\n",
      "Iteration 9075, Loss: 0.05399000644683838\n",
      "Iteration 9076, Loss: 0.05417237430810928\n",
      "Iteration 9077, Loss: 0.05399004742503166\n",
      "Iteration 9078, Loss: 0.05417248606681824\n",
      "Iteration 9079, Loss: 0.053989969193935394\n",
      "Iteration 9080, Loss: 0.05417252331972122\n",
      "Iteration 9081, Loss: 0.05398992821574211\n",
      "Iteration 9082, Loss: 0.054172441363334656\n",
      "Iteration 9083, Loss: 0.05398982763290405\n",
      "Iteration 9084, Loss: 0.05417228862643242\n",
      "Iteration 9085, Loss: 0.05399013310670853\n",
      "Iteration 9086, Loss: 0.0541720986366272\n",
      "Iteration 9087, Loss: 0.053990285843610764\n",
      "Iteration 9088, Loss: 0.05417227745056152\n",
      "Iteration 9089, Loss: 0.053990285843610764\n",
      "Iteration 9090, Loss: 0.05417218059301376\n",
      "Iteration 9091, Loss: 0.05399016663432121\n",
      "Iteration 9092, Loss: 0.05417244881391525\n",
      "Iteration 9093, Loss: 0.053989969193935394\n",
      "Iteration 9094, Loss: 0.054172635078430176\n",
      "Iteration 9095, Loss: 0.05398988723754883\n",
      "Iteration 9096, Loss: 0.054172761738300323\n",
      "Iteration 9097, Loss: 0.05398976802825928\n",
      "Iteration 9098, Loss: 0.05417264625430107\n",
      "Iteration 9099, Loss: 0.05398976802825928\n",
      "Iteration 9100, Loss: 0.05417264252901077\n",
      "Iteration 9101, Loss: 0.053989700973033905\n",
      "Iteration 9102, Loss: 0.05417248606681824\n",
      "Iteration 9103, Loss: 0.05398993194103241\n",
      "Iteration 9104, Loss: 0.0541723296046257\n",
      "Iteration 9105, Loss: 0.05398997664451599\n",
      "Iteration 9106, Loss: 0.05417221039533615\n",
      "Iteration 9107, Loss: 0.05399024486541748\n",
      "Iteration 9108, Loss: 0.05417235940694809\n",
      "Iteration 9109, Loss: 0.05399031564593315\n",
      "Iteration 9110, Loss: 0.05417221784591675\n",
      "Iteration 9111, Loss: 0.0539901964366436\n",
      "Iteration 9112, Loss: 0.05417248606681824\n",
      "Iteration 9113, Loss: 0.05399008095264435\n",
      "Iteration 9114, Loss: 0.05417255684733391\n",
      "Iteration 9115, Loss: 0.05399000644683838\n",
      "Iteration 9116, Loss: 0.05417252704501152\n",
      "Iteration 9117, Loss: 0.05398992821574211\n",
      "Iteration 9118, Loss: 0.05417248606681824\n",
      "Iteration 9119, Loss: 0.053989969193935394\n",
      "Iteration 9120, Loss: 0.05417255684733391\n",
      "Iteration 9121, Loss: 0.05399003624916077\n",
      "Iteration 9122, Loss: 0.05417244881391525\n",
      "Iteration 9123, Loss: 0.05399007722735405\n",
      "Iteration 9124, Loss: 0.05417248606681824\n",
      "Iteration 9125, Loss: 0.05398999899625778\n",
      "Iteration 9126, Loss: 0.05417260527610779\n",
      "Iteration 9127, Loss: 0.05398976802825928\n",
      "Iteration 9128, Loss: 0.054172635078430176\n",
      "Iteration 9129, Loss: 0.05398988723754883\n",
      "Iteration 9130, Loss: 0.05417248606681824\n",
      "Iteration 9131, Loss: 0.05398978292942047\n",
      "Iteration 9132, Loss: 0.054172366857528687\n",
      "Iteration 9133, Loss: 0.05399012565612793\n",
      "Iteration 9134, Loss: 0.054172247648239136\n",
      "Iteration 9135, Loss: 0.0539902001619339\n",
      "Iteration 9136, Loss: 0.05417236313223839\n",
      "Iteration 9137, Loss: 0.0539901964366436\n",
      "Iteration 9138, Loss: 0.054172366857528687\n",
      "Iteration 9139, Loss: 0.05399012193083763\n",
      "Iteration 9140, Loss: 0.05417236313223839\n",
      "Iteration 9141, Loss: 0.05398993939161301\n",
      "Iteration 9142, Loss: 0.054172366857528687\n",
      "Iteration 9143, Loss: 0.05399012193083763\n",
      "Iteration 9144, Loss: 0.054172366857528687\n",
      "Iteration 9145, Loss: 0.05399008095264435\n",
      "Iteration 9146, Loss: 0.05417244881391525\n",
      "Iteration 9147, Loss: 0.05399000644683838\n",
      "Iteration 9148, Loss: 0.05417252704501152\n",
      "Iteration 9149, Loss: 0.05398985370993614\n",
      "Iteration 9150, Loss: 0.05417260527610779\n",
      "Iteration 9151, Loss: 0.05398977920413017\n",
      "Iteration 9152, Loss: 0.05417267605662346\n",
      "Iteration 9153, Loss: 0.053989849984645844\n",
      "Iteration 9154, Loss: 0.05417240783572197\n",
      "Iteration 9155, Loss: 0.05398993194103241\n",
      "Iteration 9156, Loss: 0.05417236313223839\n",
      "Iteration 9157, Loss: 0.053990088403224945\n",
      "Iteration 9158, Loss: 0.054172128438949585\n",
      "Iteration 9159, Loss: 0.053990211337804794\n",
      "Iteration 9160, Loss: 0.054172128438949585\n",
      "Iteration 9161, Loss: 0.05399036407470703\n",
      "Iteration 9162, Loss: 0.054172173142433167\n",
      "Iteration 9163, Loss: 0.053990285843610764\n",
      "Iteration 9164, Loss: 0.054172333329916\n",
      "Iteration 9165, Loss: 0.053989969193935394\n",
      "Iteration 9166, Loss: 0.0541725680232048\n",
      "Iteration 9167, Loss: 0.05398976802825928\n",
      "Iteration 9168, Loss: 0.05417260527610779\n",
      "Iteration 9169, Loss: 0.05398961901664734\n",
      "Iteration 9170, Loss: 0.054172635078430176\n",
      "Iteration 9171, Loss: 0.053989704698324203\n",
      "Iteration 9172, Loss: 0.05417240783572197\n",
      "Iteration 9173, Loss: 0.05399005115032196\n",
      "Iteration 9174, Loss: 0.054172247648239136\n",
      "Iteration 9175, Loss: 0.05399016663432121\n",
      "Iteration 9176, Loss: 0.05417221039533615\n",
      "Iteration 9177, Loss: 0.05399031937122345\n",
      "Iteration 9178, Loss: 0.054172128438949585\n",
      "Iteration 9179, Loss: 0.05399031564593315\n",
      "Iteration 9180, Loss: 0.05417221412062645\n",
      "Iteration 9181, Loss: 0.05399012193083763\n",
      "Iteration 9182, Loss: 0.054172299802303314\n",
      "Iteration 9183, Loss: 0.05399012193083763\n",
      "Iteration 9184, Loss: 0.054172441363334656\n",
      "Iteration 9185, Loss: 0.05399004742503166\n",
      "Iteration 9186, Loss: 0.05417259782552719\n",
      "Iteration 9187, Loss: 0.053989164531230927\n",
      "Iteration 9188, Loss: 0.05417267605662346\n",
      "Iteration 9189, Loss: 0.05398915335536003\n",
      "Iteration 9190, Loss: 0.054171912372112274\n",
      "Iteration 9191, Loss: 0.053989045321941376\n",
      "Iteration 9192, Loss: 0.05417190492153168\n",
      "Iteration 9193, Loss: 0.053989239037036896\n",
      "Iteration 9194, Loss: 0.05417182296514511\n",
      "Iteration 9195, Loss: 0.05398939177393913\n",
      "Iteration 9196, Loss: 0.05417182296514511\n",
      "Iteration 9197, Loss: 0.05398942530155182\n",
      "Iteration 9198, Loss: 0.05417175218462944\n",
      "Iteration 9199, Loss: 0.053989313542842865\n",
      "Iteration 9200, Loss: 0.054171860218048096\n",
      "Iteration 9201, Loss: 0.05398927256464958\n",
      "Iteration 9202, Loss: 0.054171860218048096\n",
      "Iteration 9203, Loss: 0.05398935079574585\n",
      "Iteration 9204, Loss: 0.05417170748114586\n",
      "Iteration 9205, Loss: 0.0539894700050354\n",
      "Iteration 9206, Loss: 0.054171666502952576\n",
      "Iteration 9207, Loss: 0.0539894700050354\n",
      "Iteration 9208, Loss: 0.05417158827185631\n",
      "Iteration 9209, Loss: 0.05398961901664734\n",
      "Iteration 9210, Loss: 0.05417158827185631\n",
      "Iteration 9211, Loss: 0.0539894662797451\n",
      "Iteration 9212, Loss: 0.0541716031730175\n",
      "Iteration 9213, Loss: 0.05398939177393913\n",
      "Iteration 9214, Loss: 0.05417175218462944\n",
      "Iteration 9215, Loss: 0.05398935079574585\n",
      "Iteration 9216, Loss: 0.05417182669043541\n",
      "Iteration 9217, Loss: 0.053989313542842865\n",
      "Iteration 9218, Loss: 0.054171718657016754\n",
      "Iteration 9219, Loss: 0.05398927256464958\n",
      "Iteration 9220, Loss: 0.05417190119624138\n",
      "Iteration 9221, Loss: 0.05398938059806824\n",
      "Iteration 9222, Loss: 0.054171860218048096\n",
      "Iteration 9223, Loss: 0.053989313542842865\n",
      "Iteration 9224, Loss: 0.054171741008758545\n",
      "Iteration 9225, Loss: 0.053989432752132416\n",
      "Iteration 9226, Loss: 0.054171666502952576\n",
      "Iteration 9227, Loss: 0.05398954451084137\n",
      "Iteration 9228, Loss: 0.05417166277766228\n",
      "Iteration 9229, Loss: 0.05398955196142197\n",
      "Iteration 9230, Loss: 0.05417166277766228\n",
      "Iteration 9231, Loss: 0.05398967117071152\n",
      "Iteration 9232, Loss: 0.054171621799468994\n",
      "Iteration 9233, Loss: 0.05398954451084137\n",
      "Iteration 9234, Loss: 0.05417182296514511\n",
      "Iteration 9235, Loss: 0.05398927256464958\n",
      "Iteration 9236, Loss: 0.05417191609740257\n",
      "Iteration 9237, Loss: 0.05398903414607048\n",
      "Iteration 9238, Loss: 0.05417221784591675\n",
      "Iteration 9239, Loss: 0.05398891493678093\n",
      "Iteration 9240, Loss: 0.05417218059301376\n",
      "Iteration 9241, Loss: 0.05398907512426376\n",
      "Iteration 9242, Loss: 0.054171979427337646\n",
      "Iteration 9243, Loss: 0.05398908257484436\n",
      "Iteration 9244, Loss: 0.05417178198695183\n",
      "Iteration 9245, Loss: 0.05398940294981003\n",
      "Iteration 9246, Loss: 0.054171621799468994\n",
      "Iteration 9247, Loss: 0.05398955196142197\n",
      "Iteration 9248, Loss: 0.054171543568372726\n",
      "Iteration 9249, Loss: 0.05398965999484062\n",
      "Iteration 9250, Loss: 0.05417162925004959\n",
      "Iteration 9251, Loss: 0.05398955196142197\n",
      "Iteration 9252, Loss: 0.05417178198695183\n",
      "Iteration 9253, Loss: 0.0539892315864563\n",
      "Iteration 9254, Loss: 0.0541720986366272\n",
      "Iteration 9255, Loss: 0.05398891866207123\n",
      "Iteration 9256, Loss: 0.05417225882411003\n",
      "Iteration 9257, Loss: 0.053988873958587646\n",
      "Iteration 9258, Loss: 0.05417218059301376\n",
      "Iteration 9259, Loss: 0.05398895964026451\n",
      "Iteration 9260, Loss: 0.05417194217443466\n",
      "Iteration 9261, Loss: 0.05398927256464958\n",
      "Iteration 9262, Loss: 0.05417151376605034\n",
      "Iteration 9263, Loss: 0.053989626467227936\n",
      "Iteration 9264, Loss: 0.054171353578567505\n",
      "Iteration 9265, Loss: 0.0539897084236145\n",
      "Iteration 9266, Loss: 0.05417119711637497\n",
      "Iteration 9267, Loss: 0.053989898413419724\n",
      "Iteration 9268, Loss: 0.05417127534747124\n",
      "Iteration 9269, Loss: 0.053989749401807785\n",
      "Iteration 9270, Loss: 0.054171543568372726\n",
      "Iteration 9271, Loss: 0.053989507257938385\n",
      "Iteration 9272, Loss: 0.05417182296514511\n",
      "Iteration 9273, Loss: 0.053989164531230927\n",
      "Iteration 9274, Loss: 0.05417194962501526\n",
      "Iteration 9275, Loss: 0.053989000618457794\n",
      "Iteration 9276, Loss: 0.05417199060320854\n",
      "Iteration 9277, Loss: 0.05398896336555481\n",
      "Iteration 9278, Loss: 0.05417190492153168\n",
      "Iteration 9279, Loss: 0.053989045321941376\n",
      "Iteration 9280, Loss: 0.054171741008758545\n",
      "Iteration 9281, Loss: 0.05398924648761749\n",
      "Iteration 9282, Loss: 0.05417155474424362\n",
      "Iteration 9283, Loss: 0.05398940294981003\n",
      "Iteration 9284, Loss: 0.05417155474424362\n",
      "Iteration 9285, Loss: 0.05398951470851898\n",
      "Iteration 9286, Loss: 0.05417162925004959\n",
      "Iteration 9287, Loss: 0.05398955196142197\n",
      "Iteration 9288, Loss: 0.05417140573263168\n",
      "Iteration 9289, Loss: 0.053989510983228683\n",
      "Iteration 9290, Loss: 0.05417163297533989\n",
      "Iteration 9291, Loss: 0.053989432752132416\n",
      "Iteration 9292, Loss: 0.054171718657016754\n",
      "Iteration 9293, Loss: 0.05398934707045555\n",
      "Iteration 9294, Loss: 0.05417171120643616\n",
      "Iteration 9295, Loss: 0.05398928374052048\n",
      "Iteration 9296, Loss: 0.05417182296514511\n",
      "Iteration 9297, Loss: 0.05398920178413391\n",
      "Iteration 9298, Loss: 0.05417183041572571\n",
      "Iteration 9299, Loss: 0.05398919805884361\n",
      "Iteration 9300, Loss: 0.05417187139391899\n",
      "Iteration 9301, Loss: 0.05398912355303764\n",
      "Iteration 9302, Loss: 0.05417187139391899\n",
      "Iteration 9303, Loss: 0.05398920178413391\n",
      "Iteration 9304, Loss: 0.05417183041572571\n",
      "Iteration 9305, Loss: 0.05398928374052048\n",
      "Iteration 9306, Loss: 0.0541715994477272\n",
      "Iteration 9307, Loss: 0.053989432752132416\n",
      "Iteration 9308, Loss: 0.05417170375585556\n",
      "Iteration 9309, Loss: 0.0539894700050354\n",
      "Iteration 9310, Loss: 0.05417166277766228\n",
      "Iteration 9311, Loss: 0.0539894700050354\n",
      "Iteration 9312, Loss: 0.05417158827185631\n",
      "Iteration 9313, Loss: 0.05398944020271301\n",
      "Iteration 9314, Loss: 0.05417162925004959\n",
      "Iteration 9315, Loss: 0.053989510983228683\n",
      "Iteration 9316, Loss: 0.05417151376605034\n",
      "Iteration 9317, Loss: 0.0539894700050354\n",
      "Iteration 9318, Loss: 0.054171524941921234\n",
      "Iteration 9319, Loss: 0.053989510983228683\n",
      "Iteration 9320, Loss: 0.054171524941921234\n",
      "Iteration 9321, Loss: 0.0539894662797451\n",
      "Iteration 9322, Loss: 0.0541716031730175\n",
      "Iteration 9323, Loss: 0.053989242762327194\n",
      "Iteration 9324, Loss: 0.054171763360500336\n",
      "Iteration 9325, Loss: 0.05398908257484436\n",
      "Iteration 9326, Loss: 0.05417202413082123\n",
      "Iteration 9327, Loss: 0.053989000618457794\n",
      "Iteration 9328, Loss: 0.054171957075595856\n",
      "Iteration 9329, Loss: 0.05398892983794212\n",
      "Iteration 9330, Loss: 0.05417179316282272\n",
      "Iteration 9331, Loss: 0.05398912355303764\n",
      "Iteration 9332, Loss: 0.05417151376605034\n",
      "Iteration 9333, Loss: 0.05398952215909958\n",
      "Iteration 9334, Loss: 0.054171279072761536\n",
      "Iteration 9335, Loss: 0.053989559412002563\n",
      "Iteration 9336, Loss: 0.05417127534747124\n",
      "Iteration 9337, Loss: 0.05398990958929062\n",
      "Iteration 9338, Loss: 0.05417128652334213\n",
      "Iteration 9339, Loss: 0.05398973822593689\n",
      "Iteration 9340, Loss: 0.05417148396372795\n",
      "Iteration 9341, Loss: 0.053989313542842865\n",
      "Iteration 9342, Loss: 0.05417187511920929\n",
      "Iteration 9343, Loss: 0.053988926112651825\n",
      "Iteration 9344, Loss: 0.05417210981249809\n",
      "Iteration 9345, Loss: 0.05398888513445854\n",
      "Iteration 9346, Loss: 0.05417218804359436\n",
      "Iteration 9347, Loss: 0.05398876592516899\n",
      "Iteration 9348, Loss: 0.05417206883430481\n",
      "Iteration 9349, Loss: 0.05398888513445854\n",
      "Iteration 9350, Loss: 0.05417199060320854\n",
      "Iteration 9351, Loss: 0.053989045321941376\n",
      "Iteration 9352, Loss: 0.05417171120643616\n",
      "Iteration 9353, Loss: 0.05398935079574585\n",
      "Iteration 9354, Loss: 0.05417155474424362\n",
      "Iteration 9355, Loss: 0.05398958921432495\n",
      "Iteration 9356, Loss: 0.0541713647544384\n",
      "Iteration 9357, Loss: 0.053989484906196594\n",
      "Iteration 9358, Loss: 0.054171353578567505\n",
      "Iteration 9359, Loss: 0.053989630192518234\n",
      "Iteration 9360, Loss: 0.05417148396372795\n",
      "Iteration 9361, Loss: 0.053989510983228683\n",
      "Iteration 9362, Loss: 0.05417167395353317\n",
      "Iteration 9363, Loss: 0.053989239037036896\n",
      "Iteration 9364, Loss: 0.05417194962501526\n",
      "Iteration 9365, Loss: 0.05398915335536003\n",
      "Iteration 9366, Loss: 0.05417172238230705\n",
      "Iteration 9367, Loss: 0.05398912355303764\n",
      "Iteration 9368, Loss: 0.05417179316282272\n",
      "Iteration 9369, Loss: 0.05398927256464958\n",
      "Iteration 9370, Loss: 0.05417182669043541\n",
      "Iteration 9371, Loss: 0.053989313542842865\n",
      "Iteration 9372, Loss: 0.05417179316282272\n",
      "Iteration 9373, Loss: 0.053989239037036896\n",
      "Iteration 9374, Loss: 0.054171763360500336\n",
      "Iteration 9375, Loss: 0.053989194333553314\n",
      "Iteration 9376, Loss: 0.05417180061340332\n",
      "Iteration 9377, Loss: 0.0539892315864563\n",
      "Iteration 9378, Loss: 0.0541718415915966\n",
      "Iteration 9379, Loss: 0.05398919805884361\n",
      "Iteration 9380, Loss: 0.054171837866306305\n",
      "Iteration 9381, Loss: 0.053989194333553314\n",
      "Iteration 9382, Loss: 0.054171912372112274\n",
      "Iteration 9383, Loss: 0.05398907512426376\n",
      "Iteration 9384, Loss: 0.0541718415915966\n",
      "Iteration 9385, Loss: 0.05398908257484436\n",
      "Iteration 9386, Loss: 0.05417179316282272\n",
      "Iteration 9387, Loss: 0.05398900806903839\n",
      "Iteration 9388, Loss: 0.0541715994477272\n",
      "Iteration 9389, Loss: 0.05398932099342346\n",
      "Iteration 9390, Loss: 0.05417155846953392\n",
      "Iteration 9391, Loss: 0.05398940294981003\n",
      "Iteration 9392, Loss: 0.05417155474424362\n",
      "Iteration 9393, Loss: 0.053989510983228683\n",
      "Iteration 9394, Loss: 0.054171591997146606\n",
      "Iteration 9395, Loss: 0.053989432752132416\n",
      "Iteration 9396, Loss: 0.05417179316282272\n",
      "Iteration 9397, Loss: 0.053989313542842865\n",
      "Iteration 9398, Loss: 0.05417183041572571\n",
      "Iteration 9399, Loss: 0.053989194333553314\n",
      "Iteration 9400, Loss: 0.05417179316282272\n",
      "Iteration 9401, Loss: 0.053989239037036896\n",
      "Iteration 9402, Loss: 0.05417163670063019\n",
      "Iteration 9403, Loss: 0.05398939177393913\n",
      "Iteration 9404, Loss: 0.05417163297533989\n",
      "Iteration 9405, Loss: 0.0539894700050354\n",
      "Iteration 9406, Loss: 0.05417151749134064\n",
      "Iteration 9407, Loss: 0.053989477455616\n",
      "Iteration 9408, Loss: 0.054171524941921234\n",
      "Iteration 9409, Loss: 0.05398955196142197\n",
      "Iteration 9410, Loss: 0.054171524941921234\n",
      "Iteration 9411, Loss: 0.05398935079574585\n",
      "Iteration 9412, Loss: 0.05417175218462944\n",
      "Iteration 9413, Loss: 0.0539892315864563\n",
      "Iteration 9414, Loss: 0.05417175218462944\n",
      "Iteration 9415, Loss: 0.053989239037036896\n",
      "Iteration 9416, Loss: 0.05417171120643616\n",
      "Iteration 9417, Loss: 0.05398927628993988\n",
      "Iteration 9418, Loss: 0.054171591997146606\n",
      "Iteration 9419, Loss: 0.05398932844400406\n",
      "Iteration 9420, Loss: 0.05417143926024437\n",
      "Iteration 9421, Loss: 0.05398952215909958\n",
      "Iteration 9422, Loss: 0.05417146906256676\n",
      "Iteration 9423, Loss: 0.05398951470851898\n",
      "Iteration 9424, Loss: 0.05417148023843765\n",
      "Iteration 9425, Loss: 0.05398958921432495\n",
      "Iteration 9426, Loss: 0.054171591997146606\n",
      "Iteration 9427, Loss: 0.05398927256464958\n",
      "Iteration 9428, Loss: 0.05417175590991974\n",
      "Iteration 9429, Loss: 0.05398908257484436\n",
      "Iteration 9430, Loss: 0.05417191982269287\n",
      "Iteration 9431, Loss: 0.053988926112651825\n",
      "Iteration 9432, Loss: 0.054172031581401825\n",
      "Iteration 9433, Loss: 0.05398896336555481\n",
      "Iteration 9434, Loss: 0.05417200177907944\n",
      "Iteration 9435, Loss: 0.05398888885974884\n",
      "Iteration 9436, Loss: 0.05417199060320854\n",
      "Iteration 9437, Loss: 0.05398893356323242\n",
      "Iteration 9438, Loss: 0.054171644151210785\n",
      "Iteration 9439, Loss: 0.053989242762327194\n",
      "Iteration 9440, Loss: 0.05417139455676079\n",
      "Iteration 9441, Loss: 0.05398959666490555\n",
      "Iteration 9442, Loss: 0.054171279072761536\n",
      "Iteration 9443, Loss: 0.053989529609680176\n",
      "Iteration 9444, Loss: 0.05417139083147049\n",
      "Iteration 9445, Loss: 0.053989630192518234\n",
      "Iteration 9446, Loss: 0.054171472787857056\n",
      "Iteration 9447, Loss: 0.05398944765329361\n",
      "Iteration 9448, Loss: 0.05417175218462944\n",
      "Iteration 9449, Loss: 0.05398912355303764\n",
      "Iteration 9450, Loss: 0.05417198687791824\n",
      "Iteration 9451, Loss: 0.05398896336555481\n",
      "Iteration 9452, Loss: 0.054172031581401825\n",
      "Iteration 9453, Loss: 0.05398884415626526\n",
      "Iteration 9454, Loss: 0.05417206883430481\n",
      "Iteration 9455, Loss: 0.053988855332136154\n",
      "Iteration 9456, Loss: 0.05417179688811302\n",
      "Iteration 9457, Loss: 0.053989242762327194\n",
      "Iteration 9458, Loss: 0.05417148396372795\n",
      "Iteration 9459, Loss: 0.05398940294981003\n",
      "Iteration 9460, Loss: 0.05417148023843765\n",
      "Iteration 9461, Loss: 0.05398944020271301\n",
      "Iteration 9462, Loss: 0.05417143926024437\n",
      "Iteration 9463, Loss: 0.05398952215909958\n",
      "Iteration 9464, Loss: 0.054171472787857056\n",
      "Iteration 9465, Loss: 0.053989481180906296\n",
      "Iteration 9466, Loss: 0.05417148023843765\n",
      "Iteration 9467, Loss: 0.05398940294981003\n",
      "Iteration 9468, Loss: 0.05417155846953392\n",
      "Iteration 9469, Loss: 0.05398935824632645\n",
      "Iteration 9470, Loss: 0.054171591997146606\n",
      "Iteration 9471, Loss: 0.05398928374052048\n",
      "Iteration 9472, Loss: 0.05417167395353317\n",
      "Iteration 9473, Loss: 0.05398931726813316\n",
      "Iteration 9474, Loss: 0.054171591997146606\n",
      "Iteration 9475, Loss: 0.053989242762327194\n",
      "Iteration 9476, Loss: 0.05417155846953392\n",
      "Iteration 9477, Loss: 0.05398928374052048\n",
      "Iteration 9478, Loss: 0.05417163670063019\n",
      "Iteration 9479, Loss: 0.05398927256464958\n",
      "Iteration 9480, Loss: 0.054171644151210785\n",
      "Iteration 9481, Loss: 0.053989239037036896\n",
      "Iteration 9482, Loss: 0.05417183041572571\n",
      "Iteration 9483, Loss: 0.0539892315864563\n",
      "Iteration 9484, Loss: 0.054171763360500336\n",
      "Iteration 9485, Loss: 0.05398908257484436\n",
      "Iteration 9486, Loss: 0.05417187139391899\n",
      "Iteration 9487, Loss: 0.05398919805884361\n",
      "Iteration 9488, Loss: 0.05417167395353317\n",
      "Iteration 9489, Loss: 0.05398906022310257\n",
      "Iteration 9490, Loss: 0.054171450436115265\n",
      "Iteration 9491, Loss: 0.05398940667510033\n",
      "Iteration 9492, Loss: 0.05417144298553467\n",
      "Iteration 9493, Loss: 0.05398952215909958\n",
      "Iteration 9494, Loss: 0.05417140573263168\n",
      "Iteration 9495, Loss: 0.05398944020271301\n",
      "Iteration 9496, Loss: 0.05417151749134064\n",
      "Iteration 9497, Loss: 0.05398940294981003\n",
      "Iteration 9498, Loss: 0.05417148396372795\n",
      "Iteration 9499, Loss: 0.05398928374052048\n",
      "Iteration 9500, Loss: 0.05417180061340332\n",
      "Iteration 9501, Loss: 0.05398900434374809\n",
      "Iteration 9502, Loss: 0.054172031581401825\n",
      "Iteration 9503, Loss: 0.053988851606845856\n",
      "Iteration 9504, Loss: 0.054172076284885406\n",
      "Iteration 9505, Loss: 0.053988851606845856\n",
      "Iteration 9506, Loss: 0.05417191609740257\n",
      "Iteration 9507, Loss: 0.05398900806903839\n",
      "Iteration 9508, Loss: 0.05417179316282272\n",
      "Iteration 9509, Loss: 0.05398909002542496\n",
      "Iteration 9510, Loss: 0.054171524941921234\n",
      "Iteration 9511, Loss: 0.05398944020271301\n",
      "Iteration 9512, Loss: 0.05417144298553467\n",
      "Iteration 9513, Loss: 0.053989559412002563\n",
      "Iteration 9514, Loss: 0.054171524941921234\n",
      "Iteration 9515, Loss: 0.05398944020271301\n",
      "Iteration 9516, Loss: 0.05417163670063019\n",
      "Iteration 9517, Loss: 0.05398912355303764\n",
      "Iteration 9518, Loss: 0.054171763360500336\n",
      "Iteration 9519, Loss: 0.05398893356323242\n",
      "Iteration 9520, Loss: 0.05417194962501526\n",
      "Iteration 9521, Loss: 0.05398896336555481\n",
      "Iteration 9522, Loss: 0.05417194962501526\n",
      "Iteration 9523, Loss: 0.05398905277252197\n",
      "Iteration 9524, Loss: 0.05417179316282272\n",
      "Iteration 9525, Loss: 0.05398912727832794\n",
      "Iteration 9526, Loss: 0.05417163297533989\n",
      "Iteration 9527, Loss: 0.05398920178413391\n",
      "Iteration 9528, Loss: 0.05417151749134064\n",
      "Iteration 9529, Loss: 0.053989287465810776\n",
      "Iteration 9530, Loss: 0.05417151376605034\n",
      "Iteration 9531, Loss: 0.053989410400390625\n",
      "Iteration 9532, Loss: 0.05417139455676079\n",
      "Iteration 9533, Loss: 0.053989630192518234\n",
      "Iteration 9534, Loss: 0.054171472787857056\n",
      "Iteration 9535, Loss: 0.05398967117071152\n",
      "Iteration 9536, Loss: 0.05417140573263168\n",
      "Iteration 9537, Loss: 0.05398928374052048\n",
      "Iteration 9538, Loss: 0.054171524941921234\n",
      "Iteration 9539, Loss: 0.053989164531230927\n",
      "Iteration 9540, Loss: 0.05417179316282272\n",
      "Iteration 9541, Loss: 0.05398911237716675\n",
      "Iteration 9542, Loss: 0.054171763360500336\n",
      "Iteration 9543, Loss: 0.05398830771446228\n",
      "Iteration 9544, Loss: 0.05417163670063019\n",
      "Iteration 9545, Loss: 0.05398857593536377\n",
      "Iteration 9546, Loss: 0.05417144298553467\n",
      "Iteration 9547, Loss: 0.053988706320524216\n",
      "Iteration 9548, Loss: 0.05417066067457199\n",
      "Iteration 9549, Loss: 0.05398878455162048\n",
      "Iteration 9550, Loss: 0.054170623421669006\n",
      "Iteration 9551, Loss: 0.05398882180452347\n",
      "Iteration 9552, Loss: 0.05417077988386154\n",
      "Iteration 9553, Loss: 0.053988706320524216\n",
      "Iteration 9554, Loss: 0.05417077988386154\n",
      "Iteration 9555, Loss: 0.053988657891750336\n",
      "Iteration 9556, Loss: 0.05417077988386154\n",
      "Iteration 9557, Loss: 0.0539887361228466\n",
      "Iteration 9558, Loss: 0.05417073890566826\n",
      "Iteration 9559, Loss: 0.053988710045814514\n",
      "Iteration 9560, Loss: 0.054170623421669006\n",
      "Iteration 9561, Loss: 0.05398867279291153\n",
      "Iteration 9562, Loss: 0.05417066067457199\n",
      "Iteration 9563, Loss: 0.05398878455162048\n",
      "Iteration 9564, Loss: 0.05417069047689438\n",
      "Iteration 9565, Loss: 0.0539887472987175\n",
      "Iteration 9566, Loss: 0.05417054519057274\n",
      "Iteration 9567, Loss: 0.05398878455162048\n",
      "Iteration 9568, Loss: 0.05417061969637871\n",
      "Iteration 9569, Loss: 0.05398878455162048\n",
      "Iteration 9570, Loss: 0.05417058616876602\n",
      "Iteration 9571, Loss: 0.05398878455162048\n",
      "Iteration 9572, Loss: 0.05417058616876602\n",
      "Iteration 9573, Loss: 0.053988706320524216\n",
      "Iteration 9574, Loss: 0.05417061969637871\n",
      "Iteration 9575, Loss: 0.05398881435394287\n",
      "Iteration 9576, Loss: 0.05417054146528244\n",
      "Iteration 9577, Loss: 0.05398894101381302\n",
      "Iteration 9578, Loss: 0.05417050048708916\n",
      "Iteration 9579, Loss: 0.05398905277252197\n",
      "Iteration 9580, Loss: 0.054170653223991394\n",
      "Iteration 9581, Loss: 0.053988855332136154\n",
      "Iteration 9582, Loss: 0.05417077988386154\n",
      "Iteration 9583, Loss: 0.053988661617040634\n",
      "Iteration 9584, Loss: 0.054170817136764526\n",
      "Iteration 9585, Loss: 0.05398857593536377\n",
      "Iteration 9586, Loss: 0.05417089909315109\n",
      "Iteration 9587, Loss: 0.053988587111234665\n",
      "Iteration 9588, Loss: 0.05417082458734512\n",
      "Iteration 9589, Loss: 0.053988587111234665\n",
      "Iteration 9590, Loss: 0.05417078360915184\n",
      "Iteration 9591, Loss: 0.05398862808942795\n",
      "Iteration 9592, Loss: 0.05417077988386154\n",
      "Iteration 9593, Loss: 0.05398862808942795\n",
      "Iteration 9594, Loss: 0.05417066439986229\n",
      "Iteration 9595, Loss: 0.053988777101039886\n",
      "Iteration 9596, Loss: 0.054170578718185425\n",
      "Iteration 9597, Loss: 0.053988855332136154\n",
      "Iteration 9598, Loss: 0.05417054146528244\n",
      "Iteration 9599, Loss: 0.05398905277252197\n",
      "Iteration 9600, Loss: 0.054170381277799606\n",
      "Iteration 9601, Loss: 0.053989164531230927\n",
      "Iteration 9602, Loss: 0.05417042225599289\n",
      "Iteration 9603, Loss: 0.05398912355303764\n",
      "Iteration 9604, Loss: 0.05417061969637871\n",
      "Iteration 9605, Loss: 0.0539887361228466\n",
      "Iteration 9606, Loss: 0.05417093262076378\n",
      "Iteration 9607, Loss: 0.05398845672607422\n",
      "Iteration 9608, Loss: 0.05417101830244064\n",
      "Iteration 9609, Loss: 0.05398834869265556\n",
      "Iteration 9610, Loss: 0.05417109280824661\n",
      "Iteration 9611, Loss: 0.05398842319846153\n",
      "Iteration 9612, Loss: 0.054171010851860046\n",
      "Iteration 9613, Loss: 0.05398854240775108\n",
      "Iteration 9614, Loss: 0.05417070537805557\n",
      "Iteration 9615, Loss: 0.0539887361228466\n",
      "Iteration 9616, Loss: 0.05417054146528244\n",
      "Iteration 9617, Loss: 0.053988855332136154\n",
      "Iteration 9618, Loss: 0.05417050048708916\n",
      "Iteration 9619, Loss: 0.05398905277252197\n",
      "Iteration 9620, Loss: 0.054170459508895874\n",
      "Iteration 9621, Loss: 0.05398901551961899\n",
      "Iteration 9622, Loss: 0.05417050048708916\n",
      "Iteration 9623, Loss: 0.053989045321941376\n",
      "Iteration 9624, Loss: 0.0541706308722496\n",
      "Iteration 9625, Loss: 0.053988777101039886\n",
      "Iteration 9626, Loss: 0.05417089909315109\n",
      "Iteration 9627, Loss: 0.053988538682460785\n",
      "Iteration 9628, Loss: 0.05417105555534363\n",
      "Iteration 9629, Loss: 0.05398838222026825\n",
      "Iteration 9630, Loss: 0.05417085811495781\n",
      "Iteration 9631, Loss: 0.05398843437433243\n",
      "Iteration 9632, Loss: 0.054170817136764526\n",
      "Iteration 9633, Loss: 0.05398854613304138\n",
      "Iteration 9634, Loss: 0.05417066812515259\n",
      "Iteration 9635, Loss: 0.053988780826330185\n",
      "Iteration 9636, Loss: 0.05417047068476677\n",
      "Iteration 9637, Loss: 0.05398889631032944\n",
      "Iteration 9638, Loss: 0.05417047068476677\n",
      "Iteration 9639, Loss: 0.05398894101381302\n",
      "Iteration 9640, Loss: 0.054170578718185425\n",
      "Iteration 9641, Loss: 0.05398901551961899\n",
      "Iteration 9642, Loss: 0.054170578718185425\n",
      "Iteration 9643, Loss: 0.053988855332136154\n",
      "Iteration 9644, Loss: 0.054170697927474976\n",
      "Iteration 9645, Loss: 0.05398885905742645\n",
      "Iteration 9646, Loss: 0.05417077988386154\n",
      "Iteration 9647, Loss: 0.053988777101039886\n",
      "Iteration 9648, Loss: 0.054170697927474976\n",
      "Iteration 9649, Loss: 0.05398869514465332\n",
      "Iteration 9650, Loss: 0.054170817136764526\n",
      "Iteration 9651, Loss: 0.053988706320524216\n",
      "Iteration 9652, Loss: 0.0541706308722496\n",
      "Iteration 9653, Loss: 0.05398881435394287\n",
      "Iteration 9654, Loss: 0.05417070537805557\n",
      "Iteration 9655, Loss: 0.053988855332136154\n",
      "Iteration 9656, Loss: 0.054170750081539154\n",
      "Iteration 9657, Loss: 0.053988732397556305\n",
      "Iteration 9658, Loss: 0.05417093634605408\n",
      "Iteration 9659, Loss: 0.05398842319846153\n",
      "Iteration 9660, Loss: 0.054171137511730194\n",
      "Iteration 9661, Loss: 0.053988270461559296\n",
      "Iteration 9662, Loss: 0.05417121201753616\n",
      "Iteration 9663, Loss: 0.05398830771446228\n",
      "Iteration 9664, Loss: 0.0541711263358593\n",
      "Iteration 9665, Loss: 0.053988389670848846\n",
      "Iteration 9666, Loss: 0.05417093634605408\n",
      "Iteration 9667, Loss: 0.053988587111234665\n",
      "Iteration 9668, Loss: 0.05417097359895706\n",
      "Iteration 9669, Loss: 0.05398861691355705\n",
      "Iteration 9670, Loss: 0.05417085811495781\n",
      "Iteration 9671, Loss: 0.053988657891750336\n",
      "Iteration 9672, Loss: 0.05417089909315109\n",
      "Iteration 9673, Loss: 0.05398854613304138\n",
      "Iteration 9674, Loss: 0.05417093262076378\n",
      "Iteration 9675, Loss: 0.0539885088801384\n",
      "Iteration 9676, Loss: 0.05417093262076378\n",
      "Iteration 9677, Loss: 0.0539885088801384\n",
      "Iteration 9678, Loss: 0.054170750081539154\n",
      "Iteration 9679, Loss: 0.0539885088801384\n",
      "Iteration 9680, Loss: 0.05417089909315109\n",
      "Iteration 9681, Loss: 0.053988587111234665\n",
      "Iteration 9682, Loss: 0.054170817136764526\n",
      "Iteration 9683, Loss: 0.053988657891750336\n",
      "Iteration 9684, Loss: 0.05417093634605408\n",
      "Iteration 9685, Loss: 0.0539885088801384\n",
      "Iteration 9686, Loss: 0.05417089909315109\n",
      "Iteration 9687, Loss: 0.0539885088801384\n",
      "Iteration 9688, Loss: 0.05417093262076378\n",
      "Iteration 9689, Loss: 0.05398854613304138\n",
      "Iteration 9690, Loss: 0.05417093262076378\n",
      "Iteration 9691, Loss: 0.05398854613304138\n",
      "Iteration 9692, Loss: 0.05417097732424736\n",
      "Iteration 9693, Loss: 0.053988538682460785\n",
      "Iteration 9694, Loss: 0.05417117476463318\n",
      "Iteration 9695, Loss: 0.05398830398917198\n",
      "Iteration 9696, Loss: 0.05417133495211601\n",
      "Iteration 9697, Loss: 0.0539882592856884\n",
      "Iteration 9698, Loss: 0.05417126044631004\n",
      "Iteration 9699, Loss: 0.05398815497756004\n",
      "Iteration 9700, Loss: 0.05417132377624512\n",
      "Iteration 9701, Loss: 0.053988270461559296\n",
      "Iteration 9702, Loss: 0.05417117103934288\n",
      "Iteration 9703, Loss: 0.053988389670848846\n",
      "Iteration 9704, Loss: 0.05417097732424736\n",
      "Iteration 9705, Loss: 0.053988389670848846\n",
      "Iteration 9706, Loss: 0.05417090281844139\n",
      "Iteration 9707, Loss: 0.0539885088801384\n",
      "Iteration 9708, Loss: 0.05417086184024811\n",
      "Iteration 9709, Loss: 0.05398862808942795\n",
      "Iteration 9710, Loss: 0.05417089909315109\n",
      "Iteration 9711, Loss: 0.053988583385944366\n",
      "Iteration 9712, Loss: 0.05417101830244064\n",
      "Iteration 9713, Loss: 0.05398900806903839\n",
      "Iteration 9714, Loss: 0.05417121574282646\n",
      "Iteration 9715, Loss: 0.05398888885974884\n",
      "Iteration 9716, Loss: 0.05417173355817795\n",
      "Iteration 9717, Loss: 0.053988706320524216\n",
      "Iteration 9718, Loss: 0.05417172238230705\n",
      "Iteration 9719, Loss: 0.053988710045814514\n",
      "Iteration 9720, Loss: 0.05417126417160034\n",
      "Iteration 9721, Loss: 0.053988978266716\n",
      "Iteration 9722, Loss: 0.05417129397392273\n",
      "Iteration 9723, Loss: 0.05398906394839287\n",
      "Iteration 9724, Loss: 0.05417133495211601\n",
      "Iteration 9725, Loss: 0.05398906022310257\n",
      "Iteration 9726, Loss: 0.05417140945792198\n",
      "Iteration 9727, Loss: 0.05398917198181152\n",
      "Iteration 9728, Loss: 0.05417140945792198\n",
      "Iteration 9729, Loss: 0.053989097476005554\n",
      "Iteration 9730, Loss: 0.0541713684797287\n",
      "Iteration 9731, Loss: 0.05398917198181152\n",
      "Iteration 9732, Loss: 0.05417141318321228\n",
      "Iteration 9733, Loss: 0.053988974541425705\n",
      "Iteration 9734, Loss: 0.05417153239250183\n",
      "Iteration 9735, Loss: 0.053988970816135406\n",
      "Iteration 9736, Loss: 0.054171573370695114\n",
      "Iteration 9737, Loss: 0.05398889631032944\n",
      "Iteration 9738, Loss: 0.05417148396372795\n",
      "Iteration 9739, Loss: 0.05398893356323242\n",
      "Iteration 9740, Loss: 0.05417133495211601\n",
      "Iteration 9741, Loss: 0.05398913472890854\n",
      "Iteration 9742, Loss: 0.054171256721019745\n",
      "Iteration 9743, Loss: 0.05398913845419884\n",
      "Iteration 9744, Loss: 0.05417129397392273\n",
      "Iteration 9745, Loss: 0.05398906394839287\n",
      "Iteration 9746, Loss: 0.0541713684797287\n",
      "Iteration 9747, Loss: 0.053989093750715256\n",
      "Iteration 9748, Loss: 0.05417145416140556\n",
      "Iteration 9749, Loss: 0.05398889631032944\n",
      "Iteration 9750, Loss: 0.0541716143488884\n",
      "Iteration 9751, Loss: 0.05398893356323242\n",
      "Iteration 9752, Loss: 0.05417156219482422\n",
      "Iteration 9753, Loss: 0.05398894101381302\n",
      "Iteration 9754, Loss: 0.05417140945792198\n",
      "Iteration 9755, Loss: 0.0539889857172966\n",
      "Iteration 9756, Loss: 0.05417141318321228\n",
      "Iteration 9757, Loss: 0.05398905277252197\n",
      "Iteration 9758, Loss: 0.054171450436115265\n",
      "Iteration 9759, Loss: 0.05398905277252197\n",
      "Iteration 9760, Loss: 0.054171375930309296\n",
      "Iteration 9761, Loss: 0.05398905277252197\n",
      "Iteration 9762, Loss: 0.05417133495211601\n",
      "Iteration 9763, Loss: 0.053989022970199585\n",
      "Iteration 9764, Loss: 0.05417129397392273\n",
      "Iteration 9765, Loss: 0.05398906394839287\n",
      "Iteration 9766, Loss: 0.05417126044631004\n",
      "Iteration 9767, Loss: 0.0539889857172966\n",
      "Iteration 9768, Loss: 0.05417141318321228\n",
      "Iteration 9769, Loss: 0.053989022970199585\n",
      "Iteration 9770, Loss: 0.05417129397392273\n",
      "Iteration 9771, Loss: 0.053989022970199585\n",
      "Iteration 9772, Loss: 0.054171375930309296\n",
      "Iteration 9773, Loss: 0.0539889857172966\n",
      "Iteration 9774, Loss: 0.05417144298553467\n",
      "Iteration 9775, Loss: 0.053988978266716\n",
      "Iteration 9776, Loss: 0.05417126044631004\n",
      "Iteration 9777, Loss: 0.053989097476005554\n",
      "Iteration 9778, Loss: 0.05417133495211601\n",
      "Iteration 9779, Loss: 0.05398906394839287\n",
      "Iteration 9780, Loss: 0.05417133495211601\n",
      "Iteration 9781, Loss: 0.053989022970199585\n",
      "Iteration 9782, Loss: 0.05417133495211601\n",
      "Iteration 9783, Loss: 0.053989022970199585\n",
      "Iteration 9784, Loss: 0.05417144298553467\n",
      "Iteration 9785, Loss: 0.053988978266716\n",
      "Iteration 9786, Loss: 0.05417140573263168\n",
      "Iteration 9787, Loss: 0.0539889857172966\n",
      "Iteration 9788, Loss: 0.05417129397392273\n",
      "Iteration 9789, Loss: 0.05398906022310257\n",
      "Iteration 9790, Loss: 0.054171301424503326\n",
      "Iteration 9791, Loss: 0.05398891121149063\n",
      "Iteration 9792, Loss: 0.05417129397392273\n",
      "Iteration 9793, Loss: 0.05398913472890854\n",
      "Iteration 9794, Loss: 0.054171301424503326\n",
      "Iteration 9795, Loss: 0.05398913472890854\n",
      "Iteration 9796, Loss: 0.05417141318321228\n",
      "Iteration 9797, Loss: 0.05398905277252197\n",
      "Iteration 9798, Loss: 0.05417153239250183\n",
      "Iteration 9799, Loss: 0.053988855332136154\n",
      "Iteration 9800, Loss: 0.0541716143488884\n",
      "Iteration 9801, Loss: 0.05398866534233093\n",
      "Iteration 9802, Loss: 0.0541718453168869\n",
      "Iteration 9803, Loss: 0.053988657891750336\n",
      "Iteration 9804, Loss: 0.05417180061340332\n",
      "Iteration 9805, Loss: 0.05398866534233093\n",
      "Iteration 9806, Loss: 0.054171573370695114\n",
      "Iteration 9807, Loss: 0.05398889631032944\n",
      "Iteration 9808, Loss: 0.054171375930309296\n",
      "Iteration 9809, Loss: 0.05398913472890854\n",
      "Iteration 9810, Loss: 0.05417133495211601\n",
      "Iteration 9811, Loss: 0.053989022970199585\n",
      "Iteration 9812, Loss: 0.05417129397392273\n",
      "Iteration 9813, Loss: 0.05398906394839287\n",
      "Iteration 9814, Loss: 0.05417140573263168\n",
      "Iteration 9815, Loss: 0.0539889857172966\n",
      "Iteration 9816, Loss: 0.054171375930309296\n",
      "Iteration 9817, Loss: 0.053989022970199585\n",
      "Iteration 9818, Loss: 0.054171375930309296\n",
      "Iteration 9819, Loss: 0.05398913472890854\n",
      "Iteration 9820, Loss: 0.0541716143488884\n",
      "Iteration 9821, Loss: 0.05398893356323242\n",
      "Iteration 9822, Loss: 0.05417165160179138\n",
      "Iteration 9823, Loss: 0.05398869514465332\n",
      "Iteration 9824, Loss: 0.05417173355817795\n",
      "Iteration 9825, Loss: 0.05398866534233093\n",
      "Iteration 9826, Loss: 0.0541716143488884\n",
      "Iteration 9827, Loss: 0.05398885905742645\n",
      "Iteration 9828, Loss: 0.05417140573263168\n",
      "Iteration 9829, Loss: 0.05398906394839287\n",
      "Iteration 9830, Loss: 0.05417121574282646\n",
      "Iteration 9831, Loss: 0.05398925766348839\n",
      "Iteration 9832, Loss: 0.05417121574282646\n",
      "Iteration 9833, Loss: 0.05398925393819809\n",
      "Iteration 9834, Loss: 0.0541713647544384\n",
      "Iteration 9835, Loss: 0.05398913472890854\n",
      "Iteration 9836, Loss: 0.054171573370695114\n",
      "Iteration 9837, Loss: 0.05398878455162048\n",
      "Iteration 9838, Loss: 0.05417180061340332\n",
      "Iteration 9839, Loss: 0.0539887361228466\n",
      "Iteration 9840, Loss: 0.05417191982269287\n",
      "Iteration 9841, Loss: 0.05398862063884735\n",
      "Iteration 9842, Loss: 0.054171960800886154\n",
      "Iteration 9843, Loss: 0.053988587111234665\n",
      "Iteration 9844, Loss: 0.054171763360500336\n",
      "Iteration 9845, Loss: 0.0539887398481369\n",
      "Iteration 9846, Loss: 0.05417156219482422\n",
      "Iteration 9847, Loss: 0.053988900035619736\n",
      "Iteration 9848, Loss: 0.0541713684797287\n",
      "Iteration 9849, Loss: 0.05398910492658615\n",
      "Iteration 9850, Loss: 0.054171137511730194\n",
      "Iteration 9851, Loss: 0.053989216685295105\n",
      "Iteration 9852, Loss: 0.05417117476463318\n",
      "Iteration 9853, Loss: 0.05398925766348839\n",
      "Iteration 9854, Loss: 0.05417129397392273\n",
      "Iteration 9855, Loss: 0.053988974541425705\n",
      "Iteration 9856, Loss: 0.054171569645404816\n",
      "Iteration 9857, Loss: 0.05398889631032944\n",
      "Iteration 9858, Loss: 0.05417168140411377\n",
      "Iteration 9859, Loss: 0.05398878455162048\n",
      "Iteration 9860, Loss: 0.0541716068983078\n",
      "Iteration 9861, Loss: 0.05398885905742645\n",
      "Iteration 9862, Loss: 0.054171524941921234\n",
      "Iteration 9863, Loss: 0.05398917198181152\n",
      "Iteration 9864, Loss: 0.05417129024863243\n",
      "Iteration 9865, Loss: 0.053989291191101074\n",
      "Iteration 9866, Loss: 0.054171204566955566\n",
      "Iteration 9867, Loss: 0.05398933216929436\n",
      "Iteration 9868, Loss: 0.054171331226825714\n",
      "Iteration 9869, Loss: 0.05398917198181152\n",
      "Iteration 9870, Loss: 0.054171524941921234\n",
      "Iteration 9871, Loss: 0.05398901551961899\n",
      "Iteration 9872, Loss: 0.05417165160179138\n",
      "Iteration 9873, Loss: 0.053988851606845856\n",
      "Iteration 9874, Loss: 0.05417180806398392\n",
      "Iteration 9875, Loss: 0.053988587111234665\n",
      "Iteration 9876, Loss: 0.05417177081108093\n",
      "Iteration 9877, Loss: 0.053988661617040634\n",
      "Iteration 9878, Loss: 0.0541716143488884\n",
      "Iteration 9879, Loss: 0.0539887472987175\n",
      "Iteration 9880, Loss: 0.054171375930309296\n",
      "Iteration 9881, Loss: 0.053989022970199585\n",
      "Iteration 9882, Loss: 0.05417117476463318\n",
      "Iteration 9883, Loss: 0.053989291191101074\n",
      "Iteration 9884, Loss: 0.054171137511730194\n",
      "Iteration 9885, Loss: 0.05398937314748764\n",
      "Iteration 9886, Loss: 0.05417128652334213\n",
      "Iteration 9887, Loss: 0.05398925393819809\n",
      "Iteration 9888, Loss: 0.05417141318321228\n",
      "Iteration 9889, Loss: 0.05398901551961899\n",
      "Iteration 9890, Loss: 0.05417164787650108\n",
      "Iteration 9891, Loss: 0.0539887398481369\n",
      "Iteration 9892, Loss: 0.05417173355817795\n",
      "Iteration 9893, Loss: 0.053988780826330185\n",
      "Iteration 9894, Loss: 0.05417172238230705\n",
      "Iteration 9895, Loss: 0.05398878455162048\n",
      "Iteration 9896, Loss: 0.05417156219482422\n",
      "Iteration 9897, Loss: 0.05398885905742645\n",
      "Iteration 9898, Loss: 0.05417145416140556\n",
      "Iteration 9899, Loss: 0.05398901551961899\n",
      "Iteration 9900, Loss: 0.054171256721019745\n",
      "Iteration 9901, Loss: 0.053989022970199585\n",
      "Iteration 9902, Loss: 0.05417133495211601\n",
      "Iteration 9903, Loss: 0.053989093750715256\n",
      "Iteration 9904, Loss: 0.054171495139598846\n",
      "Iteration 9905, Loss: 0.053988974541425705\n",
      "Iteration 9906, Loss: 0.0541716143488884\n",
      "Iteration 9907, Loss: 0.05398889631032944\n",
      "Iteration 9908, Loss: 0.054171811789274216\n",
      "Iteration 9909, Loss: 0.053988657891750336\n",
      "Iteration 9910, Loss: 0.05417191982269287\n",
      "Iteration 9911, Loss: 0.05398854613304138\n",
      "Iteration 9912, Loss: 0.0541718415915966\n",
      "Iteration 9913, Loss: 0.05398870259523392\n",
      "Iteration 9914, Loss: 0.054171763360500336\n",
      "Iteration 9915, Loss: 0.053988855332136154\n",
      "Iteration 9916, Loss: 0.054171573370695114\n",
      "Iteration 9917, Loss: 0.05398886650800705\n",
      "Iteration 9918, Loss: 0.05417132377624512\n",
      "Iteration 9919, Loss: 0.05398910492658615\n",
      "Iteration 9920, Loss: 0.05417124927043915\n",
      "Iteration 9921, Loss: 0.05398918315768242\n",
      "Iteration 9922, Loss: 0.05417109653353691\n",
      "Iteration 9923, Loss: 0.05398925393819809\n",
      "Iteration 9924, Loss: 0.05417121574282646\n",
      "Iteration 9925, Loss: 0.053989216685295105\n",
      "Iteration 9926, Loss: 0.05417133495211601\n",
      "Iteration 9927, Loss: 0.05398915708065033\n",
      "Iteration 9928, Loss: 0.054171573370695114\n",
      "Iteration 9929, Loss: 0.053988777101039886\n",
      "Iteration 9930, Loss: 0.05417173355817795\n",
      "Iteration 9931, Loss: 0.05398878455162048\n",
      "Iteration 9932, Loss: 0.0541716143488884\n",
      "Iteration 9933, Loss: 0.05398889631032944\n",
      "Iteration 9934, Loss: 0.054171569645404816\n",
      "Iteration 9935, Loss: 0.05398901551961899\n",
      "Iteration 9936, Loss: 0.05417141318321228\n",
      "Iteration 9937, Loss: 0.05398901551961899\n",
      "Iteration 9938, Loss: 0.05417133495211601\n",
      "Iteration 9939, Loss: 0.053989168256521225\n",
      "Iteration 9940, Loss: 0.0541713684797287\n",
      "Iteration 9941, Loss: 0.05398906394839287\n",
      "Iteration 9942, Loss: 0.05417140945792198\n",
      "Iteration 9943, Loss: 0.05398906022310257\n",
      "Iteration 9944, Loss: 0.05417133495211601\n",
      "Iteration 9945, Loss: 0.0539889857172966\n",
      "Iteration 9946, Loss: 0.05417148023843765\n",
      "Iteration 9947, Loss: 0.053988948464393616\n",
      "Iteration 9948, Loss: 0.05417148396372795\n",
      "Iteration 9949, Loss: 0.05398906022310257\n",
      "Iteration 9950, Loss: 0.054171450436115265\n",
      "Iteration 9951, Loss: 0.05398906022310257\n",
      "Iteration 9952, Loss: 0.05417141318321228\n",
      "Iteration 9953, Loss: 0.05398905277252197\n",
      "Iteration 9954, Loss: 0.05417133867740631\n",
      "Iteration 9955, Loss: 0.05398909002542496\n",
      "Iteration 9956, Loss: 0.05417153239250183\n",
      "Iteration 9957, Loss: 0.05398889631032944\n",
      "Iteration 9958, Loss: 0.054171692579984665\n",
      "Iteration 9959, Loss: 0.05398870259523392\n",
      "Iteration 9960, Loss: 0.0541718527674675\n",
      "Iteration 9961, Loss: 0.05398862063884735\n",
      "Iteration 9962, Loss: 0.054171886295080185\n",
      "Iteration 9963, Loss: 0.05398862808942795\n",
      "Iteration 9964, Loss: 0.054171763360500336\n",
      "Iteration 9965, Loss: 0.053988780826330185\n",
      "Iteration 9966, Loss: 0.05417148768901825\n",
      "Iteration 9967, Loss: 0.053989019244909286\n",
      "Iteration 9968, Loss: 0.054171256721019745\n",
      "Iteration 9969, Loss: 0.053989216685295105\n",
      "Iteration 9970, Loss: 0.05417109653353691\n",
      "Iteration 9971, Loss: 0.05398936569690704\n",
      "Iteration 9972, Loss: 0.05417105555534363\n",
      "Iteration 9973, Loss: 0.05398937314748764\n",
      "Iteration 9974, Loss: 0.054171256721019745\n",
      "Iteration 9975, Loss: 0.053989242762327194\n",
      "Iteration 9976, Loss: 0.05417153239250183\n",
      "Iteration 9977, Loss: 0.053989045321941376\n",
      "Iteration 9978, Loss: 0.054171763360500336\n",
      "Iteration 9979, Loss: 0.0539887361228466\n",
      "Iteration 9980, Loss: 0.054171811789274216\n",
      "Iteration 9981, Loss: 0.05398862808942795\n",
      "Iteration 9982, Loss: 0.05417169630527496\n",
      "Iteration 9983, Loss: 0.05398881435394287\n",
      "Iteration 9984, Loss: 0.054171688854694366\n",
      "Iteration 9985, Loss: 0.05398893356323242\n",
      "Iteration 9986, Loss: 0.05417145416140556\n",
      "Iteration 9987, Loss: 0.053988974541425705\n",
      "Iteration 9988, Loss: 0.05417133495211601\n",
      "Iteration 9989, Loss: 0.05398913472890854\n",
      "Iteration 9990, Loss: 0.05417117476463318\n",
      "Iteration 9991, Loss: 0.05398925393819809\n",
      "Iteration 9992, Loss: 0.05417121201753616\n",
      "Iteration 9993, Loss: 0.05398925393819809\n",
      "Iteration 9994, Loss: 0.054171256721019745\n",
      "Iteration 9995, Loss: 0.05398932099342346\n",
      "Iteration 9996, Loss: 0.054171569645404816\n",
      "Iteration 9997, Loss: 0.05398892983794212\n",
      "Iteration 9998, Loss: 0.0541718415915966\n",
      "Iteration 9999, Loss: 0.053988732397556305\n",
      "Iteration 10000, Loss: 0.05417189002037048\n",
      "Iteration 10001, Loss: 0.0539885014295578\n",
      "Iteration 10002, Loss: 0.05417197197675705\n",
      "Iteration 10003, Loss: 0.053988583385944366\n",
      "Iteration 10004, Loss: 0.054171882569789886\n",
      "Iteration 10005, Loss: 0.0539887361228466\n",
      "Iteration 10006, Loss: 0.05417153239250183\n",
      "Iteration 10007, Loss: 0.05398893356323242\n",
      "Iteration 10008, Loss: 0.05417144298553467\n",
      "Iteration 10009, Loss: 0.05398928374052048\n",
      "Iteration 10010, Loss: 0.054171256721019745\n",
      "Iteration 10011, Loss: 0.05398925393819809\n",
      "Iteration 10012, Loss: 0.05417129397392273\n",
      "Iteration 10013, Loss: 0.05398913845419884\n",
      "Iteration 10014, Loss: 0.05417126044631004\n",
      "Iteration 10015, Loss: 0.05398913472890854\n",
      "Iteration 10016, Loss: 0.05417133495211601\n",
      "Iteration 10017, Loss: 0.05398920178413391\n",
      "Iteration 10018, Loss: 0.05417145416140556\n",
      "Iteration 10019, Loss: 0.053989022970199585\n",
      "Iteration 10020, Loss: 0.054171450436115265\n",
      "Iteration 10021, Loss: 0.053989093750715256\n",
      "Iteration 10022, Loss: 0.05417148396372795\n",
      "Iteration 10023, Loss: 0.05398909002542496\n",
      "Iteration 10024, Loss: 0.054171524941921234\n",
      "Iteration 10025, Loss: 0.05398901551961899\n",
      "Iteration 10026, Loss: 0.054171524941921234\n",
      "Iteration 10027, Loss: 0.053989093750715256\n",
      "Iteration 10028, Loss: 0.054171524941921234\n",
      "Iteration 10029, Loss: 0.053989019244909286\n",
      "Iteration 10030, Loss: 0.05417156219482422\n",
      "Iteration 10031, Loss: 0.05398894101381302\n",
      "Iteration 10032, Loss: 0.05417164787650108\n",
      "Iteration 10033, Loss: 0.053988974541425705\n",
      "Iteration 10034, Loss: 0.054171763360500336\n",
      "Iteration 10035, Loss: 0.053988855332136154\n",
      "Iteration 10036, Loss: 0.05417173355817795\n",
      "Iteration 10037, Loss: 0.05398881435394287\n",
      "Iteration 10038, Loss: 0.05417164787650108\n",
      "Iteration 10039, Loss: 0.053988974541425705\n",
      "Iteration 10040, Loss: 0.0541716068983078\n",
      "Iteration 10041, Loss: 0.05398901551961899\n",
      "Iteration 10042, Loss: 0.054171644151210785\n",
      "Iteration 10043, Loss: 0.053988974541425705\n",
      "Iteration 10044, Loss: 0.054171644151210785\n",
      "Iteration 10045, Loss: 0.053988974541425705\n",
      "Iteration 10046, Loss: 0.054171644151210785\n",
      "Iteration 10047, Loss: 0.053988974541425705\n",
      "Iteration 10048, Loss: 0.05417153239250183\n",
      "Iteration 10049, Loss: 0.05398893356323242\n",
      "Iteration 10050, Loss: 0.05417172610759735\n",
      "Iteration 10051, Loss: 0.053988777101039886\n",
      "Iteration 10052, Loss: 0.054171767085790634\n",
      "Iteration 10053, Loss: 0.0539887472987175\n",
      "Iteration 10054, Loss: 0.05417168140411377\n",
      "Iteration 10055, Loss: 0.053988855332136154\n",
      "Iteration 10056, Loss: 0.05417156219482422\n",
      "Iteration 10057, Loss: 0.053988974541425705\n",
      "Iteration 10058, Loss: 0.05417144298553467\n",
      "Iteration 10059, Loss: 0.05398924648761749\n",
      "Iteration 10060, Loss: 0.05417128652334213\n",
      "Iteration 10061, Loss: 0.053989481180906296\n",
      "Iteration 10062, Loss: 0.05417132377624512\n",
      "Iteration 10063, Loss: 0.05398940294981003\n",
      "Iteration 10064, Loss: 0.05417148396372795\n",
      "Iteration 10065, Loss: 0.05398912727832794\n",
      "Iteration 10066, Loss: 0.054171573370695114\n",
      "Iteration 10067, Loss: 0.05398888513445854\n",
      "Iteration 10068, Loss: 0.054171886295080185\n",
      "Iteration 10069, Loss: 0.053988657891750336\n",
      "Iteration 10070, Loss: 0.05417203530669212\n",
      "Iteration 10071, Loss: 0.05398857593536377\n",
      "Iteration 10072, Loss: 0.054171957075595856\n",
      "Iteration 10073, Loss: 0.05398869514465332\n",
      "Iteration 10074, Loss: 0.05417168140411377\n",
      "Iteration 10075, Loss: 0.053988855332136154\n",
      "Iteration 10076, Loss: 0.0541715994477272\n",
      "Iteration 10077, Loss: 0.053988978266716\n",
      "Iteration 10078, Loss: 0.05417132377624512\n",
      "Iteration 10079, Loss: 0.05398925766348839\n",
      "Iteration 10080, Loss: 0.05417121201753616\n",
      "Iteration 10081, Loss: 0.05398933216929436\n",
      "Iteration 10082, Loss: 0.05417124554514885\n",
      "Iteration 10083, Loss: 0.053989361971616745\n",
      "Iteration 10084, Loss: 0.05417156219482422\n",
      "Iteration 10085, Loss: 0.053989045321941376\n",
      "Iteration 10086, Loss: 0.0541718415915966\n",
      "Iteration 10087, Loss: 0.053988806903362274\n",
      "Iteration 10088, Loss: 0.05417200177907944\n",
      "Iteration 10089, Loss: 0.05398861691355705\n",
      "Iteration 10090, Loss: 0.054172005504369736\n",
      "Iteration 10091, Loss: 0.05398861691355705\n",
      "Iteration 10092, Loss: 0.05417194962501526\n",
      "Iteration 10093, Loss: 0.0539887398481369\n",
      "Iteration 10094, Loss: 0.05417152866721153\n",
      "Iteration 10095, Loss: 0.05398901551961899\n",
      "Iteration 10096, Loss: 0.054171375930309296\n",
      "Iteration 10097, Loss: 0.05398913472890854\n",
      "Iteration 10098, Loss: 0.05417129397392273\n",
      "Iteration 10099, Loss: 0.05398917198181152\n",
      "Iteration 10100, Loss: 0.05417148396372795\n",
      "Iteration 10101, Loss: 0.053989168256521225\n",
      "Iteration 10102, Loss: 0.05417153239250183\n",
      "Iteration 10103, Loss: 0.05398893356323242\n",
      "Iteration 10104, Loss: 0.054171573370695114\n",
      "Iteration 10105, Loss: 0.05398894101381302\n",
      "Iteration 10106, Loss: 0.05417168140411377\n",
      "Iteration 10107, Loss: 0.05398889631032944\n",
      "Iteration 10108, Loss: 0.05417152866721153\n",
      "Iteration 10109, Loss: 0.053988974541425705\n",
      "Iteration 10110, Loss: 0.05417148768901825\n",
      "Iteration 10111, Loss: 0.053989045321941376\n",
      "Iteration 10112, Loss: 0.05417148396372795\n",
      "Iteration 10113, Loss: 0.05398905277252197\n",
      "Iteration 10114, Loss: 0.05417133495211601\n",
      "Iteration 10115, Loss: 0.05398913472890854\n",
      "Iteration 10116, Loss: 0.054171524941921234\n",
      "Iteration 10117, Loss: 0.05398920178413391\n",
      "Iteration 10118, Loss: 0.05417168140411377\n",
      "Iteration 10119, Loss: 0.05398892983794212\n",
      "Iteration 10120, Loss: 0.05417172610759735\n",
      "Iteration 10121, Loss: 0.0539887361228466\n",
      "Iteration 10122, Loss: 0.054171688854694366\n",
      "Iteration 10123, Loss: 0.05398893356323242\n",
      "Iteration 10124, Loss: 0.0541716031730175\n",
      "Iteration 10125, Loss: 0.053988974541425705\n",
      "Iteration 10126, Loss: 0.054171375930309296\n",
      "Iteration 10127, Loss: 0.053989168256521225\n",
      "Iteration 10128, Loss: 0.05417133495211601\n",
      "Iteration 10129, Loss: 0.05398920178413391\n",
      "Iteration 10130, Loss: 0.05417129024863243\n",
      "Iteration 10131, Loss: 0.053989212960004807\n",
      "Iteration 10132, Loss: 0.05417133495211601\n",
      "Iteration 10133, Loss: 0.05398920923471451\n",
      "Iteration 10134, Loss: 0.05417144298553467\n",
      "Iteration 10135, Loss: 0.053989093750715256\n",
      "Iteration 10136, Loss: 0.0541716031730175\n",
      "Iteration 10137, Loss: 0.053989164531230927\n",
      "Iteration 10138, Loss: 0.05417164787650108\n",
      "Iteration 10139, Loss: 0.053988855332136154\n",
      "Iteration 10140, Loss: 0.05417180061340332\n",
      "Iteration 10141, Loss: 0.05398870259523392\n",
      "Iteration 10142, Loss: 0.054171763360500336\n",
      "Iteration 10143, Loss: 0.053988851606845856\n",
      "Iteration 10144, Loss: 0.05417168140411377\n",
      "Iteration 10145, Loss: 0.053988900035619736\n",
      "Iteration 10146, Loss: 0.05417133495211601\n",
      "Iteration 10147, Loss: 0.05398920923471451\n",
      "Iteration 10148, Loss: 0.054171256721019745\n",
      "Iteration 10149, Loss: 0.05398932099342346\n",
      "Iteration 10150, Loss: 0.054171256721019745\n",
      "Iteration 10151, Loss: 0.05398932844400406\n",
      "Iteration 10152, Loss: 0.05417133495211601\n",
      "Iteration 10153, Loss: 0.053989164531230927\n",
      "Iteration 10154, Loss: 0.05417156219482422\n",
      "Iteration 10155, Loss: 0.05398900806903839\n",
      "Iteration 10156, Loss: 0.054171688854694366\n",
      "Iteration 10157, Loss: 0.053988777101039886\n",
      "Iteration 10158, Loss: 0.05417180061340332\n",
      "Iteration 10159, Loss: 0.05398866534233093\n",
      "Iteration 10160, Loss: 0.05417177081108093\n",
      "Iteration 10161, Loss: 0.05398881062865257\n",
      "Iteration 10162, Loss: 0.05417168140411377\n",
      "Iteration 10163, Loss: 0.05398893356323242\n",
      "Iteration 10164, Loss: 0.05417148768901825\n",
      "Iteration 10165, Loss: 0.05398905277252197\n",
      "Iteration 10166, Loss: 0.05417129397392273\n",
      "Iteration 10167, Loss: 0.053989212960004807\n",
      "Iteration 10168, Loss: 0.054171256721019745\n",
      "Iteration 10169, Loss: 0.053989216685295105\n",
      "Iteration 10170, Loss: 0.0541713684797287\n",
      "Iteration 10171, Loss: 0.05398924648761749\n",
      "Iteration 10172, Loss: 0.054171573370695114\n",
      "Iteration 10173, Loss: 0.05398907512426376\n",
      "Iteration 10174, Loss: 0.0541718415915966\n",
      "Iteration 10175, Loss: 0.053988806903362274\n",
      "Iteration 10176, Loss: 0.0541718527674675\n",
      "Iteration 10177, Loss: 0.05398861691355705\n",
      "Iteration 10178, Loss: 0.054171960800886154\n",
      "Iteration 10179, Loss: 0.053988780826330185\n",
      "Iteration 10180, Loss: 0.05417172610759735\n",
      "Iteration 10181, Loss: 0.05398893356323242\n",
      "Iteration 10182, Loss: 0.05417156219482422\n",
      "Iteration 10183, Loss: 0.053988974541425705\n",
      "Iteration 10184, Loss: 0.05417140945792198\n",
      "Iteration 10185, Loss: 0.053989093750715256\n",
      "Iteration 10186, Loss: 0.05417129397392273\n",
      "Iteration 10187, Loss: 0.053989291191101074\n",
      "Iteration 10188, Loss: 0.054171256721019745\n",
      "Iteration 10189, Loss: 0.05398925393819809\n",
      "Iteration 10190, Loss: 0.054171375930309296\n",
      "Iteration 10191, Loss: 0.053989097476005554\n",
      "Iteration 10192, Loss: 0.054171375930309296\n",
      "Iteration 10193, Loss: 0.053989093750715256\n",
      "Iteration 10194, Loss: 0.05417141318321228\n",
      "Iteration 10195, Loss: 0.05398912355303764\n",
      "Iteration 10196, Loss: 0.054171569645404816\n",
      "Iteration 10197, Loss: 0.05398894101381302\n",
      "Iteration 10198, Loss: 0.054171644151210785\n",
      "Iteration 10199, Loss: 0.05398900806903839\n",
      "Iteration 10200, Loss: 0.05417168140411377\n",
      "Iteration 10201, Loss: 0.05398893356323242\n",
      "Iteration 10202, Loss: 0.0541715994477272\n",
      "Iteration 10203, Loss: 0.05398901551961899\n",
      "Iteration 10204, Loss: 0.05417148396372795\n",
      "Iteration 10205, Loss: 0.05398957058787346\n",
      "Iteration 10206, Loss: 0.054171375930309296\n",
      "Iteration 10207, Loss: 0.053989604115486145\n",
      "Iteration 10208, Loss: 0.05417081341147423\n",
      "Iteration 10209, Loss: 0.05398983880877495\n",
      "Iteration 10210, Loss: 0.05417085811495781\n",
      "Iteration 10211, Loss: 0.05398968607187271\n",
      "Iteration 10212, Loss: 0.05417109653353691\n",
      "Iteration 10213, Loss: 0.053989291191101074\n",
      "Iteration 10214, Loss: 0.05417140945792198\n",
      "Iteration 10215, Loss: 0.053989164531230927\n",
      "Iteration 10216, Loss: 0.054171692579984665\n",
      "Iteration 10217, Loss: 0.05398881435394287\n",
      "Iteration 10218, Loss: 0.054171960800886154\n",
      "Iteration 10219, Loss: 0.05398869141936302\n",
      "Iteration 10220, Loss: 0.054172009229660034\n",
      "Iteration 10221, Loss: 0.053988657891750336\n",
      "Iteration 10222, Loss: 0.05417191982269287\n",
      "Iteration 10223, Loss: 0.05398866534233093\n",
      "Iteration 10224, Loss: 0.05417180806398392\n",
      "Iteration 10225, Loss: 0.05398886650800705\n",
      "Iteration 10226, Loss: 0.054171644151210785\n",
      "Iteration 10227, Loss: 0.053988978266716\n",
      "Iteration 10228, Loss: 0.054171375930309296\n",
      "Iteration 10229, Loss: 0.053989142179489136\n",
      "Iteration 10230, Loss: 0.0541713647544384\n",
      "Iteration 10231, Loss: 0.05398945137858391\n",
      "Iteration 10232, Loss: 0.054171398282051086\n",
      "Iteration 10233, Loss: 0.05398936569690704\n",
      "Iteration 10234, Loss: 0.054171331226825714\n",
      "Iteration 10235, Loss: 0.053989287465810776\n",
      "Iteration 10236, Loss: 0.05417153239250183\n",
      "Iteration 10237, Loss: 0.053989049047231674\n",
      "Iteration 10238, Loss: 0.054171882569789886\n",
      "Iteration 10239, Loss: 0.053988806903362274\n",
      "Iteration 10240, Loss: 0.05417212098836899\n",
      "Iteration 10241, Loss: 0.053988657891750336\n",
      "Iteration 10242, Loss: 0.054172080010175705\n",
      "Iteration 10243, Loss: 0.05398854240775108\n",
      "Iteration 10244, Loss: 0.05417196452617645\n",
      "Iteration 10245, Loss: 0.053988587111234665\n",
      "Iteration 10246, Loss: 0.05417180061340332\n",
      "Iteration 10247, Loss: 0.05398893356323242\n",
      "Iteration 10248, Loss: 0.05417152866721153\n",
      "Iteration 10249, Loss: 0.05398906394839287\n",
      "Iteration 10250, Loss: 0.05417140573263168\n",
      "Iteration 10251, Loss: 0.05398918315768242\n",
      "Iteration 10252, Loss: 0.05417124927043915\n",
      "Iteration 10253, Loss: 0.05398933216929436\n",
      "Iteration 10254, Loss: 0.054171256721019745\n",
      "Iteration 10255, Loss: 0.05398940667510033\n",
      "Iteration 10256, Loss: 0.054171256721019745\n",
      "Iteration 10257, Loss: 0.053989361971616745\n",
      "Iteration 10258, Loss: 0.05417148768901825\n",
      "Iteration 10259, Loss: 0.05398920178413391\n",
      "Iteration 10260, Loss: 0.0541716143488884\n",
      "Iteration 10261, Loss: 0.05398896336555481\n",
      "Iteration 10262, Loss: 0.0541718453168869\n",
      "Iteration 10263, Loss: 0.053988732397556305\n",
      "Iteration 10264, Loss: 0.054171960800886154\n",
      "Iteration 10265, Loss: 0.0539887361228466\n",
      "Iteration 10266, Loss: 0.05417199060320854\n",
      "Iteration 10267, Loss: 0.05398881435394287\n",
      "Iteration 10268, Loss: 0.05417168140411377\n",
      "Iteration 10269, Loss: 0.05398894101381302\n",
      "Iteration 10270, Loss: 0.054171450436115265\n",
      "Iteration 10271, Loss: 0.05398925393819809\n",
      "Iteration 10272, Loss: 0.05417117476463318\n",
      "Iteration 10273, Loss: 0.05398937314748764\n",
      "Iteration 10274, Loss: 0.05417117476463318\n",
      "Iteration 10275, Loss: 0.05398937314748764\n",
      "Iteration 10276, Loss: 0.05417121574282646\n",
      "Iteration 10277, Loss: 0.05398924648761749\n",
      "Iteration 10278, Loss: 0.05417145416140556\n",
      "Iteration 10279, Loss: 0.05398910492658615\n",
      "Iteration 10280, Loss: 0.05417173355817795\n",
      "Iteration 10281, Loss: 0.05398888885974884\n",
      "Iteration 10282, Loss: 0.05417200177907944\n",
      "Iteration 10283, Loss: 0.05398861691355705\n",
      "Iteration 10284, Loss: 0.054172080010175705\n",
      "Iteration 10285, Loss: 0.053988661617040634\n",
      "Iteration 10286, Loss: 0.0541718415915966\n",
      "Iteration 10287, Loss: 0.05398889631032944\n",
      "Iteration 10288, Loss: 0.05417144298553467\n",
      "Iteration 10289, Loss: 0.05398917198181152\n",
      "Iteration 10290, Loss: 0.0541713647544384\n",
      "Iteration 10291, Loss: 0.053989361971616745\n",
      "Iteration 10292, Loss: 0.05417124554514885\n",
      "Iteration 10293, Loss: 0.053989410400390625\n",
      "Iteration 10294, Loss: 0.05417121574282646\n",
      "Iteration 10295, Loss: 0.05398937314748764\n",
      "Iteration 10296, Loss: 0.054171256721019745\n",
      "Iteration 10297, Loss: 0.05398933216929436\n",
      "Iteration 10298, Loss: 0.05417144298553467\n",
      "Iteration 10299, Loss: 0.05398906394839287\n",
      "Iteration 10300, Loss: 0.0541716068983078\n",
      "Iteration 10301, Loss: 0.05398909002542496\n",
      "Iteration 10302, Loss: 0.0541716143488884\n",
      "Iteration 10303, Loss: 0.05398901551961899\n",
      "Iteration 10304, Loss: 0.05417153239250183\n",
      "Iteration 10305, Loss: 0.05398909002542496\n",
      "Iteration 10306, Loss: 0.054171573370695114\n",
      "Iteration 10307, Loss: 0.05398901551961899\n",
      "Iteration 10308, Loss: 0.05417163297533989\n",
      "Iteration 10309, Loss: 0.053989093750715256\n",
      "Iteration 10310, Loss: 0.0541716031730175\n",
      "Iteration 10311, Loss: 0.05398912727832794\n",
      "Iteration 10312, Loss: 0.05417168140411377\n",
      "Iteration 10313, Loss: 0.05398901551961899\n",
      "Iteration 10314, Loss: 0.054171692579984665\n",
      "Iteration 10315, Loss: 0.05398889631032944\n",
      "Iteration 10316, Loss: 0.05417172238230705\n",
      "Iteration 10317, Loss: 0.05398881435394287\n",
      "Iteration 10318, Loss: 0.05417172238230705\n",
      "Iteration 10319, Loss: 0.05398900806903839\n",
      "Iteration 10320, Loss: 0.054171573370695114\n",
      "Iteration 10321, Loss: 0.053988903760910034\n",
      "Iteration 10322, Loss: 0.054171495139598846\n",
      "Iteration 10323, Loss: 0.05398913845419884\n",
      "Iteration 10324, Loss: 0.054171375930309296\n",
      "Iteration 10325, Loss: 0.053989212960004807\n",
      "Iteration 10326, Loss: 0.054171375930309296\n",
      "Iteration 10327, Loss: 0.05398913845419884\n",
      "Iteration 10328, Loss: 0.054171524941921234\n",
      "Iteration 10329, Loss: 0.05398909002542496\n",
      "Iteration 10330, Loss: 0.05417168140411377\n",
      "Iteration 10331, Loss: 0.05398908257484436\n",
      "Iteration 10332, Loss: 0.05417180061340332\n",
      "Iteration 10333, Loss: 0.053988855332136154\n",
      "Iteration 10334, Loss: 0.05417180061340332\n",
      "Iteration 10335, Loss: 0.05398889631032944\n",
      "Iteration 10336, Loss: 0.05417172238230705\n",
      "Iteration 10337, Loss: 0.05398886650800705\n",
      "Iteration 10338, Loss: 0.054171524941921234\n",
      "Iteration 10339, Loss: 0.05398906022310257\n",
      "Iteration 10340, Loss: 0.054171375930309296\n",
      "Iteration 10341, Loss: 0.053989212960004807\n",
      "Iteration 10342, Loss: 0.054171331226825714\n",
      "Iteration 10343, Loss: 0.05398925393819809\n",
      "Iteration 10344, Loss: 0.05417140573263168\n",
      "Iteration 10345, Loss: 0.05398925393819809\n",
      "Iteration 10346, Loss: 0.05417144298553467\n",
      "Iteration 10347, Loss: 0.053989242762327194\n",
      "Iteration 10348, Loss: 0.05417156219482422\n",
      "Iteration 10349, Loss: 0.053989049047231674\n",
      "Iteration 10350, Loss: 0.054171763360500336\n",
      "Iteration 10351, Loss: 0.053988855332136154\n",
      "Iteration 10352, Loss: 0.054171763360500336\n",
      "Iteration 10353, Loss: 0.05398885905742645\n",
      "Iteration 10354, Loss: 0.05417168140411377\n",
      "Iteration 10355, Loss: 0.053988903760910034\n",
      "Iteration 10356, Loss: 0.054171524941921234\n",
      "Iteration 10357, Loss: 0.05398906022310257\n",
      "Iteration 10358, Loss: 0.054171375930309296\n",
      "Iteration 10359, Loss: 0.05398925393819809\n",
      "Iteration 10360, Loss: 0.0541713647544384\n",
      "Iteration 10361, Loss: 0.053989291191101074\n",
      "Iteration 10362, Loss: 0.05417133495211601\n",
      "Iteration 10363, Loss: 0.05398928374052048\n",
      "Iteration 10364, Loss: 0.05417156219482422\n",
      "Iteration 10365, Loss: 0.053989093750715256\n",
      "Iteration 10366, Loss: 0.0541716031730175\n",
      "Iteration 10367, Loss: 0.05398912355303764\n",
      "Iteration 10368, Loss: 0.054171692579984665\n",
      "Iteration 10369, Loss: 0.053989045321941376\n",
      "Iteration 10370, Loss: 0.05417173355817795\n",
      "Iteration 10371, Loss: 0.05398830026388168\n",
      "Iteration 10372, Loss: 0.054171811789274216\n",
      "Iteration 10373, Loss: 0.05398818105459213\n",
      "Iteration 10374, Loss: 0.05417255684733391\n",
      "Iteration 10375, Loss: 0.05398791283369064\n",
      "Iteration 10376, Loss: 0.05417255684733391\n",
      "Iteration 10377, Loss: 0.05398821830749512\n",
      "Iteration 10378, Loss: 0.05417215824127197\n",
      "Iteration 10379, Loss: 0.0539885088801384\n",
      "Iteration 10380, Loss: 0.05417172238230705\n",
      "Iteration 10381, Loss: 0.053988974541425705\n",
      "Iteration 10382, Loss: 0.05417129397392273\n",
      "Iteration 10383, Loss: 0.05398925393819809\n",
      "Iteration 10384, Loss: 0.054171256721019745\n",
      "Iteration 10385, Loss: 0.05398925393819809\n",
      "Iteration 10386, Loss: 0.054171256721019745\n",
      "Iteration 10387, Loss: 0.053989093750715256\n",
      "Iteration 10388, Loss: 0.05417148768901825\n",
      "Iteration 10389, Loss: 0.05398901551961899\n",
      "Iteration 10390, Loss: 0.054171688854694366\n",
      "Iteration 10391, Loss: 0.05398881435394287\n",
      "Iteration 10392, Loss: 0.0541718527674675\n",
      "Iteration 10393, Loss: 0.053988657891750336\n",
      "Iteration 10394, Loss: 0.054171882569789886\n",
      "Iteration 10395, Loss: 0.05398861691355705\n",
      "Iteration 10396, Loss: 0.05417173355817795\n",
      "Iteration 10397, Loss: 0.05398881435394287\n",
      "Iteration 10398, Loss: 0.054171644151210785\n",
      "Iteration 10399, Loss: 0.05398909002542496\n",
      "Iteration 10400, Loss: 0.05417141318321228\n",
      "Iteration 10401, Loss: 0.053989019244909286\n",
      "Iteration 10402, Loss: 0.05417132377624512\n",
      "Iteration 10403, Loss: 0.05398917943239212\n",
      "Iteration 10404, Loss: 0.05417132377624512\n",
      "Iteration 10405, Loss: 0.05398928374052048\n",
      "Iteration 10406, Loss: 0.05417129024863243\n",
      "Iteration 10407, Loss: 0.053988974541425705\n",
      "Iteration 10408, Loss: 0.05417140945792198\n",
      "Iteration 10409, Loss: 0.05398901551961899\n",
      "Iteration 10410, Loss: 0.05417156219482422\n",
      "Iteration 10411, Loss: 0.05398912727832794\n",
      "Iteration 10412, Loss: 0.0541716068983078\n",
      "Iteration 10413, Loss: 0.05398885905742645\n",
      "Iteration 10414, Loss: 0.05417172238230705\n",
      "Iteration 10415, Loss: 0.0539887361228466\n",
      "Iteration 10416, Loss: 0.054171882569789886\n",
      "Iteration 10417, Loss: 0.05398881435394287\n",
      "Iteration 10418, Loss: 0.054171882569789886\n",
      "Iteration 10419, Loss: 0.05398870259523392\n",
      "Iteration 10420, Loss: 0.05417180806398392\n",
      "Iteration 10421, Loss: 0.053988732397556305\n",
      "Iteration 10422, Loss: 0.05417180806398392\n",
      "Iteration 10423, Loss: 0.05398861691355705\n",
      "Iteration 10424, Loss: 0.054171692579984665\n",
      "Iteration 10425, Loss: 0.05398881435394287\n",
      "Iteration 10426, Loss: 0.05417153239250183\n",
      "Iteration 10427, Loss: 0.05398900434374809\n",
      "Iteration 10428, Loss: 0.054171375930309296\n",
      "Iteration 10429, Loss: 0.05398893356323242\n",
      "Iteration 10430, Loss: 0.05417133495211601\n",
      "Iteration 10431, Loss: 0.05398913472890854\n",
      "Iteration 10432, Loss: 0.054171256721019745\n",
      "Iteration 10433, Loss: 0.053989287465810776\n",
      "Iteration 10434, Loss: 0.05417122691869736\n",
      "Iteration 10435, Loss: 0.053989093750715256\n",
      "Iteration 10436, Loss: 0.054171495139598846\n",
      "Iteration 10437, Loss: 0.053988970816135406\n",
      "Iteration 10438, Loss: 0.0541716143488884\n",
      "Iteration 10439, Loss: 0.053988777101039886\n",
      "Iteration 10440, Loss: 0.054171688854694366\n",
      "Iteration 10441, Loss: 0.0539887361228466\n",
      "Iteration 10442, Loss: 0.0541718415915966\n",
      "Iteration 10443, Loss: 0.05398869514465332\n",
      "Iteration 10444, Loss: 0.054171573370695114\n",
      "Iteration 10445, Loss: 0.05398889631032944\n",
      "Iteration 10446, Loss: 0.054171450436115265\n",
      "Iteration 10447, Loss: 0.05398920178413391\n",
      "Iteration 10448, Loss: 0.054171256721019745\n",
      "Iteration 10449, Loss: 0.05398925393819809\n",
      "Iteration 10450, Loss: 0.05417117476463318\n",
      "Iteration 10451, Loss: 0.053989212960004807\n",
      "Iteration 10452, Loss: 0.05417124554514885\n",
      "Iteration 10453, Loss: 0.053989212960004807\n",
      "Iteration 10454, Loss: 0.05417114496231079\n",
      "Iteration 10455, Loss: 0.05398906394839287\n",
      "Iteration 10456, Loss: 0.05417138338088989\n",
      "Iteration 10457, Loss: 0.05398885905742645\n",
      "Iteration 10458, Loss: 0.05417169630527496\n",
      "Iteration 10459, Loss: 0.05398861691355705\n",
      "Iteration 10460, Loss: 0.05417189002037048\n",
      "Iteration 10461, Loss: 0.05398845672607422\n",
      "Iteration 10462, Loss: 0.05417189002037048\n",
      "Iteration 10463, Loss: 0.05398854613304138\n",
      "Iteration 10464, Loss: 0.05417165160179138\n",
      "Iteration 10465, Loss: 0.05398889631032944\n",
      "Iteration 10466, Loss: 0.05417121946811676\n",
      "Iteration 10467, Loss: 0.05398917943239212\n",
      "Iteration 10468, Loss: 0.054170869290828705\n",
      "Iteration 10469, Loss: 0.05398937687277794\n",
      "Iteration 10470, Loss: 0.05417078733444214\n",
      "Iteration 10471, Loss: 0.05398952588438988\n",
      "Iteration 10472, Loss: 0.05417094752192497\n",
      "Iteration 10473, Loss: 0.05398933216929436\n",
      "Iteration 10474, Loss: 0.05417126417160034\n",
      "Iteration 10475, Loss: 0.053988974541425705\n",
      "Iteration 10476, Loss: 0.05417166277766228\n",
      "Iteration 10477, Loss: 0.053988587111234665\n",
      "Iteration 10478, Loss: 0.05417190119624138\n",
      "Iteration 10479, Loss: 0.053988389670848846\n",
      "Iteration 10480, Loss: 0.05417205020785332\n",
      "Iteration 10481, Loss: 0.053988270461559296\n",
      "Iteration 10482, Loss: 0.054171785712242126\n",
      "Iteration 10483, Loss: 0.05398857593536377\n",
      "Iteration 10484, Loss: 0.0541716143488884\n",
      "Iteration 10485, Loss: 0.053988825529813766\n",
      "Iteration 10486, Loss: 0.054171305149793625\n",
      "Iteration 10487, Loss: 0.05398905277252197\n",
      "Iteration 10488, Loss: 0.05417114496231079\n",
      "Iteration 10489, Loss: 0.053989216685295105\n",
      "Iteration 10490, Loss: 0.05417121574282646\n",
      "Iteration 10491, Loss: 0.05398913472890854\n",
      "Iteration 10492, Loss: 0.05417133867740631\n",
      "Iteration 10493, Loss: 0.05398901551961899\n",
      "Iteration 10494, Loss: 0.054171569645404816\n",
      "Iteration 10495, Loss: 0.053988780826330185\n",
      "Iteration 10496, Loss: 0.05417153239250183\n",
      "Iteration 10497, Loss: 0.0539887472987175\n",
      "Iteration 10498, Loss: 0.05417145788669586\n",
      "Iteration 10499, Loss: 0.053988903760910034\n",
      "Iteration 10500, Loss: 0.05417145416140556\n",
      "Iteration 10501, Loss: 0.05398886650800705\n",
      "Iteration 10502, Loss: 0.054171495139598846\n",
      "Iteration 10503, Loss: 0.053988780826330185\n",
      "Iteration 10504, Loss: 0.05417138338088989\n",
      "Iteration 10505, Loss: 0.05398901551961899\n",
      "Iteration 10506, Loss: 0.05417141318321228\n",
      "Iteration 10507, Loss: 0.05398901551961899\n",
      "Iteration 10508, Loss: 0.054171301424503326\n",
      "Iteration 10509, Loss: 0.05398906022310257\n",
      "Iteration 10510, Loss: 0.05417129397392273\n",
      "Iteration 10511, Loss: 0.053989022970199585\n",
      "Iteration 10512, Loss: 0.05417126044631004\n",
      "Iteration 10513, Loss: 0.05398894473910332\n",
      "Iteration 10514, Loss: 0.05417126044631004\n",
      "Iteration 10515, Loss: 0.0539889857172966\n",
      "Iteration 10516, Loss: 0.054171185940504074\n",
      "Iteration 10517, Loss: 0.05398917198181152\n",
      "Iteration 10518, Loss: 0.05417114496231079\n",
      "Iteration 10519, Loss: 0.05398906394839287\n",
      "Iteration 10520, Loss: 0.05417129397392273\n",
      "Iteration 10521, Loss: 0.05398910492658615\n",
      "Iteration 10522, Loss: 0.054171379655599594\n",
      "Iteration 10523, Loss: 0.05398886650800705\n",
      "Iteration 10524, Loss: 0.05417153239250183\n",
      "Iteration 10525, Loss: 0.05398881435394287\n",
      "Iteration 10526, Loss: 0.054171618074178696\n",
      "Iteration 10527, Loss: 0.05398862808942795\n",
      "Iteration 10528, Loss: 0.05417170375585556\n",
      "Iteration 10529, Loss: 0.05398862808942795\n",
      "Iteration 10530, Loss: 0.05417165160179138\n",
      "Iteration 10531, Loss: 0.05398870259523392\n",
      "Iteration 10532, Loss: 0.054171573370695114\n",
      "Iteration 10533, Loss: 0.05398878455162048\n",
      "Iteration 10534, Loss: 0.054171375930309296\n",
      "Iteration 10535, Loss: 0.05398894101381302\n",
      "Iteration 10536, Loss: 0.05417129397392273\n",
      "Iteration 10537, Loss: 0.05398906022310257\n",
      "Iteration 10538, Loss: 0.054171182215213776\n",
      "Iteration 10539, Loss: 0.05398917943239212\n",
      "Iteration 10540, Loss: 0.05417110025882721\n",
      "Iteration 10541, Loss: 0.05398966372013092\n",
      "Iteration 10542, Loss: 0.054170988500118256\n",
      "Iteration 10543, Loss: 0.05398969352245331\n",
      "Iteration 10544, Loss: 0.05417114496231079\n",
      "Iteration 10545, Loss: 0.05398938059806824\n",
      "Iteration 10546, Loss: 0.0541718564927578\n",
      "Iteration 10547, Loss: 0.05398926883935928\n",
      "Iteration 10548, Loss: 0.05417190119624138\n",
      "Iteration 10549, Loss: 0.05398934334516525\n",
      "Iteration 10550, Loss: 0.05417178198695183\n",
      "Iteration 10551, Loss: 0.05398939177393913\n",
      "Iteration 10552, Loss: 0.054171737283468246\n",
      "Iteration 10553, Loss: 0.05398954078555107\n",
      "Iteration 10554, Loss: 0.05417165905237198\n",
      "Iteration 10555, Loss: 0.05398954078555107\n",
      "Iteration 10556, Loss: 0.054171692579984665\n",
      "Iteration 10557, Loss: 0.05398961529135704\n",
      "Iteration 10558, Loss: 0.05417177081108093\n",
      "Iteration 10559, Loss: 0.053989388048648834\n",
      "Iteration 10560, Loss: 0.054172009229660034\n",
      "Iteration 10561, Loss: 0.05398930236697197\n",
      "Iteration 10562, Loss: 0.05417216941714287\n",
      "Iteration 10563, Loss: 0.05398906394839287\n",
      "Iteration 10564, Loss: 0.0541720986366272\n",
      "Iteration 10565, Loss: 0.05398910492658615\n",
      "Iteration 10566, Loss: 0.05417213588953018\n",
      "Iteration 10567, Loss: 0.05398906394839287\n",
      "Iteration 10568, Loss: 0.05417206138372421\n",
      "Iteration 10569, Loss: 0.05398903042078018\n",
      "Iteration 10570, Loss: 0.05417190492153168\n",
      "Iteration 10571, Loss: 0.05398937314748764\n",
      "Iteration 10572, Loss: 0.0541718527674675\n",
      "Iteration 10573, Loss: 0.0539894625544548\n",
      "Iteration 10574, Loss: 0.05417166277766228\n",
      "Iteration 10575, Loss: 0.0539894700050354\n",
      "Iteration 10576, Loss: 0.05417165905237198\n",
      "Iteration 10577, Loss: 0.053989581763744354\n",
      "Iteration 10578, Loss: 0.05417177081108093\n",
      "Iteration 10579, Loss: 0.05398957431316376\n",
      "Iteration 10580, Loss: 0.05417170375585556\n",
      "Iteration 10581, Loss: 0.05398942157626152\n",
      "Iteration 10582, Loss: 0.0541718527674675\n",
      "Iteration 10583, Loss: 0.05398934707045555\n",
      "Iteration 10584, Loss: 0.054171815514564514\n",
      "Iteration 10585, Loss: 0.053989313542842865\n",
      "Iteration 10586, Loss: 0.05417189747095108\n",
      "Iteration 10587, Loss: 0.05398930609226227\n",
      "Iteration 10588, Loss: 0.054171860218048096\n",
      "Iteration 10589, Loss: 0.0539892241358757\n",
      "Iteration 10590, Loss: 0.05417197570204735\n",
      "Iteration 10591, Loss: 0.05398929864168167\n",
      "Iteration 10592, Loss: 0.05417194217443466\n",
      "Iteration 10593, Loss: 0.05398937314748764\n",
      "Iteration 10594, Loss: 0.054172009229660034\n",
      "Iteration 10595, Loss: 0.05398918315768242\n",
      "Iteration 10596, Loss: 0.05417201668024063\n",
      "Iteration 10597, Loss: 0.05398914963006973\n",
      "Iteration 10598, Loss: 0.05417205020785332\n",
      "Iteration 10599, Loss: 0.05398914963006973\n",
      "Iteration 10600, Loss: 0.054172128438949585\n",
      "Iteration 10601, Loss: 0.053989216685295105\n",
      "Iteration 10602, Loss: 0.0541720949113369\n",
      "Iteration 10603, Loss: 0.05398910492658615\n",
      "Iteration 10604, Loss: 0.05417216941714287\n",
      "Iteration 10605, Loss: 0.05398911237716675\n",
      "Iteration 10606, Loss: 0.054172128438949585\n",
      "Iteration 10607, Loss: 0.05398914963006973\n",
      "Iteration 10608, Loss: 0.05417178198695183\n",
      "Iteration 10609, Loss: 0.05398942157626152\n",
      "Iteration 10610, Loss: 0.054171737283468246\n",
      "Iteration 10611, Loss: 0.053989507257938385\n",
      "Iteration 10612, Loss: 0.05417170375585556\n",
      "Iteration 10613, Loss: 0.0539894625544548\n",
      "Iteration 10614, Loss: 0.05417170375585556\n",
      "Iteration 10615, Loss: 0.0539894625544548\n",
      "Iteration 10616, Loss: 0.054171860218048096\n",
      "Iteration 10617, Loss: 0.05398937687277794\n",
      "Iteration 10618, Loss: 0.054172083735466\n",
      "Iteration 10619, Loss: 0.0539892241358757\n",
      "Iteration 10620, Loss: 0.05417215824127197\n",
      "Iteration 10621, Loss: 0.05398918315768242\n",
      "Iteration 10622, Loss: 0.054171934723854065\n",
      "Iteration 10623, Loss: 0.05398942157626152\n",
      "Iteration 10624, Loss: 0.054171741008758545\n",
      "Iteration 10625, Loss: 0.05398961901664734\n",
      "Iteration 10626, Loss: 0.05417158454656601\n",
      "Iteration 10627, Loss: 0.05398965999484062\n",
      "Iteration 10628, Loss: 0.05417165905237198\n",
      "Iteration 10629, Loss: 0.05398961901664734\n",
      "Iteration 10630, Loss: 0.054171591997146606\n",
      "Iteration 10631, Loss: 0.05398949980735779\n",
      "Iteration 10632, Loss: 0.054171860218048096\n",
      "Iteration 10633, Loss: 0.0539892315864563\n",
      "Iteration 10634, Loss: 0.0541720986366272\n",
      "Iteration 10635, Loss: 0.05398895591497421\n",
      "Iteration 10636, Loss: 0.05417221784591675\n",
      "Iteration 10637, Loss: 0.05398891493678093\n",
      "Iteration 10638, Loss: 0.054172173142433167\n",
      "Iteration 10639, Loss: 0.05398911237716675\n",
      "Iteration 10640, Loss: 0.05417189002037048\n",
      "Iteration 10641, Loss: 0.05398938059806824\n",
      "Iteration 10642, Loss: 0.054171692579984665\n",
      "Iteration 10643, Loss: 0.05398961901664734\n",
      "Iteration 10644, Loss: 0.05417152866721153\n",
      "Iteration 10645, Loss: 0.05398988723754883\n",
      "Iteration 10646, Loss: 0.054171375930309296\n",
      "Iteration 10647, Loss: 0.053989820182323456\n",
      "Iteration 10648, Loss: 0.05417145788669586\n",
      "Iteration 10649, Loss: 0.053989775478839874\n",
      "Iteration 10650, Loss: 0.054171621799468994\n",
      "Iteration 10651, Loss: 0.05398957431316376\n",
      "Iteration 10652, Loss: 0.05417189747095108\n",
      "Iteration 10653, Loss: 0.053989194333553314\n",
      "Iteration 10654, Loss: 0.05417190119624138\n",
      "Iteration 10655, Loss: 0.05398914963006973\n",
      "Iteration 10656, Loss: 0.054172009229660034\n",
      "Iteration 10657, Loss: 0.05398911237716675\n",
      "Iteration 10658, Loss: 0.054172009229660034\n",
      "Iteration 10659, Loss: 0.05398934334516525\n",
      "Iteration 10660, Loss: 0.054171666502952576\n",
      "Iteration 10661, Loss: 0.05398949980735779\n",
      "Iteration 10662, Loss: 0.0541716143488884\n",
      "Iteration 10663, Loss: 0.05398961901664734\n",
      "Iteration 10664, Loss: 0.054171424359083176\n",
      "Iteration 10665, Loss: 0.053989969193935394\n",
      "Iteration 10666, Loss: 0.054171230643987656\n",
      "Iteration 10667, Loss: 0.05398993939161301\n",
      "Iteration 10668, Loss: 0.054171305149793625\n",
      "Iteration 10669, Loss: 0.053989849984645844\n",
      "Iteration 10670, Loss: 0.054171495139598846\n",
      "Iteration 10671, Loss: 0.053989656269550323\n",
      "Iteration 10672, Loss: 0.054171543568372726\n",
      "Iteration 10673, Loss: 0.05398961901664734\n",
      "Iteration 10674, Loss: 0.05417169630527496\n",
      "Iteration 10675, Loss: 0.053989581763744354\n",
      "Iteration 10676, Loss: 0.05417162925004959\n",
      "Iteration 10677, Loss: 0.05398953706026077\n",
      "Iteration 10678, Loss: 0.05417178198695183\n",
      "Iteration 10679, Loss: 0.05398934334516525\n",
      "Iteration 10680, Loss: 0.05417182296514511\n",
      "Iteration 10681, Loss: 0.05398937687277794\n",
      "Iteration 10682, Loss: 0.054172009229660034\n",
      "Iteration 10683, Loss: 0.053989194333553314\n",
      "Iteration 10684, Loss: 0.05417197197675705\n",
      "Iteration 10685, Loss: 0.05398918688297272\n",
      "Iteration 10686, Loss: 0.05417189002037048\n",
      "Iteration 10687, Loss: 0.0539894625544548\n",
      "Iteration 10688, Loss: 0.05417177081108093\n",
      "Iteration 10689, Loss: 0.0539894625544548\n",
      "Iteration 10690, Loss: 0.05417165905237198\n",
      "Iteration 10691, Loss: 0.053989700973033905\n",
      "Iteration 10692, Loss: 0.054171424359083176\n",
      "Iteration 10693, Loss: 0.05398974567651749\n",
      "Iteration 10694, Loss: 0.05417134612798691\n",
      "Iteration 10695, Loss: 0.053989820182323456\n",
      "Iteration 10696, Loss: 0.054171424359083176\n",
      "Iteration 10697, Loss: 0.053989700973033905\n",
      "Iteration 10698, Loss: 0.054171543568372726\n",
      "Iteration 10699, Loss: 0.05398954078555107\n",
      "Iteration 10700, Loss: 0.05417170375585556\n",
      "Iteration 10701, Loss: 0.05398949980735779\n",
      "Iteration 10702, Loss: 0.05417178198695183\n",
      "Iteration 10703, Loss: 0.05398945137858391\n",
      "Iteration 10704, Loss: 0.05417182296514511\n",
      "Iteration 10705, Loss: 0.05398930236697197\n",
      "Iteration 10706, Loss: 0.05417197197675705\n",
      "Iteration 10707, Loss: 0.053989227861166\n",
      "Iteration 10708, Loss: 0.054171930998563766\n",
      "Iteration 10709, Loss: 0.05398938059806824\n",
      "Iteration 10710, Loss: 0.05417170375585556\n",
      "Iteration 10711, Loss: 0.05398949980735779\n",
      "Iteration 10712, Loss: 0.05417146533727646\n",
      "Iteration 10713, Loss: 0.05398977920413017\n",
      "Iteration 10714, Loss: 0.054171256721019745\n",
      "Iteration 10715, Loss: 0.05398993194103241\n",
      "Iteration 10716, Loss: 0.05417122691869736\n",
      "Iteration 10717, Loss: 0.05398993194103241\n",
      "Iteration 10718, Loss: 0.05417134612798691\n",
      "Iteration 10719, Loss: 0.053989704698324203\n",
      "Iteration 10720, Loss: 0.054171737283468246\n",
      "Iteration 10721, Loss: 0.05398949980735779\n",
      "Iteration 10722, Loss: 0.05417194217443466\n",
      "Iteration 10723, Loss: 0.053989142179489136\n",
      "Iteration 10724, Loss: 0.05417218059301376\n",
      "Iteration 10725, Loss: 0.0539889857172966\n",
      "Iteration 10726, Loss: 0.05417213961482048\n",
      "Iteration 10727, Loss: 0.053989142179489136\n",
      "Iteration 10728, Loss: 0.0541718527674675\n",
      "Iteration 10729, Loss: 0.05398930609226227\n",
      "Iteration 10730, Loss: 0.054171692579984665\n",
      "Iteration 10731, Loss: 0.05398965999484062\n",
      "Iteration 10732, Loss: 0.05417141318321228\n",
      "Iteration 10733, Loss: 0.05398977920413017\n",
      "Iteration 10734, Loss: 0.054171379655599594\n",
      "Iteration 10735, Loss: 0.05398992821574211\n",
      "Iteration 10736, Loss: 0.054171379655599594\n",
      "Iteration 10737, Loss: 0.053989849984645844\n",
      "Iteration 10738, Loss: 0.05417165160179138\n",
      "Iteration 10739, Loss: 0.053989510983228683\n",
      "Iteration 10740, Loss: 0.05417182296514511\n",
      "Iteration 10741, Loss: 0.05398927256464958\n",
      "Iteration 10742, Loss: 0.05417206510901451\n",
      "Iteration 10743, Loss: 0.0539889931678772\n",
      "Iteration 10744, Loss: 0.05417218431830406\n",
      "Iteration 10745, Loss: 0.05398891493678093\n",
      "Iteration 10746, Loss: 0.05417221039533615\n",
      "Iteration 10747, Loss: 0.05398910492658615\n",
      "Iteration 10748, Loss: 0.0541720911860466\n",
      "Iteration 10749, Loss: 0.05398914963006973\n",
      "Iteration 10750, Loss: 0.05417202040553093\n",
      "Iteration 10751, Loss: 0.053989261388778687\n",
      "Iteration 10752, Loss: 0.054172009229660034\n",
      "Iteration 10753, Loss: 0.05398930236697197\n",
      "Iteration 10754, Loss: 0.05417189747095108\n",
      "Iteration 10755, Loss: 0.05398930236697197\n",
      "Iteration 10756, Loss: 0.054171930998563766\n",
      "Iteration 10757, Loss: 0.05398930236697197\n",
      "Iteration 10758, Loss: 0.054171860218048096\n",
      "Iteration 10759, Loss: 0.05398930236697197\n",
      "Iteration 10760, Loss: 0.05417202040553093\n",
      "Iteration 10761, Loss: 0.05398925766348839\n",
      "Iteration 10762, Loss: 0.0541720949113369\n",
      "Iteration 10763, Loss: 0.053989142179489136\n",
      "Iteration 10764, Loss: 0.05417202040553093\n",
      "Iteration 10765, Loss: 0.05398911237716675\n",
      "Iteration 10766, Loss: 0.054171979427337646\n",
      "Iteration 10767, Loss: 0.0539892241358757\n",
      "Iteration 10768, Loss: 0.054171860218048096\n",
      "Iteration 10769, Loss: 0.05398938059806824\n",
      "Iteration 10770, Loss: 0.054171741008758545\n",
      "Iteration 10771, Loss: 0.0539894625544548\n",
      "Iteration 10772, Loss: 0.054171666502952576\n",
      "Iteration 10773, Loss: 0.05398942157626152\n",
      "Iteration 10774, Loss: 0.05417189747095108\n",
      "Iteration 10775, Loss: 0.05398930609226227\n",
      "Iteration 10776, Loss: 0.05417205020785332\n",
      "Iteration 10777, Loss: 0.05398930236697197\n",
      "Iteration 10778, Loss: 0.054172128438949585\n",
      "Iteration 10779, Loss: 0.053989142179489136\n",
      "Iteration 10780, Loss: 0.054172128438949585\n",
      "Iteration 10781, Loss: 0.05398903787136078\n",
      "Iteration 10782, Loss: 0.054172009229660034\n",
      "Iteration 10783, Loss: 0.05398930236697197\n",
      "Iteration 10784, Loss: 0.05417189747095108\n",
      "Iteration 10785, Loss: 0.05398938059806824\n",
      "Iteration 10786, Loss: 0.054171741008758545\n",
      "Iteration 10787, Loss: 0.0539894625544548\n",
      "Iteration 10788, Loss: 0.05417166277766228\n",
      "Iteration 10789, Loss: 0.05398957058787346\n",
      "Iteration 10790, Loss: 0.05417158827185631\n",
      "Iteration 10791, Loss: 0.0539894625544548\n",
      "Iteration 10792, Loss: 0.054171666502952576\n",
      "Iteration 10793, Loss: 0.05398949235677719\n",
      "Iteration 10794, Loss: 0.054171930998563766\n",
      "Iteration 10795, Loss: 0.05398937687277794\n",
      "Iteration 10796, Loss: 0.054171934723854065\n",
      "Iteration 10797, Loss: 0.05398930236697197\n",
      "Iteration 10798, Loss: 0.05417197570204735\n",
      "Iteration 10799, Loss: 0.05398911237716675\n",
      "Iteration 10800, Loss: 0.05417197197675705\n",
      "Iteration 10801, Loss: 0.05398934334516525\n",
      "Iteration 10802, Loss: 0.05417189002037048\n",
      "Iteration 10803, Loss: 0.0539894625544548\n",
      "Iteration 10804, Loss: 0.054171741008758545\n",
      "Iteration 10805, Loss: 0.053989388048648834\n",
      "Iteration 10806, Loss: 0.054171979427337646\n",
      "Iteration 10807, Loss: 0.053989261388778687\n",
      "Iteration 10808, Loss: 0.0541720986366272\n",
      "Iteration 10809, Loss: 0.053989067673683167\n",
      "Iteration 10810, Loss: 0.05417228862643242\n",
      "Iteration 10811, Loss: 0.05398883670568466\n",
      "Iteration 10812, Loss: 0.05417228862643242\n",
      "Iteration 10813, Loss: 0.053989142179489136\n",
      "Iteration 10814, Loss: 0.05417190119624138\n",
      "Iteration 10815, Loss: 0.0539892315864563\n",
      "Iteration 10816, Loss: 0.05417178198695183\n",
      "Iteration 10817, Loss: 0.05398949608206749\n",
      "Iteration 10818, Loss: 0.05417150259017944\n",
      "Iteration 10819, Loss: 0.053989700973033905\n",
      "Iteration 10820, Loss: 0.054171305149793625\n",
      "Iteration 10821, Loss: 0.053989820182323456\n",
      "Iteration 10822, Loss: 0.054171305149793625\n",
      "Iteration 10823, Loss: 0.05398985743522644\n",
      "Iteration 10824, Loss: 0.05417150259017944\n",
      "Iteration 10825, Loss: 0.05398977920413017\n",
      "Iteration 10826, Loss: 0.054171737283468246\n",
      "Iteration 10827, Loss: 0.0539894625544548\n",
      "Iteration 10828, Loss: 0.05417202040553093\n",
      "Iteration 10829, Loss: 0.05398914963006973\n",
      "Iteration 10830, Loss: 0.05417221784591675\n",
      "Iteration 10831, Loss: 0.053988903760910034\n",
      "Iteration 10832, Loss: 0.0541723296046257\n",
      "Iteration 10833, Loss: 0.053988873958587646\n",
      "Iteration 10834, Loss: 0.054172173142433167\n",
      "Iteration 10835, Loss: 0.05398906394839287\n",
      "Iteration 10836, Loss: 0.054172128438949585\n",
      "Iteration 10837, Loss: 0.05398918688297272\n",
      "Iteration 10838, Loss: 0.054171811789274216\n",
      "Iteration 10839, Loss: 0.053989388048648834\n",
      "Iteration 10840, Loss: 0.054171621799468994\n",
      "Iteration 10841, Loss: 0.05398965999484062\n",
      "Iteration 10842, Loss: 0.05417166277766228\n",
      "Iteration 10843, Loss: 0.05398954451084137\n",
      "Iteration 10844, Loss: 0.05417151376605034\n",
      "Iteration 10845, Loss: 0.05398964881896973\n",
      "Iteration 10846, Loss: 0.054171666502952576\n",
      "Iteration 10847, Loss: 0.05398938059806824\n",
      "Iteration 10848, Loss: 0.054172009229660034\n",
      "Iteration 10849, Loss: 0.05398929864168167\n",
      "Iteration 10850, Loss: 0.0541720986366272\n",
      "Iteration 10851, Loss: 0.05398911237716675\n",
      "Iteration 10852, Loss: 0.054172173142433167\n",
      "Iteration 10853, Loss: 0.05398895591497421\n",
      "Iteration 10854, Loss: 0.05417218059301376\n",
      "Iteration 10855, Loss: 0.05398903042078018\n",
      "Iteration 10856, Loss: 0.0541720949113369\n",
      "Iteration 10857, Loss: 0.053989142179489136\n",
      "Iteration 10858, Loss: 0.05417194217443466\n",
      "Iteration 10859, Loss: 0.05398930236697197\n",
      "Iteration 10860, Loss: 0.054171930998563766\n",
      "Iteration 10861, Loss: 0.05398938059806824\n",
      "Iteration 10862, Loss: 0.0541718527674675\n",
      "Iteration 10863, Loss: 0.05398942530155182\n",
      "Iteration 10864, Loss: 0.05417170375585556\n",
      "Iteration 10865, Loss: 0.05398942157626152\n",
      "Iteration 10866, Loss: 0.054171737283468246\n",
      "Iteration 10867, Loss: 0.0539894625544548\n",
      "Iteration 10868, Loss: 0.05417170375585556\n",
      "Iteration 10869, Loss: 0.0539894625544548\n",
      "Iteration 10870, Loss: 0.05417182296514511\n",
      "Iteration 10871, Loss: 0.05398934707045555\n",
      "Iteration 10872, Loss: 0.05417190119624138\n",
      "Iteration 10873, Loss: 0.05398937687277794\n",
      "Iteration 10874, Loss: 0.054171979427337646\n",
      "Iteration 10875, Loss: 0.053989142179489136\n",
      "Iteration 10876, Loss: 0.0541720986366272\n",
      "Iteration 10877, Loss: 0.05398911237716675\n",
      "Iteration 10878, Loss: 0.05417202040553093\n",
      "Iteration 10879, Loss: 0.05398907512426376\n",
      "Iteration 10880, Loss: 0.054171979427337646\n",
      "Iteration 10881, Loss: 0.053989261388778687\n",
      "Iteration 10882, Loss: 0.05417194217443466\n",
      "Iteration 10883, Loss: 0.05398934707045555\n",
      "Iteration 10884, Loss: 0.054171886295080185\n",
      "Iteration 10885, Loss: 0.0539894662797451\n",
      "Iteration 10886, Loss: 0.05417173355817795\n",
      "Iteration 10887, Loss: 0.05398954078555107\n",
      "Iteration 10888, Loss: 0.054171692579984665\n",
      "Iteration 10889, Loss: 0.05398954451084137\n",
      "Iteration 10890, Loss: 0.05417173355817795\n",
      "Iteration 10891, Loss: 0.05398957058787346\n",
      "Iteration 10892, Loss: 0.0541718527674675\n",
      "Iteration 10893, Loss: 0.05398942157626152\n",
      "Iteration 10894, Loss: 0.054171979427337646\n",
      "Iteration 10895, Loss: 0.05398918315768242\n",
      "Iteration 10896, Loss: 0.05417225509881973\n",
      "Iteration 10897, Loss: 0.05398891493678093\n",
      "Iteration 10898, Loss: 0.05417241156101227\n",
      "Iteration 10899, Loss: 0.05398879200220108\n",
      "Iteration 10900, Loss: 0.0541723370552063\n",
      "Iteration 10901, Loss: 0.053988873958587646\n",
      "Iteration 10902, Loss: 0.0541720986366272\n",
      "Iteration 10903, Loss: 0.05398918315768242\n",
      "Iteration 10904, Loss: 0.054171934723854065\n",
      "Iteration 10905, Loss: 0.053989313542842865\n",
      "Iteration 10906, Loss: 0.05417177081108093\n",
      "Iteration 10907, Loss: 0.05398954078555107\n",
      "Iteration 10908, Loss: 0.0541716143488884\n",
      "Iteration 10909, Loss: 0.053989700973033905\n",
      "Iteration 10910, Loss: 0.05417145788669586\n",
      "Iteration 10911, Loss: 0.05398974567651749\n",
      "Iteration 10912, Loss: 0.0541716143488884\n",
      "Iteration 10913, Loss: 0.05398968979716301\n",
      "Iteration 10914, Loss: 0.05417166277766228\n",
      "Iteration 10915, Loss: 0.053989432752132416\n",
      "Iteration 10916, Loss: 0.05417201668024063\n",
      "Iteration 10917, Loss: 0.0539892241358757\n",
      "Iteration 10918, Loss: 0.05417213961482048\n",
      "Iteration 10919, Loss: 0.0539889894425869\n",
      "Iteration 10920, Loss: 0.05417228862643242\n",
      "Iteration 10921, Loss: 0.05398891493678093\n",
      "Iteration 10922, Loss: 0.05417221039533615\n",
      "Iteration 10923, Loss: 0.05398907512426376\n",
      "Iteration 10924, Loss: 0.05417190119624138\n",
      "Iteration 10925, Loss: 0.053989313542842865\n",
      "Iteration 10926, Loss: 0.05417170375585556\n",
      "Iteration 10927, Loss: 0.05398961529135704\n",
      "Iteration 10928, Loss: 0.054171498864889145\n",
      "Iteration 10929, Loss: 0.05398977920413017\n",
      "Iteration 10930, Loss: 0.05417138338088989\n",
      "Iteration 10931, Loss: 0.053989700973033905\n",
      "Iteration 10932, Loss: 0.054171621799468994\n",
      "Iteration 10933, Loss: 0.053989700973033905\n",
      "Iteration 10934, Loss: 0.05417177081108093\n",
      "Iteration 10935, Loss: 0.05398934334516525\n",
      "Iteration 10936, Loss: 0.0541720911860466\n",
      "Iteration 10937, Loss: 0.05398910865187645\n",
      "Iteration 10938, Loss: 0.05417216941714287\n",
      "Iteration 10939, Loss: 0.05398907512426376\n",
      "Iteration 10940, Loss: 0.0541720986366272\n",
      "Iteration 10941, Loss: 0.053989000618457794\n",
      "Iteration 10942, Loss: 0.05417205020785332\n",
      "Iteration 10943, Loss: 0.05398856848478317\n",
      "Iteration 10944, Loss: 0.05417196452617645\n",
      "Iteration 10945, Loss: 0.05398861691355705\n",
      "Iteration 10946, Loss: 0.0541711151599884\n",
      "Iteration 10947, Loss: 0.05398884415626526\n",
      "Iteration 10948, Loss: 0.05417114496231079\n",
      "Iteration 10949, Loss: 0.05398896336555481\n",
      "Iteration 10950, Loss: 0.054171040654182434\n",
      "Iteration 10951, Loss: 0.053988806903362274\n",
      "Iteration 10952, Loss: 0.05417127162218094\n",
      "Iteration 10953, Loss: 0.05398868769407272\n",
      "Iteration 10954, Loss: 0.054171543568372726\n",
      "Iteration 10955, Loss: 0.053988486528396606\n",
      "Iteration 10956, Loss: 0.05417143553495407\n",
      "Iteration 10957, Loss: 0.05398845672607422\n",
      "Iteration 10958, Loss: 0.05417139455676079\n",
      "Iteration 10959, Loss: 0.053988538682460785\n",
      "Iteration 10960, Loss: 0.054171353578567505\n",
      "Iteration 10961, Loss: 0.05398865044116974\n",
      "Iteration 10962, Loss: 0.054171353578567505\n",
      "Iteration 10963, Loss: 0.05398865044116974\n",
      "Iteration 10964, Loss: 0.05417139455676079\n",
      "Iteration 10965, Loss: 0.05398864671587944\n",
      "Iteration 10966, Loss: 0.0541713610291481\n",
      "Iteration 10967, Loss: 0.0539884939789772\n",
      "Iteration 10968, Loss: 0.054171472787857056\n",
      "Iteration 10969, Loss: 0.05398841202259064\n",
      "Iteration 10970, Loss: 0.05417143926024437\n",
      "Iteration 10971, Loss: 0.053988486528396606\n",
      "Iteration 10972, Loss: 0.05417139455676079\n",
      "Iteration 10973, Loss: 0.05398845672607422\n",
      "Iteration 10974, Loss: 0.05417131632566452\n",
      "Iteration 10975, Loss: 0.05398845672607422\n",
      "Iteration 10976, Loss: 0.054171349853277206\n",
      "Iteration 10977, Loss: 0.05398865044116974\n",
      "Iteration 10978, Loss: 0.05417134612798691\n",
      "Iteration 10979, Loss: 0.05398868769407272\n",
      "Iteration 10980, Loss: 0.054171234369277954\n",
      "Iteration 10981, Loss: 0.05398876592516899\n",
      "Iteration 10982, Loss: 0.05417134612798691\n",
      "Iteration 10983, Loss: 0.05398879572749138\n",
      "Iteration 10984, Loss: 0.05417127534747124\n",
      "Iteration 10985, Loss: 0.05398867651820183\n",
      "Iteration 10986, Loss: 0.054171398282051086\n",
      "Iteration 10987, Loss: 0.05398900434374809\n",
      "Iteration 10988, Loss: 0.05417155474424362\n",
      "Iteration 10989, Loss: 0.053988777101039886\n",
      "Iteration 10990, Loss: 0.054171472787857056\n",
      "Iteration 10991, Loss: 0.053988926112651825\n",
      "Iteration 10992, Loss: 0.05417186766862869\n",
      "Iteration 10993, Loss: 0.05398901551961899\n",
      "Iteration 10994, Loss: 0.05417151749134064\n",
      "Iteration 10995, Loss: 0.053989361971616745\n",
      "Iteration 10996, Loss: 0.05417150259017944\n",
      "Iteration 10997, Loss: 0.053989477455616\n",
      "Iteration 10998, Loss: 0.05417127534747124\n",
      "Iteration 10999, Loss: 0.05398959666490555\n",
      "Iteration 11000, Loss: 0.05417127534747124\n",
      "Iteration 11001, Loss: 0.05398958921432495\n",
      "Iteration 11002, Loss: 0.05417155474424362\n",
      "Iteration 11003, Loss: 0.05398939177393913\n",
      "Iteration 11004, Loss: 0.05417179316282272\n",
      "Iteration 11005, Loss: 0.05398900434374809\n",
      "Iteration 11006, Loss: 0.054172225296497345\n",
      "Iteration 11007, Loss: 0.05398868769407272\n",
      "Iteration 11008, Loss: 0.05417222902178764\n",
      "Iteration 11009, Loss: 0.05398860573768616\n",
      "Iteration 11010, Loss: 0.05417222902178764\n",
      "Iteration 11011, Loss: 0.05398872494697571\n",
      "Iteration 11012, Loss: 0.054172031581401825\n",
      "Iteration 11013, Loss: 0.05398903414607048\n",
      "Iteration 11014, Loss: 0.05417167395353317\n",
      "Iteration 11015, Loss: 0.05398942530155182\n",
      "Iteration 11016, Loss: 0.05417143553495407\n",
      "Iteration 11017, Loss: 0.05398955196142197\n",
      "Iteration 11018, Loss: 0.05417132377624512\n",
      "Iteration 11019, Loss: 0.05398940294981003\n",
      "Iteration 11020, Loss: 0.05417151376605034\n",
      "Iteration 11021, Loss: 0.05398935079574585\n",
      "Iteration 11022, Loss: 0.05417163670063019\n",
      "Iteration 11023, Loss: 0.0539892315864563\n",
      "Iteration 11024, Loss: 0.05417182296514511\n",
      "Iteration 11025, Loss: 0.05398915708065033\n",
      "Iteration 11026, Loss: 0.054171912372112274\n",
      "Iteration 11027, Loss: 0.05398900434374809\n",
      "Iteration 11028, Loss: 0.05417191609740257\n",
      "Iteration 11029, Loss: 0.05398888513445854\n",
      "Iteration 11030, Loss: 0.05417206883430481\n",
      "Iteration 11031, Loss: 0.05398888140916824\n",
      "Iteration 11032, Loss: 0.05417206883430481\n",
      "Iteration 11033, Loss: 0.05398888513445854\n",
      "Iteration 11034, Loss: 0.05417199060320854\n",
      "Iteration 11035, Loss: 0.053989000618457794\n",
      "Iteration 11036, Loss: 0.05417187139391899\n",
      "Iteration 11037, Loss: 0.0539892315864563\n",
      "Iteration 11038, Loss: 0.05417151749134064\n",
      "Iteration 11039, Loss: 0.053989432752132416\n",
      "Iteration 11040, Loss: 0.05417151376605034\n",
      "Iteration 11041, Loss: 0.0539894700050354\n",
      "Iteration 11042, Loss: 0.05417151004076004\n",
      "Iteration 11043, Loss: 0.05398955196142197\n",
      "Iteration 11044, Loss: 0.05417146906256676\n",
      "Iteration 11045, Loss: 0.05398951470851898\n",
      "Iteration 11046, Loss: 0.05417139455676079\n",
      "Iteration 11047, Loss: 0.05398940294981003\n",
      "Iteration 11048, Loss: 0.05417151376605034\n",
      "Iteration 11049, Loss: 0.05398935079574585\n",
      "Iteration 11050, Loss: 0.05417163297533989\n",
      "Iteration 11051, Loss: 0.053989242762327194\n",
      "Iteration 11052, Loss: 0.05417171120643616\n",
      "Iteration 11053, Loss: 0.05398920178413391\n",
      "Iteration 11054, Loss: 0.05417175218462944\n",
      "Iteration 11055, Loss: 0.05398919805884361\n",
      "Iteration 11056, Loss: 0.05417190119624138\n",
      "Iteration 11057, Loss: 0.053989194333553314\n",
      "Iteration 11058, Loss: 0.05417179316282272\n",
      "Iteration 11059, Loss: 0.05398900434374809\n",
      "Iteration 11060, Loss: 0.05417190492153168\n",
      "Iteration 11061, Loss: 0.053989045321941376\n",
      "Iteration 11062, Loss: 0.05417190119624138\n",
      "Iteration 11063, Loss: 0.05398908257484436\n",
      "Iteration 11064, Loss: 0.05417182296514511\n",
      "Iteration 11065, Loss: 0.053989194333553314\n",
      "Iteration 11066, Loss: 0.05417171120643616\n",
      "Iteration 11067, Loss: 0.05398927256464958\n",
      "Iteration 11068, Loss: 0.05417151376605034\n",
      "Iteration 11069, Loss: 0.0539894700050354\n",
      "Iteration 11070, Loss: 0.054171472787857056\n",
      "Iteration 11071, Loss: 0.053989481180906296\n",
      "Iteration 11072, Loss: 0.054171472787857056\n",
      "Iteration 11073, Loss: 0.05398939177393913\n",
      "Iteration 11074, Loss: 0.05417155846953392\n",
      "Iteration 11075, Loss: 0.0539892315864563\n",
      "Iteration 11076, Loss: 0.054171785712242126\n",
      "Iteration 11077, Loss: 0.053989045321941376\n",
      "Iteration 11078, Loss: 0.05417182296514511\n",
      "Iteration 11079, Loss: 0.053989164531230927\n",
      "Iteration 11080, Loss: 0.05417171120643616\n",
      "Iteration 11081, Loss: 0.05398927628993988\n",
      "Iteration 11082, Loss: 0.05417170375585556\n",
      "Iteration 11083, Loss: 0.05398935824632645\n",
      "Iteration 11084, Loss: 0.05417151376605034\n",
      "Iteration 11085, Loss: 0.053989510983228683\n",
      "Iteration 11086, Loss: 0.05417143553495407\n",
      "Iteration 11087, Loss: 0.053989510983228683\n",
      "Iteration 11088, Loss: 0.05417155474424362\n",
      "Iteration 11089, Loss: 0.05398928374052048\n",
      "Iteration 11090, Loss: 0.05417167767882347\n",
      "Iteration 11091, Loss: 0.05398919805884361\n",
      "Iteration 11092, Loss: 0.05417194962501526\n",
      "Iteration 11093, Loss: 0.05398903414607048\n",
      "Iteration 11094, Loss: 0.054172150790691376\n",
      "Iteration 11095, Loss: 0.05398864671587944\n",
      "Iteration 11096, Loss: 0.05417222902178764\n",
      "Iteration 11097, Loss: 0.05398871749639511\n",
      "Iteration 11098, Loss: 0.054172031581401825\n",
      "Iteration 11099, Loss: 0.053989000618457794\n",
      "Iteration 11100, Loss: 0.054171785712242126\n",
      "Iteration 11101, Loss: 0.05398927628993988\n",
      "Iteration 11102, Loss: 0.05417151004076004\n",
      "Iteration 11103, Loss: 0.05398955196142197\n",
      "Iteration 11104, Loss: 0.05417127534747124\n",
      "Iteration 11105, Loss: 0.0539897084236145\n",
      "Iteration 11106, Loss: 0.05417127534747124\n",
      "Iteration 11107, Loss: 0.05398952215909958\n",
      "Iteration 11108, Loss: 0.05417139455676079\n",
      "Iteration 11109, Loss: 0.053989510983228683\n",
      "Iteration 11110, Loss: 0.054171591997146606\n",
      "Iteration 11111, Loss: 0.05398927256464958\n",
      "Iteration 11112, Loss: 0.05417179316282272\n",
      "Iteration 11113, Loss: 0.05398907512426376\n",
      "Iteration 11114, Loss: 0.054171912372112274\n",
      "Iteration 11115, Loss: 0.05398881435394287\n",
      "Iteration 11116, Loss: 0.05417194217443466\n",
      "Iteration 11117, Loss: 0.053989045321941376\n",
      "Iteration 11118, Loss: 0.05417190119624138\n",
      "Iteration 11119, Loss: 0.0539892315864563\n",
      "Iteration 11120, Loss: 0.054171741008758545\n",
      "Iteration 11121, Loss: 0.05398931726813316\n",
      "Iteration 11122, Loss: 0.05417148023843765\n",
      "Iteration 11123, Loss: 0.05398942530155182\n",
      "Iteration 11124, Loss: 0.054171472787857056\n",
      "Iteration 11125, Loss: 0.0539894700050354\n",
      "Iteration 11126, Loss: 0.05417143553495407\n",
      "Iteration 11127, Loss: 0.053989510983228683\n",
      "Iteration 11128, Loss: 0.054171472787857056\n",
      "Iteration 11129, Loss: 0.0539894700050354\n",
      "Iteration 11130, Loss: 0.05417155474424362\n",
      "Iteration 11131, Loss: 0.05398940294981003\n",
      "Iteration 11132, Loss: 0.05417155474424362\n",
      "Iteration 11133, Loss: 0.05398928374052048\n",
      "Iteration 11134, Loss: 0.054171591997146606\n",
      "Iteration 11135, Loss: 0.053989164531230927\n",
      "Iteration 11136, Loss: 0.05417167395353317\n",
      "Iteration 11137, Loss: 0.05398915335536003\n",
      "Iteration 11138, Loss: 0.05417179688811302\n",
      "Iteration 11139, Loss: 0.053989000618457794\n",
      "Iteration 11140, Loss: 0.05417194962501526\n",
      "Iteration 11141, Loss: 0.05398896336555481\n",
      "Iteration 11142, Loss: 0.05417199060320854\n",
      "Iteration 11143, Loss: 0.053988926112651825\n",
      "Iteration 11144, Loss: 0.054171912372112274\n",
      "Iteration 11145, Loss: 0.053989045321941376\n",
      "Iteration 11146, Loss: 0.05417187139391899\n",
      "Iteration 11147, Loss: 0.05398903787136078\n",
      "Iteration 11148, Loss: 0.054171912372112274\n",
      "Iteration 11149, Loss: 0.05398896336555481\n",
      "Iteration 11150, Loss: 0.05417179316282272\n",
      "Iteration 11151, Loss: 0.053989164531230927\n",
      "Iteration 11152, Loss: 0.05417171120643616\n",
      "Iteration 11153, Loss: 0.05398927628993988\n",
      "Iteration 11154, Loss: 0.05417163297533989\n",
      "Iteration 11155, Loss: 0.05398935079574585\n",
      "Iteration 11156, Loss: 0.05417155474424362\n",
      "Iteration 11157, Loss: 0.053989361971616745\n",
      "Iteration 11158, Loss: 0.05417163297533989\n",
      "Iteration 11159, Loss: 0.05398927256464958\n",
      "Iteration 11160, Loss: 0.05417175218462944\n",
      "Iteration 11161, Loss: 0.05398907884955406\n",
      "Iteration 11162, Loss: 0.05417187511920929\n",
      "Iteration 11163, Loss: 0.05398888513445854\n",
      "Iteration 11164, Loss: 0.054172106087207794\n",
      "Iteration 11165, Loss: 0.05398881435394287\n",
      "Iteration 11166, Loss: 0.05417199060320854\n",
      "Iteration 11167, Loss: 0.053989000618457794\n",
      "Iteration 11168, Loss: 0.05417190492153168\n",
      "Iteration 11169, Loss: 0.053989194333553314\n",
      "Iteration 11170, Loss: 0.05417170748114586\n",
      "Iteration 11171, Loss: 0.053989242762327194\n",
      "Iteration 11172, Loss: 0.05417158454656601\n",
      "Iteration 11173, Loss: 0.053989432752132416\n",
      "Iteration 11174, Loss: 0.0541713610291481\n",
      "Iteration 11175, Loss: 0.053989510983228683\n",
      "Iteration 11176, Loss: 0.054171472787857056\n",
      "Iteration 11177, Loss: 0.053989555686712265\n",
      "Iteration 11178, Loss: 0.054171472787857056\n",
      "Iteration 11179, Loss: 0.0539894700050354\n",
      "Iteration 11180, Loss: 0.05417155474424362\n",
      "Iteration 11181, Loss: 0.053989313542842865\n",
      "Iteration 11182, Loss: 0.05417168140411377\n",
      "Iteration 11183, Loss: 0.05398903414607048\n",
      "Iteration 11184, Loss: 0.05417194962501526\n",
      "Iteration 11185, Loss: 0.05398884415626526\n",
      "Iteration 11186, Loss: 0.054172031581401825\n",
      "Iteration 11187, Loss: 0.053988855332136154\n",
      "Iteration 11188, Loss: 0.054171912372112274\n",
      "Iteration 11189, Loss: 0.053988855332136154\n",
      "Iteration 11190, Loss: 0.054171837866306305\n",
      "Iteration 11191, Loss: 0.05398907512426376\n",
      "Iteration 11192, Loss: 0.05417190119624138\n",
      "Iteration 11193, Loss: 0.053989045321941376\n",
      "Iteration 11194, Loss: 0.05417167395353317\n",
      "Iteration 11195, Loss: 0.05398939177393913\n",
      "Iteration 11196, Loss: 0.05417155474424362\n",
      "Iteration 11197, Loss: 0.0539894700050354\n",
      "Iteration 11198, Loss: 0.05417158827185631\n",
      "Iteration 11199, Loss: 0.053989510983228683\n",
      "Iteration 11200, Loss: 0.054171591997146606\n",
      "Iteration 11201, Loss: 0.05398927256464958\n",
      "Iteration 11202, Loss: 0.05417183041572571\n",
      "Iteration 11203, Loss: 0.05398903414607048\n",
      "Iteration 11204, Loss: 0.05417183041572571\n",
      "Iteration 11205, Loss: 0.05398900434374809\n",
      "Iteration 11206, Loss: 0.054171860218048096\n",
      "Iteration 11207, Loss: 0.0539892315864563\n",
      "Iteration 11208, Loss: 0.05417167395353317\n",
      "Iteration 11209, Loss: 0.053989388048648834\n",
      "Iteration 11210, Loss: 0.054171591997146606\n",
      "Iteration 11211, Loss: 0.05398931726813316\n",
      "Iteration 11212, Loss: 0.05417163297533989\n",
      "Iteration 11213, Loss: 0.05398927628993988\n",
      "Iteration 11214, Loss: 0.05417174845933914\n",
      "Iteration 11215, Loss: 0.053989164531230927\n",
      "Iteration 11216, Loss: 0.05417179316282272\n",
      "Iteration 11217, Loss: 0.0539892315864563\n",
      "Iteration 11218, Loss: 0.05417175218462944\n",
      "Iteration 11219, Loss: 0.05398908257484436\n",
      "Iteration 11220, Loss: 0.054171860218048096\n",
      "Iteration 11221, Loss: 0.053989164531230927\n",
      "Iteration 11222, Loss: 0.05417190119624138\n",
      "Iteration 11223, Loss: 0.0539892315864563\n",
      "Iteration 11224, Loss: 0.054171860218048096\n",
      "Iteration 11225, Loss: 0.053989313542842865\n",
      "Iteration 11226, Loss: 0.05417178198695183\n",
      "Iteration 11227, Loss: 0.05398931726813316\n",
      "Iteration 11228, Loss: 0.05417171120643616\n",
      "Iteration 11229, Loss: 0.05398927256464958\n",
      "Iteration 11230, Loss: 0.05417179316282272\n",
      "Iteration 11231, Loss: 0.05398907512426376\n",
      "Iteration 11232, Loss: 0.05417183041572571\n",
      "Iteration 11233, Loss: 0.053989119827747345\n",
      "Iteration 11234, Loss: 0.05417194962501526\n",
      "Iteration 11235, Loss: 0.05398903787136078\n",
      "Iteration 11236, Loss: 0.05417206138372421\n",
      "Iteration 11237, Loss: 0.053989119827747345\n",
      "Iteration 11238, Loss: 0.05417190492153168\n",
      "Iteration 11239, Loss: 0.053989194333553314\n",
      "Iteration 11240, Loss: 0.05417190119624138\n",
      "Iteration 11241, Loss: 0.0539892315864563\n",
      "Iteration 11242, Loss: 0.054171860218048096\n",
      "Iteration 11243, Loss: 0.05398908257484436\n",
      "Iteration 11244, Loss: 0.05417186766862869\n",
      "Iteration 11245, Loss: 0.053989119827747345\n",
      "Iteration 11246, Loss: 0.05417182669043541\n",
      "Iteration 11247, Loss: 0.053989164531230927\n",
      "Iteration 11248, Loss: 0.05417179316282272\n",
      "Iteration 11249, Loss: 0.053989164531230927\n",
      "Iteration 11250, Loss: 0.05417170375585556\n",
      "Iteration 11251, Loss: 0.05398928374052048\n",
      "Iteration 11252, Loss: 0.05417170375585556\n",
      "Iteration 11253, Loss: 0.053989313542842865\n",
      "Iteration 11254, Loss: 0.054171741008758545\n",
      "Iteration 11255, Loss: 0.05398927628993988\n",
      "Iteration 11256, Loss: 0.05417174845933914\n",
      "Iteration 11257, Loss: 0.053989239037036896\n",
      "Iteration 11258, Loss: 0.05417163297533989\n",
      "Iteration 11259, Loss: 0.05398927256464958\n",
      "Iteration 11260, Loss: 0.054171666502952576\n",
      "Iteration 11261, Loss: 0.053989432752132416\n",
      "Iteration 11262, Loss: 0.05417151376605034\n",
      "Iteration 11263, Loss: 0.05398935079574585\n",
      "Iteration 11264, Loss: 0.05417151376605034\n",
      "Iteration 11265, Loss: 0.05398967117071152\n",
      "Iteration 11266, Loss: 0.05417151004076004\n",
      "Iteration 11267, Loss: 0.053989477455616\n",
      "Iteration 11268, Loss: 0.05417155474424362\n",
      "Iteration 11269, Loss: 0.05398930609226227\n",
      "Iteration 11270, Loss: 0.054171718657016754\n",
      "Iteration 11271, Loss: 0.05398907512426376\n",
      "Iteration 11272, Loss: 0.05417202413082123\n",
      "Iteration 11273, Loss: 0.05398896336555481\n",
      "Iteration 11274, Loss: 0.05417187139391899\n",
      "Iteration 11275, Loss: 0.053989045321941376\n",
      "Iteration 11276, Loss: 0.05417183041572571\n",
      "Iteration 11277, Loss: 0.05398908257484436\n",
      "Iteration 11278, Loss: 0.05417170748114586\n",
      "Iteration 11279, Loss: 0.05398927256464958\n",
      "Iteration 11280, Loss: 0.05417170375585556\n",
      "Iteration 11281, Loss: 0.0539894700050354\n",
      "Iteration 11282, Loss: 0.05417166277766228\n",
      "Iteration 11283, Loss: 0.053989432752132416\n",
      "Iteration 11284, Loss: 0.05417170375585556\n",
      "Iteration 11285, Loss: 0.05398935079574585\n",
      "Iteration 11286, Loss: 0.05417167395353317\n",
      "Iteration 11287, Loss: 0.053989313542842865\n",
      "Iteration 11288, Loss: 0.05417183041572571\n",
      "Iteration 11289, Loss: 0.05398907884955406\n",
      "Iteration 11290, Loss: 0.05417187139391899\n",
      "Iteration 11291, Loss: 0.05398911237716675\n",
      "Iteration 11292, Loss: 0.05417183041572571\n",
      "Iteration 11293, Loss: 0.053989045321941376\n",
      "Iteration 11294, Loss: 0.05417190492153168\n",
      "Iteration 11295, Loss: 0.05398912355303764\n",
      "Iteration 11296, Loss: 0.05417178198695183\n",
      "Iteration 11297, Loss: 0.05398927256464958\n",
      "Iteration 11298, Loss: 0.05417163297533989\n",
      "Iteration 11299, Loss: 0.05398928374052048\n",
      "Iteration 11300, Loss: 0.05417167395353317\n",
      "Iteration 11301, Loss: 0.05398927628993988\n",
      "Iteration 11302, Loss: 0.05417171120643616\n",
      "Iteration 11303, Loss: 0.053989239037036896\n",
      "Iteration 11304, Loss: 0.05417182669043541\n",
      "Iteration 11305, Loss: 0.053989164531230927\n",
      "Iteration 11306, Loss: 0.05417186766862869\n",
      "Iteration 11307, Loss: 0.05398911237716675\n",
      "Iteration 11308, Loss: 0.054171979427337646\n",
      "Iteration 11309, Loss: 0.05398907884955406\n",
      "Iteration 11310, Loss: 0.05417194589972496\n",
      "Iteration 11311, Loss: 0.05398918688297272\n",
      "Iteration 11312, Loss: 0.05417187139391899\n",
      "Iteration 11313, Loss: 0.05398908257484436\n",
      "Iteration 11314, Loss: 0.05417179316282272\n",
      "Iteration 11315, Loss: 0.05398934334516525\n",
      "Iteration 11316, Loss: 0.054171785712242126\n",
      "Iteration 11317, Loss: 0.05398927628993988\n",
      "Iteration 11318, Loss: 0.0541715994477272\n",
      "Iteration 11319, Loss: 0.05398935079574585\n",
      "Iteration 11320, Loss: 0.05417155846953392\n",
      "Iteration 11321, Loss: 0.0539894662797451\n",
      "Iteration 11322, Loss: 0.054171591997146606\n",
      "Iteration 11323, Loss: 0.05398928374052048\n",
      "Iteration 11324, Loss: 0.054171666502952576\n",
      "Iteration 11325, Loss: 0.053989313542842865\n",
      "Iteration 11326, Loss: 0.05417170748114586\n",
      "Iteration 11327, Loss: 0.053989242762327194\n",
      "Iteration 11328, Loss: 0.05417182296514511\n",
      "Iteration 11329, Loss: 0.05398919805884361\n",
      "Iteration 11330, Loss: 0.05417170748114586\n",
      "Iteration 11331, Loss: 0.053989313542842865\n",
      "Iteration 11332, Loss: 0.05417183041572571\n",
      "Iteration 11333, Loss: 0.05398915335536003\n",
      "Iteration 11334, Loss: 0.054171979427337646\n",
      "Iteration 11335, Loss: 0.05398907512426376\n",
      "Iteration 11336, Loss: 0.05417187139391899\n",
      "Iteration 11337, Loss: 0.05398907512426376\n",
      "Iteration 11338, Loss: 0.05417187139391899\n",
      "Iteration 11339, Loss: 0.05398907512426376\n",
      "Iteration 11340, Loss: 0.05417194589972496\n",
      "Iteration 11341, Loss: 0.05398911237716675\n",
      "Iteration 11342, Loss: 0.05417187139391899\n",
      "Iteration 11343, Loss: 0.05398896336555481\n",
      "Iteration 11344, Loss: 0.05417183041572571\n",
      "Iteration 11345, Loss: 0.05398915708065033\n",
      "Iteration 11346, Loss: 0.054171860218048096\n",
      "Iteration 11347, Loss: 0.05398915708065033\n",
      "Iteration 11348, Loss: 0.05417166277766228\n",
      "Iteration 11349, Loss: 0.053989510983228683\n",
      "Iteration 11350, Loss: 0.05417151004076004\n",
      "Iteration 11351, Loss: 0.053989481180906296\n",
      "Iteration 11352, Loss: 0.05417139083147049\n",
      "Iteration 11353, Loss: 0.053989674896001816\n",
      "Iteration 11354, Loss: 0.05417139455676079\n",
      "Iteration 11355, Loss: 0.053989630192518234\n",
      "Iteration 11356, Loss: 0.05417155474424362\n",
      "Iteration 11357, Loss: 0.053989313542842865\n",
      "Iteration 11358, Loss: 0.05417187139391899\n",
      "Iteration 11359, Loss: 0.053989000618457794\n",
      "Iteration 11360, Loss: 0.05417206883430481\n",
      "Iteration 11361, Loss: 0.05398884415626526\n",
      "Iteration 11362, Loss: 0.05417206883430481\n",
      "Iteration 11363, Loss: 0.05398896336555481\n",
      "Iteration 11364, Loss: 0.0541720911860466\n",
      "Iteration 11365, Loss: 0.053989045321941376\n",
      "Iteration 11366, Loss: 0.05417190119624138\n",
      "Iteration 11367, Loss: 0.05398930236697197\n",
      "Iteration 11368, Loss: 0.05417171120643616\n",
      "Iteration 11369, Loss: 0.053989313542842865\n",
      "Iteration 11370, Loss: 0.05417171120643616\n",
      "Iteration 11371, Loss: 0.053989239037036896\n",
      "Iteration 11372, Loss: 0.05417171120643616\n",
      "Iteration 11373, Loss: 0.05398927256464958\n",
      "Iteration 11374, Loss: 0.054171860218048096\n",
      "Iteration 11375, Loss: 0.05398927256464958\n",
      "Iteration 11376, Loss: 0.05417175590991974\n",
      "Iteration 11377, Loss: 0.05398907512426376\n",
      "Iteration 11378, Loss: 0.05417198687791824\n",
      "Iteration 11379, Loss: 0.05398903414607048\n",
      "Iteration 11380, Loss: 0.05417190492153168\n",
      "Iteration 11381, Loss: 0.05398900434374809\n",
      "Iteration 11382, Loss: 0.05417190492153168\n",
      "Iteration 11383, Loss: 0.05398915335536003\n",
      "Iteration 11384, Loss: 0.05417175218462944\n",
      "Iteration 11385, Loss: 0.053989313542842865\n",
      "Iteration 11386, Loss: 0.054171860218048096\n",
      "Iteration 11387, Loss: 0.05398927628993988\n",
      "Iteration 11388, Loss: 0.05417174845933914\n",
      "Iteration 11389, Loss: 0.053989313542842865\n",
      "Iteration 11390, Loss: 0.05417163297533989\n",
      "Iteration 11391, Loss: 0.05398927256464958\n",
      "Iteration 11392, Loss: 0.05417190119624138\n",
      "Iteration 11393, Loss: 0.053989164531230927\n",
      "Iteration 11394, Loss: 0.054171860218048096\n",
      "Iteration 11395, Loss: 0.05398908257484436\n",
      "Iteration 11396, Loss: 0.054171860218048096\n",
      "Iteration 11397, Loss: 0.053989164531230927\n",
      "Iteration 11398, Loss: 0.05417183041572571\n",
      "Iteration 11399, Loss: 0.05398915708065033\n",
      "Iteration 11400, Loss: 0.05417187139391899\n",
      "Iteration 11401, Loss: 0.053989119827747345\n",
      "Iteration 11402, Loss: 0.054171785712242126\n",
      "Iteration 11403, Loss: 0.05398930609226227\n",
      "Iteration 11404, Loss: 0.05417151749134064\n",
      "Iteration 11405, Loss: 0.05398935824632645\n",
      "Iteration 11406, Loss: 0.05417155474424362\n",
      "Iteration 11407, Loss: 0.0539894700050354\n",
      "Iteration 11408, Loss: 0.05417151376605034\n",
      "Iteration 11409, Loss: 0.053989946842193604\n",
      "Iteration 11410, Loss: 0.05417143553495407\n",
      "Iteration 11411, Loss: 0.05399002879858017\n",
      "Iteration 11412, Loss: 0.0541708841919899\n",
      "Iteration 11413, Loss: 0.05399017781019211\n",
      "Iteration 11414, Loss: 0.05417122691869736\n",
      "Iteration 11415, Loss: 0.05398985743522644\n",
      "Iteration 11416, Loss: 0.05417151376605034\n",
      "Iteration 11417, Loss: 0.0539894700050354\n",
      "Iteration 11418, Loss: 0.054171860218048096\n",
      "Iteration 11419, Loss: 0.05398920178413391\n",
      "Iteration 11420, Loss: 0.05417199060320854\n",
      "Iteration 11421, Loss: 0.05398907512426376\n",
      "Iteration 11422, Loss: 0.05417206510901451\n",
      "Iteration 11423, Loss: 0.0539889931678772\n",
      "Iteration 11424, Loss: 0.054172225296497345\n",
      "Iteration 11425, Loss: 0.05398888513445854\n",
      "Iteration 11426, Loss: 0.054172269999980927\n",
      "Iteration 11427, Loss: 0.05398884415626526\n",
      "Iteration 11428, Loss: 0.05417219549417496\n",
      "Iteration 11429, Loss: 0.05398876592516899\n",
      "Iteration 11430, Loss: 0.05417218431830406\n",
      "Iteration 11431, Loss: 0.05398888513445854\n",
      "Iteration 11432, Loss: 0.05417199060320854\n",
      "Iteration 11433, Loss: 0.05398912355303764\n",
      "Iteration 11434, Loss: 0.05417163297533989\n",
      "Iteration 11435, Loss: 0.053989242762327194\n",
      "Iteration 11436, Loss: 0.054171591997146606\n",
      "Iteration 11437, Loss: 0.053989555686712265\n",
      "Iteration 11438, Loss: 0.05417146533727646\n",
      "Iteration 11439, Loss: 0.05398951470851898\n",
      "Iteration 11440, Loss: 0.05417143553495407\n",
      "Iteration 11441, Loss: 0.05398951470851898\n",
      "Iteration 11442, Loss: 0.05417174845933914\n",
      "Iteration 11443, Loss: 0.05398939177393913\n",
      "Iteration 11444, Loss: 0.05417194962501526\n",
      "Iteration 11445, Loss: 0.053989000618457794\n",
      "Iteration 11446, Loss: 0.054172269999980927\n",
      "Iteration 11447, Loss: 0.05398868769407272\n",
      "Iteration 11448, Loss: 0.054172299802303314\n",
      "Iteration 11449, Loss: 0.05398876965045929\n",
      "Iteration 11450, Loss: 0.05417214334011078\n",
      "Iteration 11451, Loss: 0.05398900434374809\n",
      "Iteration 11452, Loss: 0.05417175218462944\n",
      "Iteration 11453, Loss: 0.05398932099342346\n",
      "Iteration 11454, Loss: 0.05417151749134064\n",
      "Iteration 11455, Loss: 0.05398958921432495\n",
      "Iteration 11456, Loss: 0.054171353578567505\n",
      "Iteration 11457, Loss: 0.05398978292942047\n",
      "Iteration 11458, Loss: 0.05417130887508392\n",
      "Iteration 11459, Loss: 0.0539897158741951\n",
      "Iteration 11460, Loss: 0.05417127534747124\n",
      "Iteration 11461, Loss: 0.05398959666490555\n",
      "Iteration 11462, Loss: 0.05417151376605034\n",
      "Iteration 11463, Loss: 0.05398958921432495\n",
      "Iteration 11464, Loss: 0.054171718657016754\n",
      "Iteration 11465, Loss: 0.053989194333553314\n",
      "Iteration 11466, Loss: 0.05417206883430481\n",
      "Iteration 11467, Loss: 0.05398895591497421\n",
      "Iteration 11468, Loss: 0.054172299802303314\n",
      "Iteration 11469, Loss: 0.05398876592516899\n",
      "Iteration 11470, Loss: 0.054172150790691376\n",
      "Iteration 11471, Loss: 0.053988777101039886\n",
      "Iteration 11472, Loss: 0.0541720986366272\n",
      "Iteration 11473, Loss: 0.05398908257484436\n",
      "Iteration 11474, Loss: 0.05417190119624138\n",
      "Iteration 11475, Loss: 0.053989239037036896\n",
      "Iteration 11476, Loss: 0.05417178198695183\n",
      "Iteration 11477, Loss: 0.05398939177393913\n",
      "Iteration 11478, Loss: 0.05417163297533989\n",
      "Iteration 11479, Loss: 0.05398939177393913\n",
      "Iteration 11480, Loss: 0.05417163297533989\n",
      "Iteration 11481, Loss: 0.0539894625544548\n",
      "Iteration 11482, Loss: 0.05417167395353317\n",
      "Iteration 11483, Loss: 0.05398920178413391\n",
      "Iteration 11484, Loss: 0.05417182296514511\n",
      "Iteration 11485, Loss: 0.05398919805884361\n",
      "Iteration 11486, Loss: 0.05417179316282272\n",
      "Iteration 11487, Loss: 0.05398912355303764\n",
      "Iteration 11488, Loss: 0.05417194962501526\n",
      "Iteration 11489, Loss: 0.05398911237716675\n",
      "Iteration 11490, Loss: 0.05417186766862869\n",
      "Iteration 11491, Loss: 0.05398908257484436\n",
      "Iteration 11492, Loss: 0.05417183041572571\n",
      "Iteration 11493, Loss: 0.053989194333553314\n",
      "Iteration 11494, Loss: 0.05417194217443466\n",
      "Iteration 11495, Loss: 0.05398912355303764\n",
      "Iteration 11496, Loss: 0.05417183041572571\n",
      "Iteration 11497, Loss: 0.05398908257484436\n",
      "Iteration 11498, Loss: 0.05417190492153168\n",
      "Iteration 11499, Loss: 0.05398915335536003\n",
      "Iteration 11500, Loss: 0.05417183041572571\n",
      "Iteration 11501, Loss: 0.05398900434374809\n",
      "Iteration 11502, Loss: 0.05417194217443466\n",
      "Iteration 11503, Loss: 0.05398915335536003\n",
      "Iteration 11504, Loss: 0.05417182669043541\n",
      "Iteration 11505, Loss: 0.05398912355303764\n",
      "Iteration 11506, Loss: 0.05417182669043541\n",
      "Iteration 11507, Loss: 0.053989164531230927\n",
      "Iteration 11508, Loss: 0.05417190492153168\n",
      "Iteration 11509, Loss: 0.05398927256464958\n",
      "Iteration 11510, Loss: 0.05417175218462944\n",
      "Iteration 11511, Loss: 0.053989239037036896\n",
      "Iteration 11512, Loss: 0.05417167395353317\n",
      "Iteration 11513, Loss: 0.053989313542842865\n",
      "Iteration 11514, Loss: 0.054171591997146606\n",
      "Iteration 11515, Loss: 0.05398920178413391\n",
      "Iteration 11516, Loss: 0.05417171120643616\n",
      "Iteration 11517, Loss: 0.05398927628993988\n",
      "Iteration 11518, Loss: 0.05417175590991974\n",
      "Iteration 11519, Loss: 0.05398908257484436\n",
      "Iteration 11520, Loss: 0.05417187139391899\n",
      "Iteration 11521, Loss: 0.05398900434374809\n",
      "Iteration 11522, Loss: 0.05417194962501526\n",
      "Iteration 11523, Loss: 0.053988974541425705\n",
      "Iteration 11524, Loss: 0.05417183041572571\n",
      "Iteration 11525, Loss: 0.05398912355303764\n",
      "Iteration 11526, Loss: 0.05417190119624138\n",
      "Iteration 11527, Loss: 0.05398920178413391\n",
      "Iteration 11528, Loss: 0.054171741008758545\n",
      "Iteration 11529, Loss: 0.05398928374052048\n",
      "Iteration 11530, Loss: 0.054171666502952576\n",
      "Iteration 11531, Loss: 0.05398935824632645\n",
      "Iteration 11532, Loss: 0.05417168140411377\n",
      "Iteration 11533, Loss: 0.05398927628993988\n",
      "Iteration 11534, Loss: 0.05417175218462944\n",
      "Iteration 11535, Loss: 0.053989119827747345\n",
      "Iteration 11536, Loss: 0.054171882569789886\n",
      "Iteration 11537, Loss: 0.053988926112651825\n",
      "Iteration 11538, Loss: 0.05417202413082123\n",
      "Iteration 11539, Loss: 0.05398896336555481\n",
      "Iteration 11540, Loss: 0.05417187139391899\n",
      "Iteration 11541, Loss: 0.0539892315864563\n",
      "Iteration 11542, Loss: 0.054171591997146606\n",
      "Iteration 11543, Loss: 0.0539894700050354\n",
      "Iteration 11544, Loss: 0.05417143926024437\n",
      "Iteration 11545, Loss: 0.05398952215909958\n",
      "Iteration 11546, Loss: 0.05417132377624512\n",
      "Iteration 11547, Loss: 0.05398958921432495\n",
      "Iteration 11548, Loss: 0.05417148396372795\n",
      "Iteration 11549, Loss: 0.05398940294981003\n",
      "Iteration 11550, Loss: 0.054171591997146606\n",
      "Iteration 11551, Loss: 0.05398928374052048\n",
      "Iteration 11552, Loss: 0.05417175218462944\n",
      "Iteration 11553, Loss: 0.05398912355303764\n",
      "Iteration 11554, Loss: 0.05417199060320854\n",
      "Iteration 11555, Loss: 0.05398888513445854\n",
      "Iteration 11556, Loss: 0.054172031581401825\n",
      "Iteration 11557, Loss: 0.05398888885974884\n",
      "Iteration 11558, Loss: 0.054171979427337646\n",
      "Iteration 11559, Loss: 0.05398915708065033\n",
      "Iteration 11560, Loss: 0.05417175218462944\n",
      "Iteration 11561, Loss: 0.053989313542842865\n",
      "Iteration 11562, Loss: 0.054171591997146606\n",
      "Iteration 11563, Loss: 0.05398955196142197\n",
      "Iteration 11564, Loss: 0.05417124554514885\n",
      "Iteration 11565, Loss: 0.0539897084236145\n",
      "Iteration 11566, Loss: 0.05417127534747124\n",
      "Iteration 11567, Loss: 0.053989749401807785\n",
      "Iteration 11568, Loss: 0.05417143553495407\n",
      "Iteration 11569, Loss: 0.053989510983228683\n",
      "Iteration 11570, Loss: 0.054171524941921234\n",
      "Iteration 11571, Loss: 0.05398928374052048\n",
      "Iteration 11572, Loss: 0.054171718657016754\n",
      "Iteration 11573, Loss: 0.05398919805884361\n",
      "Iteration 11574, Loss: 0.05417187139391899\n",
      "Iteration 11575, Loss: 0.053989045321941376\n",
      "Iteration 11576, Loss: 0.05417194589972496\n",
      "Iteration 11577, Loss: 0.05398911237716675\n",
      "Iteration 11578, Loss: 0.05417186766862869\n",
      "Iteration 11579, Loss: 0.053989045321941376\n",
      "Iteration 11580, Loss: 0.05417175218462944\n",
      "Iteration 11581, Loss: 0.05398912355303764\n",
      "Iteration 11582, Loss: 0.05417175218462944\n",
      "Iteration 11583, Loss: 0.05398927628993988\n",
      "Iteration 11584, Loss: 0.05417179316282272\n",
      "Iteration 11585, Loss: 0.053989194333553314\n",
      "Iteration 11586, Loss: 0.05417175218462944\n",
      "Iteration 11587, Loss: 0.053989164531230927\n",
      "Iteration 11588, Loss: 0.05417179688811302\n",
      "Iteration 11589, Loss: 0.05398915708065033\n",
      "Iteration 11590, Loss: 0.05417183041572571\n",
      "Iteration 11591, Loss: 0.05398915335536003\n",
      "Iteration 11592, Loss: 0.05417187139391899\n",
      "Iteration 11593, Loss: 0.053989194333553314\n",
      "Iteration 11594, Loss: 0.05417183041572571\n",
      "Iteration 11595, Loss: 0.05398908257484436\n",
      "Iteration 11596, Loss: 0.05417175218462944\n",
      "Iteration 11597, Loss: 0.053989164531230927\n",
      "Iteration 11598, Loss: 0.05417170748114586\n",
      "Iteration 11599, Loss: 0.05398928374052048\n",
      "Iteration 11600, Loss: 0.05417170375585556\n",
      "Iteration 11601, Loss: 0.05398932844400406\n",
      "Iteration 11602, Loss: 0.05417155474424362\n",
      "Iteration 11603, Loss: 0.05398932099342346\n",
      "Iteration 11604, Loss: 0.05417170748114586\n",
      "Iteration 11605, Loss: 0.05398920178413391\n",
      "Iteration 11606, Loss: 0.05417168140411377\n",
      "Iteration 11607, Loss: 0.05398909002542496\n",
      "Iteration 11608, Loss: 0.05417179316282272\n",
      "Iteration 11609, Loss: 0.05398909002542496\n",
      "Iteration 11610, Loss: 0.05417179316282272\n",
      "Iteration 11611, Loss: 0.05398905277252197\n",
      "Iteration 11612, Loss: 0.05417171120643616\n",
      "Iteration 11613, Loss: 0.053989168256521225\n",
      "Iteration 11614, Loss: 0.054171666502952576\n",
      "Iteration 11615, Loss: 0.05398944020271301\n",
      "Iteration 11616, Loss: 0.05417155474424362\n",
      "Iteration 11617, Loss: 0.05398939549922943\n",
      "Iteration 11618, Loss: 0.05417163297533989\n",
      "Iteration 11619, Loss: 0.053989168256521225\n",
      "Iteration 11620, Loss: 0.05417168140411377\n",
      "Iteration 11621, Loss: 0.05398909002542496\n",
      "Iteration 11622, Loss: 0.05417179316282272\n",
      "Iteration 11623, Loss: 0.053989164531230927\n",
      "Iteration 11624, Loss: 0.05417186766862869\n",
      "Iteration 11625, Loss: 0.05398919805884361\n",
      "Iteration 11626, Loss: 0.05417175590991974\n",
      "Iteration 11627, Loss: 0.05398908257484436\n",
      "Iteration 11628, Loss: 0.05417182669043541\n",
      "Iteration 11629, Loss: 0.053988974541425705\n",
      "Iteration 11630, Loss: 0.05417182669043541\n",
      "Iteration 11631, Loss: 0.05398893356323242\n",
      "Iteration 11632, Loss: 0.05417168140411377\n",
      "Iteration 11633, Loss: 0.053988974541425705\n",
      "Iteration 11634, Loss: 0.05417171120643616\n",
      "Iteration 11635, Loss: 0.053989242762327194\n",
      "Iteration 11636, Loss: 0.05417167395353317\n",
      "Iteration 11637, Loss: 0.053989361971616745\n",
      "Iteration 11638, Loss: 0.05417148396372795\n",
      "Iteration 11639, Loss: 0.05398924648761749\n",
      "Iteration 11640, Loss: 0.05417163297533989\n",
      "Iteration 11641, Loss: 0.05398901551961899\n",
      "Iteration 11642, Loss: 0.054171837866306305\n",
      "Iteration 11643, Loss: 0.05398896336555481\n",
      "Iteration 11644, Loss: 0.05417187139391899\n",
      "Iteration 11645, Loss: 0.053989049047231674\n",
      "Iteration 11646, Loss: 0.054171785712242126\n",
      "Iteration 11647, Loss: 0.05398917198181152\n",
      "Iteration 11648, Loss: 0.054171524941921234\n",
      "Iteration 11649, Loss: 0.05398940294981003\n",
      "Iteration 11650, Loss: 0.05417140573263168\n",
      "Iteration 11651, Loss: 0.05398940294981003\n",
      "Iteration 11652, Loss: 0.05417139455676079\n",
      "Iteration 11653, Loss: 0.05398940294981003\n",
      "Iteration 11654, Loss: 0.054171472787857056\n",
      "Iteration 11655, Loss: 0.05398933216929436\n",
      "Iteration 11656, Loss: 0.05417144298553467\n",
      "Iteration 11657, Loss: 0.05398928374052048\n",
      "Iteration 11658, Loss: 0.05417171120643616\n",
      "Iteration 11659, Loss: 0.05398920923471451\n",
      "Iteration 11660, Loss: 0.05417194962501526\n",
      "Iteration 11661, Loss: 0.05398881062865257\n",
      "Iteration 11662, Loss: 0.05417210981249809\n",
      "Iteration 11663, Loss: 0.05398861691355705\n",
      "Iteration 11664, Loss: 0.054171960800886154\n",
      "Iteration 11665, Loss: 0.0539887361228466\n",
      "Iteration 11666, Loss: 0.054171837866306305\n",
      "Iteration 11667, Loss: 0.05398905277252197\n",
      "Iteration 11668, Loss: 0.05417163297533989\n",
      "Iteration 11669, Loss: 0.05398932099342346\n",
      "Iteration 11670, Loss: 0.054171472787857056\n",
      "Iteration 11671, Loss: 0.05398952588438988\n",
      "Iteration 11672, Loss: 0.05417124181985855\n",
      "Iteration 11673, Loss: 0.053989678621292114\n",
      "Iteration 11674, Loss: 0.054171204566955566\n",
      "Iteration 11675, Loss: 0.05398964136838913\n",
      "Iteration 11676, Loss: 0.05417129024863243\n",
      "Iteration 11677, Loss: 0.05398935079574585\n",
      "Iteration 11678, Loss: 0.0541716031730175\n",
      "Iteration 11679, Loss: 0.05398912355303764\n",
      "Iteration 11680, Loss: 0.05417167767882347\n",
      "Iteration 11681, Loss: 0.053989049047231674\n",
      "Iteration 11682, Loss: 0.05417179316282272\n",
      "Iteration 11683, Loss: 0.053989049047231674\n",
      "Iteration 11684, Loss: 0.05417171120643616\n",
      "Iteration 11685, Loss: 0.053988974541425705\n",
      "Iteration 11686, Loss: 0.05417167767882347\n",
      "Iteration 11687, Loss: 0.05398905277252197\n",
      "Iteration 11688, Loss: 0.05417167395353317\n",
      "Iteration 11689, Loss: 0.05398928374052048\n",
      "Iteration 11690, Loss: 0.054171524941921234\n",
      "Iteration 11691, Loss: 0.05398932844400406\n",
      "Iteration 11692, Loss: 0.05417144298553467\n",
      "Iteration 11693, Loss: 0.053989287465810776\n",
      "Iteration 11694, Loss: 0.05417152866721153\n",
      "Iteration 11695, Loss: 0.053989164531230927\n",
      "Iteration 11696, Loss: 0.05417171120643616\n",
      "Iteration 11697, Loss: 0.05398905277252197\n",
      "Iteration 11698, Loss: 0.054171718657016754\n",
      "Iteration 11699, Loss: 0.05398900806903839\n",
      "Iteration 11700, Loss: 0.05417183041572571\n",
      "Iteration 11701, Loss: 0.05398901551961899\n",
      "Iteration 11702, Loss: 0.05417175218462944\n",
      "Iteration 11703, Loss: 0.05398920178413391\n",
      "Iteration 11704, Loss: 0.054171524941921234\n",
      "Iteration 11705, Loss: 0.05398920923471451\n",
      "Iteration 11706, Loss: 0.05417148396372795\n",
      "Iteration 11707, Loss: 0.05398928374052048\n",
      "Iteration 11708, Loss: 0.05417151749134064\n",
      "Iteration 11709, Loss: 0.05398932099342346\n",
      "Iteration 11710, Loss: 0.05417144298553467\n",
      "Iteration 11711, Loss: 0.05398932844400406\n",
      "Iteration 11712, Loss: 0.05417140573263168\n",
      "Iteration 11713, Loss: 0.05398924648761749\n",
      "Iteration 11714, Loss: 0.05417155846953392\n",
      "Iteration 11715, Loss: 0.05398924648761749\n",
      "Iteration 11716, Loss: 0.05417155474424362\n",
      "Iteration 11717, Loss: 0.053989093750715256\n",
      "Iteration 11718, Loss: 0.054171524941921234\n",
      "Iteration 11719, Loss: 0.053989212960004807\n",
      "Iteration 11720, Loss: 0.054171472787857056\n",
      "Iteration 11721, Loss: 0.05398944020271301\n",
      "Iteration 11722, Loss: 0.054171204566955566\n",
      "Iteration 11723, Loss: 0.05398963391780853\n",
      "Iteration 11724, Loss: 0.054171234369277954\n",
      "Iteration 11725, Loss: 0.05398964136838913\n",
      "Iteration 11726, Loss: 0.054171279072761536\n",
      "Iteration 11727, Loss: 0.05398967117071152\n",
      "Iteration 11728, Loss: 0.0541713647544384\n",
      "Iteration 11729, Loss: 0.05398932099342346\n",
      "Iteration 11730, Loss: 0.05417148768901825\n",
      "Iteration 11731, Loss: 0.05398909002542496\n",
      "Iteration 11732, Loss: 0.054171763360500336\n",
      "Iteration 11733, Loss: 0.05398893356323242\n",
      "Iteration 11734, Loss: 0.05417180061340332\n",
      "Iteration 11735, Loss: 0.05398889631032944\n",
      "Iteration 11736, Loss: 0.05417175218462944\n",
      "Iteration 11737, Loss: 0.053989164531230927\n",
      "Iteration 11738, Loss: 0.05417148396372795\n",
      "Iteration 11739, Loss: 0.05398932844400406\n",
      "Iteration 11740, Loss: 0.05417124554514885\n",
      "Iteration 11741, Loss: 0.053989559412002563\n",
      "Iteration 11742, Loss: 0.054171204566955566\n",
      "Iteration 11743, Loss: 0.05398957058787346\n",
      "Iteration 11744, Loss: 0.054171204566955566\n",
      "Iteration 11745, Loss: 0.05398959666490555\n",
      "Iteration 11746, Loss: 0.05417139455676079\n",
      "Iteration 11747, Loss: 0.05398944020271301\n",
      "Iteration 11748, Loss: 0.054171591997146606\n",
      "Iteration 11749, Loss: 0.053989168256521225\n",
      "Iteration 11750, Loss: 0.05417167395353317\n",
      "Iteration 11751, Loss: 0.05398909002542496\n",
      "Iteration 11752, Loss: 0.05417183041572571\n",
      "Iteration 11753, Loss: 0.05398893356323242\n",
      "Iteration 11754, Loss: 0.05417175218462944\n",
      "Iteration 11755, Loss: 0.05398894101381302\n",
      "Iteration 11756, Loss: 0.0541715994477272\n",
      "Iteration 11757, Loss: 0.053989242762327194\n",
      "Iteration 11758, Loss: 0.05417144298553467\n",
      "Iteration 11759, Loss: 0.05398944020271301\n",
      "Iteration 11760, Loss: 0.05417128652334213\n",
      "Iteration 11761, Loss: 0.05398957058787346\n",
      "Iteration 11762, Loss: 0.054171122610569\n",
      "Iteration 11763, Loss: 0.0539897195994854\n",
      "Iteration 11764, Loss: 0.054170891642570496\n",
      "Iteration 11765, Loss: 0.05398979410529137\n",
      "Iteration 11766, Loss: 0.05417100712656975\n",
      "Iteration 11767, Loss: 0.05398963391780853\n",
      "Iteration 11768, Loss: 0.05417116731405258\n",
      "Iteration 11769, Loss: 0.05398963391780853\n",
      "Iteration 11770, Loss: 0.05417124554514885\n",
      "Iteration 11771, Loss: 0.05398944020271301\n",
      "Iteration 11772, Loss: 0.05417148023843765\n",
      "Iteration 11773, Loss: 0.053989287465810776\n",
      "Iteration 11774, Loss: 0.054171524941921234\n",
      "Iteration 11775, Loss: 0.053989242762327194\n",
      "Iteration 11776, Loss: 0.05417167395353317\n",
      "Iteration 11777, Loss: 0.05398905277252197\n",
      "Iteration 11778, Loss: 0.05417163297533989\n",
      "Iteration 11779, Loss: 0.05398920923471451\n",
      "Iteration 11780, Loss: 0.054171524941921234\n",
      "Iteration 11781, Loss: 0.05398917198181152\n",
      "Iteration 11782, Loss: 0.05417148396372795\n",
      "Iteration 11783, Loss: 0.05398913472890854\n",
      "Iteration 11784, Loss: 0.05417151749134064\n",
      "Iteration 11785, Loss: 0.05398920923471451\n",
      "Iteration 11786, Loss: 0.05417143926024437\n",
      "Iteration 11787, Loss: 0.05398924648761749\n",
      "Iteration 11788, Loss: 0.05417143926024437\n",
      "Iteration 11789, Loss: 0.05398936569690704\n",
      "Iteration 11790, Loss: 0.0541713610291481\n",
      "Iteration 11791, Loss: 0.05398960039019585\n",
      "Iteration 11792, Loss: 0.05417128652334213\n",
      "Iteration 11793, Loss: 0.05398952215909958\n",
      "Iteration 11794, Loss: 0.05417132377624512\n",
      "Iteration 11795, Loss: 0.053989291191101074\n",
      "Iteration 11796, Loss: 0.054171644151210785\n",
      "Iteration 11797, Loss: 0.05398920178413391\n",
      "Iteration 11798, Loss: 0.05417171120643616\n",
      "Iteration 11799, Loss: 0.053989168256521225\n",
      "Iteration 11800, Loss: 0.0541715994477272\n",
      "Iteration 11801, Loss: 0.05398905277252197\n",
      "Iteration 11802, Loss: 0.0541715994477272\n",
      "Iteration 11803, Loss: 0.053989093750715256\n",
      "Iteration 11804, Loss: 0.05417148023843765\n",
      "Iteration 11805, Loss: 0.05398937314748764\n",
      "Iteration 11806, Loss: 0.05417143553495407\n",
      "Iteration 11807, Loss: 0.053989410400390625\n",
      "Iteration 11808, Loss: 0.05417127534747124\n",
      "Iteration 11809, Loss: 0.05398960039019585\n",
      "Iteration 11810, Loss: 0.0541711263358593\n",
      "Iteration 11811, Loss: 0.053989678621292114\n",
      "Iteration 11812, Loss: 0.0541711151599884\n",
      "Iteration 11813, Loss: 0.05398976057767868\n",
      "Iteration 11814, Loss: 0.054171085357666016\n",
      "Iteration 11815, Loss: 0.053989674896001816\n",
      "Iteration 11816, Loss: 0.05417121201753616\n",
      "Iteration 11817, Loss: 0.05398940294981003\n",
      "Iteration 11818, Loss: 0.05417148396372795\n",
      "Iteration 11819, Loss: 0.053989164531230927\n",
      "Iteration 11820, Loss: 0.05417179688811302\n",
      "Iteration 11821, Loss: 0.05398900806903839\n",
      "Iteration 11822, Loss: 0.05417187511920929\n",
      "Iteration 11823, Loss: 0.05398892983794212\n",
      "Iteration 11824, Loss: 0.054171912372112274\n",
      "Iteration 11825, Loss: 0.05398885905742645\n",
      "Iteration 11826, Loss: 0.05417172238230705\n",
      "Iteration 11827, Loss: 0.053988974541425705\n",
      "Iteration 11828, Loss: 0.05417156219482422\n",
      "Iteration 11829, Loss: 0.053988587111234665\n",
      "Iteration 11830, Loss: 0.05417155846953392\n",
      "Iteration 11831, Loss: 0.05398866534233093\n",
      "Iteration 11832, Loss: 0.054170817136764526\n",
      "Iteration 11833, Loss: 0.053988706320524216\n",
      "Iteration 11834, Loss: 0.05417073890566826\n",
      "Iteration 11835, Loss: 0.0539887398481369\n",
      "Iteration 11836, Loss: 0.054170817136764526\n",
      "Iteration 11837, Loss: 0.053988583385944366\n",
      "Iteration 11838, Loss: 0.05417093634605408\n",
      "Iteration 11839, Loss: 0.053988467901945114\n",
      "Iteration 11840, Loss: 0.054170869290828705\n",
      "Iteration 11841, Loss: 0.05398854613304138\n",
      "Iteration 11842, Loss: 0.05417082831263542\n",
      "Iteration 11843, Loss: 0.0539885088801384\n",
      "Iteration 11844, Loss: 0.05417082458734512\n",
      "Iteration 11845, Loss: 0.05398862808942795\n",
      "Iteration 11846, Loss: 0.05417078733444214\n",
      "Iteration 11847, Loss: 0.053988587111234665\n",
      "Iteration 11848, Loss: 0.05417082458734512\n",
      "Iteration 11849, Loss: 0.053988516330718994\n",
      "Iteration 11850, Loss: 0.05417078733444214\n",
      "Iteration 11851, Loss: 0.0539885088801384\n",
      "Iteration 11852, Loss: 0.05417090281844139\n",
      "Iteration 11853, Loss: 0.05398842692375183\n",
      "Iteration 11854, Loss: 0.054171137511730194\n",
      "Iteration 11855, Loss: 0.053988199681043625\n",
      "Iteration 11856, Loss: 0.05417121946811676\n",
      "Iteration 11857, Loss: 0.053988151252269745\n",
      "Iteration 11858, Loss: 0.054171375930309296\n",
      "Iteration 11859, Loss: 0.05398810654878616\n",
      "Iteration 11860, Loss: 0.054171256721019745\n",
      "Iteration 11861, Loss: 0.053988151252269745\n",
      "Iteration 11862, Loss: 0.05417117476463318\n",
      "Iteration 11863, Loss: 0.05398834869265556\n",
      "Iteration 11864, Loss: 0.05417093634605408\n",
      "Iteration 11865, Loss: 0.05398861691355705\n",
      "Iteration 11866, Loss: 0.05417073890566826\n",
      "Iteration 11867, Loss: 0.053988706320524216\n",
      "Iteration 11868, Loss: 0.054170578718185425\n",
      "Iteration 11869, Loss: 0.053988825529813766\n",
      "Iteration 11870, Loss: 0.05417051166296005\n",
      "Iteration 11871, Loss: 0.053988825529813766\n",
      "Iteration 11872, Loss: 0.05417070910334587\n",
      "Iteration 11873, Loss: 0.05398869514465332\n",
      "Iteration 11874, Loss: 0.05417090654373169\n",
      "Iteration 11875, Loss: 0.053988467901945114\n",
      "Iteration 11876, Loss: 0.05417101830244064\n",
      "Iteration 11877, Loss: 0.05398835241794586\n",
      "Iteration 11878, Loss: 0.05417105555534363\n",
      "Iteration 11879, Loss: 0.05398835241794586\n",
      "Iteration 11880, Loss: 0.054171137511730194\n",
      "Iteration 11881, Loss: 0.05398835241794586\n",
      "Iteration 11882, Loss: 0.05417102202773094\n",
      "Iteration 11883, Loss: 0.053988464176654816\n",
      "Iteration 11884, Loss: 0.05417109653353691\n",
      "Iteration 11885, Loss: 0.05398835241794586\n",
      "Iteration 11886, Loss: 0.05417109653353691\n",
      "Iteration 11887, Loss: 0.053988389670848846\n",
      "Iteration 11888, Loss: 0.05417109653353691\n",
      "Iteration 11889, Loss: 0.053988199681043625\n",
      "Iteration 11890, Loss: 0.05417105555534363\n",
      "Iteration 11891, Loss: 0.053988318890333176\n",
      "Iteration 11892, Loss: 0.05417105183005333\n",
      "Iteration 11893, Loss: 0.05398854613304138\n",
      "Iteration 11894, Loss: 0.05417089909315109\n",
      "Iteration 11895, Loss: 0.0539885088801384\n",
      "Iteration 11896, Loss: 0.05417093262076378\n",
      "Iteration 11897, Loss: 0.05398866534233093\n",
      "Iteration 11898, Loss: 0.054170750081539154\n",
      "Iteration 11899, Loss: 0.053988661617040634\n",
      "Iteration 11900, Loss: 0.05417070910334587\n",
      "Iteration 11901, Loss: 0.053988657891750336\n",
      "Iteration 11902, Loss: 0.05417089909315109\n",
      "Iteration 11903, Loss: 0.05398861691355705\n",
      "Iteration 11904, Loss: 0.05417101830244064\n",
      "Iteration 11905, Loss: 0.05398834869265556\n",
      "Iteration 11906, Loss: 0.05417106673121452\n",
      "Iteration 11907, Loss: 0.053988151252269745\n",
      "Iteration 11908, Loss: 0.05417114496231079\n",
      "Iteration 11909, Loss: 0.05398818850517273\n",
      "Iteration 11910, Loss: 0.05417117103934288\n",
      "Iteration 11911, Loss: 0.05398834869265556\n",
      "Iteration 11912, Loss: 0.05417097732424736\n",
      "Iteration 11913, Loss: 0.053988512605428696\n",
      "Iteration 11914, Loss: 0.05417073890566826\n",
      "Iteration 11915, Loss: 0.053988706320524216\n",
      "Iteration 11916, Loss: 0.05417066439986229\n",
      "Iteration 11917, Loss: 0.053988706320524216\n",
      "Iteration 11918, Loss: 0.05417070537805557\n",
      "Iteration 11919, Loss: 0.05398862808942795\n",
      "Iteration 11920, Loss: 0.05417085811495781\n",
      "Iteration 11921, Loss: 0.05398866534233093\n",
      "Iteration 11922, Loss: 0.05417097732424736\n",
      "Iteration 11923, Loss: 0.05398854613304138\n",
      "Iteration 11924, Loss: 0.054171063005924225\n",
      "Iteration 11925, Loss: 0.05398830398917198\n",
      "Iteration 11926, Loss: 0.054171185940504074\n",
      "Iteration 11927, Loss: 0.05398811027407646\n",
      "Iteration 11928, Loss: 0.054171256721019745\n",
      "Iteration 11929, Loss: 0.05398822948336601\n",
      "Iteration 11930, Loss: 0.05417109653353691\n",
      "Iteration 11931, Loss: 0.05398834869265556\n",
      "Iteration 11932, Loss: 0.05417089909315109\n",
      "Iteration 11933, Loss: 0.05398866534233093\n",
      "Iteration 11934, Loss: 0.05417066067457199\n",
      "Iteration 11935, Loss: 0.05398882180452347\n",
      "Iteration 11936, Loss: 0.05417051166296005\n",
      "Iteration 11937, Loss: 0.0539887472987175\n",
      "Iteration 11938, Loss: 0.05417066812515259\n",
      "Iteration 11939, Loss: 0.05398854613304138\n",
      "Iteration 11940, Loss: 0.05417082831263542\n",
      "Iteration 11941, Loss: 0.053988464176654816\n",
      "Iteration 11942, Loss: 0.054171063005924225\n",
      "Iteration 11943, Loss: 0.05398830771446228\n",
      "Iteration 11944, Loss: 0.054171137511730194\n",
      "Iteration 11945, Loss: 0.05398834869265556\n",
      "Iteration 11946, Loss: 0.05417117476463318\n",
      "Iteration 11947, Loss: 0.05398830771446228\n",
      "Iteration 11948, Loss: 0.054171137511730194\n",
      "Iteration 11949, Loss: 0.053988389670848846\n",
      "Iteration 11950, Loss: 0.05417101830244064\n",
      "Iteration 11951, Loss: 0.053988389670848846\n",
      "Iteration 11952, Loss: 0.05417086184024811\n",
      "Iteration 11953, Loss: 0.05398854613304138\n",
      "Iteration 11954, Loss: 0.05417093634605408\n",
      "Iteration 11955, Loss: 0.053988467901945114\n",
      "Iteration 11956, Loss: 0.05417101830244064\n",
      "Iteration 11957, Loss: 0.0539885088801384\n",
      "Iteration 11958, Loss: 0.05417097732424736\n",
      "Iteration 11959, Loss: 0.05398845672607422\n",
      "Iteration 11960, Loss: 0.054171063005924225\n",
      "Iteration 11961, Loss: 0.05398830771446228\n",
      "Iteration 11962, Loss: 0.05417109280824661\n",
      "Iteration 11963, Loss: 0.053988318890333176\n",
      "Iteration 11964, Loss: 0.05417097359895706\n",
      "Iteration 11965, Loss: 0.05398839712142944\n",
      "Iteration 11966, Loss: 0.05417077988386154\n",
      "Iteration 11967, Loss: 0.05398867279291153\n",
      "Iteration 11968, Loss: 0.054170697927474976\n",
      "Iteration 11969, Loss: 0.05398886650800705\n",
      "Iteration 11970, Loss: 0.054170697927474976\n",
      "Iteration 11971, Loss: 0.05398881435394287\n",
      "Iteration 11972, Loss: 0.05417073890566826\n",
      "Iteration 11973, Loss: 0.0539887398481369\n",
      "Iteration 11974, Loss: 0.05417085811495781\n",
      "Iteration 11975, Loss: 0.05398861691355705\n",
      "Iteration 11976, Loss: 0.05417105183005333\n",
      "Iteration 11977, Loss: 0.053988389670848846\n",
      "Iteration 11978, Loss: 0.05417124554514885\n",
      "Iteration 11979, Loss: 0.05398815497756004\n",
      "Iteration 11980, Loss: 0.05417121574282646\n",
      "Iteration 11981, Loss: 0.053988270461559296\n",
      "Iteration 11982, Loss: 0.05417117476463318\n",
      "Iteration 11983, Loss: 0.053988274186849594\n",
      "Iteration 11984, Loss: 0.05417104810476303\n",
      "Iteration 11985, Loss: 0.053988512605428696\n",
      "Iteration 11986, Loss: 0.05417077988386154\n",
      "Iteration 11987, Loss: 0.05398881435394287\n",
      "Iteration 11988, Loss: 0.05417058989405632\n",
      "Iteration 11989, Loss: 0.05398886650800705\n",
      "Iteration 11990, Loss: 0.05417054146528244\n",
      "Iteration 11991, Loss: 0.05398878455162048\n",
      "Iteration 11992, Loss: 0.054170697927474976\n",
      "Iteration 11993, Loss: 0.0539887398481369\n",
      "Iteration 11994, Loss: 0.05417089909315109\n",
      "Iteration 11995, Loss: 0.05398854613304138\n",
      "Iteration 11996, Loss: 0.054170988500118256\n",
      "Iteration 11997, Loss: 0.05398842692375183\n",
      "Iteration 11998, Loss: 0.0541713647544384\n",
      "Iteration 11999, Loss: 0.053988151252269745\n",
      "Iteration 12000, Loss: 0.05417141318321228\n",
      "Iteration 12001, Loss: 0.05398806929588318\n",
      "Iteration 12002, Loss: 0.05417133495211601\n",
      "Iteration 12003, Loss: 0.05398822948336601\n",
      "Iteration 12004, Loss: 0.0541711300611496\n",
      "Iteration 12005, Loss: 0.0539885088801384\n",
      "Iteration 12006, Loss: 0.054170817136764526\n",
      "Iteration 12007, Loss: 0.05398859828710556\n",
      "Iteration 12008, Loss: 0.05417066439986229\n",
      "Iteration 12009, Loss: 0.053988825529813766\n",
      "Iteration 12010, Loss: 0.0541706308722496\n",
      "Iteration 12011, Loss: 0.05398866534233093\n",
      "Iteration 12012, Loss: 0.05417089909315109\n",
      "Iteration 12013, Loss: 0.053988538682460785\n",
      "Iteration 12014, Loss: 0.05417102202773094\n",
      "Iteration 12015, Loss: 0.05398830771446228\n",
      "Iteration 12016, Loss: 0.054171256721019745\n",
      "Iteration 12017, Loss: 0.05398811399936676\n",
      "Iteration 12018, Loss: 0.054171256721019745\n",
      "Iteration 12019, Loss: 0.05398812144994736\n",
      "Iteration 12020, Loss: 0.05417121574282646\n",
      "Iteration 12021, Loss: 0.053987711668014526\n",
      "Iteration 12022, Loss: 0.05417124927043915\n",
      "Iteration 12023, Loss: 0.05398748442530632\n",
      "Iteration 12024, Loss: 0.054171930998563766\n",
      "Iteration 12025, Loss: 0.05398762971162796\n",
      "Iteration 12026, Loss: 0.05417173355817795\n",
      "Iteration 12027, Loss: 0.05398771911859512\n",
      "Iteration 12028, Loss: 0.05417140945792198\n",
      "Iteration 12029, Loss: 0.05398811027407646\n",
      "Iteration 12030, Loss: 0.05417105555534363\n",
      "Iteration 12031, Loss: 0.05398842692375183\n",
      "Iteration 12032, Loss: 0.05417066812515259\n",
      "Iteration 12033, Loss: 0.053988583385944366\n",
      "Iteration 12034, Loss: 0.05417073890566826\n",
      "Iteration 12035, Loss: 0.05398869514465332\n",
      "Iteration 12036, Loss: 0.05417073890566826\n",
      "Iteration 12037, Loss: 0.053988732397556305\n",
      "Iteration 12038, Loss: 0.05417073890566826\n",
      "Iteration 12039, Loss: 0.05398869141936302\n",
      "Iteration 12040, Loss: 0.05417074263095856\n",
      "Iteration 12041, Loss: 0.053988538682460785\n",
      "Iteration 12042, Loss: 0.05417078733444214\n",
      "Iteration 12043, Loss: 0.05398834869265556\n",
      "Iteration 12044, Loss: 0.05417105555534363\n",
      "Iteration 12045, Loss: 0.053988270461559296\n",
      "Iteration 12046, Loss: 0.05417109653353691\n",
      "Iteration 12047, Loss: 0.053988225758075714\n",
      "Iteration 12048, Loss: 0.05417117476463318\n",
      "Iteration 12049, Loss: 0.05398806929588318\n",
      "Iteration 12050, Loss: 0.054171256721019745\n",
      "Iteration 12051, Loss: 0.05398806929588318\n",
      "Iteration 12052, Loss: 0.05417101830244064\n",
      "Iteration 12053, Loss: 0.05398833751678467\n",
      "Iteration 12054, Loss: 0.05417097732424736\n",
      "Iteration 12055, Loss: 0.05398845672607422\n",
      "Iteration 12056, Loss: 0.05417093262076378\n",
      "Iteration 12057, Loss: 0.05398845672607422\n",
      "Iteration 12058, Loss: 0.054170817136764526\n",
      "Iteration 12059, Loss: 0.05398857593536377\n",
      "Iteration 12060, Loss: 0.05417077988386154\n",
      "Iteration 12061, Loss: 0.05398857593536377\n",
      "Iteration 12062, Loss: 0.05417070537805557\n",
      "Iteration 12063, Loss: 0.05398854240775108\n",
      "Iteration 12064, Loss: 0.054170817136764526\n",
      "Iteration 12065, Loss: 0.0539884977042675\n",
      "Iteration 12066, Loss: 0.054170869290828705\n",
      "Iteration 12067, Loss: 0.053988344967365265\n",
      "Iteration 12068, Loss: 0.05417105555534363\n",
      "Iteration 12069, Loss: 0.0539884939789772\n",
      "Iteration 12070, Loss: 0.05417093634605408\n",
      "Iteration 12071, Loss: 0.05398834869265556\n",
      "Iteration 12072, Loss: 0.05417093634605408\n",
      "Iteration 12073, Loss: 0.053988467901945114\n",
      "Iteration 12074, Loss: 0.05417093262076378\n",
      "Iteration 12075, Loss: 0.0539884977042675\n",
      "Iteration 12076, Loss: 0.05417101830244064\n",
      "Iteration 12077, Loss: 0.05398842319846153\n",
      "Iteration 12078, Loss: 0.05417109653353691\n",
      "Iteration 12079, Loss: 0.0539882630109787\n",
      "Iteration 12080, Loss: 0.054171137511730194\n",
      "Iteration 12081, Loss: 0.053988270461559296\n",
      "Iteration 12082, Loss: 0.05417121574282646\n",
      "Iteration 12083, Loss: 0.05398830771446228\n",
      "Iteration 12084, Loss: 0.054171137511730194\n",
      "Iteration 12085, Loss: 0.053988151252269745\n",
      "Iteration 12086, Loss: 0.05417105555534363\n",
      "Iteration 12087, Loss: 0.05398830398917198\n",
      "Iteration 12088, Loss: 0.05417097732424736\n",
      "Iteration 12089, Loss: 0.05398845672607422\n",
      "Iteration 12090, Loss: 0.05417085811495781\n",
      "Iteration 12091, Loss: 0.053988538682460785\n",
      "Iteration 12092, Loss: 0.05417070537805557\n",
      "Iteration 12093, Loss: 0.05398861691355705\n",
      "Iteration 12094, Loss: 0.0541706308722496\n",
      "Iteration 12095, Loss: 0.053988777101039886\n",
      "Iteration 12096, Loss: 0.054170697927474976\n",
      "Iteration 12097, Loss: 0.053989212960004807\n",
      "Iteration 12098, Loss: 0.05417070910334587\n",
      "Iteration 12099, Loss: 0.053989093750715256\n",
      "Iteration 12100, Loss: 0.05417126417160034\n",
      "Iteration 12101, Loss: 0.053989019244909286\n",
      "Iteration 12102, Loss: 0.05417153239250183\n",
      "Iteration 12103, Loss: 0.05398886650800705\n",
      "Iteration 12104, Loss: 0.05417153239250183\n",
      "Iteration 12105, Loss: 0.05398878455162048\n",
      "Iteration 12106, Loss: 0.054171573370695114\n",
      "Iteration 12107, Loss: 0.05398893356323242\n",
      "Iteration 12108, Loss: 0.05417141318321228\n",
      "Iteration 12109, Loss: 0.05398905277252197\n",
      "Iteration 12110, Loss: 0.05417129397392273\n",
      "Iteration 12111, Loss: 0.053989093750715256\n",
      "Iteration 12112, Loss: 0.05417114123702049\n",
      "Iteration 12113, Loss: 0.05398925393819809\n",
      "Iteration 12114, Loss: 0.05417121574282646\n",
      "Iteration 12115, Loss: 0.053989212960004807\n",
      "Iteration 12116, Loss: 0.05417126044631004\n",
      "Iteration 12117, Loss: 0.05398913472890854\n",
      "Iteration 12118, Loss: 0.05417126417160034\n",
      "Iteration 12119, Loss: 0.05398894473910332\n",
      "Iteration 12120, Loss: 0.05417145416140556\n",
      "Iteration 12121, Loss: 0.053988974541425705\n",
      "Iteration 12122, Loss: 0.054171495139598846\n",
      "Iteration 12123, Loss: 0.053988825529813766\n",
      "Iteration 12124, Loss: 0.054171495139598846\n",
      "Iteration 12125, Loss: 0.05398885905742645\n",
      "Iteration 12126, Loss: 0.05417153239250183\n",
      "Iteration 12127, Loss: 0.053988903760910034\n",
      "Iteration 12128, Loss: 0.054171379655599594\n",
      "Iteration 12129, Loss: 0.053988974541425705\n",
      "Iteration 12130, Loss: 0.05417122691869736\n",
      "Iteration 12131, Loss: 0.05398901551961899\n",
      "Iteration 12132, Loss: 0.05417133495211601\n",
      "Iteration 12133, Loss: 0.05398917198181152\n",
      "Iteration 12134, Loss: 0.054171256721019745\n",
      "Iteration 12135, Loss: 0.053989093750715256\n",
      "Iteration 12136, Loss: 0.05417145416140556\n",
      "Iteration 12137, Loss: 0.05398886650800705\n",
      "Iteration 12138, Loss: 0.054171495139598846\n",
      "Iteration 12139, Loss: 0.05398859828710556\n",
      "Iteration 12140, Loss: 0.05417165160179138\n",
      "Iteration 12141, Loss: 0.05398885905742645\n",
      "Iteration 12142, Loss: 0.05417153239250183\n",
      "Iteration 12143, Loss: 0.05398882180452347\n",
      "Iteration 12144, Loss: 0.054171375930309296\n",
      "Iteration 12145, Loss: 0.05398909002542496\n",
      "Iteration 12146, Loss: 0.054171185940504074\n",
      "Iteration 12147, Loss: 0.05398913472890854\n",
      "Iteration 12148, Loss: 0.05417121946811676\n",
      "Iteration 12149, Loss: 0.05398910492658615\n",
      "Iteration 12150, Loss: 0.05417126417160034\n",
      "Iteration 12151, Loss: 0.05398905277252197\n",
      "Iteration 12152, Loss: 0.05417138338088989\n",
      "Iteration 12153, Loss: 0.05398905277252197\n",
      "Iteration 12154, Loss: 0.05417146533727646\n",
      "Iteration 12155, Loss: 0.05398867279291153\n",
      "Iteration 12156, Loss: 0.05417146533727646\n",
      "Iteration 12157, Loss: 0.05398882180452347\n",
      "Iteration 12158, Loss: 0.05417153984308243\n",
      "Iteration 12159, Loss: 0.053988780826330185\n",
      "Iteration 12160, Loss: 0.054171379655599594\n",
      "Iteration 12161, Loss: 0.053988978266716\n",
      "Iteration 12162, Loss: 0.05417121946811676\n",
      "Iteration 12163, Loss: 0.053989212960004807\n",
      "Iteration 12164, Loss: 0.05417129397392273\n",
      "Iteration 12165, Loss: 0.053989168256521225\n",
      "Iteration 12166, Loss: 0.054171424359083176\n",
      "Iteration 12167, Loss: 0.05398885905742645\n",
      "Iteration 12168, Loss: 0.054171692579984665\n",
      "Iteration 12169, Loss: 0.05398862808942795\n",
      "Iteration 12170, Loss: 0.05417170375585556\n",
      "Iteration 12171, Loss: 0.053988587111234665\n",
      "Iteration 12172, Loss: 0.05417170375585556\n",
      "Iteration 12173, Loss: 0.053988587111234665\n",
      "Iteration 12174, Loss: 0.05417165160179138\n",
      "Iteration 12175, Loss: 0.05398869514465332\n",
      "Iteration 12176, Loss: 0.05417145416140556\n",
      "Iteration 12177, Loss: 0.05398893356323242\n",
      "Iteration 12178, Loss: 0.05417133495211601\n",
      "Iteration 12179, Loss: 0.053989019244909286\n",
      "Iteration 12180, Loss: 0.054171185940504074\n",
      "Iteration 12181, Loss: 0.053989093750715256\n",
      "Iteration 12182, Loss: 0.05417122691869736\n",
      "Iteration 12183, Loss: 0.05398905277252197\n",
      "Iteration 12184, Loss: 0.05417122691869736\n",
      "Iteration 12185, Loss: 0.05398905277252197\n",
      "Iteration 12186, Loss: 0.05417129397392273\n",
      "Iteration 12187, Loss: 0.053989019244909286\n",
      "Iteration 12188, Loss: 0.05417141318321228\n",
      "Iteration 12189, Loss: 0.05398894473910332\n",
      "Iteration 12190, Loss: 0.05417146533727646\n",
      "Iteration 12191, Loss: 0.05398867279291153\n",
      "Iteration 12192, Loss: 0.05417165160179138\n",
      "Iteration 12193, Loss: 0.05398882180452347\n",
      "Iteration 12194, Loss: 0.05417153239250183\n",
      "Iteration 12195, Loss: 0.05398882180452347\n",
      "Iteration 12196, Loss: 0.054171375930309296\n",
      "Iteration 12197, Loss: 0.053988978266716\n",
      "Iteration 12198, Loss: 0.054171185940504074\n",
      "Iteration 12199, Loss: 0.05398913472890854\n",
      "Iteration 12200, Loss: 0.05417117476463318\n",
      "Iteration 12201, Loss: 0.05398917198181152\n",
      "Iteration 12202, Loss: 0.05417114123702049\n",
      "Iteration 12203, Loss: 0.053989361971616745\n",
      "Iteration 12204, Loss: 0.054171185940504074\n",
      "Iteration 12205, Loss: 0.05398913472890854\n",
      "Iteration 12206, Loss: 0.05417141318321228\n",
      "Iteration 12207, Loss: 0.053988903760910034\n",
      "Iteration 12208, Loss: 0.054171618074178696\n",
      "Iteration 12209, Loss: 0.0539887398481369\n",
      "Iteration 12210, Loss: 0.054171737283468246\n",
      "Iteration 12211, Loss: 0.053988587111234665\n",
      "Iteration 12212, Loss: 0.054171692579984665\n",
      "Iteration 12213, Loss: 0.05398866534233093\n",
      "Iteration 12214, Loss: 0.05417165160179138\n",
      "Iteration 12215, Loss: 0.05398866534233093\n",
      "Iteration 12216, Loss: 0.054171495139598846\n",
      "Iteration 12217, Loss: 0.05398905277252197\n",
      "Iteration 12218, Loss: 0.05417114496231079\n",
      "Iteration 12219, Loss: 0.05398917198181152\n",
      "Iteration 12220, Loss: 0.054171256721019745\n",
      "Iteration 12221, Loss: 0.05398906394839287\n",
      "Iteration 12222, Loss: 0.05417129397392273\n",
      "Iteration 12223, Loss: 0.05398894473910332\n",
      "Iteration 12224, Loss: 0.054171424359083176\n",
      "Iteration 12225, Loss: 0.053988903760910034\n",
      "Iteration 12226, Loss: 0.05417150259017944\n",
      "Iteration 12227, Loss: 0.05398866534233093\n",
      "Iteration 12228, Loss: 0.054171621799468994\n",
      "Iteration 12229, Loss: 0.05398855358362198\n",
      "Iteration 12230, Loss: 0.05417169630527496\n",
      "Iteration 12231, Loss: 0.053988587111234665\n",
      "Iteration 12232, Loss: 0.0541716143488884\n",
      "Iteration 12233, Loss: 0.0539887472987175\n",
      "Iteration 12234, Loss: 0.05417165160179138\n",
      "Iteration 12235, Loss: 0.05398866534233093\n",
      "Iteration 12236, Loss: 0.05417153239250183\n",
      "Iteration 12237, Loss: 0.05398893356323242\n",
      "Iteration 12238, Loss: 0.05417134612798691\n",
      "Iteration 12239, Loss: 0.05398894473910332\n",
      "Iteration 12240, Loss: 0.05417133495211601\n",
      "Iteration 12241, Loss: 0.053989093750715256\n",
      "Iteration 12242, Loss: 0.054171375930309296\n",
      "Iteration 12243, Loss: 0.053988978266716\n",
      "Iteration 12244, Loss: 0.054171498864889145\n",
      "Iteration 12245, Loss: 0.05398886650800705\n",
      "Iteration 12246, Loss: 0.054171573370695114\n",
      "Iteration 12247, Loss: 0.0539887472987175\n",
      "Iteration 12248, Loss: 0.05417165160179138\n",
      "Iteration 12249, Loss: 0.053988706320524216\n",
      "Iteration 12250, Loss: 0.0541716143488884\n",
      "Iteration 12251, Loss: 0.05398878455162048\n",
      "Iteration 12252, Loss: 0.05417172610759735\n",
      "Iteration 12253, Loss: 0.0539887361228466\n",
      "Iteration 12254, Loss: 0.054171618074178696\n",
      "Iteration 12255, Loss: 0.053988587111234665\n",
      "Iteration 12256, Loss: 0.05417166277766228\n",
      "Iteration 12257, Loss: 0.0539887472987175\n",
      "Iteration 12258, Loss: 0.05417158454656601\n",
      "Iteration 12259, Loss: 0.0539887398481369\n",
      "Iteration 12260, Loss: 0.054171573370695114\n",
      "Iteration 12261, Loss: 0.05398937314748764\n",
      "Iteration 12262, Loss: 0.054171495139598846\n",
      "Iteration 12263, Loss: 0.053989410400390625\n",
      "Iteration 12264, Loss: 0.05417141318321228\n",
      "Iteration 12265, Loss: 0.05398937687277794\n",
      "Iteration 12266, Loss: 0.054171811789274216\n",
      "Iteration 12267, Loss: 0.05398945510387421\n",
      "Iteration 12268, Loss: 0.05417165160179138\n",
      "Iteration 12269, Loss: 0.05398964136838913\n",
      "Iteration 12270, Loss: 0.05417166277766228\n",
      "Iteration 12271, Loss: 0.053989678621292114\n",
      "Iteration 12272, Loss: 0.054171692579984665\n",
      "Iteration 12273, Loss: 0.05398957058787346\n",
      "Iteration 12274, Loss: 0.054171860218048096\n",
      "Iteration 12275, Loss: 0.05398949235677719\n",
      "Iteration 12276, Loss: 0.05417216569185257\n",
      "Iteration 12277, Loss: 0.05398917198181152\n",
      "Iteration 12278, Loss: 0.054172322154045105\n",
      "Iteration 12279, Loss: 0.05398886650800705\n",
      "Iteration 12280, Loss: 0.05417240411043167\n",
      "Iteration 12281, Loss: 0.05398905277252197\n",
      "Iteration 12282, Loss: 0.0541723296046257\n",
      "Iteration 12283, Loss: 0.05398905277252197\n",
      "Iteration 12284, Loss: 0.054172009229660034\n",
      "Iteration 12285, Loss: 0.05398925766348839\n",
      "Iteration 12286, Loss: 0.054171811789274216\n",
      "Iteration 12287, Loss: 0.05398945137858391\n",
      "Iteration 12288, Loss: 0.05417173355817795\n",
      "Iteration 12289, Loss: 0.053989604115486145\n",
      "Iteration 12290, Loss: 0.054171692579984665\n",
      "Iteration 12291, Loss: 0.0539897195994854\n",
      "Iteration 12292, Loss: 0.054171737283468246\n",
      "Iteration 12293, Loss: 0.05398953706026077\n",
      "Iteration 12294, Loss: 0.05417177081108093\n",
      "Iteration 12295, Loss: 0.053989529609680176\n",
      "Iteration 12296, Loss: 0.054171737283468246\n",
      "Iteration 12297, Loss: 0.05398949235677719\n",
      "Iteration 12298, Loss: 0.05417197197675705\n",
      "Iteration 12299, Loss: 0.05398933216929436\n",
      "Iteration 12300, Loss: 0.054172124713659286\n",
      "Iteration 12301, Loss: 0.053989212960004807\n",
      "Iteration 12302, Loss: 0.05417216941714287\n",
      "Iteration 12303, Loss: 0.05398925393819809\n",
      "Iteration 12304, Loss: 0.054172053933143616\n",
      "Iteration 12305, Loss: 0.05398936569690704\n",
      "Iteration 12306, Loss: 0.054172009229660034\n",
      "Iteration 12307, Loss: 0.053989335894584656\n",
      "Iteration 12308, Loss: 0.0541718527674675\n",
      "Iteration 12309, Loss: 0.05398956686258316\n",
      "Iteration 12310, Loss: 0.05417177081108093\n",
      "Iteration 12311, Loss: 0.05398957058787346\n",
      "Iteration 12312, Loss: 0.05417166277766228\n",
      "Iteration 12313, Loss: 0.053989529609680176\n",
      "Iteration 12314, Loss: 0.05417166277766228\n",
      "Iteration 12315, Loss: 0.05398942157626152\n",
      "Iteration 12316, Loss: 0.054171934723854065\n",
      "Iteration 12317, Loss: 0.053989410400390625\n",
      "Iteration 12318, Loss: 0.054171934723854065\n",
      "Iteration 12319, Loss: 0.05398936569690704\n",
      "Iteration 12320, Loss: 0.054172128438949585\n",
      "Iteration 12321, Loss: 0.053989291191101074\n",
      "Iteration 12322, Loss: 0.0541720911860466\n",
      "Iteration 12323, Loss: 0.05398932844400406\n",
      "Iteration 12324, Loss: 0.054172124713659286\n",
      "Iteration 12325, Loss: 0.05398933216929436\n",
      "Iteration 12326, Loss: 0.05417203903198242\n",
      "Iteration 12327, Loss: 0.053989410400390625\n",
      "Iteration 12328, Loss: 0.05417189747095108\n",
      "Iteration 12329, Loss: 0.05398937314748764\n",
      "Iteration 12330, Loss: 0.05417190119624138\n",
      "Iteration 12331, Loss: 0.053989410400390625\n",
      "Iteration 12332, Loss: 0.05417197570204735\n",
      "Iteration 12333, Loss: 0.05398937314748764\n",
      "Iteration 12334, Loss: 0.054172009229660034\n",
      "Iteration 12335, Loss: 0.05398933216929436\n",
      "Iteration 12336, Loss: 0.054172083735466\n",
      "Iteration 12337, Loss: 0.05398929864168167\n",
      "Iteration 12338, Loss: 0.05417197197675705\n",
      "Iteration 12339, Loss: 0.05398937687277794\n",
      "Iteration 12340, Loss: 0.054171934723854065\n",
      "Iteration 12341, Loss: 0.05398937314748764\n",
      "Iteration 12342, Loss: 0.054171860218048096\n",
      "Iteration 12343, Loss: 0.05398936569690704\n",
      "Iteration 12344, Loss: 0.05417197197675705\n",
      "Iteration 12345, Loss: 0.053989484906196594\n",
      "Iteration 12346, Loss: 0.054171930998563766\n",
      "Iteration 12347, Loss: 0.053989410400390625\n",
      "Iteration 12348, Loss: 0.054172009229660034\n",
      "Iteration 12349, Loss: 0.05398929864168167\n",
      "Iteration 12350, Loss: 0.05417197197675705\n",
      "Iteration 12351, Loss: 0.053989261388778687\n",
      "Iteration 12352, Loss: 0.054171811789274216\n",
      "Iteration 12353, Loss: 0.0539894625544548\n",
      "Iteration 12354, Loss: 0.05417146533727646\n",
      "Iteration 12355, Loss: 0.053989656269550323\n",
      "Iteration 12356, Loss: 0.054171573370695114\n",
      "Iteration 12357, Loss: 0.05398976802825928\n",
      "Iteration 12358, Loss: 0.054171618074178696\n",
      "Iteration 12359, Loss: 0.05398961156606674\n",
      "Iteration 12360, Loss: 0.05417180806398392\n",
      "Iteration 12361, Loss: 0.05398964881896973\n",
      "Iteration 12362, Loss: 0.0541718527674675\n",
      "Iteration 12363, Loss: 0.05398949235677719\n",
      "Iteration 12364, Loss: 0.054172009229660034\n",
      "Iteration 12365, Loss: 0.05398936569690704\n",
      "Iteration 12366, Loss: 0.05417221039533615\n",
      "Iteration 12367, Loss: 0.053989093750715256\n",
      "Iteration 12368, Loss: 0.054172247648239136\n",
      "Iteration 12369, Loss: 0.053989212960004807\n",
      "Iteration 12370, Loss: 0.05417216941714287\n",
      "Iteration 12371, Loss: 0.053989212960004807\n",
      "Iteration 12372, Loss: 0.05417205020785332\n",
      "Iteration 12373, Loss: 0.053989335894584656\n",
      "Iteration 12374, Loss: 0.05417200177907944\n",
      "Iteration 12375, Loss: 0.053989481180906296\n",
      "Iteration 12376, Loss: 0.05417177081108093\n",
      "Iteration 12377, Loss: 0.05398957058787346\n",
      "Iteration 12378, Loss: 0.054171811789274216\n",
      "Iteration 12379, Loss: 0.05398964509367943\n",
      "Iteration 12380, Loss: 0.054171737283468246\n",
      "Iteration 12381, Loss: 0.05398949235677719\n",
      "Iteration 12382, Loss: 0.05417197197675705\n",
      "Iteration 12383, Loss: 0.053989261388778687\n",
      "Iteration 12384, Loss: 0.05417205020785332\n",
      "Iteration 12385, Loss: 0.05398910492658615\n",
      "Iteration 12386, Loss: 0.05417216941714287\n",
      "Iteration 12387, Loss: 0.053989216685295105\n",
      "Iteration 12388, Loss: 0.054172202944755554\n",
      "Iteration 12389, Loss: 0.05398925393819809\n",
      "Iteration 12390, Loss: 0.054172124713659286\n",
      "Iteration 12391, Loss: 0.05398925393819809\n",
      "Iteration 12392, Loss: 0.05417197197675705\n",
      "Iteration 12393, Loss: 0.05398944020271301\n",
      "Iteration 12394, Loss: 0.0541718527674675\n",
      "Iteration 12395, Loss: 0.053989529609680176\n",
      "Iteration 12396, Loss: 0.0541718415915966\n",
      "Iteration 12397, Loss: 0.053989678621292114\n",
      "Iteration 12398, Loss: 0.054171737283468246\n",
      "Iteration 12399, Loss: 0.05398949235677719\n",
      "Iteration 12400, Loss: 0.05417200177907944\n",
      "Iteration 12401, Loss: 0.053989335894584656\n",
      "Iteration 12402, Loss: 0.0541720911860466\n",
      "Iteration 12403, Loss: 0.05398917943239212\n",
      "Iteration 12404, Loss: 0.054172128438949585\n",
      "Iteration 12405, Loss: 0.053989212960004807\n",
      "Iteration 12406, Loss: 0.054172128438949585\n",
      "Iteration 12407, Loss: 0.05398925393819809\n",
      "Iteration 12408, Loss: 0.054172009229660034\n",
      "Iteration 12409, Loss: 0.05398929864168167\n",
      "Iteration 12410, Loss: 0.054172009229660034\n",
      "Iteration 12411, Loss: 0.053989481180906296\n",
      "Iteration 12412, Loss: 0.05417191982269287\n",
      "Iteration 12413, Loss: 0.053989559412002563\n",
      "Iteration 12414, Loss: 0.054171886295080185\n",
      "Iteration 12415, Loss: 0.053989529609680176\n",
      "Iteration 12416, Loss: 0.0541718527674675\n",
      "Iteration 12417, Loss: 0.05398952588438988\n",
      "Iteration 12418, Loss: 0.054171960800886154\n",
      "Iteration 12419, Loss: 0.053989484906196594\n",
      "Iteration 12420, Loss: 0.05417204648256302\n",
      "Iteration 12421, Loss: 0.05398933216929436\n",
      "Iteration 12422, Loss: 0.054172124713659286\n",
      "Iteration 12423, Loss: 0.05398917198181152\n",
      "Iteration 12424, Loss: 0.054172128438949585\n",
      "Iteration 12425, Loss: 0.053989212960004807\n",
      "Iteration 12426, Loss: 0.054172128438949585\n",
      "Iteration 12427, Loss: 0.05398936569690704\n",
      "Iteration 12428, Loss: 0.054172128438949585\n",
      "Iteration 12429, Loss: 0.05398925393819809\n",
      "Iteration 12430, Loss: 0.0541720911860466\n",
      "Iteration 12431, Loss: 0.05398933216929436\n",
      "Iteration 12432, Loss: 0.05417205020785332\n",
      "Iteration 12433, Loss: 0.05398937314748764\n",
      "Iteration 12434, Loss: 0.05417204648256302\n",
      "Iteration 12435, Loss: 0.05398952215909958\n",
      "Iteration 12436, Loss: 0.054171930998563766\n",
      "Iteration 12437, Loss: 0.05398957058787346\n",
      "Iteration 12438, Loss: 0.054171930998563766\n",
      "Iteration 12439, Loss: 0.05398945137858391\n",
      "Iteration 12440, Loss: 0.054172005504369736\n",
      "Iteration 12441, Loss: 0.053989335894584656\n",
      "Iteration 12442, Loss: 0.05417191982269287\n",
      "Iteration 12443, Loss: 0.05398957058787346\n",
      "Iteration 12444, Loss: 0.05417177081108093\n",
      "Iteration 12445, Loss: 0.05398968607187271\n",
      "Iteration 12446, Loss: 0.05417173355817795\n",
      "Iteration 12447, Loss: 0.05398952588438988\n",
      "Iteration 12448, Loss: 0.054172005504369736\n",
      "Iteration 12449, Loss: 0.05398937314748764\n",
      "Iteration 12450, Loss: 0.05417197570204735\n",
      "Iteration 12451, Loss: 0.05398936569690704\n",
      "Iteration 12452, Loss: 0.05417202040553093\n",
      "Iteration 12453, Loss: 0.05398936569690704\n",
      "Iteration 12454, Loss: 0.05417202040553093\n",
      "Iteration 12455, Loss: 0.05398925393819809\n",
      "Iteration 12456, Loss: 0.05417216569185257\n",
      "Iteration 12457, Loss: 0.053989287465810776\n",
      "Iteration 12458, Loss: 0.0541720911860466\n",
      "Iteration 12459, Loss: 0.053989291191101074\n",
      "Iteration 12460, Loss: 0.054172083735466\n",
      "Iteration 12461, Loss: 0.053989410400390625\n",
      "Iteration 12462, Loss: 0.05417197197675705\n",
      "Iteration 12463, Loss: 0.05398945137858391\n",
      "Iteration 12464, Loss: 0.054172005504369736\n",
      "Iteration 12465, Loss: 0.05398949235677719\n",
      "Iteration 12466, Loss: 0.054171811789274216\n",
      "Iteration 12467, Loss: 0.05398944765329361\n",
      "Iteration 12468, Loss: 0.05417177081108093\n",
      "Iteration 12469, Loss: 0.05398960039019585\n",
      "Iteration 12470, Loss: 0.05417177826166153\n",
      "Iteration 12471, Loss: 0.05398968607187271\n",
      "Iteration 12472, Loss: 0.054171811789274216\n",
      "Iteration 12473, Loss: 0.05398945137858391\n",
      "Iteration 12474, Loss: 0.054171930998563766\n",
      "Iteration 12475, Loss: 0.05398937314748764\n",
      "Iteration 12476, Loss: 0.0541720911860466\n",
      "Iteration 12477, Loss: 0.05398925393819809\n",
      "Iteration 12478, Loss: 0.05417216569185257\n",
      "Iteration 12479, Loss: 0.053989216685295105\n",
      "Iteration 12480, Loss: 0.054172009229660034\n",
      "Iteration 12481, Loss: 0.053989291191101074\n",
      "Iteration 12482, Loss: 0.054172083735466\n",
      "Iteration 12483, Loss: 0.05398933216929436\n",
      "Iteration 12484, Loss: 0.054171930998563766\n",
      "Iteration 12485, Loss: 0.053989481180906296\n",
      "Iteration 12486, Loss: 0.054171960800886154\n",
      "Iteration 12487, Loss: 0.05398949235677719\n",
      "Iteration 12488, Loss: 0.054171860218048096\n",
      "Iteration 12489, Loss: 0.05398937314748764\n",
      "Iteration 12490, Loss: 0.0541720911860466\n",
      "Iteration 12491, Loss: 0.05398933216929436\n",
      "Iteration 12492, Loss: 0.05417205020785332\n",
      "Iteration 12493, Loss: 0.05398925393819809\n",
      "Iteration 12494, Loss: 0.054172128438949585\n",
      "Iteration 12495, Loss: 0.053989216685295105\n",
      "Iteration 12496, Loss: 0.05417216569185257\n",
      "Iteration 12497, Loss: 0.05398917943239212\n",
      "Iteration 12498, Loss: 0.05417189002037048\n",
      "Iteration 12499, Loss: 0.05398945137858391\n",
      "Iteration 12500, Loss: 0.05417180061340332\n",
      "Iteration 12501, Loss: 0.05398957058787346\n",
      "Iteration 12502, Loss: 0.05417173355817795\n",
      "Iteration 12503, Loss: 0.05398976057767868\n",
      "Iteration 12504, Loss: 0.05417177081108093\n",
      "Iteration 12505, Loss: 0.053989604115486145\n",
      "Iteration 12506, Loss: 0.054171930998563766\n",
      "Iteration 12507, Loss: 0.05398937687277794\n",
      "Iteration 12508, Loss: 0.05417205020785332\n",
      "Iteration 12509, Loss: 0.053989212960004807\n",
      "Iteration 12510, Loss: 0.054172083735466\n",
      "Iteration 12511, Loss: 0.05398933216929436\n",
      "Iteration 12512, Loss: 0.054172083735466\n",
      "Iteration 12513, Loss: 0.05398937314748764\n",
      "Iteration 12514, Loss: 0.05417205020785332\n",
      "Iteration 12515, Loss: 0.05398933216929436\n",
      "Iteration 12516, Loss: 0.05417197197675705\n",
      "Iteration 12517, Loss: 0.05398929864168167\n",
      "Iteration 12518, Loss: 0.0541718527674675\n",
      "Iteration 12519, Loss: 0.05398952588438988\n",
      "Iteration 12520, Loss: 0.05417169630527496\n",
      "Iteration 12521, Loss: 0.05398976057767868\n",
      "Iteration 12522, Loss: 0.05417165905237198\n",
      "Iteration 12523, Loss: 0.05398968979716301\n",
      "Iteration 12524, Loss: 0.05417173355817795\n",
      "Iteration 12525, Loss: 0.053989529609680176\n",
      "Iteration 12526, Loss: 0.054171930998563766\n",
      "Iteration 12527, Loss: 0.05398944765329361\n",
      "Iteration 12528, Loss: 0.0541720911860466\n",
      "Iteration 12529, Loss: 0.05398906394839287\n",
      "Iteration 12530, Loss: 0.05417227745056152\n",
      "Iteration 12531, Loss: 0.053989212960004807\n",
      "Iteration 12532, Loss: 0.054172202944755554\n",
      "Iteration 12533, Loss: 0.05398917198181152\n",
      "Iteration 12534, Loss: 0.054171960800886154\n",
      "Iteration 12535, Loss: 0.053989529609680176\n",
      "Iteration 12536, Loss: 0.05417177081108093\n",
      "Iteration 12537, Loss: 0.05398964136838913\n",
      "Iteration 12538, Loss: 0.05417177081108093\n",
      "Iteration 12539, Loss: 0.05398976057767868\n",
      "Iteration 12540, Loss: 0.05417177081108093\n",
      "Iteration 12541, Loss: 0.05398960039019585\n",
      "Iteration 12542, Loss: 0.05417189002037048\n",
      "Iteration 12543, Loss: 0.053989410400390625\n",
      "Iteration 12544, Loss: 0.05417197197675705\n",
      "Iteration 12545, Loss: 0.05398936569690704\n",
      "Iteration 12546, Loss: 0.05417212098836899\n",
      "Iteration 12547, Loss: 0.05398925393819809\n",
      "Iteration 12548, Loss: 0.054171960800886154\n",
      "Iteration 12549, Loss: 0.05398944765329361\n",
      "Iteration 12550, Loss: 0.0541718453168869\n",
      "Iteration 12551, Loss: 0.05398949235677719\n",
      "Iteration 12552, Loss: 0.054171737283468246\n",
      "Iteration 12553, Loss: 0.05398960039019585\n",
      "Iteration 12554, Loss: 0.054171811789274216\n",
      "Iteration 12555, Loss: 0.05398961156606674\n",
      "Iteration 12556, Loss: 0.05417170375585556\n",
      "Iteration 12557, Loss: 0.05398968979716301\n",
      "Iteration 12558, Loss: 0.0541718527674675\n",
      "Iteration 12559, Loss: 0.053989484906196594\n",
      "Iteration 12560, Loss: 0.05417197197675705\n",
      "Iteration 12561, Loss: 0.05398933216929436\n",
      "Iteration 12562, Loss: 0.05417206138372421\n",
      "Iteration 12563, Loss: 0.053989361971616745\n",
      "Iteration 12564, Loss: 0.054172128438949585\n",
      "Iteration 12565, Loss: 0.053989361971616745\n",
      "Iteration 12566, Loss: 0.054172199219465256\n",
      "Iteration 12567, Loss: 0.053989216685295105\n",
      "Iteration 12568, Loss: 0.05417216941714287\n",
      "Iteration 12569, Loss: 0.053989216685295105\n",
      "Iteration 12570, Loss: 0.05417216569185257\n",
      "Iteration 12571, Loss: 0.05398925393819809\n",
      "Iteration 12572, Loss: 0.05417216569185257\n",
      "Iteration 12573, Loss: 0.05398917198181152\n",
      "Iteration 12574, Loss: 0.0541720911860466\n",
      "Iteration 12575, Loss: 0.05398929864168167\n",
      "Iteration 12576, Loss: 0.05417192727327347\n",
      "Iteration 12577, Loss: 0.05398956686258316\n",
      "Iteration 12578, Loss: 0.05417173355817795\n",
      "Iteration 12579, Loss: 0.053989678621292114\n",
      "Iteration 12580, Loss: 0.05417180806398392\n",
      "Iteration 12581, Loss: 0.05398954078555107\n",
      "Iteration 12582, Loss: 0.05417177081108093\n",
      "Iteration 12583, Loss: 0.05398957058787346\n",
      "Iteration 12584, Loss: 0.054171811789274216\n",
      "Iteration 12585, Loss: 0.05398961156606674\n",
      "Iteration 12586, Loss: 0.05417189002037048\n",
      "Iteration 12587, Loss: 0.05398960039019585\n",
      "Iteration 12588, Loss: 0.05417200177907944\n",
      "Iteration 12589, Loss: 0.05398952215909958\n",
      "Iteration 12590, Loss: 0.054172009229660034\n",
      "Iteration 12591, Loss: 0.053989559412002563\n",
      "Iteration 12592, Loss: 0.05417201668024063\n",
      "Iteration 12593, Loss: 0.05398925393819809\n",
      "Iteration 12594, Loss: 0.05417221039533615\n",
      "Iteration 12595, Loss: 0.053989093750715256\n",
      "Iteration 12596, Loss: 0.054172366857528687\n",
      "Iteration 12597, Loss: 0.053989019244909286\n",
      "Iteration 12598, Loss: 0.0541723296046257\n",
      "Iteration 12599, Loss: 0.053988978266716\n",
      "Iteration 12600, Loss: 0.054172247648239136\n",
      "Iteration 12601, Loss: 0.05398918315768242\n",
      "Iteration 12602, Loss: 0.054172083735466\n",
      "Iteration 12603, Loss: 0.05398936569690704\n",
      "Iteration 12604, Loss: 0.05417177826166153\n",
      "Iteration 12605, Loss: 0.05398952588438988\n",
      "Iteration 12606, Loss: 0.05417170375585556\n",
      "Iteration 12607, Loss: 0.05398956686258316\n",
      "Iteration 12608, Loss: 0.05417165160179138\n",
      "Iteration 12609, Loss: 0.05398961156606674\n",
      "Iteration 12610, Loss: 0.05417172610759735\n",
      "Iteration 12611, Loss: 0.05398976057767868\n",
      "Iteration 12612, Loss: 0.05417170375585556\n",
      "Iteration 12613, Loss: 0.053989969193935394\n",
      "Iteration 12614, Loss: 0.05417189002037048\n",
      "Iteration 12615, Loss: 0.05398992821574211\n",
      "Iteration 12616, Loss: 0.054171930998563766\n",
      "Iteration 12617, Loss: 0.0539899617433548\n",
      "Iteration 12618, Loss: 0.054171256721019745\n",
      "Iteration 12619, Loss: 0.053990162909030914\n",
      "Iteration 12620, Loss: 0.05417129397392273\n",
      "Iteration 12621, Loss: 0.05399007722735405\n",
      "Iteration 12622, Loss: 0.05417142063379288\n",
      "Iteration 12623, Loss: 0.05398973450064659\n",
      "Iteration 12624, Loss: 0.05417170375585556\n",
      "Iteration 12625, Loss: 0.05398942157626152\n",
      "Iteration 12626, Loss: 0.05417216941714287\n",
      "Iteration 12627, Loss: 0.053989097476005554\n",
      "Iteration 12628, Loss: 0.05417221784591675\n",
      "Iteration 12629, Loss: 0.05398879200220108\n",
      "Iteration 12630, Loss: 0.05417249724268913\n",
      "Iteration 12631, Loss: 0.05398889631032944\n",
      "Iteration 12632, Loss: 0.05417248606681824\n",
      "Iteration 12633, Loss: 0.05398889631032944\n",
      "Iteration 12634, Loss: 0.05417256057262421\n",
      "Iteration 12635, Loss: 0.053989093750715256\n",
      "Iteration 12636, Loss: 0.05417221039533615\n",
      "Iteration 12637, Loss: 0.05398918315768242\n",
      "Iteration 12638, Loss: 0.05417200177907944\n",
      "Iteration 12639, Loss: 0.05398945137858391\n",
      "Iteration 12640, Loss: 0.054171692579984665\n",
      "Iteration 12641, Loss: 0.053989797830581665\n",
      "Iteration 12642, Loss: 0.05417146906256676\n",
      "Iteration 12643, Loss: 0.05398987978696823\n",
      "Iteration 12644, Loss: 0.05417165905237198\n",
      "Iteration 12645, Loss: 0.05398976802825928\n",
      "Iteration 12646, Loss: 0.05417166277766228\n",
      "Iteration 12647, Loss: 0.05398949235677719\n",
      "Iteration 12648, Loss: 0.054171979427337646\n",
      "Iteration 12649, Loss: 0.053989335894584656\n",
      "Iteration 12650, Loss: 0.05417206138372421\n",
      "Iteration 12651, Loss: 0.05398913472890854\n",
      "Iteration 12652, Loss: 0.054172247648239136\n",
      "Iteration 12653, Loss: 0.05398903042078018\n",
      "Iteration 12654, Loss: 0.0541723296046257\n",
      "Iteration 12655, Loss: 0.0539892241358757\n",
      "Iteration 12656, Loss: 0.0541720911860466\n",
      "Iteration 12657, Loss: 0.05398934334516525\n",
      "Iteration 12658, Loss: 0.05417197197675705\n",
      "Iteration 12659, Loss: 0.053989529609680176\n",
      "Iteration 12660, Loss: 0.05417177081108093\n",
      "Iteration 12661, Loss: 0.05398964881896973\n",
      "Iteration 12662, Loss: 0.0541716143488884\n",
      "Iteration 12663, Loss: 0.05398976802825928\n",
      "Iteration 12664, Loss: 0.054171618074178696\n",
      "Iteration 12665, Loss: 0.05398976802825928\n",
      "Iteration 12666, Loss: 0.05417177081108093\n",
      "Iteration 12667, Loss: 0.053989581763744354\n",
      "Iteration 12668, Loss: 0.05417197570204735\n",
      "Iteration 12669, Loss: 0.053989261388778687\n",
      "Iteration 12670, Loss: 0.0541720911860466\n",
      "Iteration 12671, Loss: 0.05398925766348839\n",
      "Iteration 12672, Loss: 0.05417213961482048\n",
      "Iteration 12673, Loss: 0.05398910865187645\n",
      "Iteration 12674, Loss: 0.0541720986366272\n",
      "Iteration 12675, Loss: 0.05398933216929436\n",
      "Iteration 12676, Loss: 0.054172009229660034\n",
      "Iteration 12677, Loss: 0.05398938059806824\n",
      "Iteration 12678, Loss: 0.054171737283468246\n",
      "Iteration 12679, Loss: 0.05398961156606674\n",
      "Iteration 12680, Loss: 0.054171621799468994\n",
      "Iteration 12681, Loss: 0.05398973077535629\n",
      "Iteration 12682, Loss: 0.05417165160179138\n",
      "Iteration 12683, Loss: 0.053989656269550323\n",
      "Iteration 12684, Loss: 0.054171692579984665\n",
      "Iteration 12685, Loss: 0.053989581763744354\n",
      "Iteration 12686, Loss: 0.054171741008758545\n",
      "Iteration 12687, Loss: 0.05398945510387421\n",
      "Iteration 12688, Loss: 0.0541718527674675\n",
      "Iteration 12689, Loss: 0.05398953706026077\n",
      "Iteration 12690, Loss: 0.0541718527674675\n",
      "Iteration 12691, Loss: 0.05398949608206749\n",
      "Iteration 12692, Loss: 0.05417197570204735\n",
      "Iteration 12693, Loss: 0.053989410400390625\n",
      "Iteration 12694, Loss: 0.05417205020785332\n",
      "Iteration 12695, Loss: 0.0539892241358757\n",
      "Iteration 12696, Loss: 0.054172009229660034\n",
      "Iteration 12697, Loss: 0.05398934334516525\n",
      "Iteration 12698, Loss: 0.05417197197675705\n",
      "Iteration 12699, Loss: 0.05398868769407272\n",
      "Iteration 12700, Loss: 0.054171860218048096\n",
      "Iteration 12701, Loss: 0.05398868769407272\n",
      "Iteration 12702, Loss: 0.054171428084373474\n",
      "Iteration 12703, Loss: 0.05398864671587944\n",
      "Iteration 12704, Loss: 0.05417139455676079\n",
      "Iteration 12705, Loss: 0.05398860573768616\n",
      "Iteration 12706, Loss: 0.05417139083147049\n",
      "Iteration 12707, Loss: 0.05398872122168541\n",
      "Iteration 12708, Loss: 0.05417118966579437\n",
      "Iteration 12709, Loss: 0.05398884043097496\n",
      "Iteration 12710, Loss: 0.054171036928892136\n",
      "Iteration 12711, Loss: 0.05398911237716675\n",
      "Iteration 12712, Loss: 0.05417107790708542\n",
      "Iteration 12713, Loss: 0.05398900434374809\n",
      "Iteration 12714, Loss: 0.054170962423086166\n",
      "Iteration 12715, Loss: 0.05398903414607048\n",
      "Iteration 12716, Loss: 0.05417108163237572\n",
      "Iteration 12717, Loss: 0.05398868769407272\n",
      "Iteration 12718, Loss: 0.05417143553495407\n",
      "Iteration 12719, Loss: 0.05398860201239586\n",
      "Iteration 12720, Loss: 0.05417151749134064\n",
      "Iteration 12721, Loss: 0.05398840829730034\n",
      "Iteration 12722, Loss: 0.054171741008758545\n",
      "Iteration 12723, Loss: 0.05398833006620407\n",
      "Iteration 12724, Loss: 0.05417170375585556\n",
      "Iteration 12725, Loss: 0.05398852750658989\n",
      "Iteration 12726, Loss: 0.054171428084373474\n",
      "Iteration 12727, Loss: 0.05398860573768616\n",
      "Iteration 12728, Loss: 0.0541711151599884\n",
      "Iteration 12729, Loss: 0.05398879945278168\n",
      "Iteration 12730, Loss: 0.05417099595069885\n",
      "Iteration 12731, Loss: 0.05398911237716675\n",
      "Iteration 12732, Loss: 0.05417092144489288\n",
      "Iteration 12733, Loss: 0.05398907884955406\n",
      "Iteration 12734, Loss: 0.05417099595069885\n",
      "Iteration 12735, Loss: 0.05398903787136078\n",
      "Iteration 12736, Loss: 0.05417107790708542\n",
      "Iteration 12737, Loss: 0.05398879945278168\n",
      "Iteration 12738, Loss: 0.054171353578567505\n",
      "Iteration 12739, Loss: 0.05398852750658989\n",
      "Iteration 12740, Loss: 0.054171666502952576\n",
      "Iteration 12741, Loss: 0.05398833006620407\n",
      "Iteration 12742, Loss: 0.05417156219482422\n",
      "Iteration 12743, Loss: 0.053988367319107056\n",
      "Iteration 12744, Loss: 0.05417166277766228\n",
      "Iteration 12745, Loss: 0.05398852750658989\n",
      "Iteration 12746, Loss: 0.05417139455676079\n",
      "Iteration 12747, Loss: 0.05398879572749138\n",
      "Iteration 12748, Loss: 0.054171156138181686\n",
      "Iteration 12749, Loss: 0.05398884043097496\n",
      "Iteration 12750, Loss: 0.05417118966579437\n",
      "Iteration 12751, Loss: 0.05398895964026451\n",
      "Iteration 12752, Loss: 0.0541711151599884\n",
      "Iteration 12753, Loss: 0.05398891493678093\n",
      "Iteration 12754, Loss: 0.05417122691869736\n",
      "Iteration 12755, Loss: 0.05398896336555481\n",
      "Iteration 12756, Loss: 0.05417116731405258\n",
      "Iteration 12757, Loss: 0.05398868769407272\n",
      "Iteration 12758, Loss: 0.0541713647544384\n",
      "Iteration 12759, Loss: 0.05398860573768616\n",
      "Iteration 12760, Loss: 0.05417151376605034\n",
      "Iteration 12761, Loss: 0.05398844927549362\n",
      "Iteration 12762, Loss: 0.054171547293663025\n",
      "Iteration 12763, Loss: 0.05398856848478317\n",
      "Iteration 12764, Loss: 0.05417143553495407\n",
      "Iteration 12765, Loss: 0.05398864299058914\n",
      "Iteration 12766, Loss: 0.05417138338088989\n",
      "Iteration 12767, Loss: 0.05398879945278168\n",
      "Iteration 12768, Loss: 0.05417127534747124\n",
      "Iteration 12769, Loss: 0.05398872494697571\n",
      "Iteration 12770, Loss: 0.05417119711637497\n",
      "Iteration 12771, Loss: 0.05398883670568466\n",
      "Iteration 12772, Loss: 0.054171234369277954\n",
      "Iteration 12773, Loss: 0.05398860573768616\n",
      "Iteration 12774, Loss: 0.05417120084166527\n",
      "Iteration 12775, Loss: 0.05398864671587944\n",
      "Iteration 12776, Loss: 0.05417139455676079\n",
      "Iteration 12777, Loss: 0.05398860573768616\n",
      "Iteration 12778, Loss: 0.05417139083147049\n",
      "Iteration 12779, Loss: 0.05398861691355705\n",
      "Iteration 12780, Loss: 0.05417127162218094\n",
      "Iteration 12781, Loss: 0.05398861691355705\n",
      "Iteration 12782, Loss: 0.054171230643987656\n",
      "Iteration 12783, Loss: 0.05398872494697571\n",
      "Iteration 12784, Loss: 0.054171159863471985\n",
      "Iteration 12785, Loss: 0.05398865044116974\n",
      "Iteration 12786, Loss: 0.05417119711637497\n",
      "Iteration 12787, Loss: 0.05398876219987869\n",
      "Iteration 12788, Loss: 0.054171234369277954\n",
      "Iteration 12789, Loss: 0.05398868769407272\n",
      "Iteration 12790, Loss: 0.05417132377624512\n",
      "Iteration 12791, Loss: 0.05398856848478317\n",
      "Iteration 12792, Loss: 0.054171591997146606\n",
      "Iteration 12793, Loss: 0.05398833006620407\n",
      "Iteration 12794, Loss: 0.05417167395353317\n",
      "Iteration 12795, Loss: 0.05398833006620407\n",
      "Iteration 12796, Loss: 0.054171666502952576\n",
      "Iteration 12797, Loss: 0.053988486528396606\n",
      "Iteration 12798, Loss: 0.05417143553495407\n",
      "Iteration 12799, Loss: 0.05398872122168541\n",
      "Iteration 12800, Loss: 0.05417119711637497\n",
      "Iteration 12801, Loss: 0.053988806903362274\n",
      "Iteration 12802, Loss: 0.054171036928892136\n",
      "Iteration 12803, Loss: 0.05398895964026451\n",
      "Iteration 12804, Loss: 0.054171036928892136\n",
      "Iteration 12805, Loss: 0.05398896336555481\n",
      "Iteration 12806, Loss: 0.05417099595069885\n",
      "Iteration 12807, Loss: 0.05398896336555481\n",
      "Iteration 12808, Loss: 0.05417099595069885\n",
      "Iteration 12809, Loss: 0.05398884415626526\n",
      "Iteration 12810, Loss: 0.05417107045650482\n",
      "Iteration 12811, Loss: 0.05398888513445854\n",
      "Iteration 12812, Loss: 0.05417099595069885\n",
      "Iteration 12813, Loss: 0.05398876592516899\n",
      "Iteration 12814, Loss: 0.054171040654182434\n",
      "Iteration 12815, Loss: 0.05398891866207123\n",
      "Iteration 12816, Loss: 0.05417095869779587\n",
      "Iteration 12817, Loss: 0.053989000618457794\n",
      "Iteration 12818, Loss: 0.05417095869779587\n",
      "Iteration 12819, Loss: 0.05398918688297272\n",
      "Iteration 12820, Loss: 0.05417060852050781\n",
      "Iteration 12821, Loss: 0.05398912355303764\n",
      "Iteration 12822, Loss: 0.054170798510313034\n",
      "Iteration 12823, Loss: 0.05398912355303764\n",
      "Iteration 12824, Loss: 0.054170768707990646\n",
      "Iteration 12825, Loss: 0.053988926112651825\n",
      "Iteration 12826, Loss: 0.05417080968618393\n",
      "Iteration 12827, Loss: 0.05398888513445854\n",
      "Iteration 12828, Loss: 0.05417092889547348\n",
      "Iteration 12829, Loss: 0.05398884415626526\n",
      "Iteration 12830, Loss: 0.054170966148376465\n",
      "Iteration 12831, Loss: 0.053988926112651825\n",
      "Iteration 12832, Loss: 0.05417095869779587\n",
      "Iteration 12833, Loss: 0.05398907884955406\n",
      "Iteration 12834, Loss: 0.05417083948850632\n",
      "Iteration 12835, Loss: 0.05398926883935928\n",
      "Iteration 12836, Loss: 0.05417076498270035\n",
      "Iteration 12837, Loss: 0.05398912355303764\n",
      "Iteration 12838, Loss: 0.0541708767414093\n",
      "Iteration 12839, Loss: 0.053989045321941376\n",
      "Iteration 12840, Loss: 0.05417097359895706\n",
      "Iteration 12841, Loss: 0.05398888513445854\n",
      "Iteration 12842, Loss: 0.05417100712656975\n",
      "Iteration 12843, Loss: 0.05398876592516899\n",
      "Iteration 12844, Loss: 0.054171085357666016\n",
      "Iteration 12845, Loss: 0.05398872494697571\n",
      "Iteration 12846, Loss: 0.05417100712656975\n",
      "Iteration 12847, Loss: 0.05398872494697571\n",
      "Iteration 12848, Loss: 0.054170962423086166\n",
      "Iteration 12849, Loss: 0.053988926112651825\n",
      "Iteration 12850, Loss: 0.054170846939086914\n",
      "Iteration 12851, Loss: 0.05398911237716675\n",
      "Iteration 12852, Loss: 0.0541706383228302\n",
      "Iteration 12853, Loss: 0.05398919805884361\n",
      "Iteration 12854, Loss: 0.05417057126760483\n",
      "Iteration 12855, Loss: 0.05398927628993988\n",
      "Iteration 12856, Loss: 0.054170720279216766\n",
      "Iteration 12857, Loss: 0.05398920178413391\n",
      "Iteration 12858, Loss: 0.054170798510313034\n",
      "Iteration 12859, Loss: 0.05398915708065033\n",
      "Iteration 12860, Loss: 0.05417085438966751\n",
      "Iteration 12861, Loss: 0.05398884415626526\n",
      "Iteration 12862, Loss: 0.054171159863471985\n",
      "Iteration 12863, Loss: 0.0539884939789772\n",
      "Iteration 12864, Loss: 0.05417143553495407\n",
      "Iteration 12865, Loss: 0.053988486528396606\n",
      "Iteration 12866, Loss: 0.05417143553495407\n",
      "Iteration 12867, Loss: 0.05398844927549362\n",
      "Iteration 12868, Loss: 0.05417128652334213\n",
      "Iteration 12869, Loss: 0.05398845672607422\n",
      "Iteration 12870, Loss: 0.05417120084166527\n",
      "Iteration 12871, Loss: 0.05398864671587944\n",
      "Iteration 12872, Loss: 0.054170966148376465\n",
      "Iteration 12873, Loss: 0.0539889931678772\n",
      "Iteration 12874, Loss: 0.05417072772979736\n",
      "Iteration 12875, Loss: 0.0539892315864563\n",
      "Iteration 12876, Loss: 0.05417072772979736\n",
      "Iteration 12877, Loss: 0.053989164531230927\n",
      "Iteration 12878, Loss: 0.05417069047689438\n",
      "Iteration 12879, Loss: 0.05398912355303764\n",
      "Iteration 12880, Loss: 0.05417069047689438\n",
      "Iteration 12881, Loss: 0.05398912355303764\n",
      "Iteration 12882, Loss: 0.054170798510313034\n",
      "Iteration 12883, Loss: 0.05398919805884361\n",
      "Iteration 12884, Loss: 0.05417067930102348\n",
      "Iteration 12885, Loss: 0.0539892315864563\n",
      "Iteration 12886, Loss: 0.05417068302631378\n",
      "Iteration 12887, Loss: 0.05398912355303764\n",
      "Iteration 12888, Loss: 0.05417072772979736\n",
      "Iteration 12889, Loss: 0.05398900434374809\n",
      "Iteration 12890, Loss: 0.054170843213796616\n",
      "Iteration 12891, Loss: 0.05398896336555481\n",
      "Iteration 12892, Loss: 0.05417092889547348\n",
      "Iteration 12893, Loss: 0.05398888513445854\n",
      "Iteration 12894, Loss: 0.054171040654182434\n",
      "Iteration 12895, Loss: 0.05398884415626526\n",
      "Iteration 12896, Loss: 0.05417100712656975\n",
      "Iteration 12897, Loss: 0.053988806903362274\n",
      "Iteration 12898, Loss: 0.05417100712656975\n",
      "Iteration 12899, Loss: 0.05398868769407272\n",
      "Iteration 12900, Loss: 0.05417100712656975\n",
      "Iteration 12901, Loss: 0.053988806903362274\n",
      "Iteration 12902, Loss: 0.054170962423086166\n",
      "Iteration 12903, Loss: 0.053988926112651825\n",
      "Iteration 12904, Loss: 0.0541708841919899\n",
      "Iteration 12905, Loss: 0.05398908257484436\n",
      "Iteration 12906, Loss: 0.05417069047689438\n",
      "Iteration 12907, Loss: 0.05398907884955406\n",
      "Iteration 12908, Loss: 0.05417092889547348\n",
      "Iteration 12909, Loss: 0.053988926112651825\n",
      "Iteration 12910, Loss: 0.054171040654182434\n",
      "Iteration 12911, Loss: 0.053988732397556305\n",
      "Iteration 12912, Loss: 0.05417116731405258\n",
      "Iteration 12913, Loss: 0.05398865044116974\n",
      "Iteration 12914, Loss: 0.05417132377624512\n",
      "Iteration 12915, Loss: 0.05398852750658989\n",
      "Iteration 12916, Loss: 0.054171472787857056\n",
      "Iteration 12917, Loss: 0.05398837476968765\n",
      "Iteration 12918, Loss: 0.05417143553495407\n",
      "Iteration 12919, Loss: 0.05398852750658989\n",
      "Iteration 12920, Loss: 0.054171305149793625\n",
      "Iteration 12921, Loss: 0.053988806903362274\n",
      "Iteration 12922, Loss: 0.05417095869779587\n",
      "Iteration 12923, Loss: 0.05398903414607048\n",
      "Iteration 12924, Loss: 0.05417095869779587\n",
      "Iteration 12925, Loss: 0.053989045321941376\n",
      "Iteration 12926, Loss: 0.05417080223560333\n",
      "Iteration 12927, Loss: 0.05398896336555481\n",
      "Iteration 12928, Loss: 0.054170966148376465\n",
      "Iteration 12929, Loss: 0.053988926112651825\n",
      "Iteration 12930, Loss: 0.0541711263358593\n",
      "Iteration 12931, Loss: 0.053988538682460785\n",
      "Iteration 12932, Loss: 0.054171398282051086\n",
      "Iteration 12933, Loss: 0.05398830026388168\n",
      "Iteration 12934, Loss: 0.05417156219482422\n",
      "Iteration 12935, Loss: 0.053988292813301086\n",
      "Iteration 12936, Loss: 0.054171591997146606\n",
      "Iteration 12937, Loss: 0.053988367319107056\n",
      "Iteration 12938, Loss: 0.05417143553495407\n",
      "Iteration 12939, Loss: 0.05398856848478317\n",
      "Iteration 12940, Loss: 0.05417131632566452\n",
      "Iteration 12941, Loss: 0.053988754749298096\n",
      "Iteration 12942, Loss: 0.0541711151599884\n",
      "Iteration 12943, Loss: 0.05398884415626526\n",
      "Iteration 12944, Loss: 0.054171036928892136\n",
      "Iteration 12945, Loss: 0.053989000618457794\n",
      "Iteration 12946, Loss: 0.05417100340127945\n",
      "Iteration 12947, Loss: 0.053988926112651825\n",
      "Iteration 12948, Loss: 0.0541711151599884\n",
      "Iteration 12949, Loss: 0.05398876965045929\n",
      "Iteration 12950, Loss: 0.054171085357666016\n",
      "Iteration 12951, Loss: 0.053988732397556305\n",
      "Iteration 12952, Loss: 0.054171159863471985\n",
      "Iteration 12953, Loss: 0.05398869514465332\n",
      "Iteration 12954, Loss: 0.054171234369277954\n",
      "Iteration 12955, Loss: 0.053988657891750336\n",
      "Iteration 12956, Loss: 0.054171353578567505\n",
      "Iteration 12957, Loss: 0.0539884977042675\n",
      "Iteration 12958, Loss: 0.05417128652334213\n",
      "Iteration 12959, Loss: 0.05398864671587944\n",
      "Iteration 12960, Loss: 0.054171204566955566\n",
      "Iteration 12961, Loss: 0.05398872494697571\n",
      "Iteration 12962, Loss: 0.054171122610569\n",
      "Iteration 12963, Loss: 0.05398881062865257\n",
      "Iteration 12964, Loss: 0.05417092889547348\n",
      "Iteration 12965, Loss: 0.053989045321941376\n",
      "Iteration 12966, Loss: 0.0541708841919899\n",
      "Iteration 12967, Loss: 0.053989045321941376\n",
      "Iteration 12968, Loss: 0.054171040654182434\n",
      "Iteration 12969, Loss: 0.05398884415626526\n",
      "Iteration 12970, Loss: 0.05417107790708542\n",
      "Iteration 12971, Loss: 0.0539887361228466\n",
      "Iteration 12972, Loss: 0.054171040654182434\n",
      "Iteration 12973, Loss: 0.053988806903362274\n",
      "Iteration 12974, Loss: 0.05417108163237572\n",
      "Iteration 12975, Loss: 0.05398884415626526\n",
      "Iteration 12976, Loss: 0.0541711263358593\n",
      "Iteration 12977, Loss: 0.05398876592516899\n",
      "Iteration 12978, Loss: 0.05417124554514885\n",
      "Iteration 12979, Loss: 0.05398868769407272\n",
      "Iteration 12980, Loss: 0.05417143553495407\n",
      "Iteration 12981, Loss: 0.05398856848478317\n",
      "Iteration 12982, Loss: 0.05417143553495407\n",
      "Iteration 12983, Loss: 0.05398852750658989\n",
      "Iteration 12984, Loss: 0.0541713647544384\n",
      "Iteration 12985, Loss: 0.05398856848478317\n",
      "Iteration 12986, Loss: 0.05417131632566452\n",
      "Iteration 12987, Loss: 0.05398876219987869\n",
      "Iteration 12988, Loss: 0.05417118966579437\n",
      "Iteration 12989, Loss: 0.05398888513445854\n",
      "Iteration 12990, Loss: 0.05417095869779587\n",
      "Iteration 12991, Loss: 0.05398900434374809\n",
      "Iteration 12992, Loss: 0.0541708841919899\n",
      "Iteration 12993, Loss: 0.05398900434374809\n",
      "Iteration 12994, Loss: 0.054170843213796616\n",
      "Iteration 12995, Loss: 0.0539892315864563\n",
      "Iteration 12996, Loss: 0.054170843213796616\n",
      "Iteration 12997, Loss: 0.05398908257484436\n",
      "Iteration 12998, Loss: 0.05417092144489288\n",
      "Iteration 12999, Loss: 0.05398888513445854\n",
      "Iteration 13000, Loss: 0.05417104810476303\n",
      "Iteration 13001, Loss: 0.05398869514465332\n",
      "Iteration 13002, Loss: 0.05417120084166527\n",
      "Iteration 13003, Loss: 0.05398861691355705\n",
      "Iteration 13004, Loss: 0.054171159863471985\n",
      "Iteration 13005, Loss: 0.05398869141936302\n",
      "Iteration 13006, Loss: 0.0541711151599884\n",
      "Iteration 13007, Loss: 0.053988873958587646\n",
      "Iteration 13008, Loss: 0.05417100712656975\n",
      "Iteration 13009, Loss: 0.05398884415626526\n",
      "Iteration 13010, Loss: 0.054171040654182434\n",
      "Iteration 13011, Loss: 0.053989000618457794\n",
      "Iteration 13012, Loss: 0.054170962423086166\n",
      "Iteration 13013, Loss: 0.05398900434374809\n",
      "Iteration 13014, Loss: 0.05417083948850632\n",
      "Iteration 13015, Loss: 0.0539892315864563\n",
      "Iteration 13016, Loss: 0.05417072772979736\n",
      "Iteration 13017, Loss: 0.053989242762327194\n",
      "Iteration 13018, Loss: 0.05417080968618393\n",
      "Iteration 13019, Loss: 0.053989164531230927\n",
      "Iteration 13020, Loss: 0.05417093262076378\n",
      "Iteration 13021, Loss: 0.05398876592516899\n",
      "Iteration 13022, Loss: 0.0541711300611496\n",
      "Iteration 13023, Loss: 0.05398857593536377\n",
      "Iteration 13024, Loss: 0.05417143553495407\n",
      "Iteration 13025, Loss: 0.053988419473171234\n",
      "Iteration 13026, Loss: 0.05417151376605034\n",
      "Iteration 13027, Loss: 0.05398853123188019\n",
      "Iteration 13028, Loss: 0.054171353578567505\n",
      "Iteration 13029, Loss: 0.05398868769407272\n",
      "Iteration 13030, Loss: 0.054171156138181686\n",
      "Iteration 13031, Loss: 0.05398895591497421\n",
      "Iteration 13032, Loss: 0.05417100340127945\n",
      "Iteration 13033, Loss: 0.05398900434374809\n",
      "Iteration 13034, Loss: 0.0541708879172802\n",
      "Iteration 13035, Loss: 0.05398911237716675\n",
      "Iteration 13036, Loss: 0.054170846939086914\n",
      "Iteration 13037, Loss: 0.053989119827747345\n",
      "Iteration 13038, Loss: 0.0541708879172802\n",
      "Iteration 13039, Loss: 0.05398911237716675\n",
      "Iteration 13040, Loss: 0.0541708879172802\n",
      "Iteration 13041, Loss: 0.053988851606845856\n",
      "Iteration 13042, Loss: 0.054171036928892136\n",
      "Iteration 13043, Loss: 0.0539887361228466\n",
      "Iteration 13044, Loss: 0.054170966148376465\n",
      "Iteration 13045, Loss: 0.05398876592516899\n",
      "Iteration 13046, Loss: 0.05417100340127945\n",
      "Iteration 13047, Loss: 0.05398876965045929\n",
      "Iteration 13048, Loss: 0.0541708879172802\n",
      "Iteration 13049, Loss: 0.053988926112651825\n",
      "Iteration 13050, Loss: 0.054171036928892136\n",
      "Iteration 13051, Loss: 0.053988926112651825\n",
      "Iteration 13052, Loss: 0.05417100340127945\n",
      "Iteration 13053, Loss: 0.05398888140916824\n",
      "Iteration 13054, Loss: 0.054171156138181686\n",
      "Iteration 13055, Loss: 0.05398869514465332\n",
      "Iteration 13056, Loss: 0.05417130887508392\n",
      "Iteration 13057, Loss: 0.05398861691355705\n",
      "Iteration 13058, Loss: 0.05417138338088989\n",
      "Iteration 13059, Loss: 0.05398876592516899\n",
      "Iteration 13060, Loss: 0.054171230643987656\n",
      "Iteration 13061, Loss: 0.05398876592516899\n",
      "Iteration 13062, Loss: 0.0541711151599884\n",
      "Iteration 13063, Loss: 0.05398891866207123\n",
      "Iteration 13064, Loss: 0.054171159863471985\n",
      "Iteration 13065, Loss: 0.05398876592516899\n",
      "Iteration 13066, Loss: 0.05417131632566452\n",
      "Iteration 13067, Loss: 0.05398872122168541\n",
      "Iteration 13068, Loss: 0.054171472787857056\n",
      "Iteration 13069, Loss: 0.05398845300078392\n",
      "Iteration 13070, Loss: 0.05417163297533989\n",
      "Iteration 13071, Loss: 0.05398837476968765\n",
      "Iteration 13072, Loss: 0.05417155846953392\n",
      "Iteration 13073, Loss: 0.05398837476968765\n",
      "Iteration 13074, Loss: 0.05417148396372795\n",
      "Iteration 13075, Loss: 0.05398833751678467\n",
      "Iteration 13076, Loss: 0.05417140573263168\n",
      "Iteration 13077, Loss: 0.053988486528396606\n",
      "Iteration 13078, Loss: 0.05417127162218094\n",
      "Iteration 13079, Loss: 0.05398884043097496\n",
      "Iteration 13080, Loss: 0.054171036928892136\n",
      "Iteration 13081, Loss: 0.05398907512426376\n",
      "Iteration 13082, Loss: 0.054170917719602585\n",
      "Iteration 13083, Loss: 0.053989194333553314\n",
      "Iteration 13084, Loss: 0.054170843213796616\n",
      "Iteration 13085, Loss: 0.05398911237716675\n",
      "Iteration 13086, Loss: 0.05417107790708542\n",
      "Iteration 13087, Loss: 0.05398891493678093\n",
      "Iteration 13088, Loss: 0.054171159863471985\n",
      "Iteration 13089, Loss: 0.05398876592516899\n",
      "Iteration 13090, Loss: 0.05417131632566452\n",
      "Iteration 13091, Loss: 0.053988680243492126\n",
      "Iteration 13092, Loss: 0.05417139455676079\n",
      "Iteration 13093, Loss: 0.05398844927549362\n",
      "Iteration 13094, Loss: 0.05417139455676079\n",
      "Iteration 13095, Loss: 0.05398860573768616\n",
      "Iteration 13096, Loss: 0.05417131632566452\n",
      "Iteration 13097, Loss: 0.053988635540008545\n",
      "Iteration 13098, Loss: 0.054171230643987656\n",
      "Iteration 13099, Loss: 0.053988806903362274\n",
      "Iteration 13100, Loss: 0.0541711151599884\n",
      "Iteration 13101, Loss: 0.053988926112651825\n",
      "Iteration 13102, Loss: 0.05417099595069885\n",
      "Iteration 13103, Loss: 0.05398900434374809\n",
      "Iteration 13104, Loss: 0.054170966148376465\n",
      "Iteration 13105, Loss: 0.05398907884955406\n",
      "Iteration 13106, Loss: 0.05417092889547348\n",
      "Iteration 13107, Loss: 0.05398903787136078\n",
      "Iteration 13108, Loss: 0.054171156138181686\n",
      "Iteration 13109, Loss: 0.05398872494697571\n",
      "Iteration 13110, Loss: 0.05417143553495407\n",
      "Iteration 13111, Loss: 0.05398852750658989\n",
      "Iteration 13112, Loss: 0.05417162925004959\n",
      "Iteration 13113, Loss: 0.053988367319107056\n",
      "Iteration 13114, Loss: 0.054171591997146606\n",
      "Iteration 13115, Loss: 0.05398844927549362\n",
      "Iteration 13116, Loss: 0.054171279072761536\n",
      "Iteration 13117, Loss: 0.053988754749298096\n",
      "Iteration 13118, Loss: 0.05417107790708542\n",
      "Iteration 13119, Loss: 0.0539889931678772\n",
      "Iteration 13120, Loss: 0.054170917719602585\n",
      "Iteration 13121, Loss: 0.05398915335536003\n",
      "Iteration 13122, Loss: 0.05417080968618393\n",
      "Iteration 13123, Loss: 0.05398915335536003\n",
      "Iteration 13124, Loss: 0.054170917719602585\n",
      "Iteration 13125, Loss: 0.05398911237716675\n",
      "Iteration 13126, Loss: 0.054171036928892136\n",
      "Iteration 13127, Loss: 0.0539889931678772\n",
      "Iteration 13128, Loss: 0.054171156138181686\n",
      "Iteration 13129, Loss: 0.05398876592516899\n",
      "Iteration 13130, Loss: 0.054171543568372726\n",
      "Iteration 13131, Loss: 0.05398844927549362\n",
      "Iteration 13132, Loss: 0.054171591997146606\n",
      "Iteration 13133, Loss: 0.05398837849497795\n",
      "Iteration 13134, Loss: 0.054171543568372726\n",
      "Iteration 13135, Loss: 0.05398852750658989\n",
      "Iteration 13136, Loss: 0.05417138338088989\n",
      "Iteration 13137, Loss: 0.053988754749298096\n",
      "Iteration 13138, Loss: 0.054171156138181686\n",
      "Iteration 13139, Loss: 0.05398888140916824\n",
      "Iteration 13140, Loss: 0.05417122691869736\n",
      "Iteration 13141, Loss: 0.05398895964026451\n",
      "Iteration 13142, Loss: 0.0541711151599884\n",
      "Iteration 13143, Loss: 0.05398888140916824\n",
      "Iteration 13144, Loss: 0.05417119711637497\n",
      "Iteration 13145, Loss: 0.05398876592516899\n",
      "Iteration 13146, Loss: 0.054171159863471985\n",
      "Iteration 13147, Loss: 0.05398876592516899\n",
      "Iteration 13148, Loss: 0.054171234369277954\n",
      "Iteration 13149, Loss: 0.05398883670568466\n",
      "Iteration 13150, Loss: 0.054171156138181686\n",
      "Iteration 13151, Loss: 0.05398891493678093\n",
      "Iteration 13152, Loss: 0.054171036928892136\n",
      "Iteration 13153, Loss: 0.05398883670568466\n",
      "Iteration 13154, Loss: 0.05417108163237572\n",
      "Iteration 13155, Loss: 0.05398891493678093\n",
      "Iteration 13156, Loss: 0.0541711151599884\n",
      "Iteration 13157, Loss: 0.05398881435394287\n",
      "Iteration 13158, Loss: 0.05417120084166527\n",
      "Iteration 13159, Loss: 0.05398865044116974\n",
      "Iteration 13160, Loss: 0.054171353578567505\n",
      "Iteration 13161, Loss: 0.05398860201239586\n",
      "Iteration 13162, Loss: 0.054171472787857056\n",
      "Iteration 13163, Loss: 0.053988486528396606\n",
      "Iteration 13164, Loss: 0.054171428084373474\n",
      "Iteration 13165, Loss: 0.05398860573768616\n",
      "Iteration 13166, Loss: 0.05417139083147049\n",
      "Iteration 13167, Loss: 0.053988754749298096\n",
      "Iteration 13168, Loss: 0.054171305149793625\n",
      "Iteration 13169, Loss: 0.053988873958587646\n",
      "Iteration 13170, Loss: 0.05417122691869736\n",
      "Iteration 13171, Loss: 0.05398891493678093\n",
      "Iteration 13172, Loss: 0.054171185940504074\n",
      "Iteration 13173, Loss: 0.05398891493678093\n",
      "Iteration 13174, Loss: 0.054171156138181686\n",
      "Iteration 13175, Loss: 0.0539889931678772\n",
      "Iteration 13176, Loss: 0.054171122610569\n",
      "Iteration 13177, Loss: 0.05398879572749138\n",
      "Iteration 13178, Loss: 0.054171353578567505\n",
      "Iteration 13179, Loss: 0.053988680243492126\n",
      "Iteration 13180, Loss: 0.05417139455676079\n",
      "Iteration 13181, Loss: 0.05398845300078392\n",
      "Iteration 13182, Loss: 0.05417148023843765\n",
      "Iteration 13183, Loss: 0.05398841202259064\n",
      "Iteration 13184, Loss: 0.054171472787857056\n",
      "Iteration 13185, Loss: 0.053988561034202576\n",
      "Iteration 13186, Loss: 0.05417150259017944\n",
      "Iteration 13187, Loss: 0.05398864299058914\n",
      "Iteration 13188, Loss: 0.05417119711637497\n",
      "Iteration 13189, Loss: 0.053989022970199585\n",
      "Iteration 13190, Loss: 0.054171185940504074\n",
      "Iteration 13191, Loss: 0.05398903414607048\n",
      "Iteration 13192, Loss: 0.05417107790708542\n",
      "Iteration 13193, Loss: 0.05398903787136078\n",
      "Iteration 13194, Loss: 0.05417119711637497\n",
      "Iteration 13195, Loss: 0.053988873958587646\n",
      "Iteration 13196, Loss: 0.05417139455676079\n",
      "Iteration 13197, Loss: 0.053988680243492126\n",
      "Iteration 13198, Loss: 0.05417151376605034\n",
      "Iteration 13199, Loss: 0.05398844927549362\n",
      "Iteration 13200, Loss: 0.05417163297533989\n",
      "Iteration 13201, Loss: 0.05398828908801079\n",
      "Iteration 13202, Loss: 0.05417166277766228\n",
      "Iteration 13203, Loss: 0.05398848280310631\n",
      "Iteration 13204, Loss: 0.054171472787857056\n",
      "Iteration 13205, Loss: 0.05398860573768616\n",
      "Iteration 13206, Loss: 0.05417127534747124\n",
      "Iteration 13207, Loss: 0.053988873958587646\n",
      "Iteration 13208, Loss: 0.054171156138181686\n",
      "Iteration 13209, Loss: 0.05398888140916824\n",
      "Iteration 13210, Loss: 0.054171036928892136\n",
      "Iteration 13211, Loss: 0.05398911237716675\n",
      "Iteration 13212, Loss: 0.054171036928892136\n",
      "Iteration 13213, Loss: 0.05398895591497421\n",
      "Iteration 13214, Loss: 0.05417127534747124\n",
      "Iteration 13215, Loss: 0.05398883670568466\n",
      "Iteration 13216, Loss: 0.05417132005095482\n",
      "Iteration 13217, Loss: 0.05398860201239586\n",
      "Iteration 13218, Loss: 0.05417163297533989\n",
      "Iteration 13219, Loss: 0.053988486528396606\n",
      "Iteration 13220, Loss: 0.05417171120643616\n",
      "Iteration 13221, Loss: 0.0539882555603981\n",
      "Iteration 13222, Loss: 0.05417163297533989\n",
      "Iteration 13223, Loss: 0.05398844927549362\n",
      "Iteration 13224, Loss: 0.05417155474424362\n",
      "Iteration 13225, Loss: 0.053988561034202576\n",
      "Iteration 13226, Loss: 0.054171424359083176\n",
      "Iteration 13227, Loss: 0.053988680243492126\n",
      "Iteration 13228, Loss: 0.05417119711637497\n",
      "Iteration 13229, Loss: 0.0539889931678772\n",
      "Iteration 13230, Loss: 0.054171230643987656\n",
      "Iteration 13231, Loss: 0.05398884043097496\n",
      "Iteration 13232, Loss: 0.05417127162218094\n",
      "Iteration 13233, Loss: 0.05398872494697571\n",
      "Iteration 13234, Loss: 0.05417127534747124\n",
      "Iteration 13235, Loss: 0.05398860573768616\n",
      "Iteration 13236, Loss: 0.05417124181985855\n",
      "Iteration 13237, Loss: 0.05398876592516899\n",
      "Iteration 13238, Loss: 0.054171234369277954\n",
      "Iteration 13239, Loss: 0.05398861691355705\n",
      "Iteration 13240, Loss: 0.05417127162218094\n",
      "Iteration 13241, Loss: 0.05398872494697571\n",
      "Iteration 13242, Loss: 0.054171156138181686\n",
      "Iteration 13243, Loss: 0.053988873958587646\n",
      "Iteration 13244, Loss: 0.054171156138181686\n",
      "Iteration 13245, Loss: 0.05398895591497421\n",
      "Iteration 13246, Loss: 0.054171156138181686\n",
      "Iteration 13247, Loss: 0.05398888513445854\n",
      "Iteration 13248, Loss: 0.0541711151599884\n",
      "Iteration 13249, Loss: 0.05398876592516899\n",
      "Iteration 13250, Loss: 0.05417127162218094\n",
      "Iteration 13251, Loss: 0.05398879572749138\n",
      "Iteration 13252, Loss: 0.05417130887508392\n",
      "Iteration 13253, Loss: 0.053988680243492126\n",
      "Iteration 13254, Loss: 0.05417145788669586\n",
      "Iteration 13255, Loss: 0.05398879572749138\n",
      "Iteration 13256, Loss: 0.05417127534747124\n",
      "Iteration 13257, Loss: 0.05398883670568466\n",
      "Iteration 13258, Loss: 0.0541711151599884\n",
      "Iteration 13259, Loss: 0.0539889931678772\n",
      "Iteration 13260, Loss: 0.054170966148376465\n",
      "Iteration 13261, Loss: 0.05398918688297272\n",
      "Iteration 13262, Loss: 0.05417095869779587\n",
      "Iteration 13263, Loss: 0.05398903414607048\n",
      "Iteration 13264, Loss: 0.05417092144489288\n",
      "Iteration 13265, Loss: 0.05398891866207123\n",
      "Iteration 13266, Loss: 0.054171085357666016\n",
      "Iteration 13267, Loss: 0.053988873958587646\n",
      "Iteration 13268, Loss: 0.05417127534747124\n",
      "Iteration 13269, Loss: 0.053988754749298096\n",
      "Iteration 13270, Loss: 0.05417124181985855\n",
      "Iteration 13271, Loss: 0.05398872494697571\n",
      "Iteration 13272, Loss: 0.05417127534747124\n",
      "Iteration 13273, Loss: 0.05398884043097496\n",
      "Iteration 13274, Loss: 0.054171230643987656\n",
      "Iteration 13275, Loss: 0.05398895591497421\n",
      "Iteration 13276, Loss: 0.054171156138181686\n",
      "Iteration 13277, Loss: 0.05398891493678093\n",
      "Iteration 13278, Loss: 0.054171156138181686\n",
      "Iteration 13279, Loss: 0.05398888140916824\n",
      "Iteration 13280, Loss: 0.05417108163237572\n",
      "Iteration 13281, Loss: 0.05398895591497421\n",
      "Iteration 13282, Loss: 0.054171230643987656\n",
      "Iteration 13283, Loss: 0.05398891493678093\n",
      "Iteration 13284, Loss: 0.054171279072761536\n",
      "Iteration 13285, Loss: 0.053988680243492126\n",
      "Iteration 13286, Loss: 0.05417140573263168\n",
      "Iteration 13287, Loss: 0.053988486528396606\n",
      "Iteration 13288, Loss: 0.054171591997146606\n",
      "Iteration 13289, Loss: 0.053988486528396606\n",
      "Iteration 13290, Loss: 0.05417151376605034\n",
      "Iteration 13291, Loss: 0.05398852750658989\n",
      "Iteration 13292, Loss: 0.05417127534747124\n",
      "Iteration 13293, Loss: 0.053988657891750336\n",
      "Iteration 13294, Loss: 0.054171107709407806\n",
      "Iteration 13295, Loss: 0.05398896336555481\n",
      "Iteration 13296, Loss: 0.0541708767414093\n",
      "Iteration 13297, Loss: 0.05398915708065033\n",
      "Iteration 13298, Loss: 0.0541708767414093\n",
      "Iteration 13299, Loss: 0.05398927256464958\n",
      "Iteration 13300, Loss: 0.054170917719602585\n",
      "Iteration 13301, Loss: 0.05398911237716675\n",
      "Iteration 13302, Loss: 0.054171036928892136\n",
      "Iteration 13303, Loss: 0.0539889931678772\n",
      "Iteration 13304, Loss: 0.05417127534747124\n",
      "Iteration 13305, Loss: 0.05398864299058914\n",
      "Iteration 13306, Loss: 0.054171472787857056\n",
      "Iteration 13307, Loss: 0.053988486528396606\n",
      "Iteration 13308, Loss: 0.05417170375585556\n",
      "Iteration 13309, Loss: 0.053988486528396606\n",
      "Iteration 13310, Loss: 0.05417151376605034\n",
      "Iteration 13311, Loss: 0.05398864299058914\n",
      "Iteration 13312, Loss: 0.05417139455676079\n",
      "Iteration 13313, Loss: 0.053988873958587646\n",
      "Iteration 13314, Loss: 0.05417119711637497\n",
      "Iteration 13315, Loss: 0.05398891493678093\n",
      "Iteration 13316, Loss: 0.05417107790708542\n",
      "Iteration 13317, Loss: 0.053989067673683167\n",
      "Iteration 13318, Loss: 0.054170966148376465\n",
      "Iteration 13319, Loss: 0.053988926112651825\n",
      "Iteration 13320, Loss: 0.054171085357666016\n",
      "Iteration 13321, Loss: 0.053988873958587646\n",
      "Iteration 13322, Loss: 0.05417132005095482\n",
      "Iteration 13323, Loss: 0.05398860201239586\n",
      "Iteration 13324, Loss: 0.054171621799468994\n",
      "Iteration 13325, Loss: 0.053988486528396606\n",
      "Iteration 13326, Loss: 0.05417158827185631\n",
      "Iteration 13327, Loss: 0.05398852750658989\n",
      "Iteration 13328, Loss: 0.05417146533727646\n",
      "Iteration 13329, Loss: 0.05398860573768616\n",
      "Iteration 13330, Loss: 0.05417138338088989\n",
      "Iteration 13331, Loss: 0.05398883670568466\n",
      "Iteration 13332, Loss: 0.05417118966579437\n",
      "Iteration 13333, Loss: 0.05398891866207123\n",
      "Iteration 13334, Loss: 0.0541711151599884\n",
      "Iteration 13335, Loss: 0.05398896336555481\n",
      "Iteration 13336, Loss: 0.054171036928892136\n",
      "Iteration 13337, Loss: 0.05398896336555481\n",
      "Iteration 13338, Loss: 0.054171085357666016\n",
      "Iteration 13339, Loss: 0.05398883670568466\n",
      "Iteration 13340, Loss: 0.054171279072761536\n",
      "Iteration 13341, Loss: 0.053988754749298096\n",
      "Iteration 13342, Loss: 0.05417150259017944\n",
      "Iteration 13343, Loss: 0.053988486528396606\n",
      "Iteration 13344, Loss: 0.054171472787857056\n",
      "Iteration 13345, Loss: 0.05398859828710556\n",
      "Iteration 13346, Loss: 0.05417139083147049\n",
      "Iteration 13347, Loss: 0.05398872494697571\n",
      "Iteration 13348, Loss: 0.0541711151599884\n",
      "Iteration 13349, Loss: 0.0539889931678772\n",
      "Iteration 13350, Loss: 0.054170917719602585\n",
      "Iteration 13351, Loss: 0.05398918688297272\n",
      "Iteration 13352, Loss: 0.05417080223560333\n",
      "Iteration 13353, Loss: 0.05398911237716675\n",
      "Iteration 13354, Loss: 0.054171036928892136\n",
      "Iteration 13355, Loss: 0.05398891866207123\n",
      "Iteration 13356, Loss: 0.05417119711637497\n",
      "Iteration 13357, Loss: 0.05398872122168541\n",
      "Iteration 13358, Loss: 0.05417155474424362\n",
      "Iteration 13359, Loss: 0.05398837476968765\n",
      "Iteration 13360, Loss: 0.054171741008758545\n",
      "Iteration 13361, Loss: 0.05398840457201004\n",
      "Iteration 13362, Loss: 0.05417155474424362\n",
      "Iteration 13363, Loss: 0.053988516330718994\n",
      "Iteration 13364, Loss: 0.05417138338088989\n",
      "Iteration 13365, Loss: 0.05398883670568466\n",
      "Iteration 13366, Loss: 0.0541711151599884\n",
      "Iteration 13367, Loss: 0.053989067673683167\n",
      "Iteration 13368, Loss: 0.05417100340127945\n",
      "Iteration 13369, Loss: 0.05398907512426376\n",
      "Iteration 13370, Loss: 0.054170962423086166\n",
      "Iteration 13371, Loss: 0.05398895964026451\n",
      "Iteration 13372, Loss: 0.054171122610569\n",
      "Iteration 13373, Loss: 0.05398876219987869\n",
      "Iteration 13374, Loss: 0.05417139455676079\n",
      "Iteration 13375, Loss: 0.05398856848478317\n",
      "Iteration 13376, Loss: 0.054171472787857056\n",
      "Iteration 13377, Loss: 0.05398844927549362\n",
      "Iteration 13378, Loss: 0.05417158827185631\n",
      "Iteration 13379, Loss: 0.05398852750658989\n",
      "Iteration 13380, Loss: 0.05417143553495407\n",
      "Iteration 13381, Loss: 0.05398856848478317\n",
      "Iteration 13382, Loss: 0.054171353578567505\n",
      "Iteration 13383, Loss: 0.05398883670568466\n",
      "Iteration 13384, Loss: 0.05417131632566452\n",
      "Iteration 13385, Loss: 0.05398883670568466\n",
      "Iteration 13386, Loss: 0.05417127534747124\n",
      "Iteration 13387, Loss: 0.05398883670568466\n",
      "Iteration 13388, Loss: 0.05417126417160034\n",
      "Iteration 13389, Loss: 0.05398895591497421\n",
      "Iteration 13390, Loss: 0.05417107790708542\n",
      "Iteration 13391, Loss: 0.05398891866207123\n",
      "Iteration 13392, Loss: 0.0541711151599884\n",
      "Iteration 13393, Loss: 0.05398876219987869\n",
      "Iteration 13394, Loss: 0.05417131632566452\n",
      "Iteration 13395, Loss: 0.05398867651820183\n",
      "Iteration 13396, Loss: 0.0541713610291481\n",
      "Iteration 13397, Loss: 0.05398867651820183\n",
      "Iteration 13398, Loss: 0.05417131632566452\n",
      "Iteration 13399, Loss: 0.053988754749298096\n",
      "Iteration 13400, Loss: 0.05417127534747124\n",
      "Iteration 13401, Loss: 0.053988806903362274\n",
      "Iteration 13402, Loss: 0.05417119711637497\n",
      "Iteration 13403, Loss: 0.05398879945278168\n",
      "Iteration 13404, Loss: 0.054171234369277954\n",
      "Iteration 13405, Loss: 0.053988873958587646\n",
      "Iteration 13406, Loss: 0.054171156138181686\n",
      "Iteration 13407, Loss: 0.05398876592516899\n",
      "Iteration 13408, Loss: 0.054171156138181686\n",
      "Iteration 13409, Loss: 0.05398895591497421\n",
      "Iteration 13410, Loss: 0.05417119711637497\n",
      "Iteration 13411, Loss: 0.053988806903362274\n",
      "Iteration 13412, Loss: 0.054171305149793625\n",
      "Iteration 13413, Loss: 0.05398876592516899\n",
      "Iteration 13414, Loss: 0.054171349853277206\n",
      "Iteration 13415, Loss: 0.05398872494697571\n",
      "Iteration 13416, Loss: 0.05417130887508392\n",
      "Iteration 13417, Loss: 0.05398883670568466\n",
      "Iteration 13418, Loss: 0.05417119711637497\n",
      "Iteration 13419, Loss: 0.05398884043097496\n",
      "Iteration 13420, Loss: 0.0541711151599884\n",
      "Iteration 13421, Loss: 0.05398888513445854\n",
      "Iteration 13422, Loss: 0.054171156138181686\n",
      "Iteration 13423, Loss: 0.05398884415626526\n",
      "Iteration 13424, Loss: 0.054171234369277954\n",
      "Iteration 13425, Loss: 0.05398883670568466\n",
      "Iteration 13426, Loss: 0.05417127534747124\n",
      "Iteration 13427, Loss: 0.05398887023329735\n",
      "Iteration 13428, Loss: 0.054171353578567505\n",
      "Iteration 13429, Loss: 0.05398864671587944\n",
      "Iteration 13430, Loss: 0.054171279072761536\n",
      "Iteration 13431, Loss: 0.05398876219987869\n",
      "Iteration 13432, Loss: 0.05417138338088989\n",
      "Iteration 13433, Loss: 0.05398884043097496\n",
      "Iteration 13434, Loss: 0.054171156138181686\n",
      "Iteration 13435, Loss: 0.053988806903362274\n",
      "Iteration 13436, Loss: 0.054171156138181686\n",
      "Iteration 13437, Loss: 0.05398895591497421\n",
      "Iteration 13438, Loss: 0.05417115241289139\n",
      "Iteration 13439, Loss: 0.05398888140916824\n",
      "Iteration 13440, Loss: 0.05417122691869736\n",
      "Iteration 13441, Loss: 0.05398876592516899\n",
      "Iteration 13442, Loss: 0.05417131632566452\n",
      "Iteration 13443, Loss: 0.05398879572749138\n",
      "Iteration 13444, Loss: 0.05417146906256676\n",
      "Iteration 13445, Loss: 0.05398856848478317\n",
      "Iteration 13446, Loss: 0.05417143553495407\n",
      "Iteration 13447, Loss: 0.053988486528396606\n",
      "Iteration 13448, Loss: 0.05417158827185631\n",
      "Iteration 13449, Loss: 0.05398859828710556\n",
      "Iteration 13450, Loss: 0.05417132005095482\n",
      "Iteration 13451, Loss: 0.05398867651820183\n",
      "Iteration 13452, Loss: 0.05417126417160034\n",
      "Iteration 13453, Loss: 0.053988806903362274\n",
      "Iteration 13454, Loss: 0.05417107045650482\n",
      "Iteration 13455, Loss: 0.05398918315768242\n",
      "Iteration 13456, Loss: 0.054170843213796616\n",
      "Iteration 13457, Loss: 0.05398915335536003\n",
      "Iteration 13458, Loss: 0.05417107045650482\n",
      "Iteration 13459, Loss: 0.05398896336555481\n",
      "Iteration 13460, Loss: 0.054171156138181686\n",
      "Iteration 13461, Loss: 0.05398876592516899\n",
      "Iteration 13462, Loss: 0.054171234369277954\n",
      "Iteration 13463, Loss: 0.05398872122168541\n",
      "Iteration 13464, Loss: 0.054171472787857056\n",
      "Iteration 13465, Loss: 0.053988486528396606\n",
      "Iteration 13466, Loss: 0.054171591997146606\n",
      "Iteration 13467, Loss: 0.053988367319107056\n",
      "Iteration 13468, Loss: 0.054171666502952576\n",
      "Iteration 13469, Loss: 0.05398847907781601\n",
      "Iteration 13470, Loss: 0.054171547293663025\n",
      "Iteration 13471, Loss: 0.053988486528396606\n",
      "Iteration 13472, Loss: 0.054171428084373474\n",
      "Iteration 13473, Loss: 0.05398867651820183\n",
      "Iteration 13474, Loss: 0.05417134612798691\n",
      "Iteration 13475, Loss: 0.05398891493678093\n",
      "Iteration 13476, Loss: 0.054171122610569\n",
      "Iteration 13477, Loss: 0.05398895591497421\n",
      "Iteration 13478, Loss: 0.054171234369277954\n",
      "Iteration 13479, Loss: 0.05398876592516899\n",
      "Iteration 13480, Loss: 0.05417127534747124\n",
      "Iteration 13481, Loss: 0.053988754749298096\n",
      "Iteration 13482, Loss: 0.054171353578567505\n",
      "Iteration 13483, Loss: 0.05398871749639511\n",
      "Iteration 13484, Loss: 0.05417131632566452\n",
      "Iteration 13485, Loss: 0.05398872494697571\n",
      "Iteration 13486, Loss: 0.05417122691869736\n",
      "Iteration 13487, Loss: 0.05398884043097496\n",
      "Iteration 13488, Loss: 0.05417118966579437\n",
      "Iteration 13489, Loss: 0.05398891866207123\n",
      "Iteration 13490, Loss: 0.05417095869779587\n",
      "Iteration 13491, Loss: 0.0539889931678772\n",
      "Iteration 13492, Loss: 0.05417092144489288\n",
      "Iteration 13493, Loss: 0.0539889931678772\n",
      "Iteration 13494, Loss: 0.054171036928892136\n",
      "Iteration 13495, Loss: 0.053988806903362274\n",
      "Iteration 13496, Loss: 0.05417119711637497\n",
      "Iteration 13497, Loss: 0.05398876592516899\n",
      "Iteration 13498, Loss: 0.05417130887508392\n",
      "Iteration 13499, Loss: 0.05398879572749138\n",
      "Iteration 13500, Loss: 0.05417127534747124\n",
      "Iteration 13501, Loss: 0.05398884043097496\n",
      "Iteration 13502, Loss: 0.05417126417160034\n",
      "Iteration 13503, Loss: 0.053988806903362274\n",
      "Iteration 13504, Loss: 0.05417119711637497\n",
      "Iteration 13505, Loss: 0.05398884043097496\n",
      "Iteration 13506, Loss: 0.054171234369277954\n",
      "Iteration 13507, Loss: 0.05398879945278168\n",
      "Iteration 13508, Loss: 0.054171305149793625\n",
      "Iteration 13509, Loss: 0.05398884043097496\n",
      "Iteration 13510, Loss: 0.054171156138181686\n",
      "Iteration 13511, Loss: 0.05398888140916824\n",
      "Iteration 13512, Loss: 0.054171156138181686\n",
      "Iteration 13513, Loss: 0.05398888140916824\n",
      "Iteration 13514, Loss: 0.054171156138181686\n",
      "Iteration 13515, Loss: 0.05398884415626526\n",
      "Iteration 13516, Loss: 0.054171085357666016\n",
      "Iteration 13517, Loss: 0.05398884043097496\n",
      "Iteration 13518, Loss: 0.05417119711637497\n",
      "Iteration 13519, Loss: 0.05398888513445854\n",
      "Iteration 13520, Loss: 0.05417119711637497\n",
      "Iteration 13521, Loss: 0.05398888513445854\n",
      "Iteration 13522, Loss: 0.054171230643987656\n",
      "Iteration 13523, Loss: 0.05398888513445854\n",
      "Iteration 13524, Loss: 0.054171156138181686\n",
      "Iteration 13525, Loss: 0.0539889931678772\n",
      "Iteration 13526, Loss: 0.054171156138181686\n",
      "Iteration 13527, Loss: 0.0539889931678772\n",
      "Iteration 13528, Loss: 0.05417118966579437\n",
      "Iteration 13529, Loss: 0.05398884043097496\n",
      "Iteration 13530, Loss: 0.05417127534747124\n",
      "Iteration 13531, Loss: 0.05398879572749138\n",
      "Iteration 13532, Loss: 0.05417131632566452\n",
      "Iteration 13533, Loss: 0.05398871749639511\n",
      "Iteration 13534, Loss: 0.0541713610291481\n",
      "Iteration 13535, Loss: 0.053988561034202576\n",
      "Iteration 13536, Loss: 0.054171398282051086\n",
      "Iteration 13537, Loss: 0.05398907512426376\n",
      "Iteration 13538, Loss: 0.05417139455676079\n",
      "Iteration 13539, Loss: 0.0539892315864563\n",
      "Iteration 13540, Loss: 0.05417175218462944\n",
      "Iteration 13541, Loss: 0.05398927256464958\n",
      "Iteration 13542, Loss: 0.05417182296514511\n",
      "Iteration 13543, Loss: 0.053989313542842865\n",
      "Iteration 13544, Loss: 0.054171591997146606\n",
      "Iteration 13545, Loss: 0.05398931726813316\n",
      "Iteration 13546, Loss: 0.054171666502952576\n",
      "Iteration 13547, Loss: 0.053989313542842865\n",
      "Iteration 13548, Loss: 0.05417171120643616\n",
      "Iteration 13549, Loss: 0.053989239037036896\n",
      "Iteration 13550, Loss: 0.05417171120643616\n",
      "Iteration 13551, Loss: 0.053989239037036896\n",
      "Iteration 13552, Loss: 0.05417175218462944\n",
      "Iteration 13553, Loss: 0.05398934707045555\n",
      "Iteration 13554, Loss: 0.05417175218462944\n",
      "Iteration 13555, Loss: 0.05398927256464958\n",
      "Iteration 13556, Loss: 0.05417182296514511\n",
      "Iteration 13557, Loss: 0.05398934707045555\n",
      "Iteration 13558, Loss: 0.054171741008758545\n",
      "Iteration 13559, Loss: 0.05398935079574585\n",
      "Iteration 13560, Loss: 0.05417170375585556\n",
      "Iteration 13561, Loss: 0.0539894662797451\n",
      "Iteration 13562, Loss: 0.054171547293663025\n",
      "Iteration 13563, Loss: 0.05398954451084137\n",
      "Iteration 13564, Loss: 0.054171591997146606\n",
      "Iteration 13565, Loss: 0.0539894662797451\n",
      "Iteration 13566, Loss: 0.05417171120643616\n",
      "Iteration 13567, Loss: 0.053989194333553314\n",
      "Iteration 13568, Loss: 0.05417199060320854\n",
      "Iteration 13569, Loss: 0.05398891493678093\n",
      "Iteration 13570, Loss: 0.054172225296497345\n",
      "Iteration 13571, Loss: 0.05398884043097496\n",
      "Iteration 13572, Loss: 0.05417221784591675\n",
      "Iteration 13573, Loss: 0.05398888513445854\n",
      "Iteration 13574, Loss: 0.05417182669043541\n",
      "Iteration 13575, Loss: 0.053989242762327194\n",
      "Iteration 13576, Loss: 0.054171621799468994\n",
      "Iteration 13577, Loss: 0.05398955196142197\n",
      "Iteration 13578, Loss: 0.05417127162218094\n",
      "Iteration 13579, Loss: 0.053989820182323456\n",
      "Iteration 13580, Loss: 0.05417122691869736\n",
      "Iteration 13581, Loss: 0.05398985743522644\n",
      "Iteration 13582, Loss: 0.05417134612798691\n",
      "Iteration 13583, Loss: 0.05398967117071152\n",
      "Iteration 13584, Loss: 0.05417151004076004\n",
      "Iteration 13585, Loss: 0.053989432752132416\n",
      "Iteration 13586, Loss: 0.054171785712242126\n",
      "Iteration 13587, Loss: 0.053989194333553314\n",
      "Iteration 13588, Loss: 0.05417206883430481\n",
      "Iteration 13589, Loss: 0.05398891866207123\n",
      "Iteration 13590, Loss: 0.05417249724268913\n",
      "Iteration 13591, Loss: 0.05398864299058914\n",
      "Iteration 13592, Loss: 0.05417242646217346\n",
      "Iteration 13593, Loss: 0.05398867651820183\n",
      "Iteration 13594, Loss: 0.05417230725288391\n",
      "Iteration 13595, Loss: 0.053988754749298096\n",
      "Iteration 13596, Loss: 0.05417194589972496\n",
      "Iteration 13597, Loss: 0.053989119827747345\n",
      "Iteration 13598, Loss: 0.05417170375585556\n",
      "Iteration 13599, Loss: 0.0539894700050354\n",
      "Iteration 13600, Loss: 0.05417151376605034\n",
      "Iteration 13601, Loss: 0.053989432752132416\n",
      "Iteration 13602, Loss: 0.054171398282051086\n",
      "Iteration 13603, Loss: 0.0539894700050354\n",
      "Iteration 13604, Loss: 0.05417151749134064\n",
      "Iteration 13605, Loss: 0.053989432752132416\n",
      "Iteration 13606, Loss: 0.05417155846953392\n",
      "Iteration 13607, Loss: 0.05398935079574585\n",
      "Iteration 13608, Loss: 0.05417170375585556\n",
      "Iteration 13609, Loss: 0.05398939177393913\n",
      "Iteration 13610, Loss: 0.054171741008758545\n",
      "Iteration 13611, Loss: 0.05398935079574585\n",
      "Iteration 13612, Loss: 0.05417186766862869\n",
      "Iteration 13613, Loss: 0.05398915335536003\n",
      "Iteration 13614, Loss: 0.0541720911860466\n",
      "Iteration 13615, Loss: 0.05398907512426376\n",
      "Iteration 13616, Loss: 0.054171912372112274\n",
      "Iteration 13617, Loss: 0.0539889931678772\n",
      "Iteration 13618, Loss: 0.05417199060320854\n",
      "Iteration 13619, Loss: 0.05398903787136078\n",
      "Iteration 13620, Loss: 0.05417183041572571\n",
      "Iteration 13621, Loss: 0.05398927256464958\n",
      "Iteration 13622, Loss: 0.054171785712242126\n",
      "Iteration 13623, Loss: 0.05398919805884361\n",
      "Iteration 13624, Loss: 0.05417171120643616\n",
      "Iteration 13625, Loss: 0.053989313542842865\n",
      "Iteration 13626, Loss: 0.05417170375585556\n",
      "Iteration 13627, Loss: 0.0539892315864563\n",
      "Iteration 13628, Loss: 0.054171666502952576\n",
      "Iteration 13629, Loss: 0.05398939177393913\n",
      "Iteration 13630, Loss: 0.05417158454656601\n",
      "Iteration 13631, Loss: 0.053989626467227936\n",
      "Iteration 13632, Loss: 0.054171353578567505\n",
      "Iteration 13633, Loss: 0.05398955196142197\n",
      "Iteration 13634, Loss: 0.05417166277766228\n",
      "Iteration 13635, Loss: 0.05398939177393913\n",
      "Iteration 13636, Loss: 0.054171785712242126\n",
      "Iteration 13637, Loss: 0.05398915335536003\n",
      "Iteration 13638, Loss: 0.05417194962501526\n",
      "Iteration 13639, Loss: 0.05398907512426376\n",
      "Iteration 13640, Loss: 0.05417218059301376\n",
      "Iteration 13641, Loss: 0.05398884043097496\n",
      "Iteration 13642, Loss: 0.05417221784591675\n",
      "Iteration 13643, Loss: 0.05398895591497421\n",
      "Iteration 13644, Loss: 0.0541720986366272\n",
      "Iteration 13645, Loss: 0.05398895964026451\n",
      "Iteration 13646, Loss: 0.05417194217443466\n",
      "Iteration 13647, Loss: 0.05398900434374809\n",
      "Iteration 13648, Loss: 0.05417174845933914\n",
      "Iteration 13649, Loss: 0.05398942157626152\n",
      "Iteration 13650, Loss: 0.05417155474424362\n",
      "Iteration 13651, Loss: 0.053989946842193604\n",
      "Iteration 13652, Loss: 0.05417158454656601\n",
      "Iteration 13653, Loss: 0.05399002879858017\n",
      "Iteration 13654, Loss: 0.054171591997146606\n",
      "Iteration 13655, Loss: 0.053989872336387634\n",
      "Iteration 13656, Loss: 0.05417210981249809\n",
      "Iteration 13657, Loss: 0.05398979038000107\n",
      "Iteration 13658, Loss: 0.05417242646217346\n",
      "Iteration 13659, Loss: 0.05398958921432495\n",
      "Iteration 13660, Loss: 0.054172582924366\n",
      "Iteration 13661, Loss: 0.05398939549922943\n",
      "Iteration 13662, Loss: 0.05417269468307495\n",
      "Iteration 13663, Loss: 0.0539894700050354\n",
      "Iteration 13664, Loss: 0.05417249724268913\n",
      "Iteration 13665, Loss: 0.05398952215909958\n",
      "Iteration 13666, Loss: 0.05417218804359436\n",
      "Iteration 13667, Loss: 0.053989797830581665\n",
      "Iteration 13668, Loss: 0.054172031581401825\n",
      "Iteration 13669, Loss: 0.05398935079574585\n",
      "Iteration 13670, Loss: 0.054172031581401825\n",
      "Iteration 13671, Loss: 0.05398919805884361\n",
      "Iteration 13672, Loss: 0.054172348231077194\n",
      "Iteration 13673, Loss: 0.05398891493678093\n",
      "Iteration 13674, Loss: 0.05417337268590927\n",
      "Iteration 13675, Loss: 0.05398860573768616\n",
      "Iteration 13676, Loss: 0.05417337641119957\n",
      "Iteration 13677, Loss: 0.05398864671587944\n",
      "Iteration 13678, Loss: 0.05417313799262047\n",
      "Iteration 13679, Loss: 0.05398881435394287\n",
      "Iteration 13680, Loss: 0.05417269468307495\n",
      "Iteration 13681, Loss: 0.05398935824632645\n",
      "Iteration 13682, Loss: 0.05417225882411003\n",
      "Iteration 13683, Loss: 0.0539897195994854\n",
      "Iteration 13684, Loss: 0.05417182296514511\n",
      "Iteration 13685, Loss: 0.05399010702967644\n",
      "Iteration 13686, Loss: 0.054171666502952576\n",
      "Iteration 13687, Loss: 0.05399022623896599\n",
      "Iteration 13688, Loss: 0.05417163297533989\n",
      "Iteration 13689, Loss: 0.05399014800786972\n",
      "Iteration 13690, Loss: 0.0541718415915966\n",
      "Iteration 13691, Loss: 0.053989898413419724\n",
      "Iteration 13692, Loss: 0.05417219549417496\n",
      "Iteration 13693, Loss: 0.053989700973033905\n",
      "Iteration 13694, Loss: 0.054172392934560776\n",
      "Iteration 13695, Loss: 0.053989313542842865\n",
      "Iteration 13696, Loss: 0.054172541946172714\n",
      "Iteration 13697, Loss: 0.053989432752132416\n",
      "Iteration 13698, Loss: 0.054172348231077194\n",
      "Iteration 13699, Loss: 0.05398954451084137\n",
      "Iteration 13700, Loss: 0.05417215824127197\n",
      "Iteration 13701, Loss: 0.05398967117071152\n",
      "Iteration 13702, Loss: 0.05417206883430481\n",
      "Iteration 13703, Loss: 0.053989898413419724\n",
      "Iteration 13704, Loss: 0.05417194962501526\n",
      "Iteration 13705, Loss: 0.05398990958929062\n",
      "Iteration 13706, Loss: 0.05417187511920929\n",
      "Iteration 13707, Loss: 0.053989898413419724\n",
      "Iteration 13708, Loss: 0.054171957075595856\n",
      "Iteration 13709, Loss: 0.0539897084236145\n",
      "Iteration 13710, Loss: 0.05417218804359436\n",
      "Iteration 13711, Loss: 0.053989626467227936\n",
      "Iteration 13712, Loss: 0.05417219549417496\n",
      "Iteration 13713, Loss: 0.0539894700050354\n",
      "Iteration 13714, Loss: 0.05417231470346451\n",
      "Iteration 13715, Loss: 0.0539894700050354\n",
      "Iteration 13716, Loss: 0.05417230725288391\n",
      "Iteration 13717, Loss: 0.0539894700050354\n",
      "Iteration 13718, Loss: 0.05417222902178764\n",
      "Iteration 13719, Loss: 0.053989749401807785\n",
      "Iteration 13720, Loss: 0.05417226254940033\n",
      "Iteration 13721, Loss: 0.05398967117071152\n",
      "Iteration 13722, Loss: 0.05417210981249809\n",
      "Iteration 13723, Loss: 0.05398967117071152\n",
      "Iteration 13724, Loss: 0.054172150790691376\n",
      "Iteration 13725, Loss: 0.05398967117071152\n",
      "Iteration 13726, Loss: 0.05417219549417496\n",
      "Iteration 13727, Loss: 0.05398961901664734\n",
      "Iteration 13728, Loss: 0.05417224019765854\n",
      "Iteration 13729, Loss: 0.05398955196142197\n",
      "Iteration 13730, Loss: 0.054172273725271225\n",
      "Iteration 13731, Loss: 0.05398954451084137\n",
      "Iteration 13732, Loss: 0.05417219549417496\n",
      "Iteration 13733, Loss: 0.053989630192518234\n",
      "Iteration 13734, Loss: 0.05417206883430481\n",
      "Iteration 13735, Loss: 0.05398979038000107\n",
      "Iteration 13736, Loss: 0.05417187139391899\n",
      "Iteration 13737, Loss: 0.05398990958929062\n",
      "Iteration 13738, Loss: 0.054171763360500336\n",
      "Iteration 13739, Loss: 0.05399005860090256\n",
      "Iteration 13740, Loss: 0.05417180061340332\n",
      "Iteration 13741, Loss: 0.05399009585380554\n",
      "Iteration 13742, Loss: 0.054171912372112274\n",
      "Iteration 13743, Loss: 0.05398986488580704\n",
      "Iteration 13744, Loss: 0.05417203530669212\n",
      "Iteration 13745, Loss: 0.053989749401807785\n",
      "Iteration 13746, Loss: 0.05417222902178764\n",
      "Iteration 13747, Loss: 0.05398955196142197\n",
      "Iteration 13748, Loss: 0.05417218804359436\n",
      "Iteration 13749, Loss: 0.05398967117071152\n",
      "Iteration 13750, Loss: 0.05417218804359436\n",
      "Iteration 13751, Loss: 0.053989630192518234\n",
      "Iteration 13752, Loss: 0.05417210981249809\n",
      "Iteration 13753, Loss: 0.0539897084236145\n",
      "Iteration 13754, Loss: 0.054172031581401825\n",
      "Iteration 13755, Loss: 0.053989823907613754\n",
      "Iteration 13756, Loss: 0.054171912372112274\n",
      "Iteration 13757, Loss: 0.053990017622709274\n",
      "Iteration 13758, Loss: 0.05417187511920929\n",
      "Iteration 13759, Loss: 0.05398997664451599\n",
      "Iteration 13760, Loss: 0.05417191982269287\n",
      "Iteration 13761, Loss: 0.05398997291922569\n",
      "Iteration 13762, Loss: 0.05417222902178764\n",
      "Iteration 13763, Loss: 0.05398959666490555\n",
      "Iteration 13764, Loss: 0.05417235940694809\n",
      "Iteration 13765, Loss: 0.053989436477422714\n",
      "Iteration 13766, Loss: 0.054172586649656296\n",
      "Iteration 13767, Loss: 0.05398920178413391\n",
      "Iteration 13768, Loss: 0.05417270585894585\n",
      "Iteration 13769, Loss: 0.05398915708065033\n",
      "Iteration 13770, Loss: 0.054172661155462265\n",
      "Iteration 13771, Loss: 0.05398931726813316\n",
      "Iteration 13772, Loss: 0.054172467440366745\n",
      "Iteration 13773, Loss: 0.05398935824632645\n",
      "Iteration 13774, Loss: 0.05417242273688316\n",
      "Iteration 13775, Loss: 0.05398944020271301\n",
      "Iteration 13776, Loss: 0.05417222902178764\n",
      "Iteration 13777, Loss: 0.05398964136838913\n",
      "Iteration 13778, Loss: 0.05417206883430481\n",
      "Iteration 13779, Loss: 0.053989753127098083\n",
      "Iteration 13780, Loss: 0.054171960800886154\n",
      "Iteration 13781, Loss: 0.05398990958929062\n",
      "Iteration 13782, Loss: 0.05417191982269287\n",
      "Iteration 13783, Loss: 0.0539897084236145\n",
      "Iteration 13784, Loss: 0.05417210981249809\n",
      "Iteration 13785, Loss: 0.05398979038000107\n",
      "Iteration 13786, Loss: 0.05417200177907944\n",
      "Iteration 13787, Loss: 0.05398963391780853\n",
      "Iteration 13788, Loss: 0.05417218804359436\n",
      "Iteration 13789, Loss: 0.05398958921432495\n",
      "Iteration 13790, Loss: 0.05417218804359436\n",
      "Iteration 13791, Loss: 0.05398952215909958\n",
      "Iteration 13792, Loss: 0.05417206883430481\n",
      "Iteration 13793, Loss: 0.0539897195994854\n",
      "Iteration 13794, Loss: 0.05417191982269287\n",
      "Iteration 13795, Loss: 0.05398979038000107\n",
      "Iteration 13796, Loss: 0.054171960800886154\n",
      "Iteration 13797, Loss: 0.05398982763290405\n",
      "Iteration 13798, Loss: 0.05417203530669212\n",
      "Iteration 13799, Loss: 0.05398959666490555\n",
      "Iteration 13800, Loss: 0.054172080010175705\n",
      "Iteration 13801, Loss: 0.05398952215909958\n",
      "Iteration 13802, Loss: 0.054172225296497345\n",
      "Iteration 13803, Loss: 0.053989674896001816\n",
      "Iteration 13804, Loss: 0.05417199432849884\n",
      "Iteration 13805, Loss: 0.05398979038000107\n",
      "Iteration 13806, Loss: 0.05417206510901451\n",
      "Iteration 13807, Loss: 0.053989872336387634\n",
      "Iteration 13808, Loss: 0.05417202413082123\n",
      "Iteration 13809, Loss: 0.053989797830581665\n",
      "Iteration 13810, Loss: 0.05417211353778839\n",
      "Iteration 13811, Loss: 0.053989630192518234\n",
      "Iteration 13812, Loss: 0.05417224019765854\n",
      "Iteration 13813, Loss: 0.0539894700050354\n",
      "Iteration 13814, Loss: 0.05417250841856003\n",
      "Iteration 13815, Loss: 0.05398935824632645\n",
      "Iteration 13816, Loss: 0.05417262762784958\n",
      "Iteration 13817, Loss: 0.0539892315864563\n",
      "Iteration 13818, Loss: 0.05417255684733391\n",
      "Iteration 13819, Loss: 0.053989529609680176\n",
      "Iteration 13820, Loss: 0.05417250841856003\n",
      "Iteration 13821, Loss: 0.05398980900645256\n",
      "Iteration 13822, Loss: 0.054171591997146606\n",
      "Iteration 13823, Loss: 0.05399034917354584\n",
      "Iteration 13824, Loss: 0.05417127534747124\n",
      "Iteration 13825, Loss: 0.053990475833415985\n",
      "Iteration 13826, Loss: 0.05417131632566452\n",
      "Iteration 13827, Loss: 0.05399058014154434\n",
      "Iteration 13828, Loss: 0.054171591997146606\n",
      "Iteration 13829, Loss: 0.053990304470062256\n",
      "Iteration 13830, Loss: 0.05417187139391899\n",
      "Iteration 13831, Loss: 0.05398990958929062\n",
      "Iteration 13832, Loss: 0.05417222902178764\n",
      "Iteration 13833, Loss: 0.05398959666490555\n",
      "Iteration 13834, Loss: 0.05417250841856003\n",
      "Iteration 13835, Loss: 0.05398928374052048\n",
      "Iteration 13836, Loss: 0.05417254567146301\n",
      "Iteration 13837, Loss: 0.05398940294981003\n",
      "Iteration 13838, Loss: 0.05417242646217346\n",
      "Iteration 13839, Loss: 0.053989481180906296\n",
      "Iteration 13840, Loss: 0.05417222902178764\n",
      "Iteration 13841, Loss: 0.05398964136838913\n",
      "Iteration 13842, Loss: 0.05417200177907944\n",
      "Iteration 13843, Loss: 0.05398982763290405\n",
      "Iteration 13844, Loss: 0.05417203530669212\n",
      "Iteration 13845, Loss: 0.053989797830581665\n",
      "Iteration 13846, Loss: 0.054171882569789886\n",
      "Iteration 13847, Loss: 0.053989868611097336\n",
      "Iteration 13848, Loss: 0.054172031581401825\n",
      "Iteration 13849, Loss: 0.0539899542927742\n",
      "Iteration 13850, Loss: 0.054171960800886154\n",
      "Iteration 13851, Loss: 0.053989678621292114\n",
      "Iteration 13852, Loss: 0.054172199219465256\n",
      "Iteration 13853, Loss: 0.05398944020271301\n",
      "Iteration 13854, Loss: 0.05417242646217346\n",
      "Iteration 13855, Loss: 0.05398940294981003\n",
      "Iteration 13856, Loss: 0.05417250096797943\n",
      "Iteration 13857, Loss: 0.05398928374052048\n",
      "Iteration 13858, Loss: 0.054172467440366745\n",
      "Iteration 13859, Loss: 0.05398940294981003\n",
      "Iteration 13860, Loss: 0.05417230352759361\n",
      "Iteration 13861, Loss: 0.05398960039019585\n",
      "Iteration 13862, Loss: 0.054172106087207794\n",
      "Iteration 13863, Loss: 0.05398983880877495\n",
      "Iteration 13864, Loss: 0.05417202413082123\n",
      "Iteration 13865, Loss: 0.0539899542927742\n",
      "Iteration 13866, Loss: 0.054171882569789886\n",
      "Iteration 13867, Loss: 0.05398991331458092\n",
      "Iteration 13868, Loss: 0.05417191982269287\n",
      "Iteration 13869, Loss: 0.05398983880877495\n",
      "Iteration 13870, Loss: 0.05417203903198242\n",
      "Iteration 13871, Loss: 0.05398982763290405\n",
      "Iteration 13872, Loss: 0.05417212098836899\n",
      "Iteration 13873, Loss: 0.053989674896001816\n",
      "Iteration 13874, Loss: 0.054172269999980927\n",
      "Iteration 13875, Loss: 0.05398944020271301\n",
      "Iteration 13876, Loss: 0.05417230725288391\n",
      "Iteration 13877, Loss: 0.05398952215909958\n",
      "Iteration 13878, Loss: 0.054172150790691376\n",
      "Iteration 13879, Loss: 0.05398982763290405\n",
      "Iteration 13880, Loss: 0.05417194962501526\n",
      "Iteration 13881, Loss: 0.0539899542927742\n",
      "Iteration 13882, Loss: 0.05417187139391899\n",
      "Iteration 13883, Loss: 0.05398998782038689\n",
      "Iteration 13884, Loss: 0.05417194962501526\n",
      "Iteration 13885, Loss: 0.05398991331458092\n",
      "Iteration 13886, Loss: 0.05417191982269287\n",
      "Iteration 13887, Loss: 0.053989872336387634\n",
      "Iteration 13888, Loss: 0.054172150790691376\n",
      "Iteration 13889, Loss: 0.05398960039019585\n",
      "Iteration 13890, Loss: 0.05417230725288391\n",
      "Iteration 13891, Loss: 0.053989559412002563\n",
      "Iteration 13892, Loss: 0.05417230725288391\n",
      "Iteration 13893, Loss: 0.053989481180906296\n",
      "Iteration 13894, Loss: 0.05417230725288391\n",
      "Iteration 13895, Loss: 0.05398944020271301\n",
      "Iteration 13896, Loss: 0.05417210981249809\n",
      "Iteration 13897, Loss: 0.0539897195994854\n",
      "Iteration 13898, Loss: 0.05417194962501526\n",
      "Iteration 13899, Loss: 0.05399002879858017\n",
      "Iteration 13900, Loss: 0.05417163670063019\n",
      "Iteration 13901, Loss: 0.05399015173316002\n",
      "Iteration 13902, Loss: 0.05417143926024437\n",
      "Iteration 13903, Loss: 0.053990304470062256\n",
      "Iteration 13904, Loss: 0.054171591997146606\n",
      "Iteration 13905, Loss: 0.05399014800786972\n",
      "Iteration 13906, Loss: 0.05417172238230705\n",
      "Iteration 13907, Loss: 0.0539899580180645\n",
      "Iteration 13908, Loss: 0.054171960800886154\n",
      "Iteration 13909, Loss: 0.05398982763290405\n",
      "Iteration 13910, Loss: 0.05417203903198242\n",
      "Iteration 13911, Loss: 0.053989559412002563\n",
      "Iteration 13912, Loss: 0.05417218804359436\n",
      "Iteration 13913, Loss: 0.05398963391780853\n",
      "Iteration 13914, Loss: 0.05417218804359436\n",
      "Iteration 13915, Loss: 0.053989749401807785\n",
      "Iteration 13916, Loss: 0.054172150790691376\n",
      "Iteration 13917, Loss: 0.053989868611097336\n",
      "Iteration 13918, Loss: 0.054172031581401825\n",
      "Iteration 13919, Loss: 0.05398976057767868\n",
      "Iteration 13920, Loss: 0.054171960800886154\n",
      "Iteration 13921, Loss: 0.053989872336387634\n",
      "Iteration 13922, Loss: 0.05417191609740257\n",
      "Iteration 13923, Loss: 0.053989946842193604\n",
      "Iteration 13924, Loss: 0.05417172238230705\n",
      "Iteration 13925, Loss: 0.053989946842193604\n",
      "Iteration 13926, Loss: 0.054171763360500336\n",
      "Iteration 13927, Loss: 0.05399002879858017\n",
      "Iteration 13928, Loss: 0.05417175218462944\n",
      "Iteration 13929, Loss: 0.05399007350206375\n",
      "Iteration 13930, Loss: 0.05417171120643616\n",
      "Iteration 13931, Loss: 0.05399007722735405\n",
      "Iteration 13932, Loss: 0.05417163670063019\n",
      "Iteration 13933, Loss: 0.05399014800786972\n",
      "Iteration 13934, Loss: 0.05417163670063019\n",
      "Iteration 13935, Loss: 0.05399002879858017\n",
      "Iteration 13936, Loss: 0.054171763360500336\n",
      "Iteration 13937, Loss: 0.053990066051483154\n",
      "Iteration 13938, Loss: 0.05417206883430481\n",
      "Iteration 13939, Loss: 0.053989678621292114\n",
      "Iteration 13940, Loss: 0.05417227745056152\n",
      "Iteration 13941, Loss: 0.05398955196142197\n",
      "Iteration 13942, Loss: 0.05417238920927048\n",
      "Iteration 13943, Loss: 0.053989361971616745\n",
      "Iteration 13944, Loss: 0.054172348231077194\n",
      "Iteration 13945, Loss: 0.05398944020271301\n",
      "Iteration 13946, Loss: 0.05417222902178764\n",
      "Iteration 13947, Loss: 0.05398964136838913\n",
      "Iteration 13948, Loss: 0.054172076284885406\n",
      "Iteration 13949, Loss: 0.053989797830581665\n",
      "Iteration 13950, Loss: 0.05417179316282272\n",
      "Iteration 13951, Loss: 0.05399003624916077\n",
      "Iteration 13952, Loss: 0.05417155846953392\n",
      "Iteration 13953, Loss: 0.05399034172296524\n",
      "Iteration 13954, Loss: 0.054171524941921234\n",
      "Iteration 13955, Loss: 0.05399026721715927\n",
      "Iteration 13956, Loss: 0.05417148768901825\n",
      "Iteration 13957, Loss: 0.053990185260772705\n",
      "Iteration 13958, Loss: 0.05417172238230705\n",
      "Iteration 13959, Loss: 0.05399003252387047\n",
      "Iteration 13960, Loss: 0.054171882569789886\n",
      "Iteration 13961, Loss: 0.05398979038000107\n",
      "Iteration 13962, Loss: 0.05417206883430481\n",
      "Iteration 13963, Loss: 0.053989678621292114\n",
      "Iteration 13964, Loss: 0.05417210981249809\n",
      "Iteration 13965, Loss: 0.053989674896001816\n",
      "Iteration 13966, Loss: 0.05417206883430481\n",
      "Iteration 13967, Loss: 0.053989749401807785\n",
      "Iteration 13968, Loss: 0.054172031581401825\n",
      "Iteration 13969, Loss: 0.053989723324775696\n",
      "Iteration 13970, Loss: 0.054171979427337646\n",
      "Iteration 13971, Loss: 0.053990066051483154\n",
      "Iteration 13972, Loss: 0.054171718657016754\n",
      "Iteration 13973, Loss: 0.05399018153548241\n",
      "Iteration 13974, Loss: 0.05417175590991974\n",
      "Iteration 13975, Loss: 0.05399010702967644\n",
      "Iteration 13976, Loss: 0.05417172238230705\n",
      "Iteration 13977, Loss: 0.05398983508348465\n",
      "Iteration 13978, Loss: 0.05417199432849884\n",
      "Iteration 13979, Loss: 0.05398982763290405\n",
      "Iteration 13980, Loss: 0.05417191982269287\n",
      "Iteration 13981, Loss: 0.053989868611097336\n",
      "Iteration 13982, Loss: 0.05417199432849884\n",
      "Iteration 13983, Loss: 0.0539897195994854\n",
      "Iteration 13984, Loss: 0.05417191982269287\n",
      "Iteration 13985, Loss: 0.05398964136838913\n",
      "Iteration 13986, Loss: 0.054171960800886154\n",
      "Iteration 13987, Loss: 0.05398961156606674\n",
      "Iteration 13988, Loss: 0.054171960800886154\n",
      "Iteration 13989, Loss: 0.05398968607187271\n",
      "Iteration 13990, Loss: 0.054172031581401825\n",
      "Iteration 13991, Loss: 0.05398968979716301\n",
      "Iteration 13992, Loss: 0.054171882569789886\n",
      "Iteration 13993, Loss: 0.0539897195994854\n",
      "Iteration 13994, Loss: 0.054172080010175705\n",
      "Iteration 13995, Loss: 0.05398960039019585\n",
      "Iteration 13996, Loss: 0.0541720911860466\n",
      "Iteration 13997, Loss: 0.05398952215909958\n",
      "Iteration 13998, Loss: 0.05417218804359436\n",
      "Iteration 13999, Loss: 0.053989410400390625\n",
      "Iteration 14000, Loss: 0.05417211353778839\n",
      "Iteration 14001, Loss: 0.05398961156606674\n",
      "Iteration 14002, Loss: 0.054172031581401825\n",
      "Iteration 14003, Loss: 0.05398987978696823\n",
      "Iteration 14004, Loss: 0.05417180806398392\n",
      "Iteration 14005, Loss: 0.053989917039871216\n",
      "Iteration 14006, Loss: 0.0541718415915966\n",
      "Iteration 14007, Loss: 0.05398976057767868\n",
      "Iteration 14008, Loss: 0.05417200177907944\n",
      "Iteration 14009, Loss: 0.05398979410529137\n",
      "Iteration 14010, Loss: 0.05417212098836899\n",
      "Iteration 14011, Loss: 0.05398959666490555\n",
      "Iteration 14012, Loss: 0.05417227745056152\n",
      "Iteration 14013, Loss: 0.053989291191101074\n",
      "Iteration 14014, Loss: 0.05417251214385033\n",
      "Iteration 14015, Loss: 0.05398920923471451\n",
      "Iteration 14016, Loss: 0.05417243763804436\n",
      "Iteration 14017, Loss: 0.05398928374052048\n",
      "Iteration 14018, Loss: 0.05417238920927048\n",
      "Iteration 14019, Loss: 0.053989410400390625\n",
      "Iteration 14020, Loss: 0.054172150790691376\n",
      "Iteration 14021, Loss: 0.053989529609680176\n",
      "Iteration 14022, Loss: 0.054171882569789886\n",
      "Iteration 14023, Loss: 0.05398988351225853\n",
      "Iteration 14024, Loss: 0.054171644151210785\n",
      "Iteration 14025, Loss: 0.05399015173316002\n",
      "Iteration 14026, Loss: 0.0541716143488884\n",
      "Iteration 14027, Loss: 0.05399007350206375\n",
      "Iteration 14028, Loss: 0.054171882569789886\n",
      "Iteration 14029, Loss: 0.05398979410529137\n",
      "Iteration 14030, Loss: 0.05417212098836899\n",
      "Iteration 14031, Loss: 0.05398960039019585\n",
      "Iteration 14032, Loss: 0.054172154515981674\n",
      "Iteration 14033, Loss: 0.053989559412002563\n",
      "Iteration 14034, Loss: 0.05417212098836899\n",
      "Iteration 14035, Loss: 0.053989481180906296\n",
      "Iteration 14036, Loss: 0.05417219549417496\n",
      "Iteration 14037, Loss: 0.053989559412002563\n",
      "Iteration 14038, Loss: 0.054172076284885406\n",
      "Iteration 14039, Loss: 0.05398964136838913\n",
      "Iteration 14040, Loss: 0.054171960800886154\n",
      "Iteration 14041, Loss: 0.053989678621292114\n",
      "Iteration 14042, Loss: 0.05417203530669212\n",
      "Iteration 14043, Loss: 0.0539897195994854\n",
      "Iteration 14044, Loss: 0.05417212098836899\n",
      "Iteration 14045, Loss: 0.05398960039019585\n",
      "Iteration 14046, Loss: 0.05417219549417496\n",
      "Iteration 14047, Loss: 0.05398952215909958\n",
      "Iteration 14048, Loss: 0.054172199219465256\n",
      "Iteration 14049, Loss: 0.05398940294981003\n",
      "Iteration 14050, Loss: 0.05417222902178764\n",
      "Iteration 14051, Loss: 0.05398933216929436\n",
      "Iteration 14052, Loss: 0.05417222902178764\n",
      "Iteration 14053, Loss: 0.05398964136838913\n",
      "Iteration 14054, Loss: 0.05417199060320854\n",
      "Iteration 14055, Loss: 0.05398976430296898\n",
      "Iteration 14056, Loss: 0.05417180061340332\n",
      "Iteration 14057, Loss: 0.05398999899625778\n",
      "Iteration 14058, Loss: 0.05417175218462944\n",
      "Iteration 14059, Loss: 0.05398999899625778\n",
      "Iteration 14060, Loss: 0.05417175590991974\n",
      "Iteration 14061, Loss: 0.05398983880877495\n",
      "Iteration 14062, Loss: 0.05417180806398392\n",
      "Iteration 14063, Loss: 0.05398976057767868\n",
      "Iteration 14064, Loss: 0.05417203903198242\n",
      "Iteration 14065, Loss: 0.05398960039019585\n",
      "Iteration 14066, Loss: 0.054172009229660034\n",
      "Iteration 14067, Loss: 0.05398944765329361\n",
      "Iteration 14068, Loss: 0.05417223274707794\n",
      "Iteration 14069, Loss: 0.05398952215909958\n",
      "Iteration 14070, Loss: 0.05417228490114212\n",
      "Iteration 14071, Loss: 0.05398937314748764\n",
      "Iteration 14072, Loss: 0.054172392934560776\n",
      "Iteration 14073, Loss: 0.05398940294981003\n",
      "Iteration 14074, Loss: 0.05417224019765854\n",
      "Iteration 14075, Loss: 0.05398944020271301\n",
      "Iteration 14076, Loss: 0.054172348231077194\n",
      "Iteration 14077, Loss: 0.05398940667510033\n",
      "Iteration 14078, Loss: 0.05417242646217346\n",
      "Iteration 14079, Loss: 0.053989481180906296\n",
      "Iteration 14080, Loss: 0.05417215824127197\n",
      "Iteration 14081, Loss: 0.05398952215909958\n",
      "Iteration 14082, Loss: 0.05417224019765854\n",
      "Iteration 14083, Loss: 0.05398944020271301\n",
      "Iteration 14084, Loss: 0.054172348231077194\n",
      "Iteration 14085, Loss: 0.053989361971616745\n",
      "Iteration 14086, Loss: 0.05417242646217346\n",
      "Iteration 14087, Loss: 0.05398944765329361\n",
      "Iteration 14088, Loss: 0.05417222902178764\n",
      "Iteration 14089, Loss: 0.05398952588438988\n",
      "Iteration 14090, Loss: 0.05417219549417496\n",
      "Iteration 14091, Loss: 0.05398964136838913\n",
      "Iteration 14092, Loss: 0.05417204648256302\n",
      "Iteration 14093, Loss: 0.05398963391780853\n",
      "Iteration 14094, Loss: 0.054172199219465256\n",
      "Iteration 14095, Loss: 0.05398952215909958\n",
      "Iteration 14096, Loss: 0.054172348231077194\n",
      "Iteration 14097, Loss: 0.05398940294981003\n",
      "Iteration 14098, Loss: 0.05417231470346451\n",
      "Iteration 14099, Loss: 0.05398952215909958\n",
      "Iteration 14100, Loss: 0.05417238920927048\n",
      "Iteration 14101, Loss: 0.05398932844400406\n",
      "Iteration 14102, Loss: 0.054172348231077194\n",
      "Iteration 14103, Loss: 0.053989481180906296\n",
      "Iteration 14104, Loss: 0.05417230725288391\n",
      "Iteration 14105, Loss: 0.053989410400390625\n",
      "Iteration 14106, Loss: 0.05417212098836899\n",
      "Iteration 14107, Loss: 0.05398960039019585\n",
      "Iteration 14108, Loss: 0.05417203530669212\n",
      "Iteration 14109, Loss: 0.05398968979716301\n",
      "Iteration 14110, Loss: 0.054171837866306305\n",
      "Iteration 14111, Loss: 0.05398987978696823\n",
      "Iteration 14112, Loss: 0.054171763360500336\n",
      "Iteration 14113, Loss: 0.05398937314748764\n",
      "Iteration 14114, Loss: 0.05417191982269287\n",
      "Iteration 14115, Loss: 0.05398920923471451\n",
      "Iteration 14116, Loss: 0.05417134612798691\n",
      "Iteration 14117, Loss: 0.053988900035619736\n",
      "Iteration 14118, Loss: 0.05417158454656601\n",
      "Iteration 14119, Loss: 0.053988777101039886\n",
      "Iteration 14120, Loss: 0.05417189002037048\n",
      "Iteration 14121, Loss: 0.053988464176654816\n",
      "Iteration 14122, Loss: 0.0541718527674675\n",
      "Iteration 14123, Loss: 0.053988587111234665\n",
      "Iteration 14124, Loss: 0.05417165160179138\n",
      "Iteration 14125, Loss: 0.05398866534233093\n",
      "Iteration 14126, Loss: 0.05417141318321228\n",
      "Iteration 14127, Loss: 0.053988978266716\n",
      "Iteration 14128, Loss: 0.05417121574282646\n",
      "Iteration 14129, Loss: 0.053989142179489136\n",
      "Iteration 14130, Loss: 0.05417109653353691\n",
      "Iteration 14131, Loss: 0.0539892241358757\n",
      "Iteration 14132, Loss: 0.05417102575302124\n",
      "Iteration 14133, Loss: 0.053989216685295105\n",
      "Iteration 14134, Loss: 0.05417133495211601\n",
      "Iteration 14135, Loss: 0.0539889857172966\n",
      "Iteration 14136, Loss: 0.05417153984308243\n",
      "Iteration 14137, Loss: 0.05398866534233093\n",
      "Iteration 14138, Loss: 0.05417178198695183\n",
      "Iteration 14139, Loss: 0.0539885014295578\n",
      "Iteration 14140, Loss: 0.05417189002037048\n",
      "Iteration 14141, Loss: 0.05398842692375183\n",
      "Iteration 14142, Loss: 0.054171811789274216\n",
      "Iteration 14143, Loss: 0.05398854613304138\n",
      "Iteration 14144, Loss: 0.05417164787650108\n",
      "Iteration 14145, Loss: 0.05398886650800705\n",
      "Iteration 14146, Loss: 0.054171331226825714\n",
      "Iteration 14147, Loss: 0.053989212960004807\n",
      "Iteration 14148, Loss: 0.05417105555534363\n",
      "Iteration 14149, Loss: 0.05398937314748764\n",
      "Iteration 14150, Loss: 0.05417097732424736\n",
      "Iteration 14151, Loss: 0.05398930236697197\n",
      "Iteration 14152, Loss: 0.05417102575302124\n",
      "Iteration 14153, Loss: 0.05398910492658615\n",
      "Iteration 14154, Loss: 0.05417126417160034\n",
      "Iteration 14155, Loss: 0.05398905277252197\n",
      "Iteration 14156, Loss: 0.05417153239250183\n",
      "Iteration 14157, Loss: 0.05398878455162048\n",
      "Iteration 14158, Loss: 0.05417165905237198\n",
      "Iteration 14159, Loss: 0.05398862808942795\n",
      "Iteration 14160, Loss: 0.0541716143488884\n",
      "Iteration 14161, Loss: 0.053988516330718994\n",
      "Iteration 14162, Loss: 0.054171767085790634\n",
      "Iteration 14163, Loss: 0.05398866534233093\n",
      "Iteration 14164, Loss: 0.054171763360500336\n",
      "Iteration 14165, Loss: 0.05398881435394287\n",
      "Iteration 14166, Loss: 0.054171450436115265\n",
      "Iteration 14167, Loss: 0.05398905277252197\n",
      "Iteration 14168, Loss: 0.0541713684797287\n",
      "Iteration 14169, Loss: 0.053989097476005554\n",
      "Iteration 14170, Loss: 0.05417122691869736\n",
      "Iteration 14171, Loss: 0.053989093750715256\n",
      "Iteration 14172, Loss: 0.05417122691869736\n",
      "Iteration 14173, Loss: 0.0539889857172966\n",
      "Iteration 14174, Loss: 0.054171375930309296\n",
      "Iteration 14175, Loss: 0.05398894473910332\n",
      "Iteration 14176, Loss: 0.05417141318321228\n",
      "Iteration 14177, Loss: 0.053988903760910034\n",
      "Iteration 14178, Loss: 0.054171379655599594\n",
      "Iteration 14179, Loss: 0.05398891121149063\n",
      "Iteration 14180, Loss: 0.054171375930309296\n",
      "Iteration 14181, Loss: 0.05398905277252197\n",
      "Iteration 14182, Loss: 0.05417140945792198\n",
      "Iteration 14183, Loss: 0.05398894101381302\n",
      "Iteration 14184, Loss: 0.054171495139598846\n",
      "Iteration 14185, Loss: 0.05398882180452347\n",
      "Iteration 14186, Loss: 0.05417173355817795\n",
      "Iteration 14187, Loss: 0.053988661617040634\n",
      "Iteration 14188, Loss: 0.05417173355817795\n",
      "Iteration 14189, Loss: 0.053988587111234665\n",
      "Iteration 14190, Loss: 0.054171692579984665\n",
      "Iteration 14191, Loss: 0.053988706320524216\n",
      "Iteration 14192, Loss: 0.05417172238230705\n",
      "Iteration 14193, Loss: 0.05398885905742645\n",
      "Iteration 14194, Loss: 0.054171375930309296\n",
      "Iteration 14195, Loss: 0.05398905277252197\n",
      "Iteration 14196, Loss: 0.05417140573263168\n",
      "Iteration 14197, Loss: 0.05398906394839287\n",
      "Iteration 14198, Loss: 0.05417114496231079\n",
      "Iteration 14199, Loss: 0.053989097476005554\n",
      "Iteration 14200, Loss: 0.05417122691869736\n",
      "Iteration 14201, Loss: 0.053988978266716\n",
      "Iteration 14202, Loss: 0.054171543568372726\n",
      "Iteration 14203, Loss: 0.05398893356323242\n",
      "Iteration 14204, Loss: 0.05417166277766228\n",
      "Iteration 14205, Loss: 0.05398862063884735\n",
      "Iteration 14206, Loss: 0.05417189002037048\n",
      "Iteration 14207, Loss: 0.05398831516504288\n",
      "Iteration 14208, Loss: 0.05417205020785332\n",
      "Iteration 14209, Loss: 0.05398842319846153\n",
      "Iteration 14210, Loss: 0.05417189002037048\n",
      "Iteration 14211, Loss: 0.0539885088801384\n",
      "Iteration 14212, Loss: 0.05417177081108093\n",
      "Iteration 14213, Loss: 0.05398855358362198\n",
      "Iteration 14214, Loss: 0.05417164787650108\n",
      "Iteration 14215, Loss: 0.053988900035619736\n",
      "Iteration 14216, Loss: 0.05417141318321228\n",
      "Iteration 14217, Loss: 0.0539889857172966\n",
      "Iteration 14218, Loss: 0.05417133495211601\n",
      "Iteration 14219, Loss: 0.05398906394839287\n",
      "Iteration 14220, Loss: 0.05417126417160034\n",
      "Iteration 14221, Loss: 0.053989019244909286\n",
      "Iteration 14222, Loss: 0.054171573370695114\n",
      "Iteration 14223, Loss: 0.05398889631032944\n",
      "Iteration 14224, Loss: 0.054171618074178696\n",
      "Iteration 14225, Loss: 0.053988706320524216\n",
      "Iteration 14226, Loss: 0.054171741008758545\n",
      "Iteration 14227, Loss: 0.053988583385944366\n",
      "Iteration 14228, Loss: 0.05417189002037048\n",
      "Iteration 14229, Loss: 0.05398870259523392\n",
      "Iteration 14230, Loss: 0.054171573370695114\n",
      "Iteration 14231, Loss: 0.05398882180452347\n",
      "Iteration 14232, Loss: 0.05417141318321228\n",
      "Iteration 14233, Loss: 0.05398894473910332\n",
      "Iteration 14234, Loss: 0.05417121574282646\n",
      "Iteration 14235, Loss: 0.05398906394839287\n",
      "Iteration 14236, Loss: 0.05417132377624512\n",
      "Iteration 14237, Loss: 0.05398910492658615\n",
      "Iteration 14238, Loss: 0.05417121574282646\n",
      "Iteration 14239, Loss: 0.053989097476005554\n",
      "Iteration 14240, Loss: 0.05417121574282646\n",
      "Iteration 14241, Loss: 0.0539889857172966\n",
      "Iteration 14242, Loss: 0.05417141318321228\n",
      "Iteration 14243, Loss: 0.0539889857172966\n",
      "Iteration 14244, Loss: 0.05417141318321228\n",
      "Iteration 14245, Loss: 0.053989019244909286\n",
      "Iteration 14246, Loss: 0.05417133495211601\n",
      "Iteration 14247, Loss: 0.053988974541425705\n",
      "Iteration 14248, Loss: 0.05417152866721153\n",
      "Iteration 14249, Loss: 0.05398893356323242\n",
      "Iteration 14250, Loss: 0.05417156219482422\n",
      "Iteration 14251, Loss: 0.05398889631032944\n",
      "Iteration 14252, Loss: 0.054171495139598846\n",
      "Iteration 14253, Loss: 0.053988855332136154\n",
      "Iteration 14254, Loss: 0.054171573370695114\n",
      "Iteration 14255, Loss: 0.05398889631032944\n",
      "Iteration 14256, Loss: 0.054171573370695114\n",
      "Iteration 14257, Loss: 0.05398889631032944\n",
      "Iteration 14258, Loss: 0.054171498864889145\n",
      "Iteration 14259, Loss: 0.05398881435394287\n",
      "Iteration 14260, Loss: 0.0541716143488884\n",
      "Iteration 14261, Loss: 0.05398885905742645\n",
      "Iteration 14262, Loss: 0.0541716143488884\n",
      "Iteration 14263, Loss: 0.0539887472987175\n",
      "Iteration 14264, Loss: 0.05417153984308243\n",
      "Iteration 14265, Loss: 0.05398893356323242\n",
      "Iteration 14266, Loss: 0.054171495139598846\n",
      "Iteration 14267, Loss: 0.05398894101381302\n",
      "Iteration 14268, Loss: 0.05417145416140556\n",
      "Iteration 14269, Loss: 0.05398893356323242\n",
      "Iteration 14270, Loss: 0.05417153239250183\n",
      "Iteration 14271, Loss: 0.053988855332136154\n",
      "Iteration 14272, Loss: 0.0541716068983078\n",
      "Iteration 14273, Loss: 0.05398885905742645\n",
      "Iteration 14274, Loss: 0.054171573370695114\n",
      "Iteration 14275, Loss: 0.05398882180452347\n",
      "Iteration 14276, Loss: 0.054171692579984665\n",
      "Iteration 14277, Loss: 0.0539887361228466\n",
      "Iteration 14278, Loss: 0.05417173355817795\n",
      "Iteration 14279, Loss: 0.05398869514465332\n",
      "Iteration 14280, Loss: 0.05417173355817795\n",
      "Iteration 14281, Loss: 0.05398881435394287\n",
      "Iteration 14282, Loss: 0.0541716143488884\n",
      "Iteration 14283, Loss: 0.05398866534233093\n",
      "Iteration 14284, Loss: 0.05417145416140556\n",
      "Iteration 14285, Loss: 0.05398893356323242\n",
      "Iteration 14286, Loss: 0.05417141318321228\n",
      "Iteration 14287, Loss: 0.05398917198181152\n",
      "Iteration 14288, Loss: 0.05417129397392273\n",
      "Iteration 14289, Loss: 0.05398928374052048\n",
      "Iteration 14290, Loss: 0.05417122691869736\n",
      "Iteration 14291, Loss: 0.053989164531230927\n",
      "Iteration 14292, Loss: 0.05417146533727646\n",
      "Iteration 14293, Loss: 0.053988974541425705\n",
      "Iteration 14294, Loss: 0.054171621799468994\n",
      "Iteration 14295, Loss: 0.053988587111234665\n",
      "Iteration 14296, Loss: 0.05417177081108093\n",
      "Iteration 14297, Loss: 0.05398847162723541\n",
      "Iteration 14298, Loss: 0.05417177081108093\n",
      "Iteration 14299, Loss: 0.05398862808942795\n",
      "Iteration 14300, Loss: 0.05417180061340332\n",
      "Iteration 14301, Loss: 0.05398881435394287\n",
      "Iteration 14302, Loss: 0.05417164787650108\n",
      "Iteration 14303, Loss: 0.05398893356323242\n",
      "Iteration 14304, Loss: 0.054171495139598846\n",
      "Iteration 14305, Loss: 0.053989049047231674\n",
      "Iteration 14306, Loss: 0.054171524941921234\n",
      "Iteration 14307, Loss: 0.05398901551961899\n",
      "Iteration 14308, Loss: 0.05417141318321228\n",
      "Iteration 14309, Loss: 0.053989093750715256\n",
      "Iteration 14310, Loss: 0.05417142063379288\n",
      "Iteration 14311, Loss: 0.053988970816135406\n",
      "Iteration 14312, Loss: 0.054171543568372726\n",
      "Iteration 14313, Loss: 0.053988777101039886\n",
      "Iteration 14314, Loss: 0.05417169630527496\n",
      "Iteration 14315, Loss: 0.053988657891750336\n",
      "Iteration 14316, Loss: 0.05417177081108093\n",
      "Iteration 14317, Loss: 0.05398881435394287\n",
      "Iteration 14318, Loss: 0.05417153239250183\n",
      "Iteration 14319, Loss: 0.05398893356323242\n",
      "Iteration 14320, Loss: 0.054171375930309296\n",
      "Iteration 14321, Loss: 0.05398920923471451\n",
      "Iteration 14322, Loss: 0.054171256721019745\n",
      "Iteration 14323, Loss: 0.05398913472890854\n",
      "Iteration 14324, Loss: 0.05417129397392273\n",
      "Iteration 14325, Loss: 0.05398913472890854\n",
      "Iteration 14326, Loss: 0.05417133495211601\n",
      "Iteration 14327, Loss: 0.053988974541425705\n",
      "Iteration 14328, Loss: 0.05417146533727646\n",
      "Iteration 14329, Loss: 0.05398892983794212\n",
      "Iteration 14330, Loss: 0.0541716143488884\n",
      "Iteration 14331, Loss: 0.05398881435394287\n",
      "Iteration 14332, Loss: 0.054171692579984665\n",
      "Iteration 14333, Loss: 0.0539887472987175\n",
      "Iteration 14334, Loss: 0.054171573370695114\n",
      "Iteration 14335, Loss: 0.05398878455162048\n",
      "Iteration 14336, Loss: 0.05417129397392273\n",
      "Iteration 14337, Loss: 0.0539889857172966\n",
      "Iteration 14338, Loss: 0.054171204566955566\n",
      "Iteration 14339, Loss: 0.05398929864168167\n",
      "Iteration 14340, Loss: 0.05417086184024811\n",
      "Iteration 14341, Loss: 0.053989410400390625\n",
      "Iteration 14342, Loss: 0.05417089909315109\n",
      "Iteration 14343, Loss: 0.05398956686258316\n",
      "Iteration 14344, Loss: 0.05417105555534363\n",
      "Iteration 14345, Loss: 0.053989291191101074\n",
      "Iteration 14346, Loss: 0.05417114496231079\n",
      "Iteration 14347, Loss: 0.05398905277252197\n",
      "Iteration 14348, Loss: 0.054171424359083176\n",
      "Iteration 14349, Loss: 0.053988777101039886\n",
      "Iteration 14350, Loss: 0.05417165905237198\n",
      "Iteration 14351, Loss: 0.05398854613304138\n",
      "Iteration 14352, Loss: 0.05417180806398392\n",
      "Iteration 14353, Loss: 0.05398869514465332\n",
      "Iteration 14354, Loss: 0.054171692579984665\n",
      "Iteration 14355, Loss: 0.053988780826330185\n",
      "Iteration 14356, Loss: 0.05417157709598541\n",
      "Iteration 14357, Loss: 0.053988855332136154\n",
      "Iteration 14358, Loss: 0.054171524941921234\n",
      "Iteration 14359, Loss: 0.05398913472890854\n",
      "Iteration 14360, Loss: 0.054171256721019745\n",
      "Iteration 14361, Loss: 0.053989093750715256\n",
      "Iteration 14362, Loss: 0.05417129397392273\n",
      "Iteration 14363, Loss: 0.053989097476005554\n",
      "Iteration 14364, Loss: 0.05417126417160034\n",
      "Iteration 14365, Loss: 0.053989164531230927\n",
      "Iteration 14366, Loss: 0.054171424359083176\n",
      "Iteration 14367, Loss: 0.0539887398481369\n",
      "Iteration 14368, Loss: 0.054171573370695114\n",
      "Iteration 14369, Loss: 0.0539887361228466\n",
      "Iteration 14370, Loss: 0.054171692579984665\n",
      "Iteration 14371, Loss: 0.053988780826330185\n",
      "Iteration 14372, Loss: 0.05417153239250183\n",
      "Iteration 14373, Loss: 0.053988855332136154\n",
      "Iteration 14374, Loss: 0.05417153239250183\n",
      "Iteration 14375, Loss: 0.053988974541425705\n",
      "Iteration 14376, Loss: 0.054171495139598846\n",
      "Iteration 14377, Loss: 0.053988903760910034\n",
      "Iteration 14378, Loss: 0.054171498864889145\n",
      "Iteration 14379, Loss: 0.05398882180452347\n",
      "Iteration 14380, Loss: 0.05417153239250183\n",
      "Iteration 14381, Loss: 0.05398878455162048\n",
      "Iteration 14382, Loss: 0.054171573370695114\n",
      "Iteration 14383, Loss: 0.053988777101039886\n",
      "Iteration 14384, Loss: 0.05417165160179138\n",
      "Iteration 14385, Loss: 0.053988855332136154\n",
      "Iteration 14386, Loss: 0.0541716068983078\n",
      "Iteration 14387, Loss: 0.05398889631032944\n",
      "Iteration 14388, Loss: 0.05417145416140556\n",
      "Iteration 14389, Loss: 0.053989019244909286\n",
      "Iteration 14390, Loss: 0.05417132377624512\n",
      "Iteration 14391, Loss: 0.053989212960004807\n",
      "Iteration 14392, Loss: 0.05417109653353691\n",
      "Iteration 14393, Loss: 0.05398925393819809\n",
      "Iteration 14394, Loss: 0.054171137511730194\n",
      "Iteration 14395, Loss: 0.05398917198181152\n",
      "Iteration 14396, Loss: 0.054171256721019745\n",
      "Iteration 14397, Loss: 0.05398905277252197\n",
      "Iteration 14398, Loss: 0.05417146533727646\n",
      "Iteration 14399, Loss: 0.05398900434374809\n",
      "Iteration 14400, Loss: 0.05417166277766228\n",
      "Iteration 14401, Loss: 0.05398854613304138\n",
      "Iteration 14402, Loss: 0.054171811789274216\n",
      "Iteration 14403, Loss: 0.05398861691355705\n",
      "Iteration 14404, Loss: 0.054171811789274216\n",
      "Iteration 14405, Loss: 0.05398862808942795\n",
      "Iteration 14406, Loss: 0.05417180061340332\n",
      "Iteration 14407, Loss: 0.05398881435394287\n",
      "Iteration 14408, Loss: 0.05417165160179138\n",
      "Iteration 14409, Loss: 0.05398893356323242\n",
      "Iteration 14410, Loss: 0.0541716031730175\n",
      "Iteration 14411, Loss: 0.053988903760910034\n",
      "Iteration 14412, Loss: 0.054171495139598846\n",
      "Iteration 14413, Loss: 0.053988900035619736\n",
      "Iteration 14414, Loss: 0.054171495139598846\n",
      "Iteration 14415, Loss: 0.05398878455162048\n",
      "Iteration 14416, Loss: 0.054171692579984665\n",
      "Iteration 14417, Loss: 0.0539887398481369\n",
      "Iteration 14418, Loss: 0.054171811789274216\n",
      "Iteration 14419, Loss: 0.053988661617040634\n",
      "Iteration 14420, Loss: 0.05417173355817795\n",
      "Iteration 14421, Loss: 0.05398869514465332\n",
      "Iteration 14422, Loss: 0.05417169630527496\n",
      "Iteration 14423, Loss: 0.05398870259523392\n",
      "Iteration 14424, Loss: 0.054171692579984665\n",
      "Iteration 14425, Loss: 0.053988855332136154\n",
      "Iteration 14426, Loss: 0.05417133495211601\n",
      "Iteration 14427, Loss: 0.05398901551961899\n",
      "Iteration 14428, Loss: 0.05417129397392273\n",
      "Iteration 14429, Loss: 0.05398917943239212\n",
      "Iteration 14430, Loss: 0.05417121574282646\n",
      "Iteration 14431, Loss: 0.053989142179489136\n",
      "Iteration 14432, Loss: 0.05417117476463318\n",
      "Iteration 14433, Loss: 0.053989291191101074\n",
      "Iteration 14434, Loss: 0.05417126044631004\n",
      "Iteration 14435, Loss: 0.05398905277252197\n",
      "Iteration 14436, Loss: 0.05417145416140556\n",
      "Iteration 14437, Loss: 0.05398881435394287\n",
      "Iteration 14438, Loss: 0.05417165160179138\n",
      "Iteration 14439, Loss: 0.0539887398481369\n",
      "Iteration 14440, Loss: 0.054171692579984665\n",
      "Iteration 14441, Loss: 0.05398878455162048\n",
      "Iteration 14442, Loss: 0.05417157709598541\n",
      "Iteration 14443, Loss: 0.0539887398481369\n",
      "Iteration 14444, Loss: 0.05417172610759735\n",
      "Iteration 14445, Loss: 0.053988777101039886\n",
      "Iteration 14446, Loss: 0.0541716143488884\n",
      "Iteration 14447, Loss: 0.05398893356323242\n",
      "Iteration 14448, Loss: 0.05417134612798691\n",
      "Iteration 14449, Loss: 0.05398905277252197\n",
      "Iteration 14450, Loss: 0.05417129397392273\n",
      "Iteration 14451, Loss: 0.05398906022310257\n",
      "Iteration 14452, Loss: 0.05417129397392273\n",
      "Iteration 14453, Loss: 0.053988441824913025\n",
      "Iteration 14454, Loss: 0.05417142063379288\n",
      "Iteration 14455, Loss: 0.05398831516504288\n",
      "Iteration 14456, Loss: 0.05417146533727646\n",
      "Iteration 14457, Loss: 0.05398815870285034\n",
      "Iteration 14458, Loss: 0.054170992225408554\n",
      "Iteration 14459, Loss: 0.053988080471754074\n",
      "Iteration 14460, Loss: 0.054170917719602585\n",
      "Iteration 14461, Loss: 0.053988080471754074\n",
      "Iteration 14462, Loss: 0.054170917719602585\n",
      "Iteration 14463, Loss: 0.053988080471754074\n",
      "Iteration 14464, Loss: 0.054171036928892136\n",
      "Iteration 14465, Loss: 0.05398803949356079\n",
      "Iteration 14466, Loss: 0.054171111434698105\n",
      "Iteration 14467, Loss: 0.053988080471754074\n",
      "Iteration 14468, Loss: 0.054171036928892136\n",
      "Iteration 14469, Loss: 0.05398812144994736\n",
      "Iteration 14470, Loss: 0.054170962423086166\n",
      "Iteration 14471, Loss: 0.053988080471754074\n",
      "Iteration 14472, Loss: 0.054171036928892136\n",
      "Iteration 14473, Loss: 0.05398803949356079\n",
      "Iteration 14474, Loss: 0.054171107709407806\n",
      "Iteration 14475, Loss: 0.05398809164762497\n",
      "Iteration 14476, Loss: 0.0541708767414093\n",
      "Iteration 14477, Loss: 0.05398827791213989\n",
      "Iteration 14478, Loss: 0.05417067930102348\n",
      "Iteration 14479, Loss: 0.053988441824913025\n",
      "Iteration 14480, Loss: 0.054170556366443634\n",
      "Iteration 14481, Loss: 0.05398859828710556\n",
      "Iteration 14482, Loss: 0.054170481860637665\n",
      "Iteration 14483, Loss: 0.05398867651820183\n",
      "Iteration 14484, Loss: 0.05417044460773468\n",
      "Iteration 14485, Loss: 0.053988635540008545\n",
      "Iteration 14486, Loss: 0.0541706383228302\n",
      "Iteration 14487, Loss: 0.05398843437433243\n",
      "Iteration 14488, Loss: 0.054170917719602585\n",
      "Iteration 14489, Loss: 0.053988199681043625\n",
      "Iteration 14490, Loss: 0.0541711151599884\n",
      "Iteration 14491, Loss: 0.053987812250852585\n",
      "Iteration 14492, Loss: 0.05417126417160034\n",
      "Iteration 14493, Loss: 0.05398792028427124\n",
      "Iteration 14494, Loss: 0.05417106673121452\n",
      "Iteration 14495, Loss: 0.053988080471754074\n",
      "Iteration 14496, Loss: 0.05417090654373169\n",
      "Iteration 14497, Loss: 0.053988318890333176\n",
      "Iteration 14498, Loss: 0.05417066812515259\n",
      "Iteration 14499, Loss: 0.053988516330718994\n",
      "Iteration 14500, Loss: 0.05417056009173393\n",
      "Iteration 14501, Loss: 0.05398859083652496\n",
      "Iteration 14502, Loss: 0.0541706383228302\n",
      "Iteration 14503, Loss: 0.05398839712142944\n",
      "Iteration 14504, Loss: 0.05417083948850632\n",
      "Iteration 14505, Loss: 0.05398824065923691\n",
      "Iteration 14506, Loss: 0.054171036928892136\n",
      "Iteration 14507, Loss: 0.05398815497756004\n",
      "Iteration 14508, Loss: 0.054171234369277954\n",
      "Iteration 14509, Loss: 0.05398784205317497\n",
      "Iteration 14510, Loss: 0.05417127534747124\n",
      "Iteration 14511, Loss: 0.05398785322904587\n",
      "Iteration 14512, Loss: 0.05417107790708542\n",
      "Iteration 14513, Loss: 0.05398789048194885\n",
      "Iteration 14514, Loss: 0.05417099595069885\n",
      "Iteration 14515, Loss: 0.05398809164762497\n",
      "Iteration 14516, Loss: 0.05417075753211975\n",
      "Iteration 14517, Loss: 0.05398836359381676\n",
      "Iteration 14518, Loss: 0.05417051538825035\n",
      "Iteration 14519, Loss: 0.05398859828710556\n",
      "Iteration 14520, Loss: 0.054170481860637665\n",
      "Iteration 14521, Loss: 0.05398871749639511\n",
      "Iteration 14522, Loss: 0.05417056009173393\n",
      "Iteration 14523, Loss: 0.05398839712142944\n",
      "Iteration 14524, Loss: 0.054170720279216766\n",
      "Iteration 14525, Loss: 0.05398821085691452\n",
      "Iteration 14526, Loss: 0.05417083203792572\n",
      "Iteration 14527, Loss: 0.05398824065923691\n",
      "Iteration 14528, Loss: 0.05417099595069885\n",
      "Iteration 14529, Loss: 0.053988050669431686\n",
      "Iteration 14530, Loss: 0.05417107790708542\n",
      "Iteration 14531, Loss: 0.05398797243833542\n",
      "Iteration 14532, Loss: 0.05417099595069885\n",
      "Iteration 14533, Loss: 0.05398796498775482\n",
      "Iteration 14534, Loss: 0.05417099595069885\n",
      "Iteration 14535, Loss: 0.05398815870285034\n",
      "Iteration 14536, Loss: 0.05417076498270035\n",
      "Iteration 14537, Loss: 0.053988393396139145\n",
      "Iteration 14538, Loss: 0.054170794785022736\n",
      "Iteration 14539, Loss: 0.053988248109817505\n",
      "Iteration 14540, Loss: 0.05417071282863617\n",
      "Iteration 14541, Loss: 0.05398839712142944\n",
      "Iteration 14542, Loss: 0.05417075753211975\n",
      "Iteration 14543, Loss: 0.05398820340633392\n",
      "Iteration 14544, Loss: 0.05417083948850632\n",
      "Iteration 14545, Loss: 0.05398824065923691\n",
      "Iteration 14546, Loss: 0.054170750081539154\n",
      "Iteration 14547, Loss: 0.053988318890333176\n",
      "Iteration 14548, Loss: 0.0541706383228302\n",
      "Iteration 14549, Loss: 0.05398840457201004\n",
      "Iteration 14550, Loss: 0.0541706308722496\n",
      "Iteration 14551, Loss: 0.053988516330718994\n",
      "Iteration 14552, Loss: 0.054170556366443634\n",
      "Iteration 14553, Loss: 0.05398859828710556\n",
      "Iteration 14554, Loss: 0.05417056009173393\n",
      "Iteration 14555, Loss: 0.05398839712142944\n",
      "Iteration 14556, Loss: 0.05417083948850632\n",
      "Iteration 14557, Loss: 0.053988270461559296\n",
      "Iteration 14558, Loss: 0.0541708841919899\n",
      "Iteration 14559, Loss: 0.05398815870285034\n",
      "Iteration 14560, Loss: 0.05417100340127945\n",
      "Iteration 14561, Loss: 0.053988002240657806\n",
      "Iteration 14562, Loss: 0.054171156138181686\n",
      "Iteration 14563, Loss: 0.053988002240657806\n",
      "Iteration 14564, Loss: 0.054171111434698105\n",
      "Iteration 14565, Loss: 0.05398803949356079\n",
      "Iteration 14566, Loss: 0.05417099595069885\n",
      "Iteration 14567, Loss: 0.053988050669431686\n",
      "Iteration 14568, Loss: 0.0541708767414093\n",
      "Iteration 14569, Loss: 0.05398827791213989\n",
      "Iteration 14570, Loss: 0.05417067930102348\n",
      "Iteration 14571, Loss: 0.05398847907781601\n",
      "Iteration 14572, Loss: 0.0541706308722496\n",
      "Iteration 14573, Loss: 0.05398859828710556\n",
      "Iteration 14574, Loss: 0.05417051911354065\n",
      "Iteration 14575, Loss: 0.05398840829730034\n",
      "Iteration 14576, Loss: 0.05417075753211975\n",
      "Iteration 14577, Loss: 0.05398824065923691\n",
      "Iteration 14578, Loss: 0.05417099595069885\n",
      "Iteration 14579, Loss: 0.05398808419704437\n",
      "Iteration 14580, Loss: 0.05417107045650482\n",
      "Iteration 14581, Loss: 0.0539880096912384\n",
      "Iteration 14582, Loss: 0.054171107709407806\n",
      "Iteration 14583, Loss: 0.053988128900527954\n",
      "Iteration 14584, Loss: 0.05417090654373169\n",
      "Iteration 14585, Loss: 0.05398827791213989\n",
      "Iteration 14586, Loss: 0.054170798510313034\n",
      "Iteration 14587, Loss: 0.053988393396139145\n",
      "Iteration 14588, Loss: 0.054170720279216766\n",
      "Iteration 14589, Loss: 0.053988393396139145\n",
      "Iteration 14590, Loss: 0.05417067930102348\n",
      "Iteration 14591, Loss: 0.053988467901945114\n",
      "Iteration 14592, Loss: 0.05417067930102348\n",
      "Iteration 14593, Loss: 0.05398854613304138\n",
      "Iteration 14594, Loss: 0.054170601069927216\n",
      "Iteration 14595, Loss: 0.05398844927549362\n",
      "Iteration 14596, Loss: 0.05417069047689438\n",
      "Iteration 14597, Loss: 0.053988322615623474\n",
      "Iteration 14598, Loss: 0.054170917719602585\n",
      "Iteration 14599, Loss: 0.05398808419704437\n",
      "Iteration 14600, Loss: 0.054171036928892136\n",
      "Iteration 14601, Loss: 0.053988002240657806\n",
      "Iteration 14602, Loss: 0.05417099595069885\n",
      "Iteration 14603, Loss: 0.05398812144994736\n",
      "Iteration 14604, Loss: 0.054170913994312286\n",
      "Iteration 14605, Loss: 0.05398827791213989\n",
      "Iteration 14606, Loss: 0.05417078360915184\n",
      "Iteration 14607, Loss: 0.05398839712142944\n",
      "Iteration 14608, Loss: 0.05417066812515259\n",
      "Iteration 14609, Loss: 0.053988587111234665\n",
      "Iteration 14610, Loss: 0.0541706308722496\n",
      "Iteration 14611, Loss: 0.05398859828710556\n",
      "Iteration 14612, Loss: 0.0541706308722496\n",
      "Iteration 14613, Loss: 0.05398855358362198\n",
      "Iteration 14614, Loss: 0.054170530289411545\n",
      "Iteration 14615, Loss: 0.05398839712142944\n",
      "Iteration 14616, Loss: 0.05417067930102348\n",
      "Iteration 14617, Loss: 0.05398839712142944\n",
      "Iteration 14618, Loss: 0.054170794785022736\n",
      "Iteration 14619, Loss: 0.05398835986852646\n",
      "Iteration 14620, Loss: 0.05417075753211975\n",
      "Iteration 14621, Loss: 0.05398835986852646\n",
      "Iteration 14622, Loss: 0.05417082831263542\n",
      "Iteration 14623, Loss: 0.053988318890333176\n",
      "Iteration 14624, Loss: 0.054170798510313034\n",
      "Iteration 14625, Loss: 0.05398815870285034\n",
      "Iteration 14626, Loss: 0.054170917719602585\n",
      "Iteration 14627, Loss: 0.05398808419704437\n",
      "Iteration 14628, Loss: 0.05417095124721527\n",
      "Iteration 14629, Loss: 0.05398815870285034\n",
      "Iteration 14630, Loss: 0.0541708767414093\n",
      "Iteration 14631, Loss: 0.05398815870285034\n",
      "Iteration 14632, Loss: 0.05417095124721527\n",
      "Iteration 14633, Loss: 0.053988199681043625\n",
      "Iteration 14634, Loss: 0.05417090654373169\n",
      "Iteration 14635, Loss: 0.05398827791213989\n",
      "Iteration 14636, Loss: 0.054170750081539154\n",
      "Iteration 14637, Loss: 0.05398847907781601\n",
      "Iteration 14638, Loss: 0.05417054891586304\n",
      "Iteration 14639, Loss: 0.05398860201239586\n",
      "Iteration 14640, Loss: 0.05417043715715408\n",
      "Iteration 14641, Loss: 0.0539887472987175\n",
      "Iteration 14642, Loss: 0.05417048558592796\n",
      "Iteration 14643, Loss: 0.05398835986852646\n",
      "Iteration 14644, Loss: 0.05417068302631378\n",
      "Iteration 14645, Loss: 0.05398831516504288\n",
      "Iteration 14646, Loss: 0.05417080223560333\n",
      "Iteration 14647, Loss: 0.05398823320865631\n",
      "Iteration 14648, Loss: 0.054170917719602585\n",
      "Iteration 14649, Loss: 0.053988199681043625\n",
      "Iteration 14650, Loss: 0.054170988500118256\n",
      "Iteration 14651, Loss: 0.053988199681043625\n",
      "Iteration 14652, Loss: 0.054170869290828705\n",
      "Iteration 14653, Loss: 0.05398827791213989\n",
      "Iteration 14654, Loss: 0.05417082831263542\n",
      "Iteration 14655, Loss: 0.05398827791213989\n",
      "Iteration 14656, Loss: 0.05417067930102348\n",
      "Iteration 14657, Loss: 0.05398833006620407\n",
      "Iteration 14658, Loss: 0.054170720279216766\n",
      "Iteration 14659, Loss: 0.05398828908801079\n",
      "Iteration 14660, Loss: 0.0541706383228302\n",
      "Iteration 14661, Loss: 0.053988441824913025\n",
      "Iteration 14662, Loss: 0.05417082831263542\n",
      "Iteration 14663, Loss: 0.05398835986852646\n",
      "Iteration 14664, Loss: 0.054170917719602585\n",
      "Iteration 14665, Loss: 0.05398816615343094\n",
      "Iteration 14666, Loss: 0.05417106673121452\n",
      "Iteration 14667, Loss: 0.05398797243833542\n",
      "Iteration 14668, Loss: 0.05417102575302124\n",
      "Iteration 14669, Loss: 0.053988080471754074\n",
      "Iteration 14670, Loss: 0.054170992225408554\n",
      "Iteration 14671, Loss: 0.05398824065923691\n",
      "Iteration 14672, Loss: 0.054170869290828705\n",
      "Iteration 14673, Loss: 0.05398835986852646\n",
      "Iteration 14674, Loss: 0.05417071282863617\n",
      "Iteration 14675, Loss: 0.05398854613304138\n",
      "Iteration 14676, Loss: 0.0541706383228302\n",
      "Iteration 14677, Loss: 0.053988438099622726\n",
      "Iteration 14678, Loss: 0.054170601069927216\n",
      "Iteration 14679, Loss: 0.05398847907781601\n",
      "Iteration 14680, Loss: 0.054170530289411545\n",
      "Iteration 14681, Loss: 0.05398828536272049\n",
      "Iteration 14682, Loss: 0.05417075753211975\n",
      "Iteration 14683, Loss: 0.05398820340633392\n",
      "Iteration 14684, Loss: 0.05417080223560333\n",
      "Iteration 14685, Loss: 0.053988199681043625\n",
      "Iteration 14686, Loss: 0.0541708841919899\n",
      "Iteration 14687, Loss: 0.05398812144994736\n",
      "Iteration 14688, Loss: 0.05417092144489288\n",
      "Iteration 14689, Loss: 0.05398811399936676\n",
      "Iteration 14690, Loss: 0.05417106673121452\n",
      "Iteration 14691, Loss: 0.05398815870285034\n",
      "Iteration 14692, Loss: 0.05417095869779587\n",
      "Iteration 14693, Loss: 0.05398824065923691\n",
      "Iteration 14694, Loss: 0.054170869290828705\n",
      "Iteration 14695, Loss: 0.05398842692375183\n",
      "Iteration 14696, Loss: 0.054170720279216766\n",
      "Iteration 14697, Loss: 0.05398847907781601\n",
      "Iteration 14698, Loss: 0.054170601069927216\n",
      "Iteration 14699, Loss: 0.053988516330718994\n",
      "Iteration 14700, Loss: 0.05417067930102348\n",
      "Iteration 14701, Loss: 0.05398847162723541\n",
      "Iteration 14702, Loss: 0.054170798510313034\n",
      "Iteration 14703, Loss: 0.05398824065923691\n",
      "Iteration 14704, Loss: 0.054170724004507065\n",
      "Iteration 14705, Loss: 0.05398824065923691\n",
      "Iteration 14706, Loss: 0.05417083948850632\n",
      "Iteration 14707, Loss: 0.053988244384527206\n",
      "Iteration 14708, Loss: 0.05417075753211975\n",
      "Iteration 14709, Loss: 0.053988248109817505\n",
      "Iteration 14710, Loss: 0.0541706383228302\n",
      "Iteration 14711, Loss: 0.05398847907781601\n",
      "Iteration 14712, Loss: 0.054170601069927216\n",
      "Iteration 14713, Loss: 0.053988587111234665\n",
      "Iteration 14714, Loss: 0.05417048558592796\n",
      "Iteration 14715, Loss: 0.053988516330718994\n",
      "Iteration 14716, Loss: 0.05417067930102348\n",
      "Iteration 14717, Loss: 0.05398835986852646\n",
      "Iteration 14718, Loss: 0.05417083948850632\n",
      "Iteration 14719, Loss: 0.053988199681043625\n",
      "Iteration 14720, Loss: 0.054171036928892136\n",
      "Iteration 14721, Loss: 0.053988002240657806\n",
      "Iteration 14722, Loss: 0.05417106673121452\n",
      "Iteration 14723, Loss: 0.05398797243833542\n",
      "Iteration 14724, Loss: 0.054171111434698105\n",
      "Iteration 14725, Loss: 0.05398816987872124\n",
      "Iteration 14726, Loss: 0.05417083948850632\n",
      "Iteration 14727, Loss: 0.05398816615343094\n",
      "Iteration 14728, Loss: 0.0541708841919899\n",
      "Iteration 14729, Loss: 0.05398815870285034\n",
      "Iteration 14730, Loss: 0.05417083948850632\n",
      "Iteration 14731, Loss: 0.053988199681043625\n",
      "Iteration 14732, Loss: 0.054170913994312286\n",
      "Iteration 14733, Loss: 0.053988199681043625\n",
      "Iteration 14734, Loss: 0.054170869290828705\n",
      "Iteration 14735, Loss: 0.053988389670848846\n",
      "Iteration 14736, Loss: 0.05417078733444214\n",
      "Iteration 14737, Loss: 0.05398835986852646\n",
      "Iteration 14738, Loss: 0.05417071282863617\n",
      "Iteration 14739, Loss: 0.05398839712142944\n",
      "Iteration 14740, Loss: 0.05417078733444214\n",
      "Iteration 14741, Loss: 0.05398839712142944\n",
      "Iteration 14742, Loss: 0.054170750081539154\n",
      "Iteration 14743, Loss: 0.05398839712142944\n",
      "Iteration 14744, Loss: 0.054170675575733185\n",
      "Iteration 14745, Loss: 0.053988512605428696\n",
      "Iteration 14746, Loss: 0.054170869290828705\n",
      "Iteration 14747, Loss: 0.05398835986852646\n",
      "Iteration 14748, Loss: 0.0541708767414093\n",
      "Iteration 14749, Loss: 0.05398830771446228\n",
      "Iteration 14750, Loss: 0.054170913994312286\n",
      "Iteration 14751, Loss: 0.053988270461559296\n",
      "Iteration 14752, Loss: 0.054170992225408554\n",
      "Iteration 14753, Loss: 0.053988195955753326\n",
      "Iteration 14754, Loss: 0.05417099595069885\n",
      "Iteration 14755, Loss: 0.05398803949356079\n",
      "Iteration 14756, Loss: 0.05417099595069885\n",
      "Iteration 14757, Loss: 0.05398815870285034\n",
      "Iteration 14758, Loss: 0.05417090654373169\n",
      "Iteration 14759, Loss: 0.05398822948336601\n",
      "Iteration 14760, Loss: 0.054170798510313034\n",
      "Iteration 14761, Loss: 0.05398835986852646\n",
      "Iteration 14762, Loss: 0.05417078733444214\n",
      "Iteration 14763, Loss: 0.05398847907781601\n",
      "Iteration 14764, Loss: 0.05417070537805557\n",
      "Iteration 14765, Loss: 0.05398855730891228\n",
      "Iteration 14766, Loss: 0.05417051538825035\n",
      "Iteration 14767, Loss: 0.05398855730891228\n",
      "Iteration 14768, Loss: 0.05417051538825035\n",
      "Iteration 14769, Loss: 0.053988516330718994\n",
      "Iteration 14770, Loss: 0.05417048558592796\n",
      "Iteration 14771, Loss: 0.053988486528396606\n",
      "Iteration 14772, Loss: 0.05417071282863617\n",
      "Iteration 14773, Loss: 0.053988318890333176\n",
      "Iteration 14774, Loss: 0.05417083948850632\n",
      "Iteration 14775, Loss: 0.05398815870285034\n",
      "Iteration 14776, Loss: 0.054171107709407806\n",
      "Iteration 14777, Loss: 0.05398812144994736\n",
      "Iteration 14778, Loss: 0.054171107709407806\n",
      "Iteration 14779, Loss: 0.053988195955753326\n",
      "Iteration 14780, Loss: 0.05417099595069885\n",
      "Iteration 14781, Loss: 0.05398815870285034\n",
      "Iteration 14782, Loss: 0.05417094752192497\n",
      "Iteration 14783, Loss: 0.05398834869265556\n",
      "Iteration 14784, Loss: 0.054170750081539154\n",
      "Iteration 14785, Loss: 0.05398842692375183\n",
      "Iteration 14786, Loss: 0.0541706383228302\n",
      "Iteration 14787, Loss: 0.05398835986852646\n",
      "Iteration 14788, Loss: 0.0541706383228302\n",
      "Iteration 14789, Loss: 0.05398835986852646\n",
      "Iteration 14790, Loss: 0.05417083948850632\n",
      "Iteration 14791, Loss: 0.05398816615343094\n",
      "Iteration 14792, Loss: 0.05417107790708542\n",
      "Iteration 14793, Loss: 0.053988002240657806\n",
      "Iteration 14794, Loss: 0.05417118966579437\n",
      "Iteration 14795, Loss: 0.05398796126246452\n",
      "Iteration 14796, Loss: 0.05417106673121452\n",
      "Iteration 14797, Loss: 0.053988050669431686\n",
      "Iteration 14798, Loss: 0.05417078733444214\n",
      "Iteration 14799, Loss: 0.05398833006620407\n",
      "Iteration 14800, Loss: 0.054170429706573486\n",
      "Iteration 14801, Loss: 0.053988825529813766\n",
      "Iteration 14802, Loss: 0.05417028069496155\n",
      "Iteration 14803, Loss: 0.05398894473910332\n",
      "Iteration 14804, Loss: 0.0541703999042511\n",
      "Iteration 14805, Loss: 0.053988710045814514\n",
      "Iteration 14806, Loss: 0.05417056009173393\n",
      "Iteration 14807, Loss: 0.0539885088801384\n",
      "Iteration 14808, Loss: 0.054170846939086914\n",
      "Iteration 14809, Loss: 0.05398823320865631\n",
      "Iteration 14810, Loss: 0.05417108163237572\n",
      "Iteration 14811, Loss: 0.05398835986852646\n",
      "Iteration 14812, Loss: 0.05417115241289139\n",
      "Iteration 14813, Loss: 0.05398847907781601\n",
      "Iteration 14814, Loss: 0.05417155474424362\n",
      "Iteration 14815, Loss: 0.05398855730891228\n",
      "Iteration 14816, Loss: 0.05417139455676079\n",
      "Iteration 14817, Loss: 0.05398879572749138\n",
      "Iteration 14818, Loss: 0.05417119711637497\n",
      "Iteration 14819, Loss: 0.05398879572749138\n",
      "Iteration 14820, Loss: 0.054171156138181686\n",
      "Iteration 14821, Loss: 0.05398891493678093\n",
      "Iteration 14822, Loss: 0.054171234369277954\n",
      "Iteration 14823, Loss: 0.053988903760910034\n",
      "Iteration 14824, Loss: 0.054171353578567505\n",
      "Iteration 14825, Loss: 0.053988710045814514\n",
      "Iteration 14826, Loss: 0.05417143553495407\n",
      "Iteration 14827, Loss: 0.05398859828710556\n",
      "Iteration 14828, Loss: 0.054171543568372726\n",
      "Iteration 14829, Loss: 0.053988516330718994\n",
      "Iteration 14830, Loss: 0.05417155474424362\n",
      "Iteration 14831, Loss: 0.05398847907781601\n",
      "Iteration 14832, Loss: 0.054171543568372726\n",
      "Iteration 14833, Loss: 0.053988516330718994\n",
      "Iteration 14834, Loss: 0.054171472787857056\n",
      "Iteration 14835, Loss: 0.05398871749639511\n",
      "Iteration 14836, Loss: 0.05417131632566452\n",
      "Iteration 14837, Loss: 0.05398879200220108\n",
      "Iteration 14838, Loss: 0.05417107790708542\n",
      "Iteration 14839, Loss: 0.0539889857172966\n",
      "Iteration 14840, Loss: 0.054171036928892136\n",
      "Iteration 14841, Loss: 0.05398903042078018\n",
      "Iteration 14842, Loss: 0.054171036928892136\n",
      "Iteration 14843, Loss: 0.053988873958587646\n",
      "Iteration 14844, Loss: 0.0541711151599884\n",
      "Iteration 14845, Loss: 0.053988829255104065\n",
      "Iteration 14846, Loss: 0.05417120084166527\n",
      "Iteration 14847, Loss: 0.05398871749639511\n",
      "Iteration 14848, Loss: 0.05417127534747124\n",
      "Iteration 14849, Loss: 0.05398871749639511\n",
      "Iteration 14850, Loss: 0.05417130887508392\n",
      "Iteration 14851, Loss: 0.05398871749639511\n",
      "Iteration 14852, Loss: 0.054171156138181686\n",
      "Iteration 14853, Loss: 0.053988903760910034\n",
      "Iteration 14854, Loss: 0.05417126417160034\n",
      "Iteration 14855, Loss: 0.053988825529813766\n",
      "Iteration 14856, Loss: 0.05417122691869736\n",
      "Iteration 14857, Loss: 0.05398883670568466\n",
      "Iteration 14858, Loss: 0.054171234369277954\n",
      "Iteration 14859, Loss: 0.053988903760910034\n",
      "Iteration 14860, Loss: 0.05417127534747124\n",
      "Iteration 14861, Loss: 0.05398871749639511\n",
      "Iteration 14862, Loss: 0.05417131632566452\n",
      "Iteration 14863, Loss: 0.05398855730891228\n",
      "Iteration 14864, Loss: 0.054171353578567505\n",
      "Iteration 14865, Loss: 0.053988561034202576\n",
      "Iteration 14866, Loss: 0.054171353578567505\n",
      "Iteration 14867, Loss: 0.05398867279291153\n",
      "Iteration 14868, Loss: 0.05417127534747124\n",
      "Iteration 14869, Loss: 0.05398859828710556\n",
      "Iteration 14870, Loss: 0.05417118966579437\n",
      "Iteration 14871, Loss: 0.05398883670568466\n",
      "Iteration 14872, Loss: 0.05417107045650482\n",
      "Iteration 14873, Loss: 0.053989000618457794\n",
      "Iteration 14874, Loss: 0.0541708767414093\n",
      "Iteration 14875, Loss: 0.05398903414607048\n",
      "Iteration 14876, Loss: 0.05417103320360184\n",
      "Iteration 14877, Loss: 0.05398891493678093\n",
      "Iteration 14878, Loss: 0.054171156138181686\n",
      "Iteration 14879, Loss: 0.05398883670568466\n",
      "Iteration 14880, Loss: 0.054171234369277954\n",
      "Iteration 14881, Loss: 0.0539887510240078\n",
      "Iteration 14882, Loss: 0.054171424359083176\n",
      "Iteration 14883, Loss: 0.05398852750658989\n",
      "Iteration 14884, Loss: 0.054171424359083176\n",
      "Iteration 14885, Loss: 0.053988561034202576\n",
      "Iteration 14886, Loss: 0.05417134612798691\n",
      "Iteration 14887, Loss: 0.05398867651820183\n",
      "Iteration 14888, Loss: 0.054171234369277954\n",
      "Iteration 14889, Loss: 0.05398883670568466\n",
      "Iteration 14890, Loss: 0.0541711151599884\n",
      "Iteration 14891, Loss: 0.05398895591497421\n",
      "Iteration 14892, Loss: 0.0541711151599884\n",
      "Iteration 14893, Loss: 0.05398891121149063\n",
      "Iteration 14894, Loss: 0.054171156138181686\n",
      "Iteration 14895, Loss: 0.053988829255104065\n",
      "Iteration 14896, Loss: 0.05417127534747124\n",
      "Iteration 14897, Loss: 0.053988635540008545\n",
      "Iteration 14898, Loss: 0.05417134612798691\n",
      "Iteration 14899, Loss: 0.05398855730891228\n",
      "Iteration 14900, Loss: 0.054171230643987656\n",
      "Iteration 14901, Loss: 0.05398868769407272\n",
      "Iteration 14902, Loss: 0.054171185940504074\n",
      "Iteration 14903, Loss: 0.053988873958587646\n",
      "Iteration 14904, Loss: 0.054171036928892136\n",
      "Iteration 14905, Loss: 0.05398891493678093\n",
      "Iteration 14906, Loss: 0.05417107790708542\n",
      "Iteration 14907, Loss: 0.053988873958587646\n",
      "Iteration 14908, Loss: 0.054171234369277954\n",
      "Iteration 14909, Loss: 0.05398879572749138\n",
      "Iteration 14910, Loss: 0.05417131632566452\n",
      "Iteration 14911, Loss: 0.05398867651820183\n",
      "Iteration 14912, Loss: 0.054171472787857056\n",
      "Iteration 14913, Loss: 0.05398859828710556\n",
      "Iteration 14914, Loss: 0.05417155474424362\n",
      "Iteration 14915, Loss: 0.053988438099622726\n",
      "Iteration 14916, Loss: 0.05417151004076004\n",
      "Iteration 14917, Loss: 0.05398848280310631\n",
      "Iteration 14918, Loss: 0.05417146533727646\n",
      "Iteration 14919, Loss: 0.05398856848478317\n",
      "Iteration 14920, Loss: 0.054171234369277954\n",
      "Iteration 14921, Loss: 0.05398871749639511\n",
      "Iteration 14922, Loss: 0.05417107790708542\n",
      "Iteration 14923, Loss: 0.0539889857172966\n",
      "Iteration 14924, Loss: 0.05417115241289139\n",
      "Iteration 14925, Loss: 0.053988873958587646\n",
      "Iteration 14926, Loss: 0.05417107790708542\n",
      "Iteration 14927, Loss: 0.053988873958587646\n",
      "Iteration 14928, Loss: 0.05417127162218094\n",
      "Iteration 14929, Loss: 0.05398879572749138\n",
      "Iteration 14930, Loss: 0.05417127534747124\n",
      "Iteration 14931, Loss: 0.05398860201239586\n",
      "Iteration 14932, Loss: 0.05417143553495407\n",
      "Iteration 14933, Loss: 0.05398855730891228\n",
      "Iteration 14934, Loss: 0.054171472787857056\n",
      "Iteration 14935, Loss: 0.05398859828710556\n",
      "Iteration 14936, Loss: 0.054171543568372726\n",
      "Iteration 14937, Loss: 0.05398855730891228\n",
      "Iteration 14938, Loss: 0.05417146533727646\n",
      "Iteration 14939, Loss: 0.053988635540008545\n",
      "Iteration 14940, Loss: 0.05417146533727646\n",
      "Iteration 14941, Loss: 0.053988706320524216\n",
      "Iteration 14942, Loss: 0.05417138338088989\n",
      "Iteration 14943, Loss: 0.05398867651820183\n",
      "Iteration 14944, Loss: 0.05417127534747124\n",
      "Iteration 14945, Loss: 0.053988873958587646\n",
      "Iteration 14946, Loss: 0.0541711151599884\n",
      "Iteration 14947, Loss: 0.0539889931678772\n",
      "Iteration 14948, Loss: 0.054171159863471985\n",
      "Iteration 14949, Loss: 0.05398883670568466\n",
      "Iteration 14950, Loss: 0.05417127534747124\n",
      "Iteration 14951, Loss: 0.053988561034202576\n",
      "Iteration 14952, Loss: 0.05417127534747124\n",
      "Iteration 14953, Loss: 0.05398864671587944\n",
      "Iteration 14954, Loss: 0.05417127162218094\n",
      "Iteration 14955, Loss: 0.05398864671587944\n",
      "Iteration 14956, Loss: 0.05417126417160034\n",
      "Iteration 14957, Loss: 0.05398879572749138\n",
      "Iteration 14958, Loss: 0.05417122691869736\n",
      "Iteration 14959, Loss: 0.053988873958587646\n",
      "Iteration 14960, Loss: 0.05417107790708542\n",
      "Iteration 14961, Loss: 0.053988948464393616\n",
      "Iteration 14962, Loss: 0.0541711151599884\n",
      "Iteration 14963, Loss: 0.05398883670568466\n",
      "Iteration 14964, Loss: 0.05417127534747124\n",
      "Iteration 14965, Loss: 0.053988635540008545\n",
      "Iteration 14966, Loss: 0.05417143553495407\n",
      "Iteration 14967, Loss: 0.05398859828710556\n",
      "Iteration 14968, Loss: 0.05417150259017944\n",
      "Iteration 14969, Loss: 0.053988635540008545\n",
      "Iteration 14970, Loss: 0.05417146906256676\n",
      "Iteration 14971, Loss: 0.053988635540008545\n",
      "Iteration 14972, Loss: 0.05417146533727646\n",
      "Iteration 14973, Loss: 0.05398860573768616\n",
      "Iteration 14974, Loss: 0.05417134612798691\n",
      "Iteration 14975, Loss: 0.05398871749639511\n",
      "Iteration 14976, Loss: 0.054171036928892136\n",
      "Iteration 14977, Loss: 0.05398891866207123\n",
      "Iteration 14978, Loss: 0.05417083948850632\n",
      "Iteration 14979, Loss: 0.05398915335536003\n",
      "Iteration 14980, Loss: 0.054170720279216766\n",
      "Iteration 14981, Loss: 0.053989194333553314\n",
      "Iteration 14982, Loss: 0.054170720279216766\n",
      "Iteration 14983, Loss: 0.05398930236697197\n",
      "Iteration 14984, Loss: 0.054170798510313034\n",
      "Iteration 14985, Loss: 0.053989194333553314\n",
      "Iteration 14986, Loss: 0.054170917719602585\n",
      "Iteration 14987, Loss: 0.05398903414607048\n",
      "Iteration 14988, Loss: 0.054170992225408554\n",
      "Iteration 14989, Loss: 0.0539889931678772\n",
      "Iteration 14990, Loss: 0.054171036928892136\n",
      "Iteration 14991, Loss: 0.05398891493678093\n",
      "Iteration 14992, Loss: 0.05417095869779587\n",
      "Iteration 14993, Loss: 0.05398888140916824\n",
      "Iteration 14994, Loss: 0.054170917719602585\n",
      "Iteration 14995, Loss: 0.05398903414607048\n",
      "Iteration 14996, Loss: 0.0541708767414093\n",
      "Iteration 14997, Loss: 0.05398914963006973\n",
      "Iteration 14998, Loss: 0.054170917719602585\n",
      "Iteration 14999, Loss: 0.05398903414607048\n",
      "Iteration 15000, Loss: 0.054171036928892136\n",
      "Iteration 15001, Loss: 0.05398891493678093\n",
      "Iteration 15002, Loss: 0.054170846939086914\n",
      "Iteration 15003, Loss: 0.05398891493678093\n",
      "Iteration 15004, Loss: 0.05417095869779587\n",
      "Iteration 15005, Loss: 0.05398895964026451\n",
      "Iteration 15006, Loss: 0.054170917719602585\n",
      "Iteration 15007, Loss: 0.05398918315768242\n",
      "Iteration 15008, Loss: 0.054170913994312286\n",
      "Iteration 15009, Loss: 0.053989142179489136\n",
      "Iteration 15010, Loss: 0.05417095869779587\n",
      "Iteration 15011, Loss: 0.05398903787136078\n",
      "Iteration 15012, Loss: 0.05417099595069885\n",
      "Iteration 15013, Loss: 0.05398903414607048\n",
      "Iteration 15014, Loss: 0.054171036928892136\n",
      "Iteration 15015, Loss: 0.05398887023329735\n",
      "Iteration 15016, Loss: 0.0541711151599884\n",
      "Iteration 15017, Loss: 0.05398883670568466\n",
      "Iteration 15018, Loss: 0.054171122610569\n",
      "Iteration 15019, Loss: 0.053988754749298096\n",
      "Iteration 15020, Loss: 0.054171156138181686\n",
      "Iteration 15021, Loss: 0.053988754749298096\n",
      "Iteration 15022, Loss: 0.05417099595069885\n",
      "Iteration 15023, Loss: 0.05398927628993988\n",
      "Iteration 15024, Loss: 0.05417094752192497\n",
      "Iteration 15025, Loss: 0.05398951470851898\n",
      "Iteration 15026, Loss: 0.054170191287994385\n",
      "Iteration 15027, Loss: 0.05398982763290405\n",
      "Iteration 15028, Loss: 0.05416996777057648\n",
      "Iteration 15029, Loss: 0.053990017622709274\n",
      "Iteration 15030, Loss: 0.054170168936252594\n",
      "Iteration 15031, Loss: 0.05398966372013092\n",
      "Iteration 15032, Loss: 0.05417048931121826\n",
      "Iteration 15033, Loss: 0.05398935079574585\n",
      "Iteration 15034, Loss: 0.054171036928892136\n",
      "Iteration 15035, Loss: 0.0539889894425869\n",
      "Iteration 15036, Loss: 0.05417116731405258\n",
      "Iteration 15037, Loss: 0.05398859828710556\n",
      "Iteration 15038, Loss: 0.05417175218462944\n",
      "Iteration 15039, Loss: 0.053988248109817505\n",
      "Iteration 15040, Loss: 0.054171591997146606\n",
      "Iteration 15041, Loss: 0.053988248109817505\n",
      "Iteration 15042, Loss: 0.05417158454656601\n",
      "Iteration 15043, Loss: 0.05398844927549362\n",
      "Iteration 15044, Loss: 0.05417127162218094\n",
      "Iteration 15045, Loss: 0.05398879945278168\n",
      "Iteration 15046, Loss: 0.054170917719602585\n",
      "Iteration 15047, Loss: 0.053989119827747345\n",
      "Iteration 15048, Loss: 0.05417082831263542\n",
      "Iteration 15049, Loss: 0.0539892315864563\n",
      "Iteration 15050, Loss: 0.0541706383228302\n",
      "Iteration 15051, Loss: 0.0539894662797451\n",
      "Iteration 15052, Loss: 0.0541706383228302\n",
      "Iteration 15053, Loss: 0.05398935079574585\n",
      "Iteration 15054, Loss: 0.05417083948850632\n",
      "Iteration 15055, Loss: 0.0539892315864563\n",
      "Iteration 15056, Loss: 0.054171156138181686\n",
      "Iteration 15057, Loss: 0.053988873958587646\n",
      "Iteration 15058, Loss: 0.05417131632566452\n",
      "Iteration 15059, Loss: 0.05398871749639511\n",
      "Iteration 15060, Loss: 0.05417131632566452\n",
      "Iteration 15061, Loss: 0.05398867651820183\n",
      "Iteration 15062, Loss: 0.054171349853277206\n",
      "Iteration 15063, Loss: 0.05398868769407272\n",
      "Iteration 15064, Loss: 0.05417127162218094\n",
      "Iteration 15065, Loss: 0.05398883670568466\n",
      "Iteration 15066, Loss: 0.0541711151599884\n",
      "Iteration 15067, Loss: 0.05398896336555481\n",
      "Iteration 15068, Loss: 0.054171036928892136\n",
      "Iteration 15069, Loss: 0.05398915335536003\n",
      "Iteration 15070, Loss: 0.054170992225408554\n",
      "Iteration 15071, Loss: 0.05398915335536003\n",
      "Iteration 15072, Loss: 0.0541711151599884\n",
      "Iteration 15073, Loss: 0.0539889931678772\n",
      "Iteration 15074, Loss: 0.054171040654182434\n",
      "Iteration 15075, Loss: 0.053988873958587646\n",
      "Iteration 15076, Loss: 0.054171156138181686\n",
      "Iteration 15077, Loss: 0.053988806903362274\n",
      "Iteration 15078, Loss: 0.05417118966579437\n",
      "Iteration 15079, Loss: 0.053988806903362274\n",
      "Iteration 15080, Loss: 0.05417134612798691\n",
      "Iteration 15081, Loss: 0.05398876219987869\n",
      "Iteration 15082, Loss: 0.05417126417160034\n",
      "Iteration 15083, Loss: 0.05398891493678093\n",
      "Iteration 15084, Loss: 0.05417126417160034\n",
      "Iteration 15085, Loss: 0.05398895591497421\n",
      "Iteration 15086, Loss: 0.054171156138181686\n",
      "Iteration 15087, Loss: 0.05398895964026451\n",
      "Iteration 15088, Loss: 0.05417099595069885\n",
      "Iteration 15089, Loss: 0.05398903042078018\n",
      "Iteration 15090, Loss: 0.0541711151599884\n",
      "Iteration 15091, Loss: 0.05398883670568466\n",
      "Iteration 15092, Loss: 0.05417131632566452\n",
      "Iteration 15093, Loss: 0.05398872122168541\n",
      "Iteration 15094, Loss: 0.054171349853277206\n",
      "Iteration 15095, Loss: 0.05398872494697571\n",
      "Iteration 15096, Loss: 0.054171230643987656\n",
      "Iteration 15097, Loss: 0.05398891493678093\n",
      "Iteration 15098, Loss: 0.05417115241289139\n",
      "Iteration 15099, Loss: 0.053988926112651825\n",
      "Iteration 15100, Loss: 0.05417099595069885\n",
      "Iteration 15101, Loss: 0.05398907512426376\n",
      "Iteration 15102, Loss: 0.05417107790708542\n",
      "Iteration 15103, Loss: 0.05398895591497421\n",
      "Iteration 15104, Loss: 0.0541711151599884\n",
      "Iteration 15105, Loss: 0.05398883670568466\n",
      "Iteration 15106, Loss: 0.05417139455676079\n",
      "Iteration 15107, Loss: 0.05398864299058914\n",
      "Iteration 15108, Loss: 0.054171398282051086\n",
      "Iteration 15109, Loss: 0.05398844927549362\n",
      "Iteration 15110, Loss: 0.054171472787857056\n",
      "Iteration 15111, Loss: 0.053988561034202576\n",
      "Iteration 15112, Loss: 0.054171353578567505\n",
      "Iteration 15113, Loss: 0.05398872122168541\n",
      "Iteration 15114, Loss: 0.05417119711637497\n",
      "Iteration 15115, Loss: 0.053988926112651825\n",
      "Iteration 15116, Loss: 0.054170917719602585\n",
      "Iteration 15117, Loss: 0.05398907884955406\n",
      "Iteration 15118, Loss: 0.054170869290828705\n",
      "Iteration 15119, Loss: 0.0539892241358757\n",
      "Iteration 15120, Loss: 0.054170917719602585\n",
      "Iteration 15121, Loss: 0.05398911237716675\n",
      "Iteration 15122, Loss: 0.05417100340127945\n",
      "Iteration 15123, Loss: 0.05398884415626526\n",
      "Iteration 15124, Loss: 0.05417119711637497\n",
      "Iteration 15125, Loss: 0.05398883670568466\n",
      "Iteration 15126, Loss: 0.0541713610291481\n",
      "Iteration 15127, Loss: 0.05398859828710556\n",
      "Iteration 15128, Loss: 0.054171472787857056\n",
      "Iteration 15129, Loss: 0.053988367319107056\n",
      "Iteration 15130, Loss: 0.05417146906256676\n",
      "Iteration 15131, Loss: 0.05398867651820183\n",
      "Iteration 15132, Loss: 0.05417131632566452\n",
      "Iteration 15133, Loss: 0.05398884043097496\n",
      "Iteration 15134, Loss: 0.05417122691869736\n",
      "Iteration 15135, Loss: 0.05398891493678093\n",
      "Iteration 15136, Loss: 0.054171156138181686\n",
      "Iteration 15137, Loss: 0.0539889931678772\n",
      "Iteration 15138, Loss: 0.0541711151599884\n",
      "Iteration 15139, Loss: 0.05398895591497421\n",
      "Iteration 15140, Loss: 0.054171234369277954\n",
      "Iteration 15141, Loss: 0.053988873958587646\n",
      "Iteration 15142, Loss: 0.054171591997146606\n",
      "Iteration 15143, Loss: 0.053988367319107056\n",
      "Iteration 15144, Loss: 0.05417182296514511\n",
      "Iteration 15145, Loss: 0.05398828536272049\n",
      "Iteration 15146, Loss: 0.05417179316282272\n",
      "Iteration 15147, Loss: 0.05398816987872124\n",
      "Iteration 15148, Loss: 0.05417167395353317\n",
      "Iteration 15149, Loss: 0.05398833006620407\n",
      "Iteration 15150, Loss: 0.054171547293663025\n",
      "Iteration 15151, Loss: 0.05398852750658989\n",
      "Iteration 15152, Loss: 0.054171305149793625\n",
      "Iteration 15153, Loss: 0.053988806903362274\n",
      "Iteration 15154, Loss: 0.0541711151599884\n",
      "Iteration 15155, Loss: 0.05398910865187645\n",
      "Iteration 15156, Loss: 0.05417099595069885\n",
      "Iteration 15157, Loss: 0.05398907512426376\n",
      "Iteration 15158, Loss: 0.054171036928892136\n",
      "Iteration 15159, Loss: 0.05398895591497421\n",
      "Iteration 15160, Loss: 0.0541711151599884\n",
      "Iteration 15161, Loss: 0.05398891493678093\n",
      "Iteration 15162, Loss: 0.05417119711637497\n",
      "Iteration 15163, Loss: 0.05398883670568466\n",
      "Iteration 15164, Loss: 0.054171353578567505\n",
      "Iteration 15165, Loss: 0.05398864671587944\n",
      "Iteration 15166, Loss: 0.054171472787857056\n",
      "Iteration 15167, Loss: 0.05398859828710556\n",
      "Iteration 15168, Loss: 0.05417151376605034\n",
      "Iteration 15169, Loss: 0.053988486528396606\n",
      "Iteration 15170, Loss: 0.0541713647544384\n",
      "Iteration 15171, Loss: 0.053988561034202576\n",
      "Iteration 15172, Loss: 0.05417131632566452\n",
      "Iteration 15173, Loss: 0.05398864671587944\n",
      "Iteration 15174, Loss: 0.054171204566955566\n",
      "Iteration 15175, Loss: 0.05398872494697571\n",
      "Iteration 15176, Loss: 0.054171085357666016\n",
      "Iteration 15177, Loss: 0.053988732397556305\n",
      "Iteration 15178, Loss: 0.054171156138181686\n",
      "Iteration 15179, Loss: 0.053988873958587646\n",
      "Iteration 15180, Loss: 0.054171156138181686\n",
      "Iteration 15181, Loss: 0.05398879945278168\n",
      "Iteration 15182, Loss: 0.054171234369277954\n",
      "Iteration 15183, Loss: 0.05398876219987869\n",
      "Iteration 15184, Loss: 0.05417127534747124\n",
      "Iteration 15185, Loss: 0.05398865044116974\n",
      "Iteration 15186, Loss: 0.054171204566955566\n",
      "Iteration 15187, Loss: 0.05398861691355705\n",
      "Iteration 15188, Loss: 0.05417127534747124\n",
      "Iteration 15189, Loss: 0.05398872494697571\n",
      "Iteration 15190, Loss: 0.05417131632566452\n",
      "Iteration 15191, Loss: 0.053988829255104065\n",
      "Iteration 15192, Loss: 0.05417139455676079\n",
      "Iteration 15193, Loss: 0.05398856848478317\n",
      "Iteration 15194, Loss: 0.054171398282051086\n",
      "Iteration 15195, Loss: 0.05398852750658989\n",
      "Iteration 15196, Loss: 0.05417129024863243\n",
      "Iteration 15197, Loss: 0.053988486528396606\n",
      "Iteration 15198, Loss: 0.05417128652334213\n",
      "Iteration 15199, Loss: 0.05398856848478317\n",
      "Iteration 15200, Loss: 0.05417128652334213\n",
      "Iteration 15201, Loss: 0.05398860573768616\n",
      "Iteration 15202, Loss: 0.05417131632566452\n",
      "Iteration 15203, Loss: 0.05398860573768616\n",
      "Iteration 15204, Loss: 0.05417119711637497\n",
      "Iteration 15205, Loss: 0.05398876592516899\n",
      "Iteration 15206, Loss: 0.05417100712656975\n",
      "Iteration 15207, Loss: 0.05398940294981003\n",
      "Iteration 15208, Loss: 0.05417099595069885\n",
      "Iteration 15209, Loss: 0.05398944020271301\n",
      "Iteration 15210, Loss: 0.054171591997146606\n",
      "Iteration 15211, Loss: 0.05398932099342346\n",
      "Iteration 15212, Loss: 0.05417168140411377\n",
      "Iteration 15213, Loss: 0.053989242762327194\n",
      "Iteration 15214, Loss: 0.05417180061340332\n",
      "Iteration 15215, Loss: 0.053989045321941376\n",
      "Iteration 15216, Loss: 0.05417190492153168\n",
      "Iteration 15217, Loss: 0.05398908257484436\n",
      "Iteration 15218, Loss: 0.054171860218048096\n",
      "Iteration 15219, Loss: 0.05398912355303764\n",
      "Iteration 15220, Loss: 0.05417163297533989\n",
      "Iteration 15221, Loss: 0.05398928374052048\n",
      "Iteration 15222, Loss: 0.05417158827185631\n",
      "Iteration 15223, Loss: 0.05398936569690704\n",
      "Iteration 15224, Loss: 0.05417143926024437\n",
      "Iteration 15225, Loss: 0.053989555686712265\n",
      "Iteration 15226, Loss: 0.05417143926024437\n",
      "Iteration 15227, Loss: 0.05398944020271301\n",
      "Iteration 15228, Loss: 0.054171591997146606\n",
      "Iteration 15229, Loss: 0.05398932099342346\n",
      "Iteration 15230, Loss: 0.054171912372112274\n",
      "Iteration 15231, Loss: 0.05398909002542496\n",
      "Iteration 15232, Loss: 0.05417194962501526\n",
      "Iteration 15233, Loss: 0.05398889631032944\n",
      "Iteration 15234, Loss: 0.05417199060320854\n",
      "Iteration 15235, Loss: 0.05398892983794212\n",
      "Iteration 15236, Loss: 0.05417187139391899\n",
      "Iteration 15237, Loss: 0.053989045321941376\n",
      "Iteration 15238, Loss: 0.054171912372112274\n",
      "Iteration 15239, Loss: 0.05398908257484436\n",
      "Iteration 15240, Loss: 0.05417186766862869\n",
      "Iteration 15241, Loss: 0.05398912355303764\n",
      "Iteration 15242, Loss: 0.05417179316282272\n",
      "Iteration 15243, Loss: 0.053989164531230927\n",
      "Iteration 15244, Loss: 0.05417175218462944\n",
      "Iteration 15245, Loss: 0.05398927256464958\n",
      "Iteration 15246, Loss: 0.05417175218462944\n",
      "Iteration 15247, Loss: 0.053989164531230927\n",
      "Iteration 15248, Loss: 0.05417183041572571\n",
      "Iteration 15249, Loss: 0.05398919805884361\n",
      "Iteration 15250, Loss: 0.05417187139391899\n",
      "Iteration 15251, Loss: 0.05398900434374809\n",
      "Iteration 15252, Loss: 0.05417191982269287\n",
      "Iteration 15253, Loss: 0.053989045321941376\n",
      "Iteration 15254, Loss: 0.05417187139391899\n",
      "Iteration 15255, Loss: 0.05398908257484436\n",
      "Iteration 15256, Loss: 0.054171785712242126\n",
      "Iteration 15257, Loss: 0.053989164531230927\n",
      "Iteration 15258, Loss: 0.05417171120643616\n",
      "Iteration 15259, Loss: 0.053989164531230927\n",
      "Iteration 15260, Loss: 0.05417167395353317\n",
      "Iteration 15261, Loss: 0.05398932099342346\n",
      "Iteration 15262, Loss: 0.05417148023843765\n",
      "Iteration 15263, Loss: 0.053989436477422714\n",
      "Iteration 15264, Loss: 0.05417151376605034\n",
      "Iteration 15265, Loss: 0.05398944020271301\n",
      "Iteration 15266, Loss: 0.054171524941921234\n",
      "Iteration 15267, Loss: 0.05398940294981003\n",
      "Iteration 15268, Loss: 0.05417167767882347\n",
      "Iteration 15269, Loss: 0.05398928374052048\n",
      "Iteration 15270, Loss: 0.05417187139391899\n",
      "Iteration 15271, Loss: 0.05398900806903839\n",
      "Iteration 15272, Loss: 0.05417199060320854\n",
      "Iteration 15273, Loss: 0.05398908257484436\n",
      "Iteration 15274, Loss: 0.05417190492153168\n",
      "Iteration 15275, Loss: 0.05398908257484436\n",
      "Iteration 15276, Loss: 0.05417175218462944\n",
      "Iteration 15277, Loss: 0.05398927256464958\n",
      "Iteration 15278, Loss: 0.05417190492153168\n",
      "Iteration 15279, Loss: 0.05398927256464958\n",
      "Iteration 15280, Loss: 0.05417183041572571\n",
      "Iteration 15281, Loss: 0.05398912355303764\n",
      "Iteration 15282, Loss: 0.05417183041572571\n",
      "Iteration 15283, Loss: 0.05398912355303764\n",
      "Iteration 15284, Loss: 0.05417183041572571\n",
      "Iteration 15285, Loss: 0.05398912355303764\n",
      "Iteration 15286, Loss: 0.05417183041572571\n",
      "Iteration 15287, Loss: 0.053988974541425705\n",
      "Iteration 15288, Loss: 0.05417182669043541\n",
      "Iteration 15289, Loss: 0.05398912727832794\n",
      "Iteration 15290, Loss: 0.05417175218462944\n",
      "Iteration 15291, Loss: 0.053989242762327194\n",
      "Iteration 15292, Loss: 0.054171666502952576\n",
      "Iteration 15293, Loss: 0.05398944020271301\n",
      "Iteration 15294, Loss: 0.054171472787857056\n",
      "Iteration 15295, Loss: 0.05398940667510033\n",
      "Iteration 15296, Loss: 0.054171524941921234\n",
      "Iteration 15297, Loss: 0.053989432752132416\n",
      "Iteration 15298, Loss: 0.05417163297533989\n",
      "Iteration 15299, Loss: 0.05398927628993988\n",
      "Iteration 15300, Loss: 0.05417171120643616\n",
      "Iteration 15301, Loss: 0.05398908257484436\n",
      "Iteration 15302, Loss: 0.054171912372112274\n",
      "Iteration 15303, Loss: 0.053989045321941376\n",
      "Iteration 15304, Loss: 0.054171882569789886\n",
      "Iteration 15305, Loss: 0.053988970816135406\n",
      "Iteration 15306, Loss: 0.05417187139391899\n",
      "Iteration 15307, Loss: 0.05398912355303764\n",
      "Iteration 15308, Loss: 0.05417175218462944\n",
      "Iteration 15309, Loss: 0.05398920178413391\n",
      "Iteration 15310, Loss: 0.05417163297533989\n",
      "Iteration 15311, Loss: 0.05398928374052048\n",
      "Iteration 15312, Loss: 0.05417163297533989\n",
      "Iteration 15313, Loss: 0.05398928374052048\n",
      "Iteration 15314, Loss: 0.05417167395353317\n",
      "Iteration 15315, Loss: 0.05398932099342346\n",
      "Iteration 15316, Loss: 0.054171785712242126\n",
      "Iteration 15317, Loss: 0.05398920178413391\n",
      "Iteration 15318, Loss: 0.05417194589972496\n",
      "Iteration 15319, Loss: 0.05398841202259064\n",
      "Iteration 15320, Loss: 0.05417203903198242\n",
      "Iteration 15321, Loss: 0.053988099098205566\n",
      "Iteration 15322, Loss: 0.05417287349700928\n",
      "Iteration 15323, Loss: 0.05398782342672348\n",
      "Iteration 15324, Loss: 0.05417286604642868\n",
      "Iteration 15325, Loss: 0.05398798733949661\n",
      "Iteration 15326, Loss: 0.05417238920927048\n",
      "Iteration 15327, Loss: 0.05398868769407272\n",
      "Iteration 15328, Loss: 0.05417178198695183\n",
      "Iteration 15329, Loss: 0.053989242762327194\n",
      "Iteration 15330, Loss: 0.054171234369277954\n",
      "Iteration 15331, Loss: 0.05398960039019585\n",
      "Iteration 15332, Loss: 0.05417099595069885\n",
      "Iteration 15333, Loss: 0.053989868611097336\n",
      "Iteration 15334, Loss: 0.0541708879172802\n",
      "Iteration 15335, Loss: 0.05398993939161301\n",
      "Iteration 15336, Loss: 0.054171156138181686\n",
      "Iteration 15337, Loss: 0.053989630192518234\n",
      "Iteration 15338, Loss: 0.0541713647544384\n",
      "Iteration 15339, Loss: 0.053989313542842865\n",
      "Iteration 15340, Loss: 0.05417179316282272\n",
      "Iteration 15341, Loss: 0.053989119827747345\n",
      "Iteration 15342, Loss: 0.054171837866306305\n",
      "Iteration 15343, Loss: 0.05398895964026451\n",
      "Iteration 15344, Loss: 0.05417183041572571\n",
      "Iteration 15345, Loss: 0.053988926112651825\n",
      "Iteration 15346, Loss: 0.05417187511920929\n",
      "Iteration 15347, Loss: 0.05398893356323242\n",
      "Iteration 15348, Loss: 0.05417179316282272\n",
      "Iteration 15349, Loss: 0.05398909002542496\n",
      "Iteration 15350, Loss: 0.05417163670063019\n",
      "Iteration 15351, Loss: 0.053989164531230927\n",
      "Iteration 15352, Loss: 0.0541716031730175\n",
      "Iteration 15353, Loss: 0.05398912727832794\n",
      "Iteration 15354, Loss: 0.05417156219482422\n",
      "Iteration 15355, Loss: 0.05398920178413391\n",
      "Iteration 15356, Loss: 0.05417155474424362\n",
      "Iteration 15357, Loss: 0.053989242762327194\n",
      "Iteration 15358, Loss: 0.05417155474424362\n",
      "Iteration 15359, Loss: 0.05398928374052048\n",
      "Iteration 15360, Loss: 0.054171591997146606\n",
      "Iteration 15361, Loss: 0.053989432752132416\n",
      "Iteration 15362, Loss: 0.05417144298553467\n",
      "Iteration 15363, Loss: 0.05398939549922943\n",
      "Iteration 15364, Loss: 0.05417144298553467\n",
      "Iteration 15365, Loss: 0.053989242762327194\n",
      "Iteration 15366, Loss: 0.054171644151210785\n",
      "Iteration 15367, Loss: 0.05398926883935928\n",
      "Iteration 15368, Loss: 0.0541716031730175\n",
      "Iteration 15369, Loss: 0.05398915335536003\n",
      "Iteration 15370, Loss: 0.054171718657016754\n",
      "Iteration 15371, Loss: 0.053989164531230927\n",
      "Iteration 15372, Loss: 0.0541715994477272\n",
      "Iteration 15373, Loss: 0.05398912727832794\n",
      "Iteration 15374, Loss: 0.054171591997146606\n",
      "Iteration 15375, Loss: 0.053989093750715256\n",
      "Iteration 15376, Loss: 0.05417144298553467\n",
      "Iteration 15377, Loss: 0.05398928374052048\n",
      "Iteration 15378, Loss: 0.05417148023843765\n",
      "Iteration 15379, Loss: 0.053989242762327194\n",
      "Iteration 15380, Loss: 0.05417155474424362\n",
      "Iteration 15381, Loss: 0.05398935824632645\n",
      "Iteration 15382, Loss: 0.05417143553495407\n",
      "Iteration 15383, Loss: 0.053989361971616745\n",
      "Iteration 15384, Loss: 0.05417143553495407\n",
      "Iteration 15385, Loss: 0.0539894700050354\n",
      "Iteration 15386, Loss: 0.05417143926024437\n",
      "Iteration 15387, Loss: 0.05398935824632645\n",
      "Iteration 15388, Loss: 0.05417163297533989\n",
      "Iteration 15389, Loss: 0.05398935079574585\n",
      "Iteration 15390, Loss: 0.05417168140411377\n",
      "Iteration 15391, Loss: 0.053989045321941376\n",
      "Iteration 15392, Loss: 0.054171882569789886\n",
      "Iteration 15393, Loss: 0.05398895964026451\n",
      "Iteration 15394, Loss: 0.05417191982269287\n",
      "Iteration 15395, Loss: 0.053988806903362274\n",
      "Iteration 15396, Loss: 0.05417199060320854\n",
      "Iteration 15397, Loss: 0.05398896336555481\n",
      "Iteration 15398, Loss: 0.05417183041572571\n",
      "Iteration 15399, Loss: 0.05398912355303764\n",
      "Iteration 15400, Loss: 0.054171591997146606\n",
      "Iteration 15401, Loss: 0.05398928374052048\n",
      "Iteration 15402, Loss: 0.05417155474424362\n",
      "Iteration 15403, Loss: 0.053989242762327194\n",
      "Iteration 15404, Loss: 0.05417171120643616\n",
      "Iteration 15405, Loss: 0.05398920178413391\n",
      "Iteration 15406, Loss: 0.054171912372112274\n",
      "Iteration 15407, Loss: 0.05398900434374809\n",
      "Iteration 15408, Loss: 0.05417191609740257\n",
      "Iteration 15409, Loss: 0.05398888513445854\n",
      "Iteration 15410, Loss: 0.05417202413082123\n",
      "Iteration 15411, Loss: 0.053988926112651825\n",
      "Iteration 15412, Loss: 0.05417190119624138\n",
      "Iteration 15413, Loss: 0.053989045321941376\n",
      "Iteration 15414, Loss: 0.05417163297533989\n",
      "Iteration 15415, Loss: 0.053989242762327194\n",
      "Iteration 15416, Loss: 0.05417143926024437\n",
      "Iteration 15417, Loss: 0.053989242762327194\n",
      "Iteration 15418, Loss: 0.05417140573263168\n",
      "Iteration 15419, Loss: 0.05398935824632645\n",
      "Iteration 15420, Loss: 0.05417140573263168\n",
      "Iteration 15421, Loss: 0.05398931726813316\n",
      "Iteration 15422, Loss: 0.05417163297533989\n",
      "Iteration 15423, Loss: 0.05398915708065033\n",
      "Iteration 15424, Loss: 0.054171644151210785\n",
      "Iteration 15425, Loss: 0.05398915708065033\n",
      "Iteration 15426, Loss: 0.054171718657016754\n",
      "Iteration 15427, Loss: 0.05398930609226227\n",
      "Iteration 15428, Loss: 0.05417172238230705\n",
      "Iteration 15429, Loss: 0.05398912355303764\n",
      "Iteration 15430, Loss: 0.05417183041572571\n",
      "Iteration 15431, Loss: 0.05398907884955406\n",
      "Iteration 15432, Loss: 0.05417183041572571\n",
      "Iteration 15433, Loss: 0.053988970816135406\n",
      "Iteration 15434, Loss: 0.054171718657016754\n",
      "Iteration 15435, Loss: 0.05398908257484436\n",
      "Iteration 15436, Loss: 0.05417175218462944\n",
      "Iteration 15437, Loss: 0.05398920178413391\n",
      "Iteration 15438, Loss: 0.0541715994477272\n",
      "Iteration 15439, Loss: 0.053989239037036896\n",
      "Iteration 15440, Loss: 0.05417168140411377\n",
      "Iteration 15441, Loss: 0.053989164531230927\n",
      "Iteration 15442, Loss: 0.054171912372112274\n",
      "Iteration 15443, Loss: 0.05398903414607048\n",
      "Iteration 15444, Loss: 0.05417210981249809\n",
      "Iteration 15445, Loss: 0.05398888513445854\n",
      "Iteration 15446, Loss: 0.054171960800886154\n",
      "Iteration 15447, Loss: 0.053988806903362274\n",
      "Iteration 15448, Loss: 0.05417194589972496\n",
      "Iteration 15449, Loss: 0.05398896336555481\n",
      "Iteration 15450, Loss: 0.05417179688811302\n",
      "Iteration 15451, Loss: 0.053989164531230927\n",
      "Iteration 15452, Loss: 0.05417167767882347\n",
      "Iteration 15453, Loss: 0.05398908257484436\n",
      "Iteration 15454, Loss: 0.0541715994477272\n",
      "Iteration 15455, Loss: 0.05398912727832794\n",
      "Iteration 15456, Loss: 0.05417163297533989\n",
      "Iteration 15457, Loss: 0.05398920178413391\n",
      "Iteration 15458, Loss: 0.05417170748114586\n",
      "Iteration 15459, Loss: 0.05398912727832794\n",
      "Iteration 15460, Loss: 0.054171524941921234\n",
      "Iteration 15461, Loss: 0.05398917198181152\n",
      "Iteration 15462, Loss: 0.05417140573263168\n",
      "Iteration 15463, Loss: 0.05398920178413391\n",
      "Iteration 15464, Loss: 0.054171524941921234\n",
      "Iteration 15465, Loss: 0.053989164531230927\n",
      "Iteration 15466, Loss: 0.05417155846953392\n",
      "Iteration 15467, Loss: 0.05398919805884361\n",
      "Iteration 15468, Loss: 0.05417155474424362\n",
      "Iteration 15469, Loss: 0.05398928374052048\n",
      "Iteration 15470, Loss: 0.05417155474424362\n",
      "Iteration 15471, Loss: 0.05398932099342346\n",
      "Iteration 15472, Loss: 0.05417163297533989\n",
      "Iteration 15473, Loss: 0.053989242762327194\n",
      "Iteration 15474, Loss: 0.05417171120643616\n",
      "Iteration 15475, Loss: 0.053989194333553314\n",
      "Iteration 15476, Loss: 0.05417199060320854\n",
      "Iteration 15477, Loss: 0.053989000618457794\n",
      "Iteration 15478, Loss: 0.054172031581401825\n",
      "Iteration 15479, Loss: 0.05398884043097496\n",
      "Iteration 15480, Loss: 0.054171960800886154\n",
      "Iteration 15481, Loss: 0.05398884415626526\n",
      "Iteration 15482, Loss: 0.054171882569789886\n",
      "Iteration 15483, Loss: 0.05398889631032944\n",
      "Iteration 15484, Loss: 0.05417171120643616\n",
      "Iteration 15485, Loss: 0.053989049047231674\n",
      "Iteration 15486, Loss: 0.054171524941921234\n",
      "Iteration 15487, Loss: 0.053989242762327194\n",
      "Iteration 15488, Loss: 0.05417151376605034\n",
      "Iteration 15489, Loss: 0.05398935824632645\n",
      "Iteration 15490, Loss: 0.05417143553495407\n",
      "Iteration 15491, Loss: 0.05398924648761749\n",
      "Iteration 15492, Loss: 0.054171472787857056\n",
      "Iteration 15493, Loss: 0.05398944020271301\n",
      "Iteration 15494, Loss: 0.05417151376605034\n",
      "Iteration 15495, Loss: 0.053989313542842865\n",
      "Iteration 15496, Loss: 0.05417172238230705\n",
      "Iteration 15497, Loss: 0.05398915335536003\n",
      "Iteration 15498, Loss: 0.05417191609740257\n",
      "Iteration 15499, Loss: 0.053988926112651825\n",
      "Iteration 15500, Loss: 0.05417206883430481\n",
      "Iteration 15501, Loss: 0.05398888513445854\n",
      "Iteration 15502, Loss: 0.054172031581401825\n",
      "Iteration 15503, Loss: 0.05398896336555481\n",
      "Iteration 15504, Loss: 0.05417175218462944\n",
      "Iteration 15505, Loss: 0.053989045321941376\n",
      "Iteration 15506, Loss: 0.05417155474424362\n",
      "Iteration 15507, Loss: 0.053989242762327194\n",
      "Iteration 15508, Loss: 0.054171472787857056\n",
      "Iteration 15509, Loss: 0.05398939177393913\n",
      "Iteration 15510, Loss: 0.054171398282051086\n",
      "Iteration 15511, Loss: 0.05398935824632645\n",
      "Iteration 15512, Loss: 0.05417143553495407\n",
      "Iteration 15513, Loss: 0.05398940294981003\n",
      "Iteration 15514, Loss: 0.05417143926024437\n",
      "Iteration 15515, Loss: 0.053989432752132416\n",
      "Iteration 15516, Loss: 0.05417171120643616\n",
      "Iteration 15517, Loss: 0.05398927256464958\n",
      "Iteration 15518, Loss: 0.05417190492153168\n",
      "Iteration 15519, Loss: 0.05398911237716675\n",
      "Iteration 15520, Loss: 0.05417194962501526\n",
      "Iteration 15521, Loss: 0.053988926112651825\n",
      "Iteration 15522, Loss: 0.05417194962501526\n",
      "Iteration 15523, Loss: 0.05398888513445854\n",
      "Iteration 15524, Loss: 0.0541718415915966\n",
      "Iteration 15525, Loss: 0.05398900434374809\n",
      "Iteration 15526, Loss: 0.05417167395353317\n",
      "Iteration 15527, Loss: 0.05398920178413391\n",
      "Iteration 15528, Loss: 0.054171472787857056\n",
      "Iteration 15529, Loss: 0.05398940294981003\n",
      "Iteration 15530, Loss: 0.05417143553495407\n",
      "Iteration 15531, Loss: 0.05398944020271301\n",
      "Iteration 15532, Loss: 0.054171398282051086\n",
      "Iteration 15533, Loss: 0.053989477455616\n",
      "Iteration 15534, Loss: 0.0541713647544384\n",
      "Iteration 15535, Loss: 0.05398928374052048\n",
      "Iteration 15536, Loss: 0.05417178198695183\n",
      "Iteration 15537, Loss: 0.05398926883935928\n",
      "Iteration 15538, Loss: 0.05417187139391899\n",
      "Iteration 15539, Loss: 0.05398900434374809\n",
      "Iteration 15540, Loss: 0.05417199060320854\n",
      "Iteration 15541, Loss: 0.05398888140916824\n",
      "Iteration 15542, Loss: 0.05417191982269287\n",
      "Iteration 15543, Loss: 0.05398888885974884\n",
      "Iteration 15544, Loss: 0.05417194962501526\n",
      "Iteration 15545, Loss: 0.05398903787136078\n",
      "Iteration 15546, Loss: 0.05417167395353317\n",
      "Iteration 15547, Loss: 0.05398912727832794\n",
      "Iteration 15548, Loss: 0.05417167395353317\n",
      "Iteration 15549, Loss: 0.05398912727832794\n",
      "Iteration 15550, Loss: 0.054171644151210785\n",
      "Iteration 15551, Loss: 0.05398919805884361\n",
      "Iteration 15552, Loss: 0.05417171120643616\n",
      "Iteration 15553, Loss: 0.053989045321941376\n",
      "Iteration 15554, Loss: 0.05417167395353317\n",
      "Iteration 15555, Loss: 0.05398912355303764\n",
      "Iteration 15556, Loss: 0.05417171120643616\n",
      "Iteration 15557, Loss: 0.053989093750715256\n",
      "Iteration 15558, Loss: 0.05417151749134064\n",
      "Iteration 15559, Loss: 0.053989287465810776\n",
      "Iteration 15560, Loss: 0.05417148023843765\n",
      "Iteration 15561, Loss: 0.053989361971616745\n",
      "Iteration 15562, Loss: 0.05417144298553467\n",
      "Iteration 15563, Loss: 0.053989432752132416\n",
      "Iteration 15564, Loss: 0.05417148396372795\n",
      "Iteration 15565, Loss: 0.05398931726813316\n",
      "Iteration 15566, Loss: 0.05417168140411377\n",
      "Iteration 15567, Loss: 0.05398900434374809\n",
      "Iteration 15568, Loss: 0.054171960800886154\n",
      "Iteration 15569, Loss: 0.05398884043097496\n",
      "Iteration 15570, Loss: 0.05417211353778839\n",
      "Iteration 15571, Loss: 0.05398872494697571\n",
      "Iteration 15572, Loss: 0.054172150790691376\n",
      "Iteration 15573, Loss: 0.0539887361228466\n",
      "Iteration 15574, Loss: 0.05417194962501526\n",
      "Iteration 15575, Loss: 0.053988777101039886\n",
      "Iteration 15576, Loss: 0.054171741008758545\n",
      "Iteration 15577, Loss: 0.053989242762327194\n",
      "Iteration 15578, Loss: 0.05417128652334213\n",
      "Iteration 15579, Loss: 0.053989559412002563\n",
      "Iteration 15580, Loss: 0.054171234369277954\n",
      "Iteration 15581, Loss: 0.053989674896001816\n",
      "Iteration 15582, Loss: 0.05417128652334213\n",
      "Iteration 15583, Loss: 0.0539894700050354\n",
      "Iteration 15584, Loss: 0.05417145416140556\n",
      "Iteration 15585, Loss: 0.05398927256464958\n",
      "Iteration 15586, Loss: 0.05417191609740257\n",
      "Iteration 15587, Loss: 0.05398895591497421\n",
      "Iteration 15588, Loss: 0.05417200177907944\n",
      "Iteration 15589, Loss: 0.05398872494697571\n",
      "Iteration 15590, Loss: 0.05417223274707794\n",
      "Iteration 15591, Loss: 0.05398857593536377\n",
      "Iteration 15592, Loss: 0.054172031581401825\n",
      "Iteration 15593, Loss: 0.05398869514465332\n",
      "Iteration 15594, Loss: 0.05417175218462944\n",
      "Iteration 15595, Loss: 0.053989049047231674\n",
      "Iteration 15596, Loss: 0.05417155474424362\n",
      "Iteration 15597, Loss: 0.05398932844400406\n",
      "Iteration 15598, Loss: 0.0541713610291481\n",
      "Iteration 15599, Loss: 0.05398951470851898\n",
      "Iteration 15600, Loss: 0.0541713647544384\n",
      "Iteration 15601, Loss: 0.05398940294981003\n",
      "Iteration 15602, Loss: 0.054171591997146606\n",
      "Iteration 15603, Loss: 0.053989242762327194\n",
      "Iteration 15604, Loss: 0.05417175218462944\n",
      "Iteration 15605, Loss: 0.05398896336555481\n",
      "Iteration 15606, Loss: 0.05417187511920929\n",
      "Iteration 15607, Loss: 0.053988851606845856\n",
      "Iteration 15608, Loss: 0.05417187139391899\n",
      "Iteration 15609, Loss: 0.053989045321941376\n",
      "Iteration 15610, Loss: 0.05417167395353317\n",
      "Iteration 15611, Loss: 0.05398920178413391\n",
      "Iteration 15612, Loss: 0.05417144298553467\n",
      "Iteration 15613, Loss: 0.05398939549922943\n",
      "Iteration 15614, Loss: 0.0541713647544384\n",
      "Iteration 15615, Loss: 0.053989481180906296\n",
      "Iteration 15616, Loss: 0.05417132005095482\n",
      "Iteration 15617, Loss: 0.05398951470851898\n",
      "Iteration 15618, Loss: 0.05417132377624512\n",
      "Iteration 15619, Loss: 0.05398944020271301\n",
      "Iteration 15620, Loss: 0.05417140573263168\n",
      "Iteration 15621, Loss: 0.05398927628993988\n",
      "Iteration 15622, Loss: 0.05417144298553467\n",
      "Iteration 15623, Loss: 0.053989242762327194\n",
      "Iteration 15624, Loss: 0.05417179316282272\n",
      "Iteration 15625, Loss: 0.05398911237716675\n",
      "Iteration 15626, Loss: 0.054171912372112274\n",
      "Iteration 15627, Loss: 0.053988926112651825\n",
      "Iteration 15628, Loss: 0.05417187139391899\n",
      "Iteration 15629, Loss: 0.053988851606845856\n",
      "Iteration 15630, Loss: 0.05417183041572571\n",
      "Iteration 15631, Loss: 0.05398908257484436\n",
      "Iteration 15632, Loss: 0.05417163297533989\n",
      "Iteration 15633, Loss: 0.053989313542842865\n",
      "Iteration 15634, Loss: 0.05417143926024437\n",
      "Iteration 15635, Loss: 0.05398932099342346\n",
      "Iteration 15636, Loss: 0.05417143926024437\n",
      "Iteration 15637, Loss: 0.053989361971616745\n",
      "Iteration 15638, Loss: 0.05417148023843765\n",
      "Iteration 15639, Loss: 0.05398939177393913\n",
      "Iteration 15640, Loss: 0.05417148396372795\n",
      "Iteration 15641, Loss: 0.05398920178413391\n",
      "Iteration 15642, Loss: 0.0541716031730175\n",
      "Iteration 15643, Loss: 0.053989261388778687\n",
      "Iteration 15644, Loss: 0.05417171120643616\n",
      "Iteration 15645, Loss: 0.053989164531230927\n",
      "Iteration 15646, Loss: 0.05417171120643616\n",
      "Iteration 15647, Loss: 0.05398912355303764\n",
      "Iteration 15648, Loss: 0.05417167395353317\n",
      "Iteration 15649, Loss: 0.053989164531230927\n",
      "Iteration 15650, Loss: 0.054171524941921234\n",
      "Iteration 15651, Loss: 0.05398912727832794\n",
      "Iteration 15652, Loss: 0.054171644151210785\n",
      "Iteration 15653, Loss: 0.0539892315864563\n",
      "Iteration 15654, Loss: 0.05417167395353317\n",
      "Iteration 15655, Loss: 0.053989164531230927\n",
      "Iteration 15656, Loss: 0.054171837866306305\n",
      "Iteration 15657, Loss: 0.05398903787136078\n",
      "Iteration 15658, Loss: 0.05417206883430481\n",
      "Iteration 15659, Loss: 0.05398884415626526\n",
      "Iteration 15660, Loss: 0.054172150790691376\n",
      "Iteration 15661, Loss: 0.053988657891750336\n",
      "Iteration 15662, Loss: 0.05417202413082123\n",
      "Iteration 15663, Loss: 0.05398881435394287\n",
      "Iteration 15664, Loss: 0.05417179316282272\n",
      "Iteration 15665, Loss: 0.05398908257484436\n",
      "Iteration 15666, Loss: 0.05417156219482422\n",
      "Iteration 15667, Loss: 0.05398928374052048\n",
      "Iteration 15668, Loss: 0.05417155474424362\n",
      "Iteration 15669, Loss: 0.05398928374052048\n",
      "Iteration 15670, Loss: 0.05417151749134064\n",
      "Iteration 15671, Loss: 0.05398931726813316\n",
      "Iteration 15672, Loss: 0.05417151749134064\n",
      "Iteration 15673, Loss: 0.05398928374052048\n",
      "Iteration 15674, Loss: 0.05417144298553467\n",
      "Iteration 15675, Loss: 0.05398920178413391\n",
      "Iteration 15676, Loss: 0.05417151749134064\n",
      "Iteration 15677, Loss: 0.05398928374052048\n",
      "Iteration 15678, Loss: 0.05417151749134064\n",
      "Iteration 15679, Loss: 0.05398920178413391\n",
      "Iteration 15680, Loss: 0.054171591997146606\n",
      "Iteration 15681, Loss: 0.05398912355303764\n",
      "Iteration 15682, Loss: 0.05417156219482422\n",
      "Iteration 15683, Loss: 0.05398920178413391\n",
      "Iteration 15684, Loss: 0.054171472787857056\n",
      "Iteration 15685, Loss: 0.053989361971616745\n",
      "Iteration 15686, Loss: 0.05417140573263168\n",
      "Iteration 15687, Loss: 0.053989432752132416\n",
      "Iteration 15688, Loss: 0.054171591997146606\n",
      "Iteration 15689, Loss: 0.05398927628993988\n",
      "Iteration 15690, Loss: 0.05417167767882347\n",
      "Iteration 15691, Loss: 0.05398915335536003\n",
      "Iteration 15692, Loss: 0.05417187139391899\n",
      "Iteration 15693, Loss: 0.05398900434374809\n",
      "Iteration 15694, Loss: 0.0541718415915966\n",
      "Iteration 15695, Loss: 0.05398892983794212\n",
      "Iteration 15696, Loss: 0.05417179316282272\n",
      "Iteration 15697, Loss: 0.053989045321941376\n",
      "Iteration 15698, Loss: 0.05417167395353317\n",
      "Iteration 15699, Loss: 0.053989164531230927\n",
      "Iteration 15700, Loss: 0.05417148396372795\n",
      "Iteration 15701, Loss: 0.053989361971616745\n",
      "Iteration 15702, Loss: 0.05417140573263168\n",
      "Iteration 15703, Loss: 0.0539894700050354\n",
      "Iteration 15704, Loss: 0.05417144298553467\n",
      "Iteration 15705, Loss: 0.05398939177393913\n",
      "Iteration 15706, Loss: 0.054171524941921234\n",
      "Iteration 15707, Loss: 0.05398920178413391\n",
      "Iteration 15708, Loss: 0.054171644151210785\n",
      "Iteration 15709, Loss: 0.05398919805884361\n",
      "Iteration 15710, Loss: 0.05417172238230705\n",
      "Iteration 15711, Loss: 0.053989119827747345\n",
      "Iteration 15712, Loss: 0.054171763360500336\n",
      "Iteration 15713, Loss: 0.05398900434374809\n",
      "Iteration 15714, Loss: 0.05417194962501526\n",
      "Iteration 15715, Loss: 0.05398896336555481\n",
      "Iteration 15716, Loss: 0.05417194589972496\n",
      "Iteration 15717, Loss: 0.05398888885974884\n",
      "Iteration 15718, Loss: 0.05417187139391899\n",
      "Iteration 15719, Loss: 0.05398900434374809\n",
      "Iteration 15720, Loss: 0.05417167395353317\n",
      "Iteration 15721, Loss: 0.05398912355303764\n",
      "Iteration 15722, Loss: 0.05417151749134064\n",
      "Iteration 15723, Loss: 0.053989361971616745\n",
      "Iteration 15724, Loss: 0.05417148396372795\n",
      "Iteration 15725, Loss: 0.05398927628993988\n",
      "Iteration 15726, Loss: 0.0541716031730175\n",
      "Iteration 15727, Loss: 0.05398927256464958\n",
      "Iteration 15728, Loss: 0.054171644151210785\n",
      "Iteration 15729, Loss: 0.053989045321941376\n",
      "Iteration 15730, Loss: 0.05417172238230705\n",
      "Iteration 15731, Loss: 0.05398907884955406\n",
      "Iteration 15732, Loss: 0.05417172238230705\n",
      "Iteration 15733, Loss: 0.05398896336555481\n",
      "Iteration 15734, Loss: 0.05417171120643616\n",
      "Iteration 15735, Loss: 0.053989049047231674\n",
      "Iteration 15736, Loss: 0.05417175218462944\n",
      "Iteration 15737, Loss: 0.05398912355303764\n",
      "Iteration 15738, Loss: 0.0541715994477272\n",
      "Iteration 15739, Loss: 0.053989242762327194\n",
      "Iteration 15740, Loss: 0.05417144298553467\n",
      "Iteration 15741, Loss: 0.05398928374052048\n",
      "Iteration 15742, Loss: 0.05417148396372795\n",
      "Iteration 15743, Loss: 0.05398935824632645\n",
      "Iteration 15744, Loss: 0.05417167395353317\n",
      "Iteration 15745, Loss: 0.0539892315864563\n",
      "Iteration 15746, Loss: 0.05417175590991974\n",
      "Iteration 15747, Loss: 0.053989045321941376\n",
      "Iteration 15748, Loss: 0.05417194962501526\n",
      "Iteration 15749, Loss: 0.05398888885974884\n",
      "Iteration 15750, Loss: 0.05417206510901451\n",
      "Iteration 15751, Loss: 0.053988851606845856\n",
      "Iteration 15752, Loss: 0.054171957075595856\n",
      "Iteration 15753, Loss: 0.053988926112651825\n",
      "Iteration 15754, Loss: 0.05417167395353317\n",
      "Iteration 15755, Loss: 0.053989164531230927\n",
      "Iteration 15756, Loss: 0.05417163297533989\n",
      "Iteration 15757, Loss: 0.05398920178413391\n",
      "Iteration 15758, Loss: 0.05417155846953392\n",
      "Iteration 15759, Loss: 0.053989168256521225\n",
      "Iteration 15760, Loss: 0.0541716031730175\n",
      "Iteration 15761, Loss: 0.0539892315864563\n",
      "Iteration 15762, Loss: 0.05417171120643616\n",
      "Iteration 15763, Loss: 0.053989045321941376\n",
      "Iteration 15764, Loss: 0.05417175590991974\n",
      "Iteration 15765, Loss: 0.05398900434374809\n",
      "Iteration 15766, Loss: 0.05417179688811302\n",
      "Iteration 15767, Loss: 0.05398900434374809\n",
      "Iteration 15768, Loss: 0.05417187139391899\n",
      "Iteration 15769, Loss: 0.05398901551961899\n",
      "Iteration 15770, Loss: 0.054171666502952576\n",
      "Iteration 15771, Loss: 0.05398927628993988\n",
      "Iteration 15772, Loss: 0.054171398282051086\n",
      "Iteration 15773, Loss: 0.05398939549922943\n",
      "Iteration 15774, Loss: 0.054171353578567505\n",
      "Iteration 15775, Loss: 0.053989481180906296\n",
      "Iteration 15776, Loss: 0.054171472787857056\n",
      "Iteration 15777, Loss: 0.053989361971616745\n",
      "Iteration 15778, Loss: 0.054171644151210785\n",
      "Iteration 15779, Loss: 0.05398911237716675\n",
      "Iteration 15780, Loss: 0.0541718415915966\n",
      "Iteration 15781, Loss: 0.05398895591497421\n",
      "Iteration 15782, Loss: 0.05417203903198242\n",
      "Iteration 15783, Loss: 0.0539887361228466\n",
      "Iteration 15784, Loss: 0.05417199432849884\n",
      "Iteration 15785, Loss: 0.05398888513445854\n",
      "Iteration 15786, Loss: 0.05417179316282272\n",
      "Iteration 15787, Loss: 0.05398908257484436\n",
      "Iteration 15788, Loss: 0.054171718657016754\n",
      "Iteration 15789, Loss: 0.053989168256521225\n",
      "Iteration 15790, Loss: 0.05417163297533989\n",
      "Iteration 15791, Loss: 0.05398920178413391\n",
      "Iteration 15792, Loss: 0.05417167395353317\n",
      "Iteration 15793, Loss: 0.053989164531230927\n",
      "Iteration 15794, Loss: 0.05417168140411377\n",
      "Iteration 15795, Loss: 0.05398908257484436\n",
      "Iteration 15796, Loss: 0.05417172238230705\n",
      "Iteration 15797, Loss: 0.053989045321941376\n",
      "Iteration 15798, Loss: 0.05417180061340332\n",
      "Iteration 15799, Loss: 0.05398896336555481\n",
      "Iteration 15800, Loss: 0.05417187139391899\n",
      "Iteration 15801, Loss: 0.053989045321941376\n",
      "Iteration 15802, Loss: 0.05417183041572571\n",
      "Iteration 15803, Loss: 0.053989045321941376\n",
      "Iteration 15804, Loss: 0.05417175218462944\n",
      "Iteration 15805, Loss: 0.053989045321941376\n",
      "Iteration 15806, Loss: 0.05417163297533989\n",
      "Iteration 15807, Loss: 0.05398912727832794\n",
      "Iteration 15808, Loss: 0.05417148023843765\n",
      "Iteration 15809, Loss: 0.053989361971616745\n",
      "Iteration 15810, Loss: 0.0541713647544384\n",
      "Iteration 15811, Loss: 0.05398940294981003\n",
      "Iteration 15812, Loss: 0.05417144298553467\n",
      "Iteration 15813, Loss: 0.05398927628993988\n",
      "Iteration 15814, Loss: 0.05417155474424362\n",
      "Iteration 15815, Loss: 0.05398930609226227\n",
      "Iteration 15816, Loss: 0.05417168140411377\n",
      "Iteration 15817, Loss: 0.053989045321941376\n",
      "Iteration 15818, Loss: 0.054171837866306305\n",
      "Iteration 15819, Loss: 0.05398888885974884\n",
      "Iteration 15820, Loss: 0.05417179316282272\n",
      "Iteration 15821, Loss: 0.053989045321941376\n",
      "Iteration 15822, Loss: 0.05417171120643616\n",
      "Iteration 15823, Loss: 0.053989168256521225\n",
      "Iteration 15824, Loss: 0.05417155846953392\n",
      "Iteration 15825, Loss: 0.053989242762327194\n",
      "Iteration 15826, Loss: 0.05417148023843765\n",
      "Iteration 15827, Loss: 0.05398940294981003\n",
      "Iteration 15828, Loss: 0.05417151376605034\n",
      "Iteration 15829, Loss: 0.05398944020271301\n",
      "Iteration 15830, Loss: 0.0541713647544384\n",
      "Iteration 15831, Loss: 0.053989436477422714\n",
      "Iteration 15832, Loss: 0.05417151376605034\n",
      "Iteration 15833, Loss: 0.05398935079574585\n",
      "Iteration 15834, Loss: 0.05417168140411377\n",
      "Iteration 15835, Loss: 0.05398903414607048\n",
      "Iteration 15836, Loss: 0.05417191982269287\n",
      "Iteration 15837, Loss: 0.05398884043097496\n",
      "Iteration 15838, Loss: 0.05417206883430481\n",
      "Iteration 15839, Loss: 0.053988806903362274\n",
      "Iteration 15840, Loss: 0.05417194962501526\n",
      "Iteration 15841, Loss: 0.05398881435394287\n",
      "Iteration 15842, Loss: 0.05417168140411377\n",
      "Iteration 15843, Loss: 0.05398908257484436\n",
      "Iteration 15844, Loss: 0.0541716031730175\n",
      "Iteration 15845, Loss: 0.05398920178413391\n",
      "Iteration 15846, Loss: 0.054171591997146606\n",
      "Iteration 15847, Loss: 0.05398928374052048\n",
      "Iteration 15848, Loss: 0.05417151749134064\n",
      "Iteration 15849, Loss: 0.05398932099342346\n",
      "Iteration 15850, Loss: 0.054171524941921234\n",
      "Iteration 15851, Loss: 0.05398927628993988\n",
      "Iteration 15852, Loss: 0.0541716031730175\n",
      "Iteration 15853, Loss: 0.05398912355303764\n",
      "Iteration 15854, Loss: 0.054171837866306305\n",
      "Iteration 15855, Loss: 0.05398896336555481\n",
      "Iteration 15856, Loss: 0.05417187139391899\n",
      "Iteration 15857, Loss: 0.05398888885974884\n",
      "Iteration 15858, Loss: 0.05417175590991974\n",
      "Iteration 15859, Loss: 0.053988974541425705\n",
      "Iteration 15860, Loss: 0.05417163297533989\n",
      "Iteration 15861, Loss: 0.053989242762327194\n",
      "Iteration 15862, Loss: 0.05417148396372795\n",
      "Iteration 15863, Loss: 0.053989361971616745\n",
      "Iteration 15864, Loss: 0.05417140573263168\n",
      "Iteration 15865, Loss: 0.053989436477422714\n",
      "Iteration 15866, Loss: 0.05417144298553467\n",
      "Iteration 15867, Loss: 0.053989313542842865\n",
      "Iteration 15868, Loss: 0.05417156219482422\n",
      "Iteration 15869, Loss: 0.053989119827747345\n",
      "Iteration 15870, Loss: 0.05417194962501526\n",
      "Iteration 15871, Loss: 0.05398888513445854\n",
      "Iteration 15872, Loss: 0.054171912372112274\n",
      "Iteration 15873, Loss: 0.053988926112651825\n",
      "Iteration 15874, Loss: 0.05417175218462944\n",
      "Iteration 15875, Loss: 0.053989049047231674\n",
      "Iteration 15876, Loss: 0.05417148396372795\n",
      "Iteration 15877, Loss: 0.05398925393819809\n",
      "Iteration 15878, Loss: 0.05417124554514885\n",
      "Iteration 15879, Loss: 0.053989481180906296\n",
      "Iteration 15880, Loss: 0.054171137511730194\n",
      "Iteration 15881, Loss: 0.053989481180906296\n",
      "Iteration 15882, Loss: 0.0541713647544384\n",
      "Iteration 15883, Loss: 0.05398939177393913\n",
      "Iteration 15884, Loss: 0.05417148396372795\n",
      "Iteration 15885, Loss: 0.053989313542842865\n",
      "Iteration 15886, Loss: 0.0541716031730175\n",
      "Iteration 15887, Loss: 0.0539892315864563\n",
      "Iteration 15888, Loss: 0.05417172238230705\n",
      "Iteration 15889, Loss: 0.053989045321941376\n",
      "Iteration 15890, Loss: 0.05417187139391899\n",
      "Iteration 15891, Loss: 0.05398888885974884\n",
      "Iteration 15892, Loss: 0.05417183041572571\n",
      "Iteration 15893, Loss: 0.05398896336555481\n",
      "Iteration 15894, Loss: 0.05417155846953392\n",
      "Iteration 15895, Loss: 0.05398912355303764\n",
      "Iteration 15896, Loss: 0.05417140573263168\n",
      "Iteration 15897, Loss: 0.05398920178413391\n",
      "Iteration 15898, Loss: 0.05417121574282646\n",
      "Iteration 15899, Loss: 0.05398940294981003\n",
      "Iteration 15900, Loss: 0.05417132377624512\n",
      "Iteration 15901, Loss: 0.053989510983228683\n",
      "Iteration 15902, Loss: 0.05417144298553467\n",
      "Iteration 15903, Loss: 0.05398928374052048\n",
      "Iteration 15904, Loss: 0.05417172238230705\n",
      "Iteration 15905, Loss: 0.053989119827747345\n",
      "Iteration 15906, Loss: 0.054171882569789886\n",
      "Iteration 15907, Loss: 0.053988926112651825\n",
      "Iteration 15908, Loss: 0.05417180061340332\n",
      "Iteration 15909, Loss: 0.053988970816135406\n",
      "Iteration 15910, Loss: 0.05417180061340332\n",
      "Iteration 15911, Loss: 0.05398896336555481\n",
      "Iteration 15912, Loss: 0.05417179316282272\n",
      "Iteration 15913, Loss: 0.053989045321941376\n",
      "Iteration 15914, Loss: 0.05417179316282272\n",
      "Iteration 15915, Loss: 0.053989239037036896\n",
      "Iteration 15916, Loss: 0.05417163297533989\n",
      "Iteration 15917, Loss: 0.05398931726813316\n",
      "Iteration 15918, Loss: 0.054171524941921234\n",
      "Iteration 15919, Loss: 0.05398932099342346\n",
      "Iteration 15920, Loss: 0.05417148396372795\n",
      "Iteration 15921, Loss: 0.05398935079574585\n",
      "Iteration 15922, Loss: 0.05417148023843765\n",
      "Iteration 15923, Loss: 0.05398932099342346\n",
      "Iteration 15924, Loss: 0.05417140573263168\n",
      "Iteration 15925, Loss: 0.05398920178413391\n",
      "Iteration 15926, Loss: 0.05417151749134064\n",
      "Iteration 15927, Loss: 0.05398920178413391\n",
      "Iteration 15928, Loss: 0.0541716031730175\n",
      "Iteration 15929, Loss: 0.05398912355303764\n",
      "Iteration 15930, Loss: 0.05417171120643616\n",
      "Iteration 15931, Loss: 0.05398908257484436\n",
      "Iteration 15932, Loss: 0.05417179316282272\n",
      "Iteration 15933, Loss: 0.05398915708065033\n",
      "Iteration 15934, Loss: 0.054171912372112274\n",
      "Iteration 15935, Loss: 0.05398907512426376\n",
      "Iteration 15936, Loss: 0.054171912372112274\n",
      "Iteration 15937, Loss: 0.053989000618457794\n",
      "Iteration 15938, Loss: 0.05417180061340332\n",
      "Iteration 15939, Loss: 0.05398903787136078\n",
      "Iteration 15940, Loss: 0.05417179688811302\n",
      "Iteration 15941, Loss: 0.053989045321941376\n",
      "Iteration 15942, Loss: 0.05417183041572571\n",
      "Iteration 15943, Loss: 0.053989119827747345\n",
      "Iteration 15944, Loss: 0.05417155474424362\n",
      "Iteration 15945, Loss: 0.05398920178413391\n",
      "Iteration 15946, Loss: 0.05417144298553467\n",
      "Iteration 15947, Loss: 0.05398931726813316\n",
      "Iteration 15948, Loss: 0.05417148396372795\n",
      "Iteration 15949, Loss: 0.053989436477422714\n",
      "Iteration 15950, Loss: 0.05417148396372795\n",
      "Iteration 15951, Loss: 0.05398928374052048\n",
      "Iteration 15952, Loss: 0.05417167767882347\n",
      "Iteration 15953, Loss: 0.05398930609226227\n",
      "Iteration 15954, Loss: 0.05417172610759735\n",
      "Iteration 15955, Loss: 0.053988926112651825\n",
      "Iteration 15956, Loss: 0.054172031581401825\n",
      "Iteration 15957, Loss: 0.05398876965045929\n",
      "Iteration 15958, Loss: 0.05417180806398392\n",
      "Iteration 15959, Loss: 0.05398881062865257\n",
      "Iteration 15960, Loss: 0.054171763360500336\n",
      "Iteration 15961, Loss: 0.053988970816135406\n",
      "Iteration 15962, Loss: 0.054171591997146606\n",
      "Iteration 15963, Loss: 0.05398928374052048\n",
      "Iteration 15964, Loss: 0.054171472787857056\n",
      "Iteration 15965, Loss: 0.05398932099342346\n",
      "Iteration 15966, Loss: 0.05417124181985855\n",
      "Iteration 15967, Loss: 0.053989481180906296\n",
      "Iteration 15968, Loss: 0.054171279072761536\n",
      "Iteration 15969, Loss: 0.05398958921432495\n",
      "Iteration 15970, Loss: 0.05417143926024437\n",
      "Iteration 15971, Loss: 0.05398928374052048\n",
      "Iteration 15972, Loss: 0.05417175218462944\n",
      "Iteration 15973, Loss: 0.05398908257484436\n",
      "Iteration 15974, Loss: 0.05417180061340332\n",
      "Iteration 15975, Loss: 0.0539889931678772\n",
      "Iteration 15976, Loss: 0.05417210981249809\n",
      "Iteration 15977, Loss: 0.05398872494697571\n",
      "Iteration 15978, Loss: 0.054172031581401825\n",
      "Iteration 15979, Loss: 0.053988806903362274\n",
      "Iteration 15980, Loss: 0.054171912372112274\n",
      "Iteration 15981, Loss: 0.05398889631032944\n",
      "Iteration 15982, Loss: 0.054171591997146606\n",
      "Iteration 15983, Loss: 0.05398901551961899\n",
      "Iteration 15984, Loss: 0.05417151376605034\n",
      "Iteration 15985, Loss: 0.05398932099342346\n",
      "Iteration 15986, Loss: 0.05417124554514885\n",
      "Iteration 15987, Loss: 0.05398940294981003\n",
      "Iteration 15988, Loss: 0.05417128652334213\n",
      "Iteration 15989, Loss: 0.05398940294981003\n",
      "Iteration 15990, Loss: 0.05417140573263168\n",
      "Iteration 15991, Loss: 0.05398928374052048\n",
      "Iteration 15992, Loss: 0.054171591997146606\n",
      "Iteration 15993, Loss: 0.05398912355303764\n",
      "Iteration 15994, Loss: 0.054171718657016754\n",
      "Iteration 15995, Loss: 0.053989119827747345\n",
      "Iteration 15996, Loss: 0.05417175218462944\n",
      "Iteration 15997, Loss: 0.05398900434374809\n",
      "Iteration 15998, Loss: 0.05417179316282272\n",
      "Iteration 15999, Loss: 0.05398896336555481\n",
      "Iteration 16000, Loss: 0.054171763360500336\n",
      "Iteration 16001, Loss: 0.05398900434374809\n",
      "Iteration 16002, Loss: 0.05417163297533989\n",
      "Iteration 16003, Loss: 0.0539892315864563\n",
      "Iteration 16004, Loss: 0.05417140573263168\n",
      "Iteration 16005, Loss: 0.05398939549922943\n",
      "Iteration 16006, Loss: 0.05417148396372795\n",
      "Iteration 16007, Loss: 0.053989477455616\n",
      "Iteration 16008, Loss: 0.05417144298553467\n",
      "Iteration 16009, Loss: 0.053989242762327194\n",
      "Iteration 16010, Loss: 0.05417171120643616\n",
      "Iteration 16011, Loss: 0.053989045321941376\n",
      "Iteration 16012, Loss: 0.05417183041572571\n",
      "Iteration 16013, Loss: 0.053988926112651825\n",
      "Iteration 16014, Loss: 0.054171912372112274\n",
      "Iteration 16015, Loss: 0.053988851606845856\n",
      "Iteration 16016, Loss: 0.054171912372112274\n",
      "Iteration 16017, Loss: 0.05398889631032944\n",
      "Iteration 16018, Loss: 0.05417167395353317\n",
      "Iteration 16019, Loss: 0.05398928374052048\n",
      "Iteration 16020, Loss: 0.05417148023843765\n",
      "Iteration 16021, Loss: 0.053989287465810776\n",
      "Iteration 16022, Loss: 0.05417151376605034\n",
      "Iteration 16023, Loss: 0.053989477455616\n",
      "Iteration 16024, Loss: 0.05417151376605034\n",
      "Iteration 16025, Loss: 0.053989313542842865\n",
      "Iteration 16026, Loss: 0.05417168140411377\n",
      "Iteration 16027, Loss: 0.05398907512426376\n",
      "Iteration 16028, Loss: 0.054171767085790634\n",
      "Iteration 16029, Loss: 0.05398884043097496\n",
      "Iteration 16030, Loss: 0.054171882569789886\n",
      "Iteration 16031, Loss: 0.05398881062865257\n",
      "Iteration 16032, Loss: 0.054171837866306305\n",
      "Iteration 16033, Loss: 0.053989045321941376\n",
      "Iteration 16034, Loss: 0.05417183041572571\n",
      "Iteration 16035, Loss: 0.05398915708065033\n",
      "Iteration 16036, Loss: 0.05417163297533989\n",
      "Iteration 16037, Loss: 0.05398913472890854\n",
      "Iteration 16038, Loss: 0.054171591997146606\n",
      "Iteration 16039, Loss: 0.053989242762327194\n",
      "Iteration 16040, Loss: 0.05417148023843765\n",
      "Iteration 16041, Loss: 0.053989361971616745\n",
      "Iteration 16042, Loss: 0.054171524941921234\n",
      "Iteration 16043, Loss: 0.05398935824632645\n",
      "Iteration 16044, Loss: 0.05417163670063019\n",
      "Iteration 16045, Loss: 0.05398927256464958\n",
      "Iteration 16046, Loss: 0.054171763360500336\n",
      "Iteration 16047, Loss: 0.05398896336555481\n",
      "Iteration 16048, Loss: 0.0541718415915966\n",
      "Iteration 16049, Loss: 0.05398881435394287\n",
      "Iteration 16050, Loss: 0.054171912372112274\n",
      "Iteration 16051, Loss: 0.05398892983794212\n",
      "Iteration 16052, Loss: 0.05417163297533989\n",
      "Iteration 16053, Loss: 0.053989242762327194\n",
      "Iteration 16054, Loss: 0.05417151376605034\n",
      "Iteration 16055, Loss: 0.05398932099342346\n",
      "Iteration 16056, Loss: 0.05417140573263168\n",
      "Iteration 16057, Loss: 0.053989477455616\n",
      "Iteration 16058, Loss: 0.05417144298553467\n",
      "Iteration 16059, Loss: 0.05398931726813316\n",
      "Iteration 16060, Loss: 0.05417167767882347\n",
      "Iteration 16061, Loss: 0.053989239037036896\n",
      "Iteration 16062, Loss: 0.05417165160179138\n",
      "Iteration 16063, Loss: 0.05398896336555481\n",
      "Iteration 16064, Loss: 0.054171882569789886\n",
      "Iteration 16065, Loss: 0.05398869514465332\n",
      "Iteration 16066, Loss: 0.05417191982269287\n",
      "Iteration 16067, Loss: 0.053988851606845856\n",
      "Iteration 16068, Loss: 0.054171644151210785\n",
      "Iteration 16069, Loss: 0.05398901551961899\n",
      "Iteration 16070, Loss: 0.05417143553495407\n",
      "Iteration 16071, Loss: 0.05398924648761749\n",
      "Iteration 16072, Loss: 0.054171279072761536\n",
      "Iteration 16073, Loss: 0.05398940294981003\n",
      "Iteration 16074, Loss: 0.05417131632566452\n",
      "Iteration 16075, Loss: 0.05398952215909958\n",
      "Iteration 16076, Loss: 0.05417116731405258\n",
      "Iteration 16077, Loss: 0.05398952215909958\n",
      "Iteration 16078, Loss: 0.05417140573263168\n",
      "Iteration 16079, Loss: 0.053989361971616745\n",
      "Iteration 16080, Loss: 0.05417163297533989\n",
      "Iteration 16081, Loss: 0.05398928374052048\n",
      "Iteration 16082, Loss: 0.05417167395353317\n",
      "Iteration 16083, Loss: 0.05398912355303764\n",
      "Iteration 16084, Loss: 0.05417172238230705\n",
      "Iteration 16085, Loss: 0.053989555686712265\n",
      "Iteration 16086, Loss: 0.05417168140411377\n",
      "Iteration 16087, Loss: 0.053989559412002563\n",
      "Iteration 16088, Loss: 0.054172031581401825\n",
      "Iteration 16089, Loss: 0.0539897195994854\n",
      "Iteration 16090, Loss: 0.05417179688811302\n",
      "Iteration 16091, Loss: 0.05398990958929062\n",
      "Iteration 16092, Loss: 0.05417175218462944\n",
      "Iteration 16093, Loss: 0.05398987978696823\n",
      "Iteration 16094, Loss: 0.05417175590991974\n",
      "Iteration 16095, Loss: 0.053989917039871216\n",
      "Iteration 16096, Loss: 0.054171644151210785\n",
      "Iteration 16097, Loss: 0.05398987978696823\n",
      "Iteration 16098, Loss: 0.05417164787650108\n",
      "Iteration 16099, Loss: 0.0539899580180645\n",
      "Iteration 16100, Loss: 0.0541718415915966\n",
      "Iteration 16101, Loss: 0.05398982763290405\n",
      "Iteration 16102, Loss: 0.05417199432849884\n",
      "Iteration 16103, Loss: 0.05398957058787346\n",
      "Iteration 16104, Loss: 0.054172031581401825\n",
      "Iteration 16105, Loss: 0.05398964136838913\n",
      "Iteration 16106, Loss: 0.054172031581401825\n",
      "Iteration 16107, Loss: 0.05398964136838913\n",
      "Iteration 16108, Loss: 0.054171957075595856\n",
      "Iteration 16109, Loss: 0.0539897195994854\n",
      "Iteration 16110, Loss: 0.0541718415915966\n",
      "Iteration 16111, Loss: 0.0539897195994854\n",
      "Iteration 16112, Loss: 0.05417172238230705\n",
      "Iteration 16113, Loss: 0.053989917039871216\n",
      "Iteration 16114, Loss: 0.054171763360500336\n",
      "Iteration 16115, Loss: 0.05398983880877495\n",
      "Iteration 16116, Loss: 0.05417180061340332\n",
      "Iteration 16117, Loss: 0.053989872336387634\n",
      "Iteration 16118, Loss: 0.05417180061340332\n",
      "Iteration 16119, Loss: 0.053989797830581665\n",
      "Iteration 16120, Loss: 0.05417194589972496\n",
      "Iteration 16121, Loss: 0.053989723324775696\n",
      "Iteration 16122, Loss: 0.054171718657016754\n",
      "Iteration 16123, Loss: 0.05398984253406525\n",
      "Iteration 16124, Loss: 0.0541716031730175\n",
      "Iteration 16125, Loss: 0.05398992449045181\n",
      "Iteration 16126, Loss: 0.0541715994477272\n",
      "Iteration 16127, Loss: 0.05399014800786972\n",
      "Iteration 16128, Loss: 0.05417167767882347\n",
      "Iteration 16129, Loss: 0.05398998782038689\n",
      "Iteration 16130, Loss: 0.054171882569789886\n",
      "Iteration 16131, Loss: 0.053989749401807785\n",
      "Iteration 16132, Loss: 0.054172080010175705\n",
      "Iteration 16133, Loss: 0.053989481180906296\n",
      "Iteration 16134, Loss: 0.054172348231077194\n",
      "Iteration 16135, Loss: 0.05398940294981003\n",
      "Iteration 16136, Loss: 0.05417223274707794\n",
      "Iteration 16137, Loss: 0.05398936569690704\n",
      "Iteration 16138, Loss: 0.05417210981249809\n",
      "Iteration 16139, Loss: 0.053989678621292114\n",
      "Iteration 16140, Loss: 0.05417179316282272\n",
      "Iteration 16141, Loss: 0.053989991545677185\n",
      "Iteration 16142, Loss: 0.054171666502952576\n",
      "Iteration 16143, Loss: 0.05399011820554733\n",
      "Iteration 16144, Loss: 0.05417132377624512\n",
      "Iteration 16145, Loss: 0.05399022623896599\n",
      "Iteration 16146, Loss: 0.05417144298553467\n",
      "Iteration 16147, Loss: 0.053990259766578674\n",
      "Iteration 16148, Loss: 0.05417152866721153\n",
      "Iteration 16149, Loss: 0.0539899580180645\n",
      "Iteration 16150, Loss: 0.054171886295080185\n",
      "Iteration 16151, Loss: 0.053989674896001816\n",
      "Iteration 16152, Loss: 0.054172124713659286\n",
      "Iteration 16153, Loss: 0.05398940294981003\n",
      "Iteration 16154, Loss: 0.054172322154045105\n",
      "Iteration 16155, Loss: 0.05398920923471451\n",
      "Iteration 16156, Loss: 0.05417254567146301\n",
      "Iteration 16157, Loss: 0.05398917198181152\n",
      "Iteration 16158, Loss: 0.054172467440366745\n",
      "Iteration 16159, Loss: 0.05398917943239212\n",
      "Iteration 16160, Loss: 0.054172269999980927\n",
      "Iteration 16161, Loss: 0.05398937314748764\n",
      "Iteration 16162, Loss: 0.05417206883430481\n",
      "Iteration 16163, Loss: 0.053989678621292114\n",
      "Iteration 16164, Loss: 0.05417187511920929\n",
      "Iteration 16165, Loss: 0.05398976802825928\n",
      "Iteration 16166, Loss: 0.0541718415915966\n",
      "Iteration 16167, Loss: 0.053989917039871216\n",
      "Iteration 16168, Loss: 0.0541718415915966\n",
      "Iteration 16169, Loss: 0.053989872336387634\n",
      "Iteration 16170, Loss: 0.054171886295080185\n",
      "Iteration 16171, Loss: 0.0539897084236145\n",
      "Iteration 16172, Loss: 0.054172199219465256\n",
      "Iteration 16173, Loss: 0.0539894700050354\n",
      "Iteration 16174, Loss: 0.05417227745056152\n",
      "Iteration 16175, Loss: 0.05398920923471451\n",
      "Iteration 16176, Loss: 0.05417238920927048\n",
      "Iteration 16177, Loss: 0.053989216685295105\n",
      "Iteration 16178, Loss: 0.05417230725288391\n",
      "Iteration 16179, Loss: 0.05398944020271301\n",
      "Iteration 16180, Loss: 0.05417218804359436\n",
      "Iteration 16181, Loss: 0.053989484906196594\n",
      "Iteration 16182, Loss: 0.054172076284885406\n",
      "Iteration 16183, Loss: 0.05398960039019585\n",
      "Iteration 16184, Loss: 0.054172076284885406\n",
      "Iteration 16185, Loss: 0.05398960039019585\n",
      "Iteration 16186, Loss: 0.054172225296497345\n",
      "Iteration 16187, Loss: 0.053989559412002563\n",
      "Iteration 16188, Loss: 0.05417218804359436\n",
      "Iteration 16189, Loss: 0.053989481180906296\n",
      "Iteration 16190, Loss: 0.054172080010175705\n",
      "Iteration 16191, Loss: 0.05398960039019585\n",
      "Iteration 16192, Loss: 0.05417214334011078\n",
      "Iteration 16193, Loss: 0.053989604115486145\n",
      "Iteration 16194, Loss: 0.054171960800886154\n",
      "Iteration 16195, Loss: 0.053989678621292114\n",
      "Iteration 16196, Loss: 0.05417191982269287\n",
      "Iteration 16197, Loss: 0.053989630192518234\n",
      "Iteration 16198, Loss: 0.054171960800886154\n",
      "Iteration 16199, Loss: 0.053989559412002563\n",
      "Iteration 16200, Loss: 0.05417212098836899\n",
      "Iteration 16201, Loss: 0.05398964136838913\n",
      "Iteration 16202, Loss: 0.05417203530669212\n",
      "Iteration 16203, Loss: 0.05398960039019585\n",
      "Iteration 16204, Loss: 0.05417226254940033\n",
      "Iteration 16205, Loss: 0.053989481180906296\n",
      "Iteration 16206, Loss: 0.05417218804359436\n",
      "Iteration 16207, Loss: 0.053989484906196594\n",
      "Iteration 16208, Loss: 0.05417203530669212\n",
      "Iteration 16209, Loss: 0.053988873958587646\n",
      "Iteration 16210, Loss: 0.054172031581401825\n",
      "Iteration 16211, Loss: 0.0539889894425869\n",
      "Iteration 16212, Loss: 0.054171256721019745\n",
      "Iteration 16213, Loss: 0.05398918315768242\n",
      "Iteration 16214, Loss: 0.05417117476463318\n",
      "Iteration 16215, Loss: 0.053989291191101074\n",
      "Iteration 16216, Loss: 0.05417122691869736\n",
      "Iteration 16217, Loss: 0.053989097476005554\n",
      "Iteration 16218, Loss: 0.05417145788669586\n",
      "Iteration 16219, Loss: 0.05398893356323242\n",
      "Iteration 16220, Loss: 0.05417158454656601\n",
      "Iteration 16221, Loss: 0.05398870259523392\n",
      "Iteration 16222, Loss: 0.05417178198695183\n",
      "Iteration 16223, Loss: 0.053988467901945114\n",
      "Iteration 16224, Loss: 0.0541718564927578\n",
      "Iteration 16225, Loss: 0.05398862808942795\n",
      "Iteration 16226, Loss: 0.05417165160179138\n",
      "Iteration 16227, Loss: 0.05398878455162048\n",
      "Iteration 16228, Loss: 0.054171569645404816\n",
      "Iteration 16229, Loss: 0.05398934334516525\n",
      "Iteration 16230, Loss: 0.0541713684797287\n",
      "Iteration 16231, Loss: 0.05398968979716301\n",
      "Iteration 16232, Loss: 0.054170578718185425\n",
      "Iteration 16233, Loss: 0.05398985370993614\n",
      "Iteration 16234, Loss: 0.05417061969637871\n",
      "Iteration 16235, Loss: 0.05398981273174286\n",
      "Iteration 16236, Loss: 0.05417070537805557\n",
      "Iteration 16237, Loss: 0.05398964881896973\n",
      "Iteration 16238, Loss: 0.054171107709407806\n",
      "Iteration 16239, Loss: 0.053989216685295105\n",
      "Iteration 16240, Loss: 0.05417157709598541\n",
      "Iteration 16241, Loss: 0.05398885905742645\n",
      "Iteration 16242, Loss: 0.05417182669043541\n",
      "Iteration 16243, Loss: 0.053988467901945114\n",
      "Iteration 16244, Loss: 0.05417215824127197\n",
      "Iteration 16245, Loss: 0.053988393396139145\n",
      "Iteration 16246, Loss: 0.054171811789274216\n",
      "Iteration 16247, Loss: 0.053988635540008545\n",
      "Iteration 16248, Loss: 0.054171644151210785\n",
      "Iteration 16249, Loss: 0.05398894473910332\n",
      "Iteration 16250, Loss: 0.05417129024863243\n",
      "Iteration 16251, Loss: 0.05398929864168167\n",
      "Iteration 16252, Loss: 0.05417102575302124\n",
      "Iteration 16253, Loss: 0.05398945137858391\n",
      "Iteration 16254, Loss: 0.05417110025882721\n",
      "Iteration 16255, Loss: 0.05398949235677719\n",
      "Iteration 16256, Loss: 0.05417126044631004\n",
      "Iteration 16257, Loss: 0.05398925393819809\n",
      "Iteration 16258, Loss: 0.05417153239250183\n",
      "Iteration 16259, Loss: 0.05398910492658615\n",
      "Iteration 16260, Loss: 0.054171543568372726\n",
      "Iteration 16261, Loss: 0.0539887472987175\n",
      "Iteration 16262, Loss: 0.05417169630527496\n",
      "Iteration 16263, Loss: 0.053988706320524216\n",
      "Iteration 16264, Loss: 0.054171930998563766\n",
      "Iteration 16265, Loss: 0.05398862808942795\n",
      "Iteration 16266, Loss: 0.0541718453168869\n",
      "Iteration 16267, Loss: 0.053988635540008545\n",
      "Iteration 16268, Loss: 0.05417165160179138\n",
      "Iteration 16269, Loss: 0.053988903760910034\n",
      "Iteration 16270, Loss: 0.05417145416140556\n",
      "Iteration 16271, Loss: 0.05398917943239212\n",
      "Iteration 16272, Loss: 0.054171375930309296\n",
      "Iteration 16273, Loss: 0.053989212960004807\n",
      "Iteration 16274, Loss: 0.054171375930309296\n",
      "Iteration 16275, Loss: 0.053989097476005554\n",
      "Iteration 16276, Loss: 0.054171375930309296\n",
      "Iteration 16277, Loss: 0.053989022970199585\n",
      "Iteration 16278, Loss: 0.054171301424503326\n",
      "Iteration 16279, Loss: 0.05398910492658615\n",
      "Iteration 16280, Loss: 0.054171256721019745\n",
      "Iteration 16281, Loss: 0.05398930236697197\n",
      "Iteration 16282, Loss: 0.05417114496231079\n",
      "Iteration 16283, Loss: 0.05398933216929436\n",
      "Iteration 16284, Loss: 0.05417129397392273\n",
      "Iteration 16285, Loss: 0.053989097476005554\n",
      "Iteration 16286, Loss: 0.054171450436115265\n",
      "Iteration 16287, Loss: 0.05398906022310257\n",
      "Iteration 16288, Loss: 0.054171375930309296\n",
      "Iteration 16289, Loss: 0.05398910492658615\n",
      "Iteration 16290, Loss: 0.05417152866721153\n",
      "Iteration 16291, Loss: 0.053989093750715256\n",
      "Iteration 16292, Loss: 0.0541716143488884\n",
      "Iteration 16293, Loss: 0.05398886650800705\n",
      "Iteration 16294, Loss: 0.054171688854694366\n",
      "Iteration 16295, Loss: 0.05398879200220108\n",
      "Iteration 16296, Loss: 0.05417168140411377\n",
      "Iteration 16297, Loss: 0.053988903760910034\n",
      "Iteration 16298, Loss: 0.054171569645404816\n",
      "Iteration 16299, Loss: 0.0539889857172966\n",
      "Iteration 16300, Loss: 0.05417145416140556\n",
      "Iteration 16301, Loss: 0.05398894473910332\n",
      "Iteration 16302, Loss: 0.054171569645404816\n",
      "Iteration 16303, Loss: 0.05398901551961899\n",
      "Iteration 16304, Loss: 0.05417153239250183\n",
      "Iteration 16305, Loss: 0.053988974541425705\n",
      "Iteration 16306, Loss: 0.05417168140411377\n",
      "Iteration 16307, Loss: 0.05398901551961899\n",
      "Iteration 16308, Loss: 0.05417165905237198\n",
      "Iteration 16309, Loss: 0.0539887472987175\n",
      "Iteration 16310, Loss: 0.0541718527674675\n",
      "Iteration 16311, Loss: 0.05398866534233093\n",
      "Iteration 16312, Loss: 0.05417203903198242\n",
      "Iteration 16313, Loss: 0.053988583385944366\n",
      "Iteration 16314, Loss: 0.05417192727327347\n",
      "Iteration 16315, Loss: 0.05398862808942795\n",
      "Iteration 16316, Loss: 0.054171763360500336\n",
      "Iteration 16317, Loss: 0.053988829255104065\n",
      "Iteration 16318, Loss: 0.0541715994477272\n",
      "Iteration 16319, Loss: 0.0539889931678772\n",
      "Iteration 16320, Loss: 0.054171450436115265\n",
      "Iteration 16321, Loss: 0.053989142179489136\n",
      "Iteration 16322, Loss: 0.05417129397392273\n",
      "Iteration 16323, Loss: 0.053989142179489136\n",
      "Iteration 16324, Loss: 0.054171331226825714\n",
      "Iteration 16325, Loss: 0.0539892241358757\n",
      "Iteration 16326, Loss: 0.05417133495211601\n",
      "Iteration 16327, Loss: 0.05398910492658615\n",
      "Iteration 16328, Loss: 0.054171573370695114\n",
      "Iteration 16329, Loss: 0.05398885905742645\n",
      "Iteration 16330, Loss: 0.054171763360500336\n",
      "Iteration 16331, Loss: 0.053988855332136154\n",
      "Iteration 16332, Loss: 0.05417180061340332\n",
      "Iteration 16333, Loss: 0.05398885905742645\n",
      "Iteration 16334, Loss: 0.05417168140411377\n",
      "Iteration 16335, Loss: 0.053989022970199585\n",
      "Iteration 16336, Loss: 0.05417133867740631\n",
      "Iteration 16337, Loss: 0.05398913845419884\n",
      "Iteration 16338, Loss: 0.054171375930309296\n",
      "Iteration 16339, Loss: 0.05398917943239212\n",
      "Iteration 16340, Loss: 0.05417133495211601\n",
      "Iteration 16341, Loss: 0.053989212960004807\n",
      "Iteration 16342, Loss: 0.05417145416140556\n",
      "Iteration 16343, Loss: 0.05398906394839287\n",
      "Iteration 16344, Loss: 0.054171495139598846\n",
      "Iteration 16345, Loss: 0.05398906394839287\n",
      "Iteration 16346, Loss: 0.0541716143488884\n",
      "Iteration 16347, Loss: 0.05398883670568466\n",
      "Iteration 16348, Loss: 0.05417173355817795\n",
      "Iteration 16349, Loss: 0.053988825529813766\n",
      "Iteration 16350, Loss: 0.05417165160179138\n",
      "Iteration 16351, Loss: 0.05398859828710556\n",
      "Iteration 16352, Loss: 0.05417153239250183\n",
      "Iteration 16353, Loss: 0.05398876219987869\n",
      "Iteration 16354, Loss: 0.05417145416140556\n",
      "Iteration 16355, Loss: 0.05398903042078018\n",
      "Iteration 16356, Loss: 0.054171375930309296\n",
      "Iteration 16357, Loss: 0.05398917943239212\n",
      "Iteration 16358, Loss: 0.05417141318321228\n",
      "Iteration 16359, Loss: 0.05398906394839287\n",
      "Iteration 16360, Loss: 0.054171495139598846\n",
      "Iteration 16361, Loss: 0.05398906394839287\n",
      "Iteration 16362, Loss: 0.054171573370695114\n",
      "Iteration 16363, Loss: 0.05398894473910332\n",
      "Iteration 16364, Loss: 0.05417165905237198\n",
      "Iteration 16365, Loss: 0.05398871749639511\n",
      "Iteration 16366, Loss: 0.05417166277766228\n",
      "Iteration 16367, Loss: 0.053988706320524216\n",
      "Iteration 16368, Loss: 0.05417177081108093\n",
      "Iteration 16369, Loss: 0.05398867651820183\n",
      "Iteration 16370, Loss: 0.0541716143488884\n",
      "Iteration 16371, Loss: 0.053988754749298096\n",
      "Iteration 16372, Loss: 0.05417153984308243\n",
      "Iteration 16373, Loss: 0.05398883670568466\n",
      "Iteration 16374, Loss: 0.054171305149793625\n",
      "Iteration 16375, Loss: 0.053988873958587646\n",
      "Iteration 16376, Loss: 0.05417133495211601\n",
      "Iteration 16377, Loss: 0.053989142179489136\n",
      "Iteration 16378, Loss: 0.054171375930309296\n",
      "Iteration 16379, Loss: 0.05398925393819809\n",
      "Iteration 16380, Loss: 0.054171450436115265\n",
      "Iteration 16381, Loss: 0.05398906394839287\n",
      "Iteration 16382, Loss: 0.05417153984308243\n",
      "Iteration 16383, Loss: 0.053988825529813766\n",
      "Iteration 16384, Loss: 0.054171621799468994\n",
      "Iteration 16385, Loss: 0.053988706320524216\n",
      "Iteration 16386, Loss: 0.054171811789274216\n",
      "Iteration 16387, Loss: 0.053988706320524216\n",
      "Iteration 16388, Loss: 0.054171767085790634\n",
      "Iteration 16389, Loss: 0.05398879572749138\n",
      "Iteration 16390, Loss: 0.05417153239250183\n",
      "Iteration 16391, Loss: 0.053988903760910034\n",
      "Iteration 16392, Loss: 0.054171305149793625\n",
      "Iteration 16393, Loss: 0.05398906394839287\n",
      "Iteration 16394, Loss: 0.054171305149793625\n",
      "Iteration 16395, Loss: 0.0539889931678772\n",
      "Iteration 16396, Loss: 0.05417134612798691\n",
      "Iteration 16397, Loss: 0.0539889857172966\n",
      "Iteration 16398, Loss: 0.054171424359083176\n",
      "Iteration 16399, Loss: 0.05398827791213989\n",
      "Iteration 16400, Loss: 0.054171573370695114\n",
      "Iteration 16401, Loss: 0.05398816615343094\n",
      "Iteration 16402, Loss: 0.05417099595069885\n",
      "Iteration 16403, Loss: 0.053987935185432434\n",
      "Iteration 16404, Loss: 0.054170962423086166\n",
      "Iteration 16405, Loss: 0.053988050669431686\n",
      "Iteration 16406, Loss: 0.05417102575302124\n",
      "Iteration 16407, Loss: 0.05398809164762497\n",
      "Iteration 16408, Loss: 0.054170869290828705\n",
      "Iteration 16409, Loss: 0.053988173604011536\n",
      "Iteration 16410, Loss: 0.05417071282863617\n",
      "Iteration 16411, Loss: 0.05398839712142944\n",
      "Iteration 16412, Loss: 0.05417056381702423\n",
      "Iteration 16413, Loss: 0.05398847907781601\n",
      "Iteration 16414, Loss: 0.05417067930102348\n",
      "Iteration 16415, Loss: 0.05398843437433243\n",
      "Iteration 16416, Loss: 0.05417075753211975\n",
      "Iteration 16417, Loss: 0.05398824065923691\n",
      "Iteration 16418, Loss: 0.054170917719602585\n",
      "Iteration 16419, Loss: 0.05398812144994736\n",
      "Iteration 16420, Loss: 0.0541708841919899\n",
      "Iteration 16421, Loss: 0.0539880096912384\n",
      "Iteration 16422, Loss: 0.054170917719602585\n",
      "Iteration 16423, Loss: 0.05398809164762497\n",
      "Iteration 16424, Loss: 0.054170917719602585\n",
      "Iteration 16425, Loss: 0.05398806184530258\n",
      "Iteration 16426, Loss: 0.05417083948850632\n",
      "Iteration 16427, Loss: 0.053988128900527954\n",
      "Iteration 16428, Loss: 0.05417083948850632\n",
      "Iteration 16429, Loss: 0.05398821085691452\n",
      "Iteration 16430, Loss: 0.05417076498270035\n",
      "Iteration 16431, Loss: 0.053988248109817505\n",
      "Iteration 16432, Loss: 0.05417075753211975\n",
      "Iteration 16433, Loss: 0.053988248109817505\n",
      "Iteration 16434, Loss: 0.054170798510313034\n",
      "Iteration 16435, Loss: 0.05398827791213989\n",
      "Iteration 16436, Loss: 0.054170917719602585\n",
      "Iteration 16437, Loss: 0.053988128900527954\n",
      "Iteration 16438, Loss: 0.05417106673121452\n",
      "Iteration 16439, Loss: 0.05398797243833542\n",
      "Iteration 16440, Loss: 0.0541711151599884\n",
      "Iteration 16441, Loss: 0.05398804694414139\n",
      "Iteration 16442, Loss: 0.05417102575302124\n",
      "Iteration 16443, Loss: 0.053988050669431686\n",
      "Iteration 16444, Loss: 0.054170917719602585\n",
      "Iteration 16445, Loss: 0.05398820340633392\n",
      "Iteration 16446, Loss: 0.054170720279216766\n",
      "Iteration 16447, Loss: 0.05398835986852646\n",
      "Iteration 16448, Loss: 0.054170530289411545\n",
      "Iteration 16449, Loss: 0.05398833006620407\n",
      "Iteration 16450, Loss: 0.05417075753211975\n",
      "Iteration 16451, Loss: 0.05398839712142944\n",
      "Iteration 16452, Loss: 0.05417082831263542\n",
      "Iteration 16453, Loss: 0.053988199681043625\n",
      "Iteration 16454, Loss: 0.05417083948850632\n",
      "Iteration 16455, Loss: 0.05398809164762497\n",
      "Iteration 16456, Loss: 0.05417095869779587\n",
      "Iteration 16457, Loss: 0.053988248109817505\n",
      "Iteration 16458, Loss: 0.05417075753211975\n",
      "Iteration 16459, Loss: 0.053988248109817505\n",
      "Iteration 16460, Loss: 0.05417075753211975\n",
      "Iteration 16461, Loss: 0.05398828908801079\n",
      "Iteration 16462, Loss: 0.05417075753211975\n",
      "Iteration 16463, Loss: 0.05398827791213989\n",
      "Iteration 16464, Loss: 0.05417083948850632\n",
      "Iteration 16465, Loss: 0.053988318890333176\n",
      "Iteration 16466, Loss: 0.054170873016119\n",
      "Iteration 16467, Loss: 0.053988199681043625\n",
      "Iteration 16468, Loss: 0.054170913994312286\n",
      "Iteration 16469, Loss: 0.05398816987872124\n",
      "Iteration 16470, Loss: 0.0541708767414093\n",
      "Iteration 16471, Loss: 0.05398816987872124\n",
      "Iteration 16472, Loss: 0.05417075753211975\n",
      "Iteration 16473, Loss: 0.053988318890333176\n",
      "Iteration 16474, Loss: 0.054170724004507065\n",
      "Iteration 16475, Loss: 0.053988248109817505\n",
      "Iteration 16476, Loss: 0.054170873016119\n",
      "Iteration 16477, Loss: 0.05398828908801079\n",
      "Iteration 16478, Loss: 0.054170720279216766\n",
      "Iteration 16479, Loss: 0.053988318890333176\n",
      "Iteration 16480, Loss: 0.054170604795217514\n",
      "Iteration 16481, Loss: 0.05398828908801079\n",
      "Iteration 16482, Loss: 0.0541706383228302\n",
      "Iteration 16483, Loss: 0.05398833006620407\n",
      "Iteration 16484, Loss: 0.054170530289411545\n",
      "Iteration 16485, Loss: 0.053988367319107056\n",
      "Iteration 16486, Loss: 0.0541706383228302\n",
      "Iteration 16487, Loss: 0.05398840829730034\n",
      "Iteration 16488, Loss: 0.05417067930102348\n",
      "Iteration 16489, Loss: 0.05398839712142944\n",
      "Iteration 16490, Loss: 0.054170720279216766\n",
      "Iteration 16491, Loss: 0.05398828908801079\n",
      "Iteration 16492, Loss: 0.054170794785022736\n",
      "Iteration 16493, Loss: 0.05398835986852646\n",
      "Iteration 16494, Loss: 0.05417067930102348\n",
      "Iteration 16495, Loss: 0.05398833006620407\n",
      "Iteration 16496, Loss: 0.05417075753211975\n",
      "Iteration 16497, Loss: 0.05398833006620407\n",
      "Iteration 16498, Loss: 0.05417075380682945\n",
      "Iteration 16499, Loss: 0.053988367319107056\n",
      "Iteration 16500, Loss: 0.05417076498270035\n",
      "Iteration 16501, Loss: 0.05398827791213989\n",
      "Iteration 16502, Loss: 0.054170913994312286\n",
      "Iteration 16503, Loss: 0.05398816615343094\n",
      "Iteration 16504, Loss: 0.05417095869779587\n",
      "Iteration 16505, Loss: 0.053988050669431686\n",
      "Iteration 16506, Loss: 0.054171036928892136\n",
      "Iteration 16507, Loss: 0.05398812144994736\n",
      "Iteration 16508, Loss: 0.054171040654182434\n",
      "Iteration 16509, Loss: 0.05398789048194885\n",
      "Iteration 16510, Loss: 0.05417106673121452\n",
      "Iteration 16511, Loss: 0.053988050669431686\n",
      "Iteration 16512, Loss: 0.05417090654373169\n",
      "Iteration 16513, Loss: 0.05398813635110855\n",
      "Iteration 16514, Loss: 0.054170601069927216\n",
      "Iteration 16515, Loss: 0.05398840829730034\n",
      "Iteration 16516, Loss: 0.05417051166296005\n",
      "Iteration 16517, Loss: 0.05398844927549362\n",
      "Iteration 16518, Loss: 0.05417044088244438\n",
      "Iteration 16519, Loss: 0.053988561034202576\n",
      "Iteration 16520, Loss: 0.05417048558592796\n",
      "Iteration 16521, Loss: 0.053988635540008545\n",
      "Iteration 16522, Loss: 0.05417067930102348\n",
      "Iteration 16523, Loss: 0.05398847907781601\n",
      "Iteration 16524, Loss: 0.05417075753211975\n",
      "Iteration 16525, Loss: 0.05398809164762497\n",
      "Iteration 16526, Loss: 0.05417107045650482\n",
      "Iteration 16527, Loss: 0.05398797243833542\n",
      "Iteration 16528, Loss: 0.054171156138181686\n",
      "Iteration 16529, Loss: 0.05398797243833542\n",
      "Iteration 16530, Loss: 0.05417107790708542\n",
      "Iteration 16531, Loss: 0.053987931460142136\n",
      "Iteration 16532, Loss: 0.05417103320360184\n",
      "Iteration 16533, Loss: 0.05398812144994736\n",
      "Iteration 16534, Loss: 0.05417083948850632\n",
      "Iteration 16535, Loss: 0.05398828908801079\n",
      "Iteration 16536, Loss: 0.05417066812515259\n",
      "Iteration 16537, Loss: 0.053988367319107056\n",
      "Iteration 16538, Loss: 0.05417056009173393\n",
      "Iteration 16539, Loss: 0.05398844927549362\n",
      "Iteration 16540, Loss: 0.054170601069927216\n",
      "Iteration 16541, Loss: 0.05398839712142944\n",
      "Iteration 16542, Loss: 0.05417075753211975\n",
      "Iteration 16543, Loss: 0.05398835986852646\n",
      "Iteration 16544, Loss: 0.05417095869779587\n",
      "Iteration 16545, Loss: 0.053988017141819\n",
      "Iteration 16546, Loss: 0.05417103320360184\n",
      "Iteration 16547, Loss: 0.053988050669431686\n",
      "Iteration 16548, Loss: 0.05417107790708542\n",
      "Iteration 16549, Loss: 0.05398797243833542\n",
      "Iteration 16550, Loss: 0.05417102575302124\n",
      "Iteration 16551, Loss: 0.053988125175237656\n",
      "Iteration 16552, Loss: 0.05417094752192497\n",
      "Iteration 16553, Loss: 0.05398824065923691\n",
      "Iteration 16554, Loss: 0.05417075753211975\n",
      "Iteration 16555, Loss: 0.0539882555603981\n",
      "Iteration 16556, Loss: 0.054170720279216766\n",
      "Iteration 16557, Loss: 0.0539882555603981\n",
      "Iteration 16558, Loss: 0.054170720279216766\n",
      "Iteration 16559, Loss: 0.053988318890333176\n",
      "Iteration 16560, Loss: 0.05417095124721527\n",
      "Iteration 16561, Loss: 0.053988199681043625\n",
      "Iteration 16562, Loss: 0.05417099595069885\n",
      "Iteration 16563, Loss: 0.05398808419704437\n",
      "Iteration 16564, Loss: 0.054170917719602585\n",
      "Iteration 16565, Loss: 0.05398821085691452\n",
      "Iteration 16566, Loss: 0.054170869290828705\n",
      "Iteration 16567, Loss: 0.053988248109817505\n",
      "Iteration 16568, Loss: 0.054170601069927216\n",
      "Iteration 16569, Loss: 0.05398833006620407\n",
      "Iteration 16570, Loss: 0.05417070910334587\n",
      "Iteration 16571, Loss: 0.05398848280310631\n",
      "Iteration 16572, Loss: 0.05417051911354065\n",
      "Iteration 16573, Loss: 0.05398855730891228\n",
      "Iteration 16574, Loss: 0.05417048931121826\n",
      "Iteration 16575, Loss: 0.053988512605428696\n",
      "Iteration 16576, Loss: 0.05417075753211975\n",
      "Iteration 16577, Loss: 0.053988318890333176\n",
      "Iteration 16578, Loss: 0.05417090654373169\n",
      "Iteration 16579, Loss: 0.05398808419704437\n",
      "Iteration 16580, Loss: 0.05417095124721527\n",
      "Iteration 16581, Loss: 0.05398809164762497\n",
      "Iteration 16582, Loss: 0.054170917719602585\n",
      "Iteration 16583, Loss: 0.053988128900527954\n",
      "Iteration 16584, Loss: 0.0541708767414093\n",
      "Iteration 16585, Loss: 0.05398827791213989\n",
      "Iteration 16586, Loss: 0.05417067930102348\n",
      "Iteration 16587, Loss: 0.053988438099622726\n",
      "Iteration 16588, Loss: 0.05417067930102348\n",
      "Iteration 16589, Loss: 0.053988367319107056\n",
      "Iteration 16590, Loss: 0.0541706383228302\n",
      "Iteration 16591, Loss: 0.053988389670848846\n",
      "Iteration 16592, Loss: 0.05417083948850632\n",
      "Iteration 16593, Loss: 0.053988199681043625\n",
      "Iteration 16594, Loss: 0.054170992225408554\n",
      "Iteration 16595, Loss: 0.05398808419704437\n",
      "Iteration 16596, Loss: 0.05417095869779587\n",
      "Iteration 16597, Loss: 0.0539880096912384\n",
      "Iteration 16598, Loss: 0.054171107709407806\n",
      "Iteration 16599, Loss: 0.05398797616362572\n",
      "Iteration 16600, Loss: 0.0541708767414093\n",
      "Iteration 16601, Loss: 0.05398808419704437\n",
      "Iteration 16602, Loss: 0.05417090654373169\n",
      "Iteration 16603, Loss: 0.053988248109817505\n",
      "Iteration 16604, Loss: 0.05417071282863617\n",
      "Iteration 16605, Loss: 0.053988322615623474\n",
      "Iteration 16606, Loss: 0.0541706383228302\n",
      "Iteration 16607, Loss: 0.053988438099622726\n",
      "Iteration 16608, Loss: 0.05417056009173393\n",
      "Iteration 16609, Loss: 0.05398855730891228\n",
      "Iteration 16610, Loss: 0.0541706383228302\n",
      "Iteration 16611, Loss: 0.05398839712142944\n",
      "Iteration 16612, Loss: 0.054170720279216766\n",
      "Iteration 16613, Loss: 0.05398835241794586\n",
      "Iteration 16614, Loss: 0.05417080223560333\n",
      "Iteration 16615, Loss: 0.05398816615343094\n",
      "Iteration 16616, Loss: 0.054170917719602585\n",
      "Iteration 16617, Loss: 0.05398808419704437\n",
      "Iteration 16618, Loss: 0.054170843213796616\n",
      "Iteration 16619, Loss: 0.05398815870285034\n",
      "Iteration 16620, Loss: 0.05417075753211975\n",
      "Iteration 16621, Loss: 0.05398828908801079\n",
      "Iteration 16622, Loss: 0.05417067930102348\n",
      "Iteration 16623, Loss: 0.05398839712142944\n",
      "Iteration 16624, Loss: 0.0541706383228302\n",
      "Iteration 16625, Loss: 0.053988367319107056\n",
      "Iteration 16626, Loss: 0.05417056009173393\n",
      "Iteration 16627, Loss: 0.053988516330718994\n",
      "Iteration 16628, Loss: 0.05417051911354065\n",
      "Iteration 16629, Loss: 0.05398852378129959\n",
      "Iteration 16630, Loss: 0.05417048931121826\n",
      "Iteration 16631, Loss: 0.053988512605428696\n",
      "Iteration 16632, Loss: 0.054170798510313034\n",
      "Iteration 16633, Loss: 0.053988322615623474\n",
      "Iteration 16634, Loss: 0.05417083948850632\n",
      "Iteration 16635, Loss: 0.05398812144994736\n",
      "Iteration 16636, Loss: 0.05417095124721527\n",
      "Iteration 16637, Loss: 0.053988050669431686\n",
      "Iteration 16638, Loss: 0.054170917719602585\n",
      "Iteration 16639, Loss: 0.0539880096912384\n",
      "Iteration 16640, Loss: 0.05417083948850632\n",
      "Iteration 16641, Loss: 0.05398824065923691\n",
      "Iteration 16642, Loss: 0.054170601069927216\n",
      "Iteration 16643, Loss: 0.053988438099622726\n",
      "Iteration 16644, Loss: 0.0541706383228302\n",
      "Iteration 16645, Loss: 0.053988441824913025\n",
      "Iteration 16646, Loss: 0.054170604795217514\n",
      "Iteration 16647, Loss: 0.05398843437433243\n",
      "Iteration 16648, Loss: 0.054170724004507065\n",
      "Iteration 16649, Loss: 0.05398821085691452\n",
      "Iteration 16650, Loss: 0.05417075753211975\n",
      "Iteration 16651, Loss: 0.05398828908801079\n",
      "Iteration 16652, Loss: 0.05417067930102348\n",
      "Iteration 16653, Loss: 0.05398828908801079\n",
      "Iteration 16654, Loss: 0.05417067930102348\n",
      "Iteration 16655, Loss: 0.0539882555603981\n",
      "Iteration 16656, Loss: 0.054170720279216766\n",
      "Iteration 16657, Loss: 0.053988367319107056\n",
      "Iteration 16658, Loss: 0.0541706383228302\n",
      "Iteration 16659, Loss: 0.05398835986852646\n",
      "Iteration 16660, Loss: 0.05417056381702423\n",
      "Iteration 16661, Loss: 0.053988441824913025\n",
      "Iteration 16662, Loss: 0.054170604795217514\n",
      "Iteration 16663, Loss: 0.05398833006620407\n",
      "Iteration 16664, Loss: 0.054170720279216766\n",
      "Iteration 16665, Loss: 0.05398828908801079\n",
      "Iteration 16666, Loss: 0.05417067930102348\n",
      "Iteration 16667, Loss: 0.05398833006620407\n",
      "Iteration 16668, Loss: 0.054170720279216766\n",
      "Iteration 16669, Loss: 0.05398833006620407\n",
      "Iteration 16670, Loss: 0.054170720279216766\n",
      "Iteration 16671, Loss: 0.05398828908801079\n",
      "Iteration 16672, Loss: 0.05417067930102348\n",
      "Iteration 16673, Loss: 0.05398828908801079\n",
      "Iteration 16674, Loss: 0.05417067930102348\n",
      "Iteration 16675, Loss: 0.05398828908801079\n",
      "Iteration 16676, Loss: 0.054170720279216766\n",
      "Iteration 16677, Loss: 0.053988248109817505\n",
      "Iteration 16678, Loss: 0.05417069047689438\n",
      "Iteration 16679, Loss: 0.053988248109817505\n",
      "Iteration 16680, Loss: 0.05417075753211975\n",
      "Iteration 16681, Loss: 0.05398821085691452\n",
      "Iteration 16682, Loss: 0.0541708767414093\n",
      "Iteration 16683, Loss: 0.053988050669431686\n",
      "Iteration 16684, Loss: 0.054170917719602585\n",
      "Iteration 16685, Loss: 0.053988125175237656\n",
      "Iteration 16686, Loss: 0.054170843213796616\n",
      "Iteration 16687, Loss: 0.05398809164762497\n",
      "Iteration 16688, Loss: 0.054170873016119\n",
      "Iteration 16689, Loss: 0.053988248109817505\n",
      "Iteration 16690, Loss: 0.05417071282863617\n",
      "Iteration 16691, Loss: 0.05398835986852646\n",
      "Iteration 16692, Loss: 0.0541706345975399\n",
      "Iteration 16693, Loss: 0.05398840457201004\n",
      "Iteration 16694, Loss: 0.05417056381702423\n",
      "Iteration 16695, Loss: 0.053988516330718994\n",
      "Iteration 16696, Loss: 0.054170601069927216\n",
      "Iteration 16697, Loss: 0.05398855358362198\n",
      "Iteration 16698, Loss: 0.05417067930102348\n",
      "Iteration 16699, Loss: 0.05398839712142944\n",
      "Iteration 16700, Loss: 0.054170649498701096\n",
      "Iteration 16701, Loss: 0.05398824065923691\n",
      "Iteration 16702, Loss: 0.0541708767414093\n",
      "Iteration 16703, Loss: 0.05398797243833542\n",
      "Iteration 16704, Loss: 0.0541711151599884\n",
      "Iteration 16705, Loss: 0.0539880096912384\n",
      "Iteration 16706, Loss: 0.05417099595069885\n",
      "Iteration 16707, Loss: 0.05398797616362572\n",
      "Iteration 16708, Loss: 0.05417095124721527\n",
      "Iteration 16709, Loss: 0.053988128900527954\n",
      "Iteration 16710, Loss: 0.054170750081539154\n",
      "Iteration 16711, Loss: 0.05398833006620407\n",
      "Iteration 16712, Loss: 0.0541706308722496\n",
      "Iteration 16713, Loss: 0.05398855730891228\n",
      "Iteration 16714, Loss: 0.054170481860637665\n",
      "Iteration 16715, Loss: 0.05398855730891228\n",
      "Iteration 16716, Loss: 0.054170720279216766\n",
      "Iteration 16717, Loss: 0.053988438099622726\n",
      "Iteration 16718, Loss: 0.054170798510313034\n",
      "Iteration 16719, Loss: 0.05398824065923691\n",
      "Iteration 16720, Loss: 0.054171040654182434\n",
      "Iteration 16721, Loss: 0.053988002240657806\n",
      "Iteration 16722, Loss: 0.054171156138181686\n",
      "Iteration 16723, Loss: 0.05398780107498169\n",
      "Iteration 16724, Loss: 0.05417119711637497\n",
      "Iteration 16725, Loss: 0.0539877787232399\n",
      "Iteration 16726, Loss: 0.054171156138181686\n",
      "Iteration 16727, Loss: 0.053987856954336166\n",
      "Iteration 16728, Loss: 0.054170917719602585\n",
      "Iteration 16729, Loss: 0.053988128900527954\n",
      "Iteration 16730, Loss: 0.0541706383228302\n",
      "Iteration 16731, Loss: 0.05398848280310631\n",
      "Iteration 16732, Loss: 0.054170362651348114\n",
      "Iteration 16733, Loss: 0.05398860573768616\n",
      "Iteration 16734, Loss: 0.054170407354831696\n",
      "Iteration 16735, Loss: 0.05398859828710556\n",
      "Iteration 16736, Loss: 0.05417078733444214\n",
      "Iteration 16737, Loss: 0.05398839712142944\n",
      "Iteration 16738, Loss: 0.054170798510313034\n",
      "Iteration 16739, Loss: 0.05398824065923691\n",
      "Iteration 16740, Loss: 0.054171107709407806\n",
      "Iteration 16741, Loss: 0.0539880096912384\n",
      "Iteration 16742, Loss: 0.05417126417160034\n",
      "Iteration 16743, Loss: 0.0539880096912384\n",
      "Iteration 16744, Loss: 0.05417107790708542\n",
      "Iteration 16745, Loss: 0.05398785322904587\n",
      "Iteration 16746, Loss: 0.05417092889547348\n",
      "Iteration 16747, Loss: 0.05398789793252945\n",
      "Iteration 16748, Loss: 0.054170873016119\n",
      "Iteration 16749, Loss: 0.05398821085691452\n",
      "Iteration 16750, Loss: 0.05417069047689438\n",
      "Iteration 16751, Loss: 0.05398828908801079\n",
      "Iteration 16752, Loss: 0.05417069047689438\n",
      "Iteration 16753, Loss: 0.053988248109817505\n",
      "Iteration 16754, Loss: 0.05417075753211975\n",
      "Iteration 16755, Loss: 0.05398820340633392\n",
      "Iteration 16756, Loss: 0.054170798510313034\n",
      "Iteration 16757, Loss: 0.05398821085691452\n",
      "Iteration 16758, Loss: 0.05417076498270035\n",
      "Iteration 16759, Loss: 0.05398821085691452\n",
      "Iteration 16760, Loss: 0.05417075753211975\n",
      "Iteration 16761, Loss: 0.05398872494697571\n",
      "Iteration 16762, Loss: 0.054170601069927216\n",
      "Iteration 16763, Loss: 0.053988806903362274\n",
      "Iteration 16764, Loss: 0.054170601069927216\n",
      "Iteration 16765, Loss: 0.05398888513445854\n",
      "Iteration 16766, Loss: 0.05417107790708542\n",
      "Iteration 16767, Loss: 0.05398896336555481\n",
      "Iteration 16768, Loss: 0.05417100340127945\n",
      "Iteration 16769, Loss: 0.05398889631032944\n",
      "Iteration 16770, Loss: 0.05417118966579437\n",
      "Iteration 16771, Loss: 0.05398884043097496\n",
      "Iteration 16772, Loss: 0.05417127162218094\n",
      "Iteration 16773, Loss: 0.053988754749298096\n",
      "Iteration 16774, Loss: 0.0541713647544384\n",
      "Iteration 16775, Loss: 0.05398871749639511\n",
      "Iteration 16776, Loss: 0.054171428084373474\n",
      "Iteration 16777, Loss: 0.05398852750658989\n",
      "Iteration 16778, Loss: 0.05417139455676079\n",
      "Iteration 16779, Loss: 0.05398860573768616\n",
      "Iteration 16780, Loss: 0.0541713610291481\n",
      "Iteration 16781, Loss: 0.05398864299058914\n",
      "Iteration 16782, Loss: 0.05417127534747124\n",
      "Iteration 16783, Loss: 0.05398868769407272\n",
      "Iteration 16784, Loss: 0.054171234369277954\n",
      "Iteration 16785, Loss: 0.053988806903362274\n",
      "Iteration 16786, Loss: 0.0541711151599884\n",
      "Iteration 16787, Loss: 0.05398888885974884\n",
      "Iteration 16788, Loss: 0.0541711151599884\n",
      "Iteration 16789, Loss: 0.05398872494697571\n",
      "Iteration 16790, Loss: 0.054171156138181686\n",
      "Iteration 16791, Loss: 0.05398872494697571\n",
      "Iteration 16792, Loss: 0.054171156138181686\n",
      "Iteration 16793, Loss: 0.05398872494697571\n",
      "Iteration 16794, Loss: 0.05417119711637497\n",
      "Iteration 16795, Loss: 0.053988806903362274\n",
      "Iteration 16796, Loss: 0.054171159863471985\n",
      "Iteration 16797, Loss: 0.05398876592516899\n",
      "Iteration 16798, Loss: 0.054171156138181686\n",
      "Iteration 16799, Loss: 0.053988806903362274\n",
      "Iteration 16800, Loss: 0.05417119711637497\n",
      "Iteration 16801, Loss: 0.053988806903362274\n",
      "Iteration 16802, Loss: 0.05417119711637497\n",
      "Iteration 16803, Loss: 0.05398876592516899\n",
      "Iteration 16804, Loss: 0.05417119711637497\n",
      "Iteration 16805, Loss: 0.053988806903362274\n",
      "Iteration 16806, Loss: 0.054171159863471985\n",
      "Iteration 16807, Loss: 0.053988806903362274\n",
      "Iteration 16808, Loss: 0.05417120084166527\n",
      "Iteration 16809, Loss: 0.053988806903362274\n",
      "Iteration 16810, Loss: 0.054171156138181686\n",
      "Iteration 16811, Loss: 0.05398876592516899\n",
      "Iteration 16812, Loss: 0.0541711151599884\n",
      "Iteration 16813, Loss: 0.053988851606845856\n",
      "Iteration 16814, Loss: 0.05417107790708542\n",
      "Iteration 16815, Loss: 0.05398888885974884\n",
      "Iteration 16816, Loss: 0.054170962423086166\n",
      "Iteration 16817, Loss: 0.05398900434374809\n",
      "Iteration 16818, Loss: 0.05417099595069885\n",
      "Iteration 16819, Loss: 0.05398907512426376\n",
      "Iteration 16820, Loss: 0.05417100712656975\n",
      "Iteration 16821, Loss: 0.05398884415626526\n",
      "Iteration 16822, Loss: 0.054171353578567505\n",
      "Iteration 16823, Loss: 0.05398864671587944\n",
      "Iteration 16824, Loss: 0.05417155474424362\n",
      "Iteration 16825, Loss: 0.05398852378129959\n",
      "Iteration 16826, Loss: 0.05417182296514511\n",
      "Iteration 16827, Loss: 0.053988367319107056\n",
      "Iteration 16828, Loss: 0.05417167395353317\n",
      "Iteration 16829, Loss: 0.05398840829730034\n",
      "Iteration 16830, Loss: 0.05417151376605034\n",
      "Iteration 16831, Loss: 0.05398844927549362\n",
      "Iteration 16832, Loss: 0.05417132005095482\n",
      "Iteration 16833, Loss: 0.05398868769407272\n",
      "Iteration 16834, Loss: 0.05417124181985855\n",
      "Iteration 16835, Loss: 0.05398876592516899\n",
      "Iteration 16836, Loss: 0.054171156138181686\n",
      "Iteration 16837, Loss: 0.05398884415626526\n",
      "Iteration 16838, Loss: 0.05417108163237572\n",
      "Iteration 16839, Loss: 0.05398891493678093\n",
      "Iteration 16840, Loss: 0.05417127162218094\n",
      "Iteration 16841, Loss: 0.05398876219987869\n",
      "Iteration 16842, Loss: 0.054171424359083176\n",
      "Iteration 16843, Loss: 0.05398864299058914\n",
      "Iteration 16844, Loss: 0.05417146906256676\n",
      "Iteration 16845, Loss: 0.05398856848478317\n",
      "Iteration 16846, Loss: 0.05417151004076004\n",
      "Iteration 16847, Loss: 0.05398853123188019\n",
      "Iteration 16848, Loss: 0.054171353578567505\n",
      "Iteration 16849, Loss: 0.05398856848478317\n",
      "Iteration 16850, Loss: 0.05417131632566452\n",
      "Iteration 16851, Loss: 0.05398872494697571\n",
      "Iteration 16852, Loss: 0.05417119711637497\n",
      "Iteration 16853, Loss: 0.053988806903362274\n",
      "Iteration 16854, Loss: 0.054171122610569\n",
      "Iteration 16855, Loss: 0.05398888513445854\n",
      "Iteration 16856, Loss: 0.054171156138181686\n",
      "Iteration 16857, Loss: 0.053988806903362274\n",
      "Iteration 16858, Loss: 0.054171230643987656\n",
      "Iteration 16859, Loss: 0.053988873958587646\n",
      "Iteration 16860, Loss: 0.0541711300611496\n",
      "Iteration 16861, Loss: 0.05398864299058914\n",
      "Iteration 16862, Loss: 0.05417143553495407\n",
      "Iteration 16863, Loss: 0.05398856848478317\n",
      "Iteration 16864, Loss: 0.05417139455676079\n",
      "Iteration 16865, Loss: 0.05398860573768616\n",
      "Iteration 16866, Loss: 0.05417127534747124\n",
      "Iteration 16867, Loss: 0.05398879572749138\n",
      "Iteration 16868, Loss: 0.05417115241289139\n",
      "Iteration 16869, Loss: 0.053988926112651825\n",
      "Iteration 16870, Loss: 0.05417100340127945\n",
      "Iteration 16871, Loss: 0.05398892983794212\n",
      "Iteration 16872, Loss: 0.05417107790708542\n",
      "Iteration 16873, Loss: 0.05398895964026451\n",
      "Iteration 16874, Loss: 0.05417131632566452\n",
      "Iteration 16875, Loss: 0.053988635540008545\n",
      "Iteration 16876, Loss: 0.05417148396372795\n",
      "Iteration 16877, Loss: 0.05398840457201004\n",
      "Iteration 16878, Loss: 0.05417172238230705\n",
      "Iteration 16879, Loss: 0.053988128900527954\n",
      "Iteration 16880, Loss: 0.05417183041572571\n",
      "Iteration 16881, Loss: 0.05398821830749512\n",
      "Iteration 16882, Loss: 0.05417162925004959\n",
      "Iteration 16883, Loss: 0.05398841202259064\n",
      "Iteration 16884, Loss: 0.05417134612798691\n",
      "Iteration 16885, Loss: 0.05398872494697571\n",
      "Iteration 16886, Loss: 0.054171185940504074\n",
      "Iteration 16887, Loss: 0.05398895964026451\n",
      "Iteration 16888, Loss: 0.05417100340127945\n",
      "Iteration 16889, Loss: 0.05398907512426376\n",
      "Iteration 16890, Loss: 0.05417115241289139\n",
      "Iteration 16891, Loss: 0.05398903042078018\n",
      "Iteration 16892, Loss: 0.05417108163237572\n",
      "Iteration 16893, Loss: 0.05398884043097496\n",
      "Iteration 16894, Loss: 0.054171234369277954\n",
      "Iteration 16895, Loss: 0.05398872122168541\n",
      "Iteration 16896, Loss: 0.05417131632566452\n",
      "Iteration 16897, Loss: 0.05398864671587944\n",
      "Iteration 16898, Loss: 0.054171353578567505\n",
      "Iteration 16899, Loss: 0.05398861691355705\n",
      "Iteration 16900, Loss: 0.05417124554514885\n",
      "Iteration 16901, Loss: 0.05398869141936302\n",
      "Iteration 16902, Loss: 0.054171159863471985\n",
      "Iteration 16903, Loss: 0.05398876592516899\n",
      "Iteration 16904, Loss: 0.05417119711637497\n",
      "Iteration 16905, Loss: 0.053988806903362274\n",
      "Iteration 16906, Loss: 0.054171040654182434\n",
      "Iteration 16907, Loss: 0.053988926112651825\n",
      "Iteration 16908, Loss: 0.054171040654182434\n",
      "Iteration 16909, Loss: 0.05398907512426376\n",
      "Iteration 16910, Loss: 0.05417107790708542\n",
      "Iteration 16911, Loss: 0.053989000618457794\n",
      "Iteration 16912, Loss: 0.05417107790708542\n",
      "Iteration 16913, Loss: 0.05398891493678093\n",
      "Iteration 16914, Loss: 0.05417127162218094\n",
      "Iteration 16915, Loss: 0.053988806903362274\n",
      "Iteration 16916, Loss: 0.05417132377624512\n",
      "Iteration 16917, Loss: 0.053988635540008545\n",
      "Iteration 16918, Loss: 0.05417156219482422\n",
      "Iteration 16919, Loss: 0.053988322615623474\n",
      "Iteration 16920, Loss: 0.05417168140411377\n",
      "Iteration 16921, Loss: 0.05398821085691452\n",
      "Iteration 16922, Loss: 0.05417171120643616\n",
      "Iteration 16923, Loss: 0.0539882555603981\n",
      "Iteration 16924, Loss: 0.054171472787857056\n",
      "Iteration 16925, Loss: 0.0539884939789772\n",
      "Iteration 16926, Loss: 0.05417119711637497\n",
      "Iteration 16927, Loss: 0.05398876592516899\n",
      "Iteration 16928, Loss: 0.054171040654182434\n",
      "Iteration 16929, Loss: 0.05398888885974884\n",
      "Iteration 16930, Loss: 0.05417100340127945\n",
      "Iteration 16931, Loss: 0.05398900434374809\n",
      "Iteration 16932, Loss: 0.05417100340127945\n",
      "Iteration 16933, Loss: 0.05398891493678093\n",
      "Iteration 16934, Loss: 0.054171185940504074\n",
      "Iteration 16935, Loss: 0.05398884043097496\n",
      "Iteration 16936, Loss: 0.05417127162218094\n",
      "Iteration 16937, Loss: 0.05398876219987869\n",
      "Iteration 16938, Loss: 0.05417139455676079\n",
      "Iteration 16939, Loss: 0.05398868769407272\n",
      "Iteration 16940, Loss: 0.054171353578567505\n",
      "Iteration 16941, Loss: 0.053988486528396606\n",
      "Iteration 16942, Loss: 0.05417151376605034\n",
      "Iteration 16943, Loss: 0.05398852750658989\n",
      "Iteration 16944, Loss: 0.05417143553495407\n",
      "Iteration 16945, Loss: 0.05398845300078392\n",
      "Iteration 16946, Loss: 0.054171398282051086\n",
      "Iteration 16947, Loss: 0.053988538682460785\n",
      "Iteration 16948, Loss: 0.054171204566955566\n",
      "Iteration 16949, Loss: 0.05398868769407272\n",
      "Iteration 16950, Loss: 0.054171085357666016\n",
      "Iteration 16951, Loss: 0.05398883670568466\n",
      "Iteration 16952, Loss: 0.054171156138181686\n",
      "Iteration 16953, Loss: 0.053988926112651825\n",
      "Iteration 16954, Loss: 0.054171036928892136\n",
      "Iteration 16955, Loss: 0.053989045321941376\n",
      "Iteration 16956, Loss: 0.05417095124721527\n",
      "Iteration 16957, Loss: 0.05398900434374809\n",
      "Iteration 16958, Loss: 0.05417095869779587\n",
      "Iteration 16959, Loss: 0.053989119827747345\n",
      "Iteration 16960, Loss: 0.054171156138181686\n",
      "Iteration 16961, Loss: 0.05398895591497421\n",
      "Iteration 16962, Loss: 0.05417104810476303\n",
      "Iteration 16963, Loss: 0.05398876219987869\n",
      "Iteration 16964, Loss: 0.05417127534747124\n",
      "Iteration 16965, Loss: 0.05398860573768616\n",
      "Iteration 16966, Loss: 0.054171543568372726\n",
      "Iteration 16967, Loss: 0.05398852750658989\n",
      "Iteration 16968, Loss: 0.05417143553495407\n",
      "Iteration 16969, Loss: 0.05398790165781975\n",
      "Iteration 16970, Loss: 0.0541713647544384\n",
      "Iteration 16971, Loss: 0.05398789048194885\n",
      "Iteration 16972, Loss: 0.05417204648256302\n",
      "Iteration 16973, Loss: 0.053987737745046616\n",
      "Iteration 16974, Loss: 0.05417191982269287\n",
      "Iteration 16975, Loss: 0.053987935185432434\n",
      "Iteration 16976, Loss: 0.054171644151210785\n",
      "Iteration 16977, Loss: 0.05398833006620407\n",
      "Iteration 16978, Loss: 0.05417139455676079\n",
      "Iteration 16979, Loss: 0.053988680243492126\n",
      "Iteration 16980, Loss: 0.05417104810476303\n",
      "Iteration 16981, Loss: 0.053988926112651825\n",
      "Iteration 16982, Loss: 0.054171036928892136\n",
      "Iteration 16983, Loss: 0.05398884415626526\n",
      "Iteration 16984, Loss: 0.05417100340127945\n",
      "Iteration 16985, Loss: 0.05398868769407272\n",
      "Iteration 16986, Loss: 0.054170966148376465\n",
      "Iteration 16987, Loss: 0.05398857221007347\n",
      "Iteration 16988, Loss: 0.05417105183005333\n",
      "Iteration 16989, Loss: 0.05398860573768616\n",
      "Iteration 16990, Loss: 0.05417117103934288\n",
      "Iteration 16991, Loss: 0.05398845672607422\n",
      "Iteration 16992, Loss: 0.054171204566955566\n",
      "Iteration 16993, Loss: 0.05398845300078392\n",
      "Iteration 16994, Loss: 0.05417124181985855\n",
      "Iteration 16995, Loss: 0.053988486528396606\n",
      "Iteration 16996, Loss: 0.0541713610291481\n",
      "Iteration 16997, Loss: 0.053988635540008545\n",
      "Iteration 16998, Loss: 0.05417124181985855\n",
      "Iteration 16999, Loss: 0.05398860573768616\n",
      "Iteration 17000, Loss: 0.054171204566955566\n",
      "Iteration 17001, Loss: 0.05398860573768616\n",
      "Iteration 17002, Loss: 0.05417120084166527\n",
      "Iteration 17003, Loss: 0.05398860573768616\n",
      "Iteration 17004, Loss: 0.0541711263358593\n",
      "Iteration 17005, Loss: 0.05398867651820183\n",
      "Iteration 17006, Loss: 0.05417120084166527\n",
      "Iteration 17007, Loss: 0.05398864671587944\n",
      "Iteration 17008, Loss: 0.054171234369277954\n",
      "Iteration 17009, Loss: 0.05398864671587944\n",
      "Iteration 17010, Loss: 0.05417119711637497\n",
      "Iteration 17011, Loss: 0.05398868769407272\n",
      "Iteration 17012, Loss: 0.054170966148376465\n",
      "Iteration 17013, Loss: 0.05398876592516899\n",
      "Iteration 17014, Loss: 0.0541708879172802\n",
      "Iteration 17015, Loss: 0.05398881062865257\n",
      "Iteration 17016, Loss: 0.05417099595069885\n",
      "Iteration 17017, Loss: 0.053988873958587646\n",
      "Iteration 17018, Loss: 0.05417093262076378\n",
      "Iteration 17019, Loss: 0.05398872122168541\n",
      "Iteration 17020, Loss: 0.05417105183005333\n",
      "Iteration 17021, Loss: 0.05398856848478317\n",
      "Iteration 17022, Loss: 0.05417127534747124\n",
      "Iteration 17023, Loss: 0.05398856848478317\n",
      "Iteration 17024, Loss: 0.05417119711637497\n",
      "Iteration 17025, Loss: 0.05398879572749138\n",
      "Iteration 17026, Loss: 0.054171040654182434\n",
      "Iteration 17027, Loss: 0.05398884043097496\n",
      "Iteration 17028, Loss: 0.054170962423086166\n",
      "Iteration 17029, Loss: 0.053988926112651825\n",
      "Iteration 17030, Loss: 0.05417080968618393\n",
      "Iteration 17031, Loss: 0.053989000618457794\n",
      "Iteration 17032, Loss: 0.054170768707990646\n",
      "Iteration 17033, Loss: 0.05398895964026451\n",
      "Iteration 17034, Loss: 0.0541708879172802\n",
      "Iteration 17035, Loss: 0.05398884415626526\n",
      "Iteration 17036, Loss: 0.054171085357666016\n",
      "Iteration 17037, Loss: 0.05398856848478317\n",
      "Iteration 17038, Loss: 0.05417139455676079\n",
      "Iteration 17039, Loss: 0.05398837476968765\n",
      "Iteration 17040, Loss: 0.05417139455676079\n",
      "Iteration 17041, Loss: 0.05398830026388168\n",
      "Iteration 17042, Loss: 0.05417131632566452\n",
      "Iteration 17043, Loss: 0.05398856848478317\n",
      "Iteration 17044, Loss: 0.0541711151599884\n",
      "Iteration 17045, Loss: 0.05398868769407272\n",
      "Iteration 17046, Loss: 0.054170966148376465\n",
      "Iteration 17047, Loss: 0.05398895964026451\n",
      "Iteration 17048, Loss: 0.05417099595069885\n",
      "Iteration 17049, Loss: 0.05398876965045929\n",
      "Iteration 17050, Loss: 0.054170891642570496\n",
      "Iteration 17051, Loss: 0.05398868769407272\n",
      "Iteration 17052, Loss: 0.054171085357666016\n",
      "Iteration 17053, Loss: 0.05398860573768616\n",
      "Iteration 17054, Loss: 0.05417124554514885\n",
      "Iteration 17055, Loss: 0.05398840829730034\n",
      "Iteration 17056, Loss: 0.05417129397392273\n",
      "Iteration 17057, Loss: 0.053988367319107056\n",
      "Iteration 17058, Loss: 0.054171472787857056\n",
      "Iteration 17059, Loss: 0.05398830026388168\n",
      "Iteration 17060, Loss: 0.05417132377624512\n",
      "Iteration 17061, Loss: 0.05398860573768616\n",
      "Iteration 17062, Loss: 0.05417104810476303\n",
      "Iteration 17063, Loss: 0.05398864671587944\n",
      "Iteration 17064, Loss: 0.05417104810476303\n",
      "Iteration 17065, Loss: 0.053988732397556305\n",
      "Iteration 17066, Loss: 0.05417100712656975\n",
      "Iteration 17067, Loss: 0.05398876592516899\n",
      "Iteration 17068, Loss: 0.05417100712656975\n",
      "Iteration 17069, Loss: 0.053988777101039886\n",
      "Iteration 17070, Loss: 0.054170891642570496\n",
      "Iteration 17071, Loss: 0.053988657891750336\n",
      "Iteration 17072, Loss: 0.054171204566955566\n",
      "Iteration 17073, Loss: 0.053988486528396606\n",
      "Iteration 17074, Loss: 0.05417139455676079\n",
      "Iteration 17075, Loss: 0.053988367319107056\n",
      "Iteration 17076, Loss: 0.05417132377624512\n",
      "Iteration 17077, Loss: 0.05398830026388168\n",
      "Iteration 17078, Loss: 0.054171353578567505\n",
      "Iteration 17079, Loss: 0.0539884939789772\n",
      "Iteration 17080, Loss: 0.054171156138181686\n",
      "Iteration 17081, Loss: 0.05398872494697571\n",
      "Iteration 17082, Loss: 0.05417089909315109\n",
      "Iteration 17083, Loss: 0.05398891493678093\n",
      "Iteration 17084, Loss: 0.05417092889547348\n",
      "Iteration 17085, Loss: 0.053988926112651825\n",
      "Iteration 17086, Loss: 0.05417099595069885\n",
      "Iteration 17087, Loss: 0.053988873958587646\n",
      "Iteration 17088, Loss: 0.05417108163237572\n",
      "Iteration 17089, Loss: 0.05398872122168541\n",
      "Iteration 17090, Loss: 0.054171204566955566\n",
      "Iteration 17091, Loss: 0.053988486528396606\n",
      "Iteration 17092, Loss: 0.054171204566955566\n",
      "Iteration 17093, Loss: 0.05398845300078392\n",
      "Iteration 17094, Loss: 0.05417139455676079\n",
      "Iteration 17095, Loss: 0.05398833751678467\n",
      "Iteration 17096, Loss: 0.0541713610291481\n",
      "Iteration 17097, Loss: 0.05398821830749512\n",
      "Iteration 17098, Loss: 0.054171353578567505\n",
      "Iteration 17099, Loss: 0.053988419473171234\n",
      "Iteration 17100, Loss: 0.05417107790708542\n",
      "Iteration 17101, Loss: 0.05398872494697571\n",
      "Iteration 17102, Loss: 0.05417099595069885\n",
      "Iteration 17103, Loss: 0.053988926112651825\n",
      "Iteration 17104, Loss: 0.05417081341147423\n",
      "Iteration 17105, Loss: 0.05398884415626526\n",
      "Iteration 17106, Loss: 0.054171085357666016\n",
      "Iteration 17107, Loss: 0.053988754749298096\n",
      "Iteration 17108, Loss: 0.054171353578567505\n",
      "Iteration 17109, Loss: 0.05398852378129959\n",
      "Iteration 17110, Loss: 0.054171331226825714\n",
      "Iteration 17111, Loss: 0.053988367319107056\n",
      "Iteration 17112, Loss: 0.054171472787857056\n",
      "Iteration 17113, Loss: 0.05398844927549362\n",
      "Iteration 17114, Loss: 0.05417143553495407\n",
      "Iteration 17115, Loss: 0.053988486528396606\n",
      "Iteration 17116, Loss: 0.054171428084373474\n",
      "Iteration 17117, Loss: 0.053988680243492126\n",
      "Iteration 17118, Loss: 0.0541711151599884\n",
      "Iteration 17119, Loss: 0.05398872494697571\n",
      "Iteration 17120, Loss: 0.0541711151599884\n",
      "Iteration 17121, Loss: 0.05398883670568466\n",
      "Iteration 17122, Loss: 0.054171036928892136\n",
      "Iteration 17123, Loss: 0.05398868769407272\n",
      "Iteration 17124, Loss: 0.05417109280824661\n",
      "Iteration 17125, Loss: 0.05398860573768616\n",
      "Iteration 17126, Loss: 0.05417131632566452\n",
      "Iteration 17127, Loss: 0.05398864299058914\n",
      "Iteration 17128, Loss: 0.05417124181985855\n",
      "Iteration 17129, Loss: 0.05398856848478317\n",
      "Iteration 17130, Loss: 0.054171230643987656\n",
      "Iteration 17131, Loss: 0.05398868769407272\n",
      "Iteration 17132, Loss: 0.054171085357666016\n",
      "Iteration 17133, Loss: 0.05398876592516899\n",
      "Iteration 17134, Loss: 0.0541711151599884\n",
      "Iteration 17135, Loss: 0.05398876592516899\n",
      "Iteration 17136, Loss: 0.054170966148376465\n",
      "Iteration 17137, Loss: 0.05398879572749138\n",
      "Iteration 17138, Loss: 0.05417116731405258\n",
      "Iteration 17139, Loss: 0.05398860573768616\n",
      "Iteration 17140, Loss: 0.0541711263358593\n",
      "Iteration 17141, Loss: 0.053988486528396606\n",
      "Iteration 17142, Loss: 0.05417127534747124\n",
      "Iteration 17143, Loss: 0.05398864299058914\n",
      "Iteration 17144, Loss: 0.05417127534747124\n",
      "Iteration 17145, Loss: 0.05398860573768616\n",
      "Iteration 17146, Loss: 0.05417124181985855\n",
      "Iteration 17147, Loss: 0.05398857221007347\n",
      "Iteration 17148, Loss: 0.05417127534747124\n",
      "Iteration 17149, Loss: 0.053988613188266754\n",
      "Iteration 17150, Loss: 0.05417104810476303\n",
      "Iteration 17151, Loss: 0.05398868769407272\n",
      "Iteration 17152, Loss: 0.0541711151599884\n",
      "Iteration 17153, Loss: 0.05398879572749138\n",
      "Iteration 17154, Loss: 0.0541711151599884\n",
      "Iteration 17155, Loss: 0.05398872494697571\n",
      "Iteration 17156, Loss: 0.05417108163237572\n",
      "Iteration 17157, Loss: 0.05398879572749138\n",
      "Iteration 17158, Loss: 0.054171036928892136\n",
      "Iteration 17159, Loss: 0.053988754749298096\n",
      "Iteration 17160, Loss: 0.054171085357666016\n",
      "Iteration 17161, Loss: 0.05398860573768616\n",
      "Iteration 17162, Loss: 0.05417107790708542\n",
      "Iteration 17163, Loss: 0.05398872494697571\n",
      "Iteration 17164, Loss: 0.054171036928892136\n",
      "Iteration 17165, Loss: 0.05398876592516899\n",
      "Iteration 17166, Loss: 0.05417080223560333\n",
      "Iteration 17167, Loss: 0.05398896336555481\n",
      "Iteration 17168, Loss: 0.05417060852050781\n",
      "Iteration 17169, Loss: 0.053988974541425705\n",
      "Iteration 17170, Loss: 0.054170530289411545\n",
      "Iteration 17171, Loss: 0.0539892315864563\n",
      "Iteration 17172, Loss: 0.054170526564121246\n",
      "Iteration 17173, Loss: 0.05398920178413391\n",
      "Iteration 17174, Loss: 0.05417060852050781\n",
      "Iteration 17175, Loss: 0.053989045321941376\n",
      "Iteration 17176, Loss: 0.0541708841919899\n",
      "Iteration 17177, Loss: 0.05398888140916824\n",
      "Iteration 17178, Loss: 0.05417100712656975\n",
      "Iteration 17179, Loss: 0.05398868769407272\n",
      "Iteration 17180, Loss: 0.05417116731405258\n",
      "Iteration 17181, Loss: 0.05398856848478317\n",
      "Iteration 17182, Loss: 0.05417116731405258\n",
      "Iteration 17183, Loss: 0.05398844927549362\n",
      "Iteration 17184, Loss: 0.05417127162218094\n",
      "Iteration 17185, Loss: 0.05398860573768616\n",
      "Iteration 17186, Loss: 0.05417099595069885\n",
      "Iteration 17187, Loss: 0.05398876965045929\n",
      "Iteration 17188, Loss: 0.0541708767414093\n",
      "Iteration 17189, Loss: 0.05398903414607048\n",
      "Iteration 17190, Loss: 0.05417072772979736\n",
      "Iteration 17191, Loss: 0.05398911237716675\n",
      "Iteration 17192, Loss: 0.054170798510313034\n",
      "Iteration 17193, Loss: 0.05398903787136078\n",
      "Iteration 17194, Loss: 0.05417066067457199\n",
      "Iteration 17195, Loss: 0.053988926112651825\n",
      "Iteration 17196, Loss: 0.054170891642570496\n",
      "Iteration 17197, Loss: 0.05398876592516899\n",
      "Iteration 17198, Loss: 0.054170966148376465\n",
      "Iteration 17199, Loss: 0.053988754749298096\n",
      "Iteration 17200, Loss: 0.054171085357666016\n",
      "Iteration 17201, Loss: 0.05398864671587944\n",
      "Iteration 17202, Loss: 0.05417127534747124\n",
      "Iteration 17203, Loss: 0.05398857221007347\n",
      "Iteration 17204, Loss: 0.054170966148376465\n",
      "Iteration 17205, Loss: 0.05398865044116974\n",
      "Iteration 17206, Loss: 0.054171036928892136\n",
      "Iteration 17207, Loss: 0.05398876592516899\n",
      "Iteration 17208, Loss: 0.054170843213796616\n",
      "Iteration 17209, Loss: 0.05398896336555481\n",
      "Iteration 17210, Loss: 0.054170768707990646\n",
      "Iteration 17211, Loss: 0.05398908257484436\n",
      "Iteration 17212, Loss: 0.054170798510313034\n",
      "Iteration 17213, Loss: 0.053989045321941376\n",
      "Iteration 17214, Loss: 0.054170913994312286\n",
      "Iteration 17215, Loss: 0.05398896336555481\n",
      "Iteration 17216, Loss: 0.05417083948850632\n",
      "Iteration 17217, Loss: 0.05398895964026451\n",
      "Iteration 17218, Loss: 0.054170917719602585\n",
      "Iteration 17219, Loss: 0.05398903414607048\n",
      "Iteration 17220, Loss: 0.05417095869779587\n",
      "Iteration 17221, Loss: 0.053988926112651825\n",
      "Iteration 17222, Loss: 0.0541708841919899\n",
      "Iteration 17223, Loss: 0.05398895964026451\n",
      "Iteration 17224, Loss: 0.054170846939086914\n",
      "Iteration 17225, Loss: 0.05398879572749138\n",
      "Iteration 17226, Loss: 0.05417104810476303\n",
      "Iteration 17227, Loss: 0.05398868769407272\n",
      "Iteration 17228, Loss: 0.0541711263358593\n",
      "Iteration 17229, Loss: 0.053988486528396606\n",
      "Iteration 17230, Loss: 0.05417127534747124\n",
      "Iteration 17231, Loss: 0.05398845300078392\n",
      "Iteration 17232, Loss: 0.05417127534747124\n",
      "Iteration 17233, Loss: 0.05398864671587944\n",
      "Iteration 17234, Loss: 0.05417100712656975\n",
      "Iteration 17235, Loss: 0.05398865044116974\n",
      "Iteration 17236, Loss: 0.054170846939086914\n",
      "Iteration 17237, Loss: 0.05398893356323242\n",
      "Iteration 17238, Loss: 0.054170649498701096\n",
      "Iteration 17239, Loss: 0.053989194333553314\n",
      "Iteration 17240, Loss: 0.05417067930102348\n",
      "Iteration 17241, Loss: 0.05398919805884361\n",
      "Iteration 17242, Loss: 0.054170798510313034\n",
      "Iteration 17243, Loss: 0.05398888513445854\n",
      "Iteration 17244, Loss: 0.054170966148376465\n",
      "Iteration 17245, Loss: 0.053988806903362274\n",
      "Iteration 17246, Loss: 0.05417130887508392\n",
      "Iteration 17247, Loss: 0.05398860201239586\n",
      "Iteration 17248, Loss: 0.054171375930309296\n",
      "Iteration 17249, Loss: 0.0539882555603981\n",
      "Iteration 17250, Loss: 0.054171495139598846\n",
      "Iteration 17251, Loss: 0.053987979888916016\n",
      "Iteration 17252, Loss: 0.05417155846953392\n",
      "Iteration 17253, Loss: 0.0539882592856884\n",
      "Iteration 17254, Loss: 0.05417131632566452\n",
      "Iteration 17255, Loss: 0.05398852750658989\n",
      "Iteration 17256, Loss: 0.05417107790708542\n",
      "Iteration 17257, Loss: 0.053988926112651825\n",
      "Iteration 17258, Loss: 0.054170798510313034\n",
      "Iteration 17259, Loss: 0.053988970816135406\n",
      "Iteration 17260, Loss: 0.05417068302631378\n",
      "Iteration 17261, Loss: 0.05398912355303764\n",
      "Iteration 17262, Loss: 0.054170649498701096\n",
      "Iteration 17263, Loss: 0.053988926112651825\n",
      "Iteration 17264, Loss: 0.0541708879172802\n",
      "Iteration 17265, Loss: 0.05398884415626526\n",
      "Iteration 17266, Loss: 0.05417116731405258\n",
      "Iteration 17267, Loss: 0.05398864299058914\n",
      "Iteration 17268, Loss: 0.054171398282051086\n",
      "Iteration 17269, Loss: 0.053988367319107056\n",
      "Iteration 17270, Loss: 0.05417155846953392\n",
      "Iteration 17271, Loss: 0.05398818105459213\n",
      "Iteration 17272, Loss: 0.05417158827185631\n",
      "Iteration 17273, Loss: 0.05398833751678467\n",
      "Iteration 17274, Loss: 0.05417131632566452\n",
      "Iteration 17275, Loss: 0.05398868769407272\n",
      "Iteration 17276, Loss: 0.05417099595069885\n",
      "Iteration 17277, Loss: 0.05398895964026451\n",
      "Iteration 17278, Loss: 0.05417072772979736\n",
      "Iteration 17279, Loss: 0.05398919805884361\n",
      "Iteration 17280, Loss: 0.054170578718185425\n",
      "Iteration 17281, Loss: 0.05398907512426376\n",
      "Iteration 17282, Loss: 0.05417085438966751\n",
      "Iteration 17283, Loss: 0.05398879945278168\n",
      "Iteration 17284, Loss: 0.0541711300611496\n",
      "Iteration 17285, Loss: 0.05398860201239586\n",
      "Iteration 17286, Loss: 0.05417132377624512\n",
      "Iteration 17287, Loss: 0.0539882592856884\n",
      "Iteration 17288, Loss: 0.0541713647544384\n",
      "Iteration 17289, Loss: 0.05398844927549362\n",
      "Iteration 17290, Loss: 0.0541713647544384\n",
      "Iteration 17291, Loss: 0.053988486528396606\n",
      "Iteration 17292, Loss: 0.05417127534747124\n",
      "Iteration 17293, Loss: 0.05398852750658989\n",
      "Iteration 17294, Loss: 0.054171156138181686\n",
      "Iteration 17295, Loss: 0.05398872494697571\n",
      "Iteration 17296, Loss: 0.054170966148376465\n",
      "Iteration 17297, Loss: 0.05398883670568466\n",
      "Iteration 17298, Loss: 0.054170966148376465\n",
      "Iteration 17299, Loss: 0.05398868769407272\n",
      "Iteration 17300, Loss: 0.054171204566955566\n",
      "Iteration 17301, Loss: 0.05398864299058914\n",
      "Iteration 17302, Loss: 0.05417143553495407\n",
      "Iteration 17303, Loss: 0.053988367319107056\n",
      "Iteration 17304, Loss: 0.054171450436115265\n",
      "Iteration 17305, Loss: 0.05398830026388168\n",
      "Iteration 17306, Loss: 0.05417144298553467\n",
      "Iteration 17307, Loss: 0.05398840457201004\n",
      "Iteration 17308, Loss: 0.054171398282051086\n",
      "Iteration 17309, Loss: 0.05398852750658989\n",
      "Iteration 17310, Loss: 0.0541711151599884\n",
      "Iteration 17311, Loss: 0.05398868769407272\n",
      "Iteration 17312, Loss: 0.0541708879172802\n",
      "Iteration 17313, Loss: 0.053988873958587646\n",
      "Iteration 17314, Loss: 0.054170966148376465\n",
      "Iteration 17315, Loss: 0.053988732397556305\n",
      "Iteration 17316, Loss: 0.054171122610569\n",
      "Iteration 17317, Loss: 0.05398860573768616\n",
      "Iteration 17318, Loss: 0.054171204566955566\n",
      "Iteration 17319, Loss: 0.05398845672607422\n",
      "Iteration 17320, Loss: 0.05417124554514885\n",
      "Iteration 17321, Loss: 0.05398852750658989\n",
      "Iteration 17322, Loss: 0.054171234369277954\n",
      "Iteration 17323, Loss: 0.05398857221007347\n",
      "Iteration 17324, Loss: 0.0541711151599884\n",
      "Iteration 17325, Loss: 0.05398876592516899\n",
      "Iteration 17326, Loss: 0.05417095869779587\n",
      "Iteration 17327, Loss: 0.05398891866207123\n",
      "Iteration 17328, Loss: 0.05417095869779587\n",
      "Iteration 17329, Loss: 0.05398903787136078\n",
      "Iteration 17330, Loss: 0.054170843213796616\n",
      "Iteration 17331, Loss: 0.05398895964026451\n",
      "Iteration 17332, Loss: 0.05417092889547348\n",
      "Iteration 17333, Loss: 0.053988873958587646\n",
      "Iteration 17334, Loss: 0.05417104810476303\n",
      "Iteration 17335, Loss: 0.05398864671587944\n",
      "Iteration 17336, Loss: 0.05417131632566452\n",
      "Iteration 17337, Loss: 0.05398844927549362\n",
      "Iteration 17338, Loss: 0.0541713647544384\n",
      "Iteration 17339, Loss: 0.05398840829730034\n",
      "Iteration 17340, Loss: 0.054171353578567505\n",
      "Iteration 17341, Loss: 0.053988367319107056\n",
      "Iteration 17342, Loss: 0.05417128652334213\n",
      "Iteration 17343, Loss: 0.05398845300078392\n",
      "Iteration 17344, Loss: 0.0541711300611496\n",
      "Iteration 17345, Loss: 0.05398852750658989\n",
      "Iteration 17346, Loss: 0.05417127162218094\n",
      "Iteration 17347, Loss: 0.05398857221007347\n",
      "Iteration 17348, Loss: 0.05417108163237572\n",
      "Iteration 17349, Loss: 0.05398884415626526\n",
      "Iteration 17350, Loss: 0.05417100340127945\n",
      "Iteration 17351, Loss: 0.0539889931678772\n",
      "Iteration 17352, Loss: 0.054170966148376465\n",
      "Iteration 17353, Loss: 0.05398884415626526\n",
      "Iteration 17354, Loss: 0.054171122610569\n",
      "Iteration 17355, Loss: 0.05398864671587944\n",
      "Iteration 17356, Loss: 0.0541711300611496\n",
      "Iteration 17357, Loss: 0.0539884939789772\n",
      "Iteration 17358, Loss: 0.05417124554514885\n",
      "Iteration 17359, Loss: 0.05398907884955406\n",
      "Iteration 17360, Loss: 0.0541711263358593\n",
      "Iteration 17361, Loss: 0.053989045321941376\n",
      "Iteration 17362, Loss: 0.054171591997146606\n",
      "Iteration 17363, Loss: 0.05398908257484436\n",
      "Iteration 17364, Loss: 0.05417148396372795\n",
      "Iteration 17365, Loss: 0.053989164531230927\n",
      "Iteration 17366, Loss: 0.05417143926024437\n",
      "Iteration 17367, Loss: 0.05398939549922943\n",
      "Iteration 17368, Loss: 0.05417128652334213\n",
      "Iteration 17369, Loss: 0.05398927628993988\n",
      "Iteration 17370, Loss: 0.05417140573263168\n",
      "Iteration 17371, Loss: 0.053989239037036896\n",
      "Iteration 17372, Loss: 0.0541716031730175\n",
      "Iteration 17373, Loss: 0.05398903787136078\n",
      "Iteration 17374, Loss: 0.05417175218462944\n",
      "Iteration 17375, Loss: 0.05398908257484436\n",
      "Iteration 17376, Loss: 0.05417167395353317\n",
      "Iteration 17377, Loss: 0.05398912355303764\n",
      "Iteration 17378, Loss: 0.0541716031730175\n",
      "Iteration 17379, Loss: 0.05398907884955406\n",
      "Iteration 17380, Loss: 0.05417167395353317\n",
      "Iteration 17381, Loss: 0.053989119827747345\n",
      "Iteration 17382, Loss: 0.05417163297533989\n",
      "Iteration 17383, Loss: 0.05398915708065033\n",
      "Iteration 17384, Loss: 0.05417167395353317\n",
      "Iteration 17385, Loss: 0.05398915708065033\n",
      "Iteration 17386, Loss: 0.05417167395353317\n",
      "Iteration 17387, Loss: 0.05398912355303764\n",
      "Iteration 17388, Loss: 0.05417156219482422\n",
      "Iteration 17389, Loss: 0.05398908257484436\n",
      "Iteration 17390, Loss: 0.0541716031730175\n",
      "Iteration 17391, Loss: 0.05398908257484436\n",
      "Iteration 17392, Loss: 0.05417148396372795\n",
      "Iteration 17393, Loss: 0.05398911237716675\n",
      "Iteration 17394, Loss: 0.05417177826166153\n",
      "Iteration 17395, Loss: 0.05398919805884361\n",
      "Iteration 17396, Loss: 0.054171547293663025\n",
      "Iteration 17397, Loss: 0.05398928374052048\n",
      "Iteration 17398, Loss: 0.05417151004076004\n",
      "Iteration 17399, Loss: 0.053989361971616745\n",
      "Iteration 17400, Loss: 0.05417134612798691\n",
      "Iteration 17401, Loss: 0.053989477455616\n",
      "Iteration 17402, Loss: 0.054171204566955566\n",
      "Iteration 17403, Loss: 0.053989477455616\n",
      "Iteration 17404, Loss: 0.0541713610291481\n",
      "Iteration 17405, Loss: 0.05398935079574585\n",
      "Iteration 17406, Loss: 0.05417148023843765\n",
      "Iteration 17407, Loss: 0.05398927256464958\n",
      "Iteration 17408, Loss: 0.05417171120643616\n",
      "Iteration 17409, Loss: 0.05398896336555481\n",
      "Iteration 17410, Loss: 0.05417175218462944\n",
      "Iteration 17411, Loss: 0.053988926112651825\n",
      "Iteration 17412, Loss: 0.05417179316282272\n",
      "Iteration 17413, Loss: 0.05398888513445854\n",
      "Iteration 17414, Loss: 0.054171785712242126\n",
      "Iteration 17415, Loss: 0.05398900434374809\n",
      "Iteration 17416, Loss: 0.054171591997146606\n",
      "Iteration 17417, Loss: 0.053989164531230927\n",
      "Iteration 17418, Loss: 0.05417158827185631\n",
      "Iteration 17419, Loss: 0.053989242762327194\n",
      "Iteration 17420, Loss: 0.0541713647544384\n",
      "Iteration 17421, Loss: 0.05398935079574585\n",
      "Iteration 17422, Loss: 0.05417155474424362\n",
      "Iteration 17423, Loss: 0.05398919805884361\n",
      "Iteration 17424, Loss: 0.05417163670063019\n",
      "Iteration 17425, Loss: 0.05398908257484436\n",
      "Iteration 17426, Loss: 0.05417168140411377\n",
      "Iteration 17427, Loss: 0.053988926112651825\n",
      "Iteration 17428, Loss: 0.05417187139391899\n",
      "Iteration 17429, Loss: 0.05398888513445854\n",
      "Iteration 17430, Loss: 0.05417183041572571\n",
      "Iteration 17431, Loss: 0.05398891866207123\n",
      "Iteration 17432, Loss: 0.05417190119624138\n",
      "Iteration 17433, Loss: 0.053989361971616745\n",
      "Iteration 17434, Loss: 0.05417167395353317\n",
      "Iteration 17435, Loss: 0.053989678621292114\n",
      "Iteration 17436, Loss: 0.05417083203792572\n",
      "Iteration 17437, Loss: 0.05399010702967644\n",
      "Iteration 17438, Loss: 0.054170720279216766\n",
      "Iteration 17439, Loss: 0.053990066051483154\n",
      "Iteration 17440, Loss: 0.0541708767414093\n",
      "Iteration 17441, Loss: 0.053989868611097336\n",
      "Iteration 17442, Loss: 0.05417127534747124\n",
      "Iteration 17443, Loss: 0.05398955196142197\n",
      "Iteration 17444, Loss: 0.054171569645404816\n",
      "Iteration 17445, Loss: 0.05398911237716675\n",
      "Iteration 17446, Loss: 0.054172150790691376\n",
      "Iteration 17447, Loss: 0.05398868769407272\n",
      "Iteration 17448, Loss: 0.05417222902178764\n",
      "Iteration 17449, Loss: 0.0539884977042675\n",
      "Iteration 17450, Loss: 0.05417218804359436\n",
      "Iteration 17451, Loss: 0.05398861691355705\n",
      "Iteration 17452, Loss: 0.05417194962501526\n",
      "Iteration 17453, Loss: 0.05398889631032944\n",
      "Iteration 17454, Loss: 0.05417171120643616\n",
      "Iteration 17455, Loss: 0.053989164531230927\n",
      "Iteration 17456, Loss: 0.05417155474424362\n",
      "Iteration 17457, Loss: 0.05398939549922943\n",
      "Iteration 17458, Loss: 0.054171472787857056\n",
      "Iteration 17459, Loss: 0.05398928374052048\n",
      "Iteration 17460, Loss: 0.05417148396372795\n",
      "Iteration 17461, Loss: 0.053989242762327194\n",
      "Iteration 17462, Loss: 0.05417175218462944\n",
      "Iteration 17463, Loss: 0.05398915708065033\n",
      "Iteration 17464, Loss: 0.05417172238230705\n",
      "Iteration 17465, Loss: 0.05398903414607048\n",
      "Iteration 17466, Loss: 0.054172031581401825\n",
      "Iteration 17467, Loss: 0.05398881062865257\n",
      "Iteration 17468, Loss: 0.05417218431830406\n",
      "Iteration 17469, Loss: 0.05398872494697571\n",
      "Iteration 17470, Loss: 0.05417213961482048\n",
      "Iteration 17471, Loss: 0.05398884415626526\n",
      "Iteration 17472, Loss: 0.054171912372112274\n",
      "Iteration 17473, Loss: 0.05398903787136078\n",
      "Iteration 17474, Loss: 0.054171666502952576\n",
      "Iteration 17475, Loss: 0.05398928374052048\n",
      "Iteration 17476, Loss: 0.05417155474424362\n",
      "Iteration 17477, Loss: 0.053989477455616\n",
      "Iteration 17478, Loss: 0.05417131632566452\n",
      "Iteration 17479, Loss: 0.05398952215909958\n",
      "Iteration 17480, Loss: 0.05417131632566452\n",
      "Iteration 17481, Loss: 0.053989481180906296\n",
      "Iteration 17482, Loss: 0.05417144298553467\n",
      "Iteration 17483, Loss: 0.05398931726813316\n",
      "Iteration 17484, Loss: 0.05417171120643616\n",
      "Iteration 17485, Loss: 0.05398908257484436\n",
      "Iteration 17486, Loss: 0.05417194589972496\n",
      "Iteration 17487, Loss: 0.053988926112651825\n",
      "Iteration 17488, Loss: 0.05417187139391899\n",
      "Iteration 17489, Loss: 0.05398896336555481\n",
      "Iteration 17490, Loss: 0.05417187139391899\n",
      "Iteration 17491, Loss: 0.05398896336555481\n",
      "Iteration 17492, Loss: 0.05417199060320854\n",
      "Iteration 17493, Loss: 0.05398891866207123\n",
      "Iteration 17494, Loss: 0.054171837866306305\n",
      "Iteration 17495, Loss: 0.053988926112651825\n",
      "Iteration 17496, Loss: 0.05417206138372421\n",
      "Iteration 17497, Loss: 0.05398896336555481\n",
      "Iteration 17498, Loss: 0.05417183041572571\n",
      "Iteration 17499, Loss: 0.05398915708065033\n",
      "Iteration 17500, Loss: 0.05417163297533989\n",
      "Iteration 17501, Loss: 0.053989239037036896\n",
      "Iteration 17502, Loss: 0.054171591997146606\n",
      "Iteration 17503, Loss: 0.05398932099342346\n",
      "Iteration 17504, Loss: 0.054171472787857056\n",
      "Iteration 17505, Loss: 0.05398932099342346\n",
      "Iteration 17506, Loss: 0.05417144298553467\n",
      "Iteration 17507, Loss: 0.05398931726813316\n",
      "Iteration 17508, Loss: 0.05417175218462944\n",
      "Iteration 17509, Loss: 0.053989049047231674\n",
      "Iteration 17510, Loss: 0.054171763360500336\n",
      "Iteration 17511, Loss: 0.053989045321941376\n",
      "Iteration 17512, Loss: 0.054171882569789886\n",
      "Iteration 17513, Loss: 0.053988926112651825\n",
      "Iteration 17514, Loss: 0.05417203530669212\n",
      "Iteration 17515, Loss: 0.05398876592516899\n",
      "Iteration 17516, Loss: 0.054172106087207794\n",
      "Iteration 17517, Loss: 0.053988926112651825\n",
      "Iteration 17518, Loss: 0.054171912372112274\n",
      "Iteration 17519, Loss: 0.053989045321941376\n",
      "Iteration 17520, Loss: 0.05417163297533989\n",
      "Iteration 17521, Loss: 0.05398920923471451\n",
      "Iteration 17522, Loss: 0.05417151376605034\n",
      "Iteration 17523, Loss: 0.053989361971616745\n",
      "Iteration 17524, Loss: 0.05417151376605034\n",
      "Iteration 17525, Loss: 0.05398940294981003\n",
      "Iteration 17526, Loss: 0.05417143553495407\n",
      "Iteration 17527, Loss: 0.053989361971616745\n",
      "Iteration 17528, Loss: 0.054171375930309296\n",
      "Iteration 17529, Loss: 0.05398935824632645\n",
      "Iteration 17530, Loss: 0.0541716031730175\n",
      "Iteration 17531, Loss: 0.05398900434374809\n",
      "Iteration 17532, Loss: 0.05417187511920929\n",
      "Iteration 17533, Loss: 0.05398888885974884\n",
      "Iteration 17534, Loss: 0.05417200177907944\n",
      "Iteration 17535, Loss: 0.0539887361228466\n",
      "Iteration 17536, Loss: 0.054171886295080185\n",
      "Iteration 17537, Loss: 0.053988657891750336\n",
      "Iteration 17538, Loss: 0.05417199060320854\n",
      "Iteration 17539, Loss: 0.05398888513445854\n",
      "Iteration 17540, Loss: 0.05417183041572571\n",
      "Iteration 17541, Loss: 0.05398908257484436\n",
      "Iteration 17542, Loss: 0.05417163297533989\n",
      "Iteration 17543, Loss: 0.053989242762327194\n",
      "Iteration 17544, Loss: 0.054171524941921234\n",
      "Iteration 17545, Loss: 0.05398932099342346\n",
      "Iteration 17546, Loss: 0.05417140573263168\n",
      "Iteration 17547, Loss: 0.05398920178413391\n",
      "Iteration 17548, Loss: 0.05417156219482422\n",
      "Iteration 17549, Loss: 0.053989049047231674\n",
      "Iteration 17550, Loss: 0.054171644151210785\n",
      "Iteration 17551, Loss: 0.05398892983794212\n",
      "Iteration 17552, Loss: 0.054171644151210785\n",
      "Iteration 17553, Loss: 0.05398900434374809\n",
      "Iteration 17554, Loss: 0.054171718657016754\n",
      "Iteration 17555, Loss: 0.05398893356323242\n",
      "Iteration 17556, Loss: 0.05417172238230705\n",
      "Iteration 17557, Loss: 0.05398896336555481\n",
      "Iteration 17558, Loss: 0.05417183041572571\n",
      "Iteration 17559, Loss: 0.05398900434374809\n",
      "Iteration 17560, Loss: 0.05417168140411377\n",
      "Iteration 17561, Loss: 0.053989168256521225\n",
      "Iteration 17562, Loss: 0.05417144298553467\n",
      "Iteration 17563, Loss: 0.05398940294981003\n",
      "Iteration 17564, Loss: 0.0541713647544384\n",
      "Iteration 17565, Loss: 0.053989361971616745\n",
      "Iteration 17566, Loss: 0.0541713610291481\n",
      "Iteration 17567, Loss: 0.05398933216929436\n",
      "Iteration 17568, Loss: 0.054171256721019745\n",
      "Iteration 17569, Loss: 0.05398928374052048\n",
      "Iteration 17570, Loss: 0.05417148396372795\n",
      "Iteration 17571, Loss: 0.053989164531230927\n",
      "Iteration 17572, Loss: 0.054171644151210785\n",
      "Iteration 17573, Loss: 0.05398900806903839\n",
      "Iteration 17574, Loss: 0.05417179316282272\n",
      "Iteration 17575, Loss: 0.05398900806903839\n",
      "Iteration 17576, Loss: 0.054171763360500336\n",
      "Iteration 17577, Loss: 0.05398896336555481\n",
      "Iteration 17578, Loss: 0.05417183041572571\n",
      "Iteration 17579, Loss: 0.05398892983794212\n",
      "Iteration 17580, Loss: 0.054171763360500336\n",
      "Iteration 17581, Loss: 0.053988926112651825\n",
      "Iteration 17582, Loss: 0.054171763360500336\n",
      "Iteration 17583, Loss: 0.05398888885974884\n",
      "Iteration 17584, Loss: 0.054171763360500336\n",
      "Iteration 17585, Loss: 0.053988851606845856\n",
      "Iteration 17586, Loss: 0.0541718415915966\n",
      "Iteration 17587, Loss: 0.05398893356323242\n",
      "Iteration 17588, Loss: 0.05417168140411377\n",
      "Iteration 17589, Loss: 0.05398893356323242\n",
      "Iteration 17590, Loss: 0.054171718657016754\n",
      "Iteration 17591, Loss: 0.05398889631032944\n",
      "Iteration 17592, Loss: 0.05417175590991974\n",
      "Iteration 17593, Loss: 0.05398889631032944\n",
      "Iteration 17594, Loss: 0.05417183041572571\n",
      "Iteration 17595, Loss: 0.05398909002542496\n",
      "Iteration 17596, Loss: 0.05417167767882347\n",
      "Iteration 17597, Loss: 0.053989164531230927\n",
      "Iteration 17598, Loss: 0.05417179316282272\n",
      "Iteration 17599, Loss: 0.05398896336555481\n",
      "Iteration 17600, Loss: 0.05417180061340332\n",
      "Iteration 17601, Loss: 0.053988851606845856\n",
      "Iteration 17602, Loss: 0.05417180061340332\n",
      "Iteration 17603, Loss: 0.05398881435394287\n",
      "Iteration 17604, Loss: 0.05417194962501526\n",
      "Iteration 17605, Loss: 0.05398888885974884\n",
      "Iteration 17606, Loss: 0.05417179316282272\n",
      "Iteration 17607, Loss: 0.053989164531230927\n",
      "Iteration 17608, Loss: 0.054171591997146606\n",
      "Iteration 17609, Loss: 0.053989361971616745\n",
      "Iteration 17610, Loss: 0.0541713647544384\n",
      "Iteration 17611, Loss: 0.05398944020271301\n",
      "Iteration 17612, Loss: 0.05417124181985855\n",
      "Iteration 17613, Loss: 0.053989559412002563\n",
      "Iteration 17614, Loss: 0.05417117476463318\n",
      "Iteration 17615, Loss: 0.05398951470851898\n",
      "Iteration 17616, Loss: 0.05417148396372795\n",
      "Iteration 17617, Loss: 0.053989242762327194\n",
      "Iteration 17618, Loss: 0.05417175218462944\n",
      "Iteration 17619, Loss: 0.053988970816135406\n",
      "Iteration 17620, Loss: 0.05417180061340332\n",
      "Iteration 17621, Loss: 0.053988855332136154\n",
      "Iteration 17622, Loss: 0.0541718415915966\n",
      "Iteration 17623, Loss: 0.05398881435394287\n",
      "Iteration 17624, Loss: 0.05417187139391899\n",
      "Iteration 17625, Loss: 0.05398900434374809\n",
      "Iteration 17626, Loss: 0.05417186766862869\n",
      "Iteration 17627, Loss: 0.05398893356323242\n",
      "Iteration 17628, Loss: 0.05417178198695183\n",
      "Iteration 17629, Loss: 0.053989049047231674\n",
      "Iteration 17630, Loss: 0.05417163297533989\n",
      "Iteration 17631, Loss: 0.05398931726813316\n",
      "Iteration 17632, Loss: 0.05417151749134064\n",
      "Iteration 17633, Loss: 0.05398932099342346\n",
      "Iteration 17634, Loss: 0.05417151376605034\n",
      "Iteration 17635, Loss: 0.05398940294981003\n",
      "Iteration 17636, Loss: 0.05417143926024437\n",
      "Iteration 17637, Loss: 0.053989361971616745\n",
      "Iteration 17638, Loss: 0.054171256721019745\n",
      "Iteration 17639, Loss: 0.05398924648761749\n",
      "Iteration 17640, Loss: 0.054171375930309296\n",
      "Iteration 17641, Loss: 0.053989313542842865\n",
      "Iteration 17642, Loss: 0.054171591997146606\n",
      "Iteration 17643, Loss: 0.05398908257484436\n",
      "Iteration 17644, Loss: 0.05417156219482422\n",
      "Iteration 17645, Loss: 0.05398896336555481\n",
      "Iteration 17646, Loss: 0.0541716031730175\n",
      "Iteration 17647, Loss: 0.05398893356323242\n",
      "Iteration 17648, Loss: 0.05417171120643616\n",
      "Iteration 17649, Loss: 0.05398909002542496\n",
      "Iteration 17650, Loss: 0.05417179316282272\n",
      "Iteration 17651, Loss: 0.05398908257484436\n",
      "Iteration 17652, Loss: 0.054171524941921234\n",
      "Iteration 17653, Loss: 0.05398900806903839\n",
      "Iteration 17654, Loss: 0.054171569645404816\n",
      "Iteration 17655, Loss: 0.05398893356323242\n",
      "Iteration 17656, Loss: 0.054171718657016754\n",
      "Iteration 17657, Loss: 0.053989045321941376\n",
      "Iteration 17658, Loss: 0.05417164787650108\n",
      "Iteration 17659, Loss: 0.05398888885974884\n",
      "Iteration 17660, Loss: 0.05417183041572571\n",
      "Iteration 17661, Loss: 0.053989045321941376\n",
      "Iteration 17662, Loss: 0.05417175218462944\n",
      "Iteration 17663, Loss: 0.05398908257484436\n",
      "Iteration 17664, Loss: 0.054171644151210785\n",
      "Iteration 17665, Loss: 0.05398920178413391\n",
      "Iteration 17666, Loss: 0.05417140945792198\n",
      "Iteration 17667, Loss: 0.053989239037036896\n",
      "Iteration 17668, Loss: 0.054171524941921234\n",
      "Iteration 17669, Loss: 0.05398912355303764\n",
      "Iteration 17670, Loss: 0.0541716031730175\n",
      "Iteration 17671, Loss: 0.05398909002542496\n",
      "Iteration 17672, Loss: 0.05417168140411377\n",
      "Iteration 17673, Loss: 0.053988970816135406\n",
      "Iteration 17674, Loss: 0.05417163670063019\n",
      "Iteration 17675, Loss: 0.053988855332136154\n",
      "Iteration 17676, Loss: 0.05417172238230705\n",
      "Iteration 17677, Loss: 0.05398889631032944\n",
      "Iteration 17678, Loss: 0.05417180061340332\n",
      "Iteration 17679, Loss: 0.05398881435394287\n",
      "Iteration 17680, Loss: 0.05417183041572571\n",
      "Iteration 17681, Loss: 0.053989045321941376\n",
      "Iteration 17682, Loss: 0.05417190119624138\n",
      "Iteration 17683, Loss: 0.053989049047231674\n",
      "Iteration 17684, Loss: 0.05417175218462944\n",
      "Iteration 17685, Loss: 0.053989045321941376\n",
      "Iteration 17686, Loss: 0.05417167767882347\n",
      "Iteration 17687, Loss: 0.05398908257484436\n",
      "Iteration 17688, Loss: 0.05417175218462944\n",
      "Iteration 17689, Loss: 0.05398908257484436\n",
      "Iteration 17690, Loss: 0.05417171120643616\n",
      "Iteration 17691, Loss: 0.05398912355303764\n",
      "Iteration 17692, Loss: 0.054171591997146606\n",
      "Iteration 17693, Loss: 0.05398920178413391\n",
      "Iteration 17694, Loss: 0.05417155474424362\n",
      "Iteration 17695, Loss: 0.053989242762327194\n",
      "Iteration 17696, Loss: 0.054171331226825714\n",
      "Iteration 17697, Loss: 0.05398940294981003\n",
      "Iteration 17698, Loss: 0.0541713610291481\n",
      "Iteration 17699, Loss: 0.05398940294981003\n",
      "Iteration 17700, Loss: 0.05417143553495407\n",
      "Iteration 17701, Loss: 0.05398940294981003\n",
      "Iteration 17702, Loss: 0.054171398282051086\n",
      "Iteration 17703, Loss: 0.053989361971616745\n",
      "Iteration 17704, Loss: 0.05417133495211601\n",
      "Iteration 17705, Loss: 0.05398932099342346\n",
      "Iteration 17706, Loss: 0.05417167395353317\n",
      "Iteration 17707, Loss: 0.05398900806903839\n",
      "Iteration 17708, Loss: 0.05417183041572571\n",
      "Iteration 17709, Loss: 0.05398888513445854\n",
      "Iteration 17710, Loss: 0.054172076284885406\n",
      "Iteration 17711, Loss: 0.05398865044116974\n",
      "Iteration 17712, Loss: 0.05417214334011078\n",
      "Iteration 17713, Loss: 0.05398888513445854\n",
      "Iteration 17714, Loss: 0.05417187139391899\n",
      "Iteration 17715, Loss: 0.053989049047231674\n",
      "Iteration 17716, Loss: 0.05417162925004959\n",
      "Iteration 17717, Loss: 0.05398928374052048\n",
      "Iteration 17718, Loss: 0.05417148023843765\n",
      "Iteration 17719, Loss: 0.05398951470851898\n",
      "Iteration 17720, Loss: 0.05417124554514885\n",
      "Iteration 17721, Loss: 0.053989559412002563\n",
      "Iteration 17722, Loss: 0.05417117103934288\n",
      "Iteration 17723, Loss: 0.05398940667510033\n",
      "Iteration 17724, Loss: 0.05417140573263168\n",
      "Iteration 17725, Loss: 0.053989239037036896\n",
      "Iteration 17726, Loss: 0.054171644151210785\n",
      "Iteration 17727, Loss: 0.05398912355303764\n",
      "Iteration 17728, Loss: 0.05417180061340332\n",
      "Iteration 17729, Loss: 0.053988855332136154\n",
      "Iteration 17730, Loss: 0.05417191609740257\n",
      "Iteration 17731, Loss: 0.05398881062865257\n",
      "Iteration 17732, Loss: 0.054171882569789886\n",
      "Iteration 17733, Loss: 0.05398881435394287\n",
      "Iteration 17734, Loss: 0.05417180061340332\n",
      "Iteration 17735, Loss: 0.05398888513445854\n",
      "Iteration 17736, Loss: 0.05417183041572571\n",
      "Iteration 17737, Loss: 0.05398908257484436\n",
      "Iteration 17738, Loss: 0.054171718657016754\n",
      "Iteration 17739, Loss: 0.053989168256521225\n",
      "Iteration 17740, Loss: 0.05417163297533989\n",
      "Iteration 17741, Loss: 0.05398928374052048\n",
      "Iteration 17742, Loss: 0.05417155474424362\n",
      "Iteration 17743, Loss: 0.05398920923471451\n",
      "Iteration 17744, Loss: 0.05417141318321228\n",
      "Iteration 17745, Loss: 0.053989242762327194\n",
      "Iteration 17746, Loss: 0.05417168140411377\n",
      "Iteration 17747, Loss: 0.05398908257484436\n",
      "Iteration 17748, Loss: 0.054171837866306305\n",
      "Iteration 17749, Loss: 0.05398896336555481\n",
      "Iteration 17750, Loss: 0.05417191609740257\n",
      "Iteration 17751, Loss: 0.05398881062865257\n",
      "Iteration 17752, Loss: 0.0541718415915966\n",
      "Iteration 17753, Loss: 0.05398876965045929\n",
      "Iteration 17754, Loss: 0.05417179688811302\n",
      "Iteration 17755, Loss: 0.053989045321941376\n",
      "Iteration 17756, Loss: 0.05417163297533989\n",
      "Iteration 17757, Loss: 0.053989242762327194\n",
      "Iteration 17758, Loss: 0.05417128652334213\n",
      "Iteration 17759, Loss: 0.05398952215909958\n",
      "Iteration 17760, Loss: 0.05417124554514885\n",
      "Iteration 17761, Loss: 0.053989481180906296\n",
      "Iteration 17762, Loss: 0.054171331226825714\n",
      "Iteration 17763, Loss: 0.053989242762327194\n",
      "Iteration 17764, Loss: 0.0541716031730175\n",
      "Iteration 17765, Loss: 0.05398912355303764\n",
      "Iteration 17766, Loss: 0.05417164787650108\n",
      "Iteration 17767, Loss: 0.053988970816135406\n",
      "Iteration 17768, Loss: 0.05417194962501526\n",
      "Iteration 17769, Loss: 0.05398881062865257\n",
      "Iteration 17770, Loss: 0.054171763360500336\n",
      "Iteration 17771, Loss: 0.053988926112651825\n",
      "Iteration 17772, Loss: 0.054171912372112274\n",
      "Iteration 17773, Loss: 0.05398900434374809\n",
      "Iteration 17774, Loss: 0.05417179316282272\n",
      "Iteration 17775, Loss: 0.05398908257484436\n",
      "Iteration 17776, Loss: 0.05417167395353317\n",
      "Iteration 17777, Loss: 0.053989164531230927\n",
      "Iteration 17778, Loss: 0.05417163297533989\n",
      "Iteration 17779, Loss: 0.05398920178413391\n",
      "Iteration 17780, Loss: 0.05417152866721153\n",
      "Iteration 17781, Loss: 0.05398912355303764\n",
      "Iteration 17782, Loss: 0.054171763360500336\n",
      "Iteration 17783, Loss: 0.053988926112651825\n",
      "Iteration 17784, Loss: 0.05417183041572571\n",
      "Iteration 17785, Loss: 0.05398892983794212\n",
      "Iteration 17786, Loss: 0.05417179316282272\n",
      "Iteration 17787, Loss: 0.05398905277252197\n",
      "Iteration 17788, Loss: 0.05417167767882347\n",
      "Iteration 17789, Loss: 0.053989093750715256\n",
      "Iteration 17790, Loss: 0.054171591997146606\n",
      "Iteration 17791, Loss: 0.05398920178413391\n",
      "Iteration 17792, Loss: 0.05417156219482422\n",
      "Iteration 17793, Loss: 0.05398920178413391\n",
      "Iteration 17794, Loss: 0.054171644151210785\n",
      "Iteration 17795, Loss: 0.05398908257484436\n",
      "Iteration 17796, Loss: 0.054171837866306305\n",
      "Iteration 17797, Loss: 0.05398896336555481\n",
      "Iteration 17798, Loss: 0.05417168140411377\n",
      "Iteration 17799, Loss: 0.05398900434374809\n",
      "Iteration 17800, Loss: 0.05417183041572571\n",
      "Iteration 17801, Loss: 0.05398900806903839\n",
      "Iteration 17802, Loss: 0.05417182296514511\n",
      "Iteration 17803, Loss: 0.053989049047231674\n",
      "Iteration 17804, Loss: 0.05417167395353317\n",
      "Iteration 17805, Loss: 0.05398912727832794\n",
      "Iteration 17806, Loss: 0.054171591997146606\n",
      "Iteration 17807, Loss: 0.053989239037036896\n",
      "Iteration 17808, Loss: 0.054171524941921234\n",
      "Iteration 17809, Loss: 0.053989242762327194\n",
      "Iteration 17810, Loss: 0.05417155474424362\n",
      "Iteration 17811, Loss: 0.05398932099342346\n",
      "Iteration 17812, Loss: 0.05417140945792198\n",
      "Iteration 17813, Loss: 0.05398912727832794\n",
      "Iteration 17814, Loss: 0.0541716031730175\n",
      "Iteration 17815, Loss: 0.05398909002542496\n",
      "Iteration 17816, Loss: 0.05417156219482422\n",
      "Iteration 17817, Loss: 0.053989045321941376\n",
      "Iteration 17818, Loss: 0.054171718657016754\n",
      "Iteration 17819, Loss: 0.05398900806903839\n",
      "Iteration 17820, Loss: 0.05417171120643616\n",
      "Iteration 17821, Loss: 0.05398900806903839\n",
      "Iteration 17822, Loss: 0.05417175218462944\n",
      "Iteration 17823, Loss: 0.053988974541425705\n",
      "Iteration 17824, Loss: 0.05417182296514511\n",
      "Iteration 17825, Loss: 0.05398912355303764\n",
      "Iteration 17826, Loss: 0.0541716031730175\n",
      "Iteration 17827, Loss: 0.05398908257484436\n",
      "Iteration 17828, Loss: 0.054171644151210785\n",
      "Iteration 17829, Loss: 0.05398900806903839\n",
      "Iteration 17830, Loss: 0.05417175218462944\n",
      "Iteration 17831, Loss: 0.05398900434374809\n",
      "Iteration 17832, Loss: 0.0541718415915966\n",
      "Iteration 17833, Loss: 0.05398896336555481\n",
      "Iteration 17834, Loss: 0.05417191609740257\n",
      "Iteration 17835, Loss: 0.0539887361228466\n",
      "Iteration 17836, Loss: 0.0541718415915966\n",
      "Iteration 17837, Loss: 0.053988777101039886\n",
      "Iteration 17838, Loss: 0.05417177081108093\n",
      "Iteration 17839, Loss: 0.053988926112651825\n",
      "Iteration 17840, Loss: 0.05417183041572571\n",
      "Iteration 17841, Loss: 0.053989049047231674\n",
      "Iteration 17842, Loss: 0.054171718657016754\n",
      "Iteration 17843, Loss: 0.05398927628993988\n",
      "Iteration 17844, Loss: 0.054171524941921234\n",
      "Iteration 17845, Loss: 0.05398932844400406\n",
      "Iteration 17846, Loss: 0.05417151376605034\n",
      "Iteration 17847, Loss: 0.053989361971616745\n",
      "Iteration 17848, Loss: 0.054171524941921234\n",
      "Iteration 17849, Loss: 0.05398920178413391\n",
      "Iteration 17850, Loss: 0.05417168140411377\n",
      "Iteration 17851, Loss: 0.053988974541425705\n",
      "Iteration 17852, Loss: 0.05417180061340332\n",
      "Iteration 17853, Loss: 0.05398892983794212\n",
      "Iteration 17854, Loss: 0.05417187511920929\n",
      "Iteration 17855, Loss: 0.0539887361228466\n",
      "Iteration 17856, Loss: 0.05417194962501526\n",
      "Iteration 17857, Loss: 0.053988926112651825\n",
      "Iteration 17858, Loss: 0.05417183041572571\n",
      "Iteration 17859, Loss: 0.05398908257484436\n",
      "Iteration 17860, Loss: 0.054171524941921234\n",
      "Iteration 17861, Loss: 0.05398912355303764\n",
      "Iteration 17862, Loss: 0.05417167767882347\n",
      "Iteration 17863, Loss: 0.05398908257484436\n",
      "Iteration 17864, Loss: 0.054171718657016754\n",
      "Iteration 17865, Loss: 0.053989045321941376\n",
      "Iteration 17866, Loss: 0.05417180061340332\n",
      "Iteration 17867, Loss: 0.05398893356323242\n",
      "Iteration 17868, Loss: 0.0541718415915966\n",
      "Iteration 17869, Loss: 0.053988777101039886\n",
      "Iteration 17870, Loss: 0.05417180061340332\n",
      "Iteration 17871, Loss: 0.05398881435394287\n",
      "Iteration 17872, Loss: 0.05417180061340332\n",
      "Iteration 17873, Loss: 0.053988855332136154\n",
      "Iteration 17874, Loss: 0.0541718415915966\n",
      "Iteration 17875, Loss: 0.05398881435394287\n",
      "Iteration 17876, Loss: 0.05417180061340332\n",
      "Iteration 17877, Loss: 0.053988780826330185\n",
      "Iteration 17878, Loss: 0.054171763360500336\n",
      "Iteration 17879, Loss: 0.053988926112651825\n",
      "Iteration 17880, Loss: 0.054171763360500336\n",
      "Iteration 17881, Loss: 0.05398900434374809\n",
      "Iteration 17882, Loss: 0.054171763360500336\n",
      "Iteration 17883, Loss: 0.053988855332136154\n",
      "Iteration 17884, Loss: 0.05417187511920929\n",
      "Iteration 17885, Loss: 0.053988855332136154\n",
      "Iteration 17886, Loss: 0.05417172610759735\n",
      "Iteration 17887, Loss: 0.05398888513445854\n",
      "Iteration 17888, Loss: 0.05417187139391899\n",
      "Iteration 17889, Loss: 0.05398896336555481\n",
      "Iteration 17890, Loss: 0.05417171120643616\n",
      "Iteration 17891, Loss: 0.053989164531230927\n",
      "Iteration 17892, Loss: 0.05417156219482422\n",
      "Iteration 17893, Loss: 0.05398932099342346\n",
      "Iteration 17894, Loss: 0.05417148023843765\n",
      "Iteration 17895, Loss: 0.05398932844400406\n",
      "Iteration 17896, Loss: 0.054171331226825714\n",
      "Iteration 17897, Loss: 0.05398928374052048\n",
      "Iteration 17898, Loss: 0.05417148396372795\n",
      "Iteration 17899, Loss: 0.05398912355303764\n",
      "Iteration 17900, Loss: 0.05417172238230705\n",
      "Iteration 17901, Loss: 0.05398901551961899\n",
      "Iteration 17902, Loss: 0.05417187511920929\n",
      "Iteration 17903, Loss: 0.053988926112651825\n",
      "Iteration 17904, Loss: 0.05417191982269287\n",
      "Iteration 17905, Loss: 0.05398869514465332\n",
      "Iteration 17906, Loss: 0.05417202040553093\n",
      "Iteration 17907, Loss: 0.053988926112651825\n",
      "Iteration 17908, Loss: 0.05417179316282272\n",
      "Iteration 17909, Loss: 0.05398908257484436\n",
      "Iteration 17910, Loss: 0.05417151376605034\n",
      "Iteration 17911, Loss: 0.053989361971616745\n",
      "Iteration 17912, Loss: 0.05417143553495407\n",
      "Iteration 17913, Loss: 0.05398940294981003\n",
      "Iteration 17914, Loss: 0.05417124554514885\n",
      "Iteration 17915, Loss: 0.053989361971616745\n",
      "Iteration 17916, Loss: 0.05417144298553467\n",
      "Iteration 17917, Loss: 0.05398920178413391\n",
      "Iteration 17918, Loss: 0.05417172238230705\n",
      "Iteration 17919, Loss: 0.05398900806903839\n",
      "Iteration 17920, Loss: 0.054171882569789886\n",
      "Iteration 17921, Loss: 0.05398888513445854\n",
      "Iteration 17922, Loss: 0.05417192727327347\n",
      "Iteration 17923, Loss: 0.05398881062865257\n",
      "Iteration 17924, Loss: 0.054171960800886154\n",
      "Iteration 17925, Loss: 0.0539887361228466\n",
      "Iteration 17926, Loss: 0.05417191982269287\n",
      "Iteration 17927, Loss: 0.05398881062865257\n",
      "Iteration 17928, Loss: 0.05417187511920929\n",
      "Iteration 17929, Loss: 0.053989045321941376\n",
      "Iteration 17930, Loss: 0.05417171120643616\n",
      "Iteration 17931, Loss: 0.05398912355303764\n",
      "Iteration 17932, Loss: 0.05417144298553467\n",
      "Iteration 17933, Loss: 0.053989432752132416\n",
      "Iteration 17934, Loss: 0.05417143553495407\n",
      "Iteration 17935, Loss: 0.05398940294981003\n",
      "Iteration 17936, Loss: 0.05417132377624512\n",
      "Iteration 17937, Loss: 0.053989361971616745\n",
      "Iteration 17938, Loss: 0.05417140573263168\n",
      "Iteration 17939, Loss: 0.053989168256521225\n",
      "Iteration 17940, Loss: 0.05417148396372795\n",
      "Iteration 17941, Loss: 0.05398909002542496\n",
      "Iteration 17942, Loss: 0.0541716031730175\n",
      "Iteration 17943, Loss: 0.05398909002542496\n",
      "Iteration 17944, Loss: 0.054171524941921234\n",
      "Iteration 17945, Loss: 0.05398901551961899\n",
      "Iteration 17946, Loss: 0.054171763360500336\n",
      "Iteration 17947, Loss: 0.05398896336555481\n",
      "Iteration 17948, Loss: 0.05417172238230705\n",
      "Iteration 17949, Loss: 0.05398900434374809\n",
      "Iteration 17950, Loss: 0.05417183041572571\n",
      "Iteration 17951, Loss: 0.053988974541425705\n",
      "Iteration 17952, Loss: 0.0541716031730175\n",
      "Iteration 17953, Loss: 0.05398900434374809\n",
      "Iteration 17954, Loss: 0.05417167767882347\n",
      "Iteration 17955, Loss: 0.053989045321941376\n",
      "Iteration 17956, Loss: 0.05417167767882347\n",
      "Iteration 17957, Loss: 0.05398892983794212\n",
      "Iteration 17958, Loss: 0.05417163670063019\n",
      "Iteration 17959, Loss: 0.053989045321941376\n",
      "Iteration 17960, Loss: 0.05417163670063019\n",
      "Iteration 17961, Loss: 0.053989242762327194\n",
      "Iteration 17962, Loss: 0.05417143926024437\n",
      "Iteration 17963, Loss: 0.053989432752132416\n",
      "Iteration 17964, Loss: 0.05417139455676079\n",
      "Iteration 17965, Loss: 0.05398867651820183\n",
      "Iteration 17966, Loss: 0.054171353578567505\n",
      "Iteration 17967, Loss: 0.053988903760910034\n",
      "Iteration 17968, Loss: 0.05417066812515259\n",
      "Iteration 17969, Loss: 0.053988780826330185\n",
      "Iteration 17970, Loss: 0.05417093634605408\n",
      "Iteration 17971, Loss: 0.05398854613304138\n",
      "Iteration 17972, Loss: 0.05417117476463318\n",
      "Iteration 17973, Loss: 0.05398822948336601\n",
      "Iteration 17974, Loss: 0.054171301424503326\n",
      "Iteration 17975, Loss: 0.053988151252269745\n",
      "Iteration 17976, Loss: 0.05417118966579437\n",
      "Iteration 17977, Loss: 0.05398822948336601\n",
      "Iteration 17978, Loss: 0.054171256721019745\n",
      "Iteration 17979, Loss: 0.053988389670848846\n",
      "Iteration 17980, Loss: 0.05417101830244064\n",
      "Iteration 17981, Loss: 0.0539885088801384\n",
      "Iteration 17982, Loss: 0.05417073890566826\n",
      "Iteration 17983, Loss: 0.0539887472987175\n",
      "Iteration 17984, Loss: 0.05417066067457199\n",
      "Iteration 17985, Loss: 0.053988825529813766\n",
      "Iteration 17986, Loss: 0.054170697927474976\n",
      "Iteration 17987, Loss: 0.053988706320524216\n",
      "Iteration 17988, Loss: 0.05417085811495781\n",
      "Iteration 17989, Loss: 0.053988512605428696\n",
      "Iteration 17990, Loss: 0.05417102575302124\n",
      "Iteration 17991, Loss: 0.05398831516504288\n",
      "Iteration 17992, Loss: 0.054171107709407806\n",
      "Iteration 17993, Loss: 0.05398822948336601\n",
      "Iteration 17994, Loss: 0.054171256721019745\n",
      "Iteration 17995, Loss: 0.053988195955753326\n",
      "Iteration 17996, Loss: 0.05417121574282646\n",
      "Iteration 17997, Loss: 0.05398815870285034\n",
      "Iteration 17998, Loss: 0.05417121574282646\n",
      "Iteration 17999, Loss: 0.05398815497756004\n",
      "Iteration 18000, Loss: 0.05417117476463318\n",
      "Iteration 18001, Loss: 0.053988274186849594\n",
      "Iteration 18002, Loss: 0.05417124554514885\n",
      "Iteration 18003, Loss: 0.053988389670848846\n",
      "Iteration 18004, Loss: 0.05417116731405258\n",
      "Iteration 18005, Loss: 0.05398854613304138\n",
      "Iteration 18006, Loss: 0.05417105555534363\n",
      "Iteration 18007, Loss: 0.0539885088801384\n",
      "Iteration 18008, Loss: 0.05417101830244064\n",
      "Iteration 18009, Loss: 0.0539885088801384\n",
      "Iteration 18010, Loss: 0.05417090281844139\n",
      "Iteration 18011, Loss: 0.053988318890333176\n",
      "Iteration 18012, Loss: 0.05417105555534363\n",
      "Iteration 18013, Loss: 0.05398831516504288\n",
      "Iteration 18014, Loss: 0.05417114123702049\n",
      "Iteration 18015, Loss: 0.05398815870285034\n",
      "Iteration 18016, Loss: 0.05417121574282646\n",
      "Iteration 18017, Loss: 0.05398815870285034\n",
      "Iteration 18018, Loss: 0.05417116731405258\n",
      "Iteration 18019, Loss: 0.053988393396139145\n",
      "Iteration 18020, Loss: 0.05417097732424736\n",
      "Iteration 18021, Loss: 0.053988661617040634\n",
      "Iteration 18022, Loss: 0.054170817136764526\n",
      "Iteration 18023, Loss: 0.053988706320524216\n",
      "Iteration 18024, Loss: 0.05417082458734512\n",
      "Iteration 18025, Loss: 0.05398862063884735\n",
      "Iteration 18026, Loss: 0.05417089909315109\n",
      "Iteration 18027, Loss: 0.053988587111234665\n",
      "Iteration 18028, Loss: 0.05417098104953766\n",
      "Iteration 18029, Loss: 0.05398834869265556\n",
      "Iteration 18030, Loss: 0.054171063005924225\n",
      "Iteration 18031, Loss: 0.05398830771446228\n",
      "Iteration 18032, Loss: 0.05417124554514885\n",
      "Iteration 18033, Loss: 0.05398834869265556\n",
      "Iteration 18034, Loss: 0.05417097732424736\n",
      "Iteration 18035, Loss: 0.05398835986852646\n",
      "Iteration 18036, Loss: 0.05417093634605408\n",
      "Iteration 18037, Loss: 0.05398862808942795\n",
      "Iteration 18038, Loss: 0.05417089909315109\n",
      "Iteration 18039, Loss: 0.053988706320524216\n",
      "Iteration 18040, Loss: 0.05417085811495781\n",
      "Iteration 18041, Loss: 0.05398866534233093\n",
      "Iteration 18042, Loss: 0.05417086184024811\n",
      "Iteration 18043, Loss: 0.053988657891750336\n",
      "Iteration 18044, Loss: 0.05417109653353691\n",
      "Iteration 18045, Loss: 0.053988270461559296\n",
      "Iteration 18046, Loss: 0.054171331226825714\n",
      "Iteration 18047, Loss: 0.05398818850517273\n",
      "Iteration 18048, Loss: 0.05417129397392273\n",
      "Iteration 18049, Loss: 0.05398811399936676\n",
      "Iteration 18050, Loss: 0.05417141318321228\n",
      "Iteration 18051, Loss: 0.053988076746463776\n",
      "Iteration 18052, Loss: 0.05417126044631004\n",
      "Iteration 18053, Loss: 0.05398812144994736\n",
      "Iteration 18054, Loss: 0.05417121574282646\n",
      "Iteration 18055, Loss: 0.05398842692375183\n",
      "Iteration 18056, Loss: 0.05417101830244064\n",
      "Iteration 18057, Loss: 0.05398854613304138\n",
      "Iteration 18058, Loss: 0.05417085811495781\n",
      "Iteration 18059, Loss: 0.05398866534233093\n",
      "Iteration 18060, Loss: 0.05417070910334587\n",
      "Iteration 18061, Loss: 0.05398869514465332\n",
      "Iteration 18062, Loss: 0.05417075380682945\n",
      "Iteration 18063, Loss: 0.05398854613304138\n",
      "Iteration 18064, Loss: 0.054170720279216766\n",
      "Iteration 18065, Loss: 0.0539885088801384\n",
      "Iteration 18066, Loss: 0.054170794785022736\n",
      "Iteration 18067, Loss: 0.053988318890333176\n",
      "Iteration 18068, Loss: 0.05417086184024811\n",
      "Iteration 18069, Loss: 0.0539885088801384\n",
      "Iteration 18070, Loss: 0.05417082831263542\n",
      "Iteration 18071, Loss: 0.0539885088801384\n",
      "Iteration 18072, Loss: 0.054170794785022736\n",
      "Iteration 18073, Loss: 0.05398843437433243\n",
      "Iteration 18074, Loss: 0.05417090654373169\n",
      "Iteration 18075, Loss: 0.053988467901945114\n",
      "Iteration 18076, Loss: 0.054171063005924225\n",
      "Iteration 18077, Loss: 0.053988393396139145\n",
      "Iteration 18078, Loss: 0.05417121574282646\n",
      "Iteration 18079, Loss: 0.053988195955753326\n",
      "Iteration 18080, Loss: 0.05417141318321228\n",
      "Iteration 18081, Loss: 0.05398799106478691\n",
      "Iteration 18082, Loss: 0.054171349853277206\n",
      "Iteration 18083, Loss: 0.053987957537174225\n",
      "Iteration 18084, Loss: 0.05417133495211601\n",
      "Iteration 18085, Loss: 0.05398818850517273\n",
      "Iteration 18086, Loss: 0.05417106673121452\n",
      "Iteration 18087, Loss: 0.053988389670848846\n",
      "Iteration 18088, Loss: 0.05417074263095856\n",
      "Iteration 18089, Loss: 0.05398859828710556\n",
      "Iteration 18090, Loss: 0.05417051166296005\n",
      "Iteration 18091, Loss: 0.05398894101381302\n",
      "Iteration 18092, Loss: 0.05417058616876602\n",
      "Iteration 18093, Loss: 0.0539887472987175\n",
      "Iteration 18094, Loss: 0.0541706308722496\n",
      "Iteration 18095, Loss: 0.05398881435394287\n",
      "Iteration 18096, Loss: 0.05417082831263542\n",
      "Iteration 18097, Loss: 0.05398854613304138\n",
      "Iteration 18098, Loss: 0.05417109653353691\n",
      "Iteration 18099, Loss: 0.053988270461559296\n",
      "Iteration 18100, Loss: 0.054171305149793625\n",
      "Iteration 18101, Loss: 0.053988002240657806\n",
      "Iteration 18102, Loss: 0.05417138338088989\n",
      "Iteration 18103, Loss: 0.05398803576827049\n",
      "Iteration 18104, Loss: 0.054171331226825714\n",
      "Iteration 18105, Loss: 0.05398834869265556\n",
      "Iteration 18106, Loss: 0.05417116731405258\n",
      "Iteration 18107, Loss: 0.053988389670848846\n",
      "Iteration 18108, Loss: 0.05417074263095856\n",
      "Iteration 18109, Loss: 0.053988710045814514\n",
      "Iteration 18110, Loss: 0.05417054891586304\n",
      "Iteration 18111, Loss: 0.053988900035619736\n",
      "Iteration 18112, Loss: 0.05417051538825035\n",
      "Iteration 18113, Loss: 0.0539887472987175\n",
      "Iteration 18114, Loss: 0.05417070910334587\n",
      "Iteration 18115, Loss: 0.053988587111234665\n",
      "Iteration 18116, Loss: 0.054170988500118256\n",
      "Iteration 18117, Loss: 0.05398834869265556\n",
      "Iteration 18118, Loss: 0.05417106673121452\n",
      "Iteration 18119, Loss: 0.05398824065923691\n",
      "Iteration 18120, Loss: 0.05417114496231079\n",
      "Iteration 18121, Loss: 0.053988199681043625\n",
      "Iteration 18122, Loss: 0.05417106673121452\n",
      "Iteration 18123, Loss: 0.053988199681043625\n",
      "Iteration 18124, Loss: 0.05417106673121452\n",
      "Iteration 18125, Loss: 0.05398815870285034\n",
      "Iteration 18126, Loss: 0.05417110025882721\n",
      "Iteration 18127, Loss: 0.053988393396139145\n",
      "Iteration 18128, Loss: 0.05417097732424736\n",
      "Iteration 18129, Loss: 0.053988587111234665\n",
      "Iteration 18130, Loss: 0.05417085811495781\n",
      "Iteration 18131, Loss: 0.05398859828710556\n",
      "Iteration 18132, Loss: 0.05417078733444214\n",
      "Iteration 18133, Loss: 0.053988587111234665\n",
      "Iteration 18134, Loss: 0.05417086184024811\n",
      "Iteration 18135, Loss: 0.05398839712142944\n",
      "Iteration 18136, Loss: 0.05417082831263542\n",
      "Iteration 18137, Loss: 0.05398839712142944\n",
      "Iteration 18138, Loss: 0.054170988500118256\n",
      "Iteration 18139, Loss: 0.053988393396139145\n",
      "Iteration 18140, Loss: 0.05417094752192497\n",
      "Iteration 18141, Loss: 0.05398831516504288\n",
      "Iteration 18142, Loss: 0.054170988500118256\n",
      "Iteration 18143, Loss: 0.05398835986852646\n",
      "Iteration 18144, Loss: 0.05417102575302124\n",
      "Iteration 18145, Loss: 0.05398824065923691\n",
      "Iteration 18146, Loss: 0.054171111434698105\n",
      "Iteration 18147, Loss: 0.05398815870285034\n",
      "Iteration 18148, Loss: 0.054171036928892136\n",
      "Iteration 18149, Loss: 0.05398803949356079\n",
      "Iteration 18150, Loss: 0.054171107709407806\n",
      "Iteration 18151, Loss: 0.05398812144994736\n",
      "Iteration 18152, Loss: 0.054171107709407806\n",
      "Iteration 18153, Loss: 0.05398812144994736\n",
      "Iteration 18154, Loss: 0.054171137511730194\n",
      "Iteration 18155, Loss: 0.053988318890333176\n",
      "Iteration 18156, Loss: 0.05417101830244064\n",
      "Iteration 18157, Loss: 0.05398862808942795\n",
      "Iteration 18158, Loss: 0.05417078733444214\n",
      "Iteration 18159, Loss: 0.05398866534233093\n",
      "Iteration 18160, Loss: 0.05417066812515259\n",
      "Iteration 18161, Loss: 0.05398871749639511\n",
      "Iteration 18162, Loss: 0.05417074263095856\n",
      "Iteration 18163, Loss: 0.05398866534233093\n",
      "Iteration 18164, Loss: 0.054170794785022736\n",
      "Iteration 18165, Loss: 0.053988512605428696\n",
      "Iteration 18166, Loss: 0.054170988500118256\n",
      "Iteration 18167, Loss: 0.05398834869265556\n",
      "Iteration 18168, Loss: 0.054171107709407806\n",
      "Iteration 18169, Loss: 0.05398812144994736\n",
      "Iteration 18170, Loss: 0.05417107045650482\n",
      "Iteration 18171, Loss: 0.053988080471754074\n",
      "Iteration 18172, Loss: 0.054171036928892136\n",
      "Iteration 18173, Loss: 0.05398812144994736\n",
      "Iteration 18174, Loss: 0.054171137511730194\n",
      "Iteration 18175, Loss: 0.05398835986852646\n",
      "Iteration 18176, Loss: 0.05417101830244064\n",
      "Iteration 18177, Loss: 0.05398862808942795\n",
      "Iteration 18178, Loss: 0.054170675575733185\n",
      "Iteration 18179, Loss: 0.05398866534233093\n",
      "Iteration 18180, Loss: 0.054170750081539154\n",
      "Iteration 18181, Loss: 0.05398867279291153\n",
      "Iteration 18182, Loss: 0.05417070910334587\n",
      "Iteration 18183, Loss: 0.053988587111234665\n",
      "Iteration 18184, Loss: 0.054170794785022736\n",
      "Iteration 18185, Loss: 0.05398839712142944\n",
      "Iteration 18186, Loss: 0.05417094752192497\n",
      "Iteration 18187, Loss: 0.05398824065923691\n",
      "Iteration 18188, Loss: 0.054171107709407806\n",
      "Iteration 18189, Loss: 0.05398830771446228\n",
      "Iteration 18190, Loss: 0.05417114496231079\n",
      "Iteration 18191, Loss: 0.05398815870285034\n",
      "Iteration 18192, Loss: 0.05417102575302124\n",
      "Iteration 18193, Loss: 0.053988151252269745\n",
      "Iteration 18194, Loss: 0.05417121574282646\n",
      "Iteration 18195, Loss: 0.05398835241794586\n",
      "Iteration 18196, Loss: 0.05417093634605408\n",
      "Iteration 18197, Loss: 0.05398862808942795\n",
      "Iteration 18198, Loss: 0.05417078733444214\n",
      "Iteration 18199, Loss: 0.0539887398481369\n",
      "Iteration 18200, Loss: 0.05417058989405632\n",
      "Iteration 18201, Loss: 0.05398859828710556\n",
      "Iteration 18202, Loss: 0.054170750081539154\n",
      "Iteration 18203, Loss: 0.053988512605428696\n",
      "Iteration 18204, Loss: 0.054170988500118256\n",
      "Iteration 18205, Loss: 0.053988274186849594\n",
      "Iteration 18206, Loss: 0.05417122691869736\n",
      "Iteration 18207, Loss: 0.05398812144994736\n",
      "Iteration 18208, Loss: 0.054171036928892136\n",
      "Iteration 18209, Loss: 0.05398812144994736\n",
      "Iteration 18210, Loss: 0.054171107709407806\n",
      "Iteration 18211, Loss: 0.053988199681043625\n",
      "Iteration 18212, Loss: 0.05417101830244064\n",
      "Iteration 18213, Loss: 0.05398843437433243\n",
      "Iteration 18214, Loss: 0.05417089909315109\n",
      "Iteration 18215, Loss: 0.05398847162723541\n",
      "Iteration 18216, Loss: 0.05417077988386154\n",
      "Iteration 18217, Loss: 0.05398881435394287\n",
      "Iteration 18218, Loss: 0.05417074263095856\n",
      "Iteration 18219, Loss: 0.05398870259523392\n",
      "Iteration 18220, Loss: 0.054170750081539154\n",
      "Iteration 18221, Loss: 0.053988583385944366\n",
      "Iteration 18222, Loss: 0.05417094752192497\n",
      "Iteration 18223, Loss: 0.05398824065923691\n",
      "Iteration 18224, Loss: 0.05417102575302124\n",
      "Iteration 18225, Loss: 0.05398815870285034\n",
      "Iteration 18226, Loss: 0.054171063005924225\n",
      "Iteration 18227, Loss: 0.05398824065923691\n",
      "Iteration 18228, Loss: 0.05417109653353691\n",
      "Iteration 18229, Loss: 0.05398827791213989\n",
      "Iteration 18230, Loss: 0.05417089909315109\n",
      "Iteration 18231, Loss: 0.05398855358362198\n",
      "Iteration 18232, Loss: 0.054170869290828705\n",
      "Iteration 18233, Loss: 0.053988631814718246\n",
      "Iteration 18234, Loss: 0.05417082831263542\n",
      "Iteration 18235, Loss: 0.053988512605428696\n",
      "Iteration 18236, Loss: 0.05417082831263542\n",
      "Iteration 18237, Loss: 0.053988318890333176\n",
      "Iteration 18238, Loss: 0.05417117103934288\n",
      "Iteration 18239, Loss: 0.053988199681043625\n",
      "Iteration 18240, Loss: 0.05417106673121452\n",
      "Iteration 18241, Loss: 0.05398815870285034\n",
      "Iteration 18242, Loss: 0.05417121201753616\n",
      "Iteration 18243, Loss: 0.05398827791213989\n",
      "Iteration 18244, Loss: 0.05417086184024811\n",
      "Iteration 18245, Loss: 0.05398847907781601\n",
      "Iteration 18246, Loss: 0.05417061969637871\n",
      "Iteration 18247, Loss: 0.05398878455162048\n",
      "Iteration 18248, Loss: 0.05417027696967125\n",
      "Iteration 18249, Loss: 0.053988873958587646\n",
      "Iteration 18250, Loss: 0.0541701540350914\n",
      "Iteration 18251, Loss: 0.053989142179489136\n",
      "Iteration 18252, Loss: 0.0541701465845108\n",
      "Iteration 18253, Loss: 0.05398918315768242\n",
      "Iteration 18254, Loss: 0.0541701577603817\n",
      "Iteration 18255, Loss: 0.053989022970199585\n",
      "Iteration 18256, Loss: 0.0541706308722496\n",
      "Iteration 18257, Loss: 0.05398862808942795\n",
      "Iteration 18258, Loss: 0.05417067930102348\n",
      "Iteration 18259, Loss: 0.05398839712142944\n",
      "Iteration 18260, Loss: 0.054170869290828705\n",
      "Iteration 18261, Loss: 0.05398835986852646\n",
      "Iteration 18262, Loss: 0.05417075380682945\n",
      "Iteration 18263, Loss: 0.05398847162723541\n",
      "Iteration 18264, Loss: 0.054170891642570496\n",
      "Iteration 18265, Loss: 0.053988587111234665\n",
      "Iteration 18266, Loss: 0.054170697927474976\n",
      "Iteration 18267, Loss: 0.053988780826330185\n",
      "Iteration 18268, Loss: 0.05417061969637871\n",
      "Iteration 18269, Loss: 0.05398893356323242\n",
      "Iteration 18270, Loss: 0.054170578718185425\n",
      "Iteration 18271, Loss: 0.053988825529813766\n",
      "Iteration 18272, Loss: 0.05417043715715408\n",
      "Iteration 18273, Loss: 0.0539887510240078\n",
      "Iteration 18274, Loss: 0.05417073890566826\n",
      "Iteration 18275, Loss: 0.053988706320524216\n",
      "Iteration 18276, Loss: 0.05417070910334587\n",
      "Iteration 18277, Loss: 0.05398862063884735\n",
      "Iteration 18278, Loss: 0.05417070910334587\n",
      "Iteration 18279, Loss: 0.053988661617040634\n",
      "Iteration 18280, Loss: 0.05417077988386154\n",
      "Iteration 18281, Loss: 0.05398866534233093\n",
      "Iteration 18282, Loss: 0.05417061969637871\n",
      "Iteration 18283, Loss: 0.05398867651820183\n",
      "Iteration 18284, Loss: 0.054170578718185425\n",
      "Iteration 18285, Loss: 0.053988900035619736\n",
      "Iteration 18286, Loss: 0.05417054891586304\n",
      "Iteration 18287, Loss: 0.05398886650800705\n",
      "Iteration 18288, Loss: 0.05417058989405632\n",
      "Iteration 18289, Loss: 0.053988631814718246\n",
      "Iteration 18290, Loss: 0.054170750081539154\n",
      "Iteration 18291, Loss: 0.05398847907781601\n",
      "Iteration 18292, Loss: 0.05417090281844139\n",
      "Iteration 18293, Loss: 0.053988438099622726\n",
      "Iteration 18294, Loss: 0.05417082831263542\n",
      "Iteration 18295, Loss: 0.05398847162723541\n",
      "Iteration 18296, Loss: 0.05417082831263542\n",
      "Iteration 18297, Loss: 0.053988438099622726\n",
      "Iteration 18298, Loss: 0.05417078360915184\n",
      "Iteration 18299, Loss: 0.053988587111234665\n",
      "Iteration 18300, Loss: 0.05417077988386154\n",
      "Iteration 18301, Loss: 0.053988587111234665\n",
      "Iteration 18302, Loss: 0.05417051166296005\n",
      "Iteration 18303, Loss: 0.053988900035619736\n",
      "Iteration 18304, Loss: 0.05417050048708916\n",
      "Iteration 18305, Loss: 0.05398901551961899\n",
      "Iteration 18306, Loss: 0.05417042225599289\n",
      "Iteration 18307, Loss: 0.05398913472890854\n",
      "Iteration 18308, Loss: 0.05417028069496155\n",
      "Iteration 18309, Loss: 0.053988974541425705\n",
      "Iteration 18310, Loss: 0.05417051166296005\n",
      "Iteration 18311, Loss: 0.05398878455162048\n",
      "Iteration 18312, Loss: 0.05417058989405632\n",
      "Iteration 18313, Loss: 0.053988631814718246\n",
      "Iteration 18314, Loss: 0.054170750081539154\n",
      "Iteration 18315, Loss: 0.053988512605428696\n",
      "Iteration 18316, Loss: 0.05417067930102348\n",
      "Iteration 18317, Loss: 0.05398906394839287\n",
      "Iteration 18318, Loss: 0.05417071282863617\n",
      "Iteration 18319, Loss: 0.053989022970199585\n",
      "Iteration 18320, Loss: 0.05417126417160034\n",
      "Iteration 18321, Loss: 0.053989022970199585\n",
      "Iteration 18322, Loss: 0.054171379655599594\n",
      "Iteration 18323, Loss: 0.05398895591497421\n",
      "Iteration 18324, Loss: 0.054171498864889145\n",
      "Iteration 18325, Loss: 0.0539889857172966\n",
      "Iteration 18326, Loss: 0.054171573370695114\n",
      "Iteration 18327, Loss: 0.05398886650800705\n",
      "Iteration 18328, Loss: 0.054171618074178696\n",
      "Iteration 18329, Loss: 0.05398879200220108\n",
      "Iteration 18330, Loss: 0.054171543568372726\n",
      "Iteration 18331, Loss: 0.053988680243492126\n",
      "Iteration 18332, Loss: 0.054171495139598846\n",
      "Iteration 18333, Loss: 0.05398883670568466\n",
      "Iteration 18334, Loss: 0.05417134612798691\n",
      "Iteration 18335, Loss: 0.0539889894425869\n",
      "Iteration 18336, Loss: 0.05417141318321228\n",
      "Iteration 18337, Loss: 0.0539889857172966\n",
      "Iteration 18338, Loss: 0.05417126417160034\n",
      "Iteration 18339, Loss: 0.05398903414607048\n",
      "Iteration 18340, Loss: 0.05417138338088989\n",
      "Iteration 18341, Loss: 0.05398891493678093\n",
      "Iteration 18342, Loss: 0.05417153984308243\n",
      "Iteration 18343, Loss: 0.05398883670568466\n",
      "Iteration 18344, Loss: 0.05417165160179138\n",
      "Iteration 18345, Loss: 0.05398871749639511\n",
      "Iteration 18346, Loss: 0.05417169630527496\n",
      "Iteration 18347, Loss: 0.05398859828710556\n",
      "Iteration 18348, Loss: 0.05417158827185631\n",
      "Iteration 18349, Loss: 0.053988635540008545\n",
      "Iteration 18350, Loss: 0.054171543568372726\n",
      "Iteration 18351, Loss: 0.053988825529813766\n",
      "Iteration 18352, Loss: 0.054171569645404816\n",
      "Iteration 18353, Loss: 0.05398891493678093\n",
      "Iteration 18354, Loss: 0.05417140945792198\n",
      "Iteration 18355, Loss: 0.05398918688297272\n",
      "Iteration 18356, Loss: 0.054171137511730194\n",
      "Iteration 18357, Loss: 0.05398941785097122\n",
      "Iteration 18358, Loss: 0.05417083948850632\n",
      "Iteration 18359, Loss: 0.05398934334516525\n",
      "Iteration 18360, Loss: 0.05417094752192497\n",
      "Iteration 18361, Loss: 0.05398926883935928\n",
      "Iteration 18362, Loss: 0.05417122691869736\n",
      "Iteration 18363, Loss: 0.05398910492658615\n",
      "Iteration 18364, Loss: 0.054171424359083176\n",
      "Iteration 18365, Loss: 0.05398879572749138\n",
      "Iteration 18366, Loss: 0.05417158454656601\n",
      "Iteration 18367, Loss: 0.05398860201239586\n",
      "Iteration 18368, Loss: 0.05417166277766228\n",
      "Iteration 18369, Loss: 0.053988635540008545\n",
      "Iteration 18370, Loss: 0.05417157709598541\n",
      "Iteration 18371, Loss: 0.05398879200220108\n",
      "Iteration 18372, Loss: 0.0541716143488884\n",
      "Iteration 18373, Loss: 0.05398887023329735\n",
      "Iteration 18374, Loss: 0.054171573370695114\n",
      "Iteration 18375, Loss: 0.05398894473910332\n",
      "Iteration 18376, Loss: 0.054171573370695114\n",
      "Iteration 18377, Loss: 0.05398894473910332\n",
      "Iteration 18378, Loss: 0.05417153239250183\n",
      "Iteration 18379, Loss: 0.05398894473910332\n",
      "Iteration 18380, Loss: 0.054171424359083176\n",
      "Iteration 18381, Loss: 0.05398879200220108\n",
      "Iteration 18382, Loss: 0.054171424359083176\n",
      "Iteration 18383, Loss: 0.0539889894425869\n",
      "Iteration 18384, Loss: 0.054171379655599594\n",
      "Iteration 18385, Loss: 0.05398895591497421\n",
      "Iteration 18386, Loss: 0.054171234369277954\n",
      "Iteration 18387, Loss: 0.053988873958587646\n",
      "Iteration 18388, Loss: 0.054171305149793625\n",
      "Iteration 18389, Loss: 0.05398895591497421\n",
      "Iteration 18390, Loss: 0.054171301424503326\n",
      "Iteration 18391, Loss: 0.05398918315768242\n",
      "Iteration 18392, Loss: 0.054171256721019745\n",
      "Iteration 18393, Loss: 0.05398937687277794\n",
      "Iteration 18394, Loss: 0.054170992225408554\n",
      "Iteration 18395, Loss: 0.05398918688297272\n",
      "Iteration 18396, Loss: 0.05417122691869736\n",
      "Iteration 18397, Loss: 0.05398910492658615\n",
      "Iteration 18398, Loss: 0.054171305149793625\n",
      "Iteration 18399, Loss: 0.05398891493678093\n",
      "Iteration 18400, Loss: 0.05417150259017944\n",
      "Iteration 18401, Loss: 0.05398883670568466\n",
      "Iteration 18402, Loss: 0.05417150259017944\n",
      "Iteration 18403, Loss: 0.053988873958587646\n",
      "Iteration 18404, Loss: 0.054171498864889145\n",
      "Iteration 18405, Loss: 0.0539889894425869\n",
      "Iteration 18406, Loss: 0.054171498864889145\n",
      "Iteration 18407, Loss: 0.053988873958587646\n",
      "Iteration 18408, Loss: 0.054171498864889145\n",
      "Iteration 18409, Loss: 0.053988754749298096\n",
      "Iteration 18410, Loss: 0.05417158454656601\n",
      "Iteration 18411, Loss: 0.05398879200220108\n",
      "Iteration 18412, Loss: 0.05417150259017944\n",
      "Iteration 18413, Loss: 0.053988754749298096\n",
      "Iteration 18414, Loss: 0.05417146906256676\n",
      "Iteration 18415, Loss: 0.053988900035619736\n",
      "Iteration 18416, Loss: 0.05417150259017944\n",
      "Iteration 18417, Loss: 0.05398879200220108\n",
      "Iteration 18418, Loss: 0.05417146533727646\n",
      "Iteration 18419, Loss: 0.053988873958587646\n",
      "Iteration 18420, Loss: 0.05417134612798691\n",
      "Iteration 18421, Loss: 0.05398906394839287\n",
      "Iteration 18422, Loss: 0.05417126417160034\n",
      "Iteration 18423, Loss: 0.05398906394839287\n",
      "Iteration 18424, Loss: 0.0541713647544384\n",
      "Iteration 18425, Loss: 0.053989261388778687\n",
      "Iteration 18426, Loss: 0.05417102575302124\n",
      "Iteration 18427, Loss: 0.05398934334516525\n",
      "Iteration 18428, Loss: 0.05417122691869736\n",
      "Iteration 18429, Loss: 0.053989142179489136\n",
      "Iteration 18430, Loss: 0.05417138338088989\n",
      "Iteration 18431, Loss: 0.053988829255104065\n",
      "Iteration 18432, Loss: 0.054171621799468994\n",
      "Iteration 18433, Loss: 0.05398867279291153\n",
      "Iteration 18434, Loss: 0.05417177081108093\n",
      "Iteration 18435, Loss: 0.05398855730891228\n",
      "Iteration 18436, Loss: 0.054171547293663025\n",
      "Iteration 18437, Loss: 0.05398878455162048\n",
      "Iteration 18438, Loss: 0.05417146533727646\n",
      "Iteration 18439, Loss: 0.053988978266716\n",
      "Iteration 18440, Loss: 0.05417145416140556\n",
      "Iteration 18441, Loss: 0.05398895591497421\n",
      "Iteration 18442, Loss: 0.05417121574282646\n",
      "Iteration 18443, Loss: 0.053989261388778687\n",
      "Iteration 18444, Loss: 0.054171137511730194\n",
      "Iteration 18445, Loss: 0.053989261388778687\n",
      "Iteration 18446, Loss: 0.05417114496231079\n",
      "Iteration 18447, Loss: 0.05398918315768242\n",
      "Iteration 18448, Loss: 0.05417126417160034\n",
      "Iteration 18449, Loss: 0.053989022970199585\n",
      "Iteration 18450, Loss: 0.05417157709598541\n",
      "Iteration 18451, Loss: 0.05398879572749138\n",
      "Iteration 18452, Loss: 0.05417170375585556\n",
      "Iteration 18453, Loss: 0.05398844927549362\n",
      "Iteration 18454, Loss: 0.05417189747095108\n",
      "Iteration 18455, Loss: 0.05398836359381676\n",
      "Iteration 18456, Loss: 0.05417170375585556\n",
      "Iteration 18457, Loss: 0.05398867651820183\n",
      "Iteration 18458, Loss: 0.0541716143488884\n",
      "Iteration 18459, Loss: 0.05398872122168541\n",
      "Iteration 18460, Loss: 0.05417141318321228\n",
      "Iteration 18461, Loss: 0.05398895591497421\n",
      "Iteration 18462, Loss: 0.05417114496231079\n",
      "Iteration 18463, Loss: 0.05398934334516525\n",
      "Iteration 18464, Loss: 0.05417105555534363\n",
      "Iteration 18465, Loss: 0.053989529609680176\n",
      "Iteration 18466, Loss: 0.0541711300611496\n",
      "Iteration 18467, Loss: 0.05398930236697197\n",
      "Iteration 18468, Loss: 0.05417121946811676\n",
      "Iteration 18469, Loss: 0.05398915335536003\n",
      "Iteration 18470, Loss: 0.05417134612798691\n",
      "Iteration 18471, Loss: 0.053988903760910034\n",
      "Iteration 18472, Loss: 0.054171621799468994\n",
      "Iteration 18473, Loss: 0.05398855358362198\n",
      "Iteration 18474, Loss: 0.05417197570204735\n",
      "Iteration 18475, Loss: 0.05398839712142944\n",
      "Iteration 18476, Loss: 0.05417190119624138\n",
      "Iteration 18477, Loss: 0.05398835986852646\n",
      "Iteration 18478, Loss: 0.054171860218048096\n",
      "Iteration 18479, Loss: 0.053988516330718994\n",
      "Iteration 18480, Loss: 0.054171688854694366\n",
      "Iteration 18481, Loss: 0.05398876219987869\n",
      "Iteration 18482, Loss: 0.054171569645404816\n",
      "Iteration 18483, Loss: 0.05398906394839287\n",
      "Iteration 18484, Loss: 0.05417126417160034\n",
      "Iteration 18485, Loss: 0.05398918315768242\n",
      "Iteration 18486, Loss: 0.05417133495211601\n",
      "Iteration 18487, Loss: 0.0539889931678772\n",
      "Iteration 18488, Loss: 0.05417145788669586\n",
      "Iteration 18489, Loss: 0.05398879200220108\n",
      "Iteration 18490, Loss: 0.05417164787650108\n",
      "Iteration 18491, Loss: 0.053988754749298096\n",
      "Iteration 18492, Loss: 0.054171688854694366\n",
      "Iteration 18493, Loss: 0.05398894473910332\n",
      "Iteration 18494, Loss: 0.05417145416140556\n",
      "Iteration 18495, Loss: 0.05398906394839287\n",
      "Iteration 18496, Loss: 0.054171495139598846\n",
      "Iteration 18497, Loss: 0.05398895591497421\n",
      "Iteration 18498, Loss: 0.05417133867740631\n",
      "Iteration 18499, Loss: 0.05398906394839287\n",
      "Iteration 18500, Loss: 0.054171305149793625\n",
      "Iteration 18501, Loss: 0.0539889894425869\n",
      "Iteration 18502, Loss: 0.05417138338088989\n",
      "Iteration 18503, Loss: 0.053989022970199585\n",
      "Iteration 18504, Loss: 0.05417153239250183\n",
      "Iteration 18505, Loss: 0.05398883670568466\n",
      "Iteration 18506, Loss: 0.05417153239250183\n",
      "Iteration 18507, Loss: 0.05398883670568466\n",
      "Iteration 18508, Loss: 0.05417145416140556\n",
      "Iteration 18509, Loss: 0.053988903760910034\n",
      "Iteration 18510, Loss: 0.05417133495211601\n",
      "Iteration 18511, Loss: 0.053989142179489136\n",
      "Iteration 18512, Loss: 0.054171375930309296\n",
      "Iteration 18513, Loss: 0.053989022970199585\n",
      "Iteration 18514, Loss: 0.05417133867740631\n",
      "Iteration 18515, Loss: 0.053989067673683167\n",
      "Iteration 18516, Loss: 0.054171495139598846\n",
      "Iteration 18517, Loss: 0.0539889857172966\n",
      "Iteration 18518, Loss: 0.05417153984308243\n",
      "Iteration 18519, Loss: 0.05398879572749138\n",
      "Iteration 18520, Loss: 0.054171573370695114\n",
      "Iteration 18521, Loss: 0.053988829255104065\n",
      "Iteration 18522, Loss: 0.05417153239250183\n",
      "Iteration 18523, Loss: 0.05398894473910332\n",
      "Iteration 18524, Loss: 0.054171305149793625\n",
      "Iteration 18525, Loss: 0.053989022970199585\n",
      "Iteration 18526, Loss: 0.054171379655599594\n",
      "Iteration 18527, Loss: 0.05398917943239212\n",
      "Iteration 18528, Loss: 0.05417133867740631\n",
      "Iteration 18529, Loss: 0.053989142179489136\n",
      "Iteration 18530, Loss: 0.05417129397392273\n",
      "Iteration 18531, Loss: 0.053989261388778687\n",
      "Iteration 18532, Loss: 0.054171185940504074\n",
      "Iteration 18533, Loss: 0.05398907884955406\n",
      "Iteration 18534, Loss: 0.054171182215213776\n",
      "Iteration 18535, Loss: 0.05398914963006973\n",
      "Iteration 18536, Loss: 0.05417122691869736\n",
      "Iteration 18537, Loss: 0.05398918315768242\n",
      "Iteration 18538, Loss: 0.05417127534747124\n",
      "Iteration 18539, Loss: 0.05398879572749138\n",
      "Iteration 18540, Loss: 0.05417158454656601\n",
      "Iteration 18541, Loss: 0.05398867279291153\n",
      "Iteration 18542, Loss: 0.054171737283468246\n",
      "Iteration 18543, Loss: 0.05398867651820183\n",
      "Iteration 18544, Loss: 0.054171573370695114\n",
      "Iteration 18545, Loss: 0.05398879572749138\n",
      "Iteration 18546, Loss: 0.05417148768901825\n",
      "Iteration 18547, Loss: 0.05398910492658615\n",
      "Iteration 18548, Loss: 0.05417124927043915\n",
      "Iteration 18549, Loss: 0.053989227861166\n",
      "Iteration 18550, Loss: 0.05417102202773094\n",
      "Iteration 18551, Loss: 0.05398945137858391\n",
      "Iteration 18552, Loss: 0.054170992225408554\n",
      "Iteration 18553, Loss: 0.05398934334516525\n",
      "Iteration 18554, Loss: 0.05417114496231079\n",
      "Iteration 18555, Loss: 0.053989261388778687\n",
      "Iteration 18556, Loss: 0.05417133867740631\n",
      "Iteration 18557, Loss: 0.0539889894425869\n",
      "Iteration 18558, Loss: 0.05417157709598541\n",
      "Iteration 18559, Loss: 0.0539887510240078\n",
      "Iteration 18560, Loss: 0.05417173355817795\n",
      "Iteration 18561, Loss: 0.053988635540008545\n",
      "Iteration 18562, Loss: 0.05417173355817795\n",
      "Iteration 18563, Loss: 0.053988706320524216\n",
      "Iteration 18564, Loss: 0.05417153984308243\n",
      "Iteration 18565, Loss: 0.05398879572749138\n",
      "Iteration 18566, Loss: 0.05417145416140556\n",
      "Iteration 18567, Loss: 0.053989067673683167\n",
      "Iteration 18568, Loss: 0.05417129024863243\n",
      "Iteration 18569, Loss: 0.053989261388778687\n",
      "Iteration 18570, Loss: 0.05417121201753616\n",
      "Iteration 18571, Loss: 0.05398934334516525\n",
      "Iteration 18572, Loss: 0.054171256721019745\n",
      "Iteration 18573, Loss: 0.05398910492658615\n",
      "Iteration 18574, Loss: 0.05417145416140556\n",
      "Iteration 18575, Loss: 0.0539889857172966\n",
      "Iteration 18576, Loss: 0.05417150259017944\n",
      "Iteration 18577, Loss: 0.053988754749298096\n",
      "Iteration 18578, Loss: 0.0541718453168869\n",
      "Iteration 18579, Loss: 0.05398866534233093\n",
      "Iteration 18580, Loss: 0.05417165905237198\n",
      "Iteration 18581, Loss: 0.05398879200220108\n",
      "Iteration 18582, Loss: 0.054171543568372726\n",
      "Iteration 18583, Loss: 0.053988873958587646\n",
      "Iteration 18584, Loss: 0.05417145416140556\n",
      "Iteration 18585, Loss: 0.05398895591497421\n",
      "Iteration 18586, Loss: 0.05417126417160034\n",
      "Iteration 18587, Loss: 0.05398906394839287\n",
      "Iteration 18588, Loss: 0.05417114496231079\n",
      "Iteration 18589, Loss: 0.05398915335536003\n",
      "Iteration 18590, Loss: 0.05417106673121452\n",
      "Iteration 18591, Loss: 0.053989261388778687\n",
      "Iteration 18592, Loss: 0.05417117476463318\n",
      "Iteration 18593, Loss: 0.053989261388778687\n",
      "Iteration 18594, Loss: 0.05417126417160034\n",
      "Iteration 18595, Loss: 0.05398903042078018\n",
      "Iteration 18596, Loss: 0.054171424359083176\n",
      "Iteration 18597, Loss: 0.05398894473910332\n",
      "Iteration 18598, Loss: 0.05417168140411377\n",
      "Iteration 18599, Loss: 0.05398879572749138\n",
      "Iteration 18600, Loss: 0.054171573370695114\n",
      "Iteration 18601, Loss: 0.053988873958587646\n",
      "Iteration 18602, Loss: 0.05417153239250183\n",
      "Iteration 18603, Loss: 0.053989022970199585\n",
      "Iteration 18604, Loss: 0.05417145416140556\n",
      "Iteration 18605, Loss: 0.053989022970199585\n",
      "Iteration 18606, Loss: 0.05417145788669586\n",
      "Iteration 18607, Loss: 0.05398894473910332\n",
      "Iteration 18608, Loss: 0.054171573370695114\n",
      "Iteration 18609, Loss: 0.05398879572749138\n",
      "Iteration 18610, Loss: 0.05417157709598541\n",
      "Iteration 18611, Loss: 0.05398879200220108\n",
      "Iteration 18612, Loss: 0.054171543568372726\n",
      "Iteration 18613, Loss: 0.053988903760910034\n",
      "Iteration 18614, Loss: 0.05417134612798691\n",
      "Iteration 18615, Loss: 0.0539889857172966\n",
      "Iteration 18616, Loss: 0.05417122691869736\n",
      "Iteration 18617, Loss: 0.053988512605428696\n",
      "Iteration 18618, Loss: 0.05417129397392273\n",
      "Iteration 18619, Loss: 0.05398847162723541\n",
      "Iteration 18620, Loss: 0.054171495139598846\n",
      "Iteration 18621, Loss: 0.053988195955753326\n",
      "Iteration 18622, Loss: 0.054172419011592865\n",
      "Iteration 18623, Loss: 0.05398784205317497\n",
      "Iteration 18624, Loss: 0.05417267978191376\n",
      "Iteration 18625, Loss: 0.053987957537174225\n",
      "Iteration 18626, Loss: 0.0541723370552063\n",
      "Iteration 18627, Loss: 0.05398811399936676\n",
      "Iteration 18628, Loss: 0.0541720911860466\n",
      "Iteration 18629, Loss: 0.05398835986852646\n",
      "Iteration 18630, Loss: 0.05417153239250183\n",
      "Iteration 18631, Loss: 0.05398879572749138\n",
      "Iteration 18632, Loss: 0.05417110025882721\n",
      "Iteration 18633, Loss: 0.053989700973033905\n",
      "Iteration 18634, Loss: 0.05417082831263542\n",
      "Iteration 18635, Loss: 0.05398992821574211\n",
      "Iteration 18636, Loss: 0.05417133867740631\n",
      "Iteration 18637, Loss: 0.053990285843610764\n",
      "Iteration 18638, Loss: 0.05417153239250183\n",
      "Iteration 18639, Loss: 0.05399024486541748\n",
      "Iteration 18640, Loss: 0.05417153239250183\n",
      "Iteration 18641, Loss: 0.053990207612514496\n",
      "Iteration 18642, Loss: 0.05417114123702049\n",
      "Iteration 18643, Loss: 0.05399016663432121\n",
      "Iteration 18644, Loss: 0.054171305149793625\n",
      "Iteration 18645, Loss: 0.05398985743522644\n",
      "Iteration 18646, Loss: 0.05417158454656601\n",
      "Iteration 18647, Loss: 0.05398954451084137\n",
      "Iteration 18648, Loss: 0.05417190119624138\n",
      "Iteration 18649, Loss: 0.0539892315864563\n",
      "Iteration 18650, Loss: 0.05417206138372421\n",
      "Iteration 18651, Loss: 0.053989142179489136\n",
      "Iteration 18652, Loss: 0.05417221039533615\n",
      "Iteration 18653, Loss: 0.05398918315768242\n",
      "Iteration 18654, Loss: 0.054172322154045105\n",
      "Iteration 18655, Loss: 0.0539889931678772\n",
      "Iteration 18656, Loss: 0.0541720949113369\n",
      "Iteration 18657, Loss: 0.053989261388778687\n",
      "Iteration 18658, Loss: 0.054172009229660034\n",
      "Iteration 18659, Loss: 0.0539894625544548\n",
      "Iteration 18660, Loss: 0.05417189002037048\n",
      "Iteration 18661, Loss: 0.0539894700050354\n",
      "Iteration 18662, Loss: 0.054171815514564514\n",
      "Iteration 18663, Loss: 0.05398957431316376\n",
      "Iteration 18664, Loss: 0.054171815514564514\n",
      "Iteration 18665, Loss: 0.0539894625544548\n",
      "Iteration 18666, Loss: 0.05417205020785332\n",
      "Iteration 18667, Loss: 0.05398937687277794\n",
      "Iteration 18668, Loss: 0.054172009229660034\n",
      "Iteration 18669, Loss: 0.05398949980735779\n",
      "Iteration 18670, Loss: 0.054171930998563766\n",
      "Iteration 18671, Loss: 0.05398949980735779\n",
      "Iteration 18672, Loss: 0.0541718527674675\n",
      "Iteration 18673, Loss: 0.05398934334516525\n",
      "Iteration 18674, Loss: 0.054171930998563766\n",
      "Iteration 18675, Loss: 0.05398934707045555\n",
      "Iteration 18676, Loss: 0.05417189747095108\n",
      "Iteration 18677, Loss: 0.0539894625544548\n",
      "Iteration 18678, Loss: 0.05417177826166153\n",
      "Iteration 18679, Loss: 0.05398957058787346\n",
      "Iteration 18680, Loss: 0.054171930998563766\n",
      "Iteration 18681, Loss: 0.05398942157626152\n",
      "Iteration 18682, Loss: 0.05417189002037048\n",
      "Iteration 18683, Loss: 0.05398871749639511\n",
      "Iteration 18684, Loss: 0.054172009229660034\n",
      "Iteration 18685, Loss: 0.05398864671587944\n",
      "Iteration 18686, Loss: 0.054171234369277954\n",
      "Iteration 18687, Loss: 0.05398879572749138\n",
      "Iteration 18688, Loss: 0.054171185940504074\n",
      "Iteration 18689, Loss: 0.0539889931678772\n",
      "Iteration 18690, Loss: 0.0541708841919899\n",
      "Iteration 18691, Loss: 0.05398910865187645\n",
      "Iteration 18692, Loss: 0.05417080223560333\n",
      "Iteration 18693, Loss: 0.05398903414607048\n",
      "Iteration 18694, Loss: 0.05417092889547348\n",
      "Iteration 18695, Loss: 0.05398891493678093\n",
      "Iteration 18696, Loss: 0.054171040654182434\n",
      "Iteration 18697, Loss: 0.05398891493678093\n",
      "Iteration 18698, Loss: 0.05417108163237572\n",
      "Iteration 18699, Loss: 0.05398872494697571\n",
      "Iteration 18700, Loss: 0.054171159863471985\n",
      "Iteration 18701, Loss: 0.05398864299058914\n",
      "Iteration 18702, Loss: 0.05417124181985855\n",
      "Iteration 18703, Loss: 0.053988486528396606\n",
      "Iteration 18704, Loss: 0.054171234369277954\n",
      "Iteration 18705, Loss: 0.05398856848478317\n",
      "Iteration 18706, Loss: 0.054171234369277954\n",
      "Iteration 18707, Loss: 0.05398856848478317\n",
      "Iteration 18708, Loss: 0.0541711151599884\n",
      "Iteration 18709, Loss: 0.05398879572749138\n",
      "Iteration 18710, Loss: 0.054170966148376465\n",
      "Iteration 18711, Loss: 0.05398888513445854\n",
      "Iteration 18712, Loss: 0.054170966148376465\n",
      "Iteration 18713, Loss: 0.053989000618457794\n",
      "Iteration 18714, Loss: 0.05417119711637497\n",
      "Iteration 18715, Loss: 0.05398868769407272\n",
      "Iteration 18716, Loss: 0.05417124554514885\n",
      "Iteration 18717, Loss: 0.05398840829730034\n",
      "Iteration 18718, Loss: 0.05417148396372795\n",
      "Iteration 18719, Loss: 0.05398833006620407\n",
      "Iteration 18720, Loss: 0.05417140573263168\n",
      "Iteration 18721, Loss: 0.05398833006620407\n",
      "Iteration 18722, Loss: 0.054171279072761536\n",
      "Iteration 18723, Loss: 0.05398860573768616\n",
      "Iteration 18724, Loss: 0.054171230643987656\n",
      "Iteration 18725, Loss: 0.05398876592516899\n",
      "Iteration 18726, Loss: 0.05417095869779587\n",
      "Iteration 18727, Loss: 0.053989045321941376\n",
      "Iteration 18728, Loss: 0.05417069047689438\n",
      "Iteration 18729, Loss: 0.053989045321941376\n",
      "Iteration 18730, Loss: 0.0541708841919899\n",
      "Iteration 18731, Loss: 0.0539889931678772\n",
      "Iteration 18732, Loss: 0.05417107790708542\n",
      "Iteration 18733, Loss: 0.05398869514465332\n",
      "Iteration 18734, Loss: 0.05417124554514885\n",
      "Iteration 18735, Loss: 0.05398852750658989\n",
      "Iteration 18736, Loss: 0.05417140573263168\n",
      "Iteration 18737, Loss: 0.05398852378129959\n",
      "Iteration 18738, Loss: 0.0541713647544384\n",
      "Iteration 18739, Loss: 0.05398844927549362\n",
      "Iteration 18740, Loss: 0.054171424359083176\n",
      "Iteration 18741, Loss: 0.05398853123188019\n",
      "Iteration 18742, Loss: 0.054171156138181686\n",
      "Iteration 18743, Loss: 0.05398876965045929\n",
      "Iteration 18744, Loss: 0.05417094752192497\n",
      "Iteration 18745, Loss: 0.05398903414607048\n",
      "Iteration 18746, Loss: 0.054170724004507065\n",
      "Iteration 18747, Loss: 0.05398926883935928\n",
      "Iteration 18748, Loss: 0.05417069047689438\n",
      "Iteration 18749, Loss: 0.05398911237716675\n",
      "Iteration 18750, Loss: 0.0541708841919899\n",
      "Iteration 18751, Loss: 0.05398910492658615\n",
      "Iteration 18752, Loss: 0.05417104810476303\n",
      "Iteration 18753, Loss: 0.05398868769407272\n",
      "Iteration 18754, Loss: 0.054171279072761536\n",
      "Iteration 18755, Loss: 0.05398845300078392\n",
      "Iteration 18756, Loss: 0.05417148396372795\n",
      "Iteration 18757, Loss: 0.05398833006620407\n",
      "Iteration 18758, Loss: 0.05417155474424362\n",
      "Iteration 18759, Loss: 0.05398828908801079\n",
      "Iteration 18760, Loss: 0.05417143553495407\n",
      "Iteration 18761, Loss: 0.053988367319107056\n",
      "Iteration 18762, Loss: 0.05417120084166527\n",
      "Iteration 18763, Loss: 0.05398845672607422\n",
      "Iteration 18764, Loss: 0.054171230643987656\n",
      "Iteration 18765, Loss: 0.05398879572749138\n",
      "Iteration 18766, Loss: 0.05417092889547348\n",
      "Iteration 18767, Loss: 0.05398895591497421\n",
      "Iteration 18768, Loss: 0.054170966148376465\n",
      "Iteration 18769, Loss: 0.05398895591497421\n",
      "Iteration 18770, Loss: 0.054171234369277954\n",
      "Iteration 18771, Loss: 0.05398868769407272\n",
      "Iteration 18772, Loss: 0.05417131632566452\n",
      "Iteration 18773, Loss: 0.053988635540008545\n",
      "Iteration 18774, Loss: 0.054171204566955566\n",
      "Iteration 18775, Loss: 0.05398855730891228\n",
      "Iteration 18776, Loss: 0.05417120084166527\n",
      "Iteration 18777, Loss: 0.05398864671587944\n",
      "Iteration 18778, Loss: 0.054171234369277954\n",
      "Iteration 18779, Loss: 0.05398868769407272\n",
      "Iteration 18780, Loss: 0.05417104810476303\n",
      "Iteration 18781, Loss: 0.05398879572749138\n",
      "Iteration 18782, Loss: 0.05417124554514885\n",
      "Iteration 18783, Loss: 0.05398856848478317\n",
      "Iteration 18784, Loss: 0.054171472787857056\n",
      "Iteration 18785, Loss: 0.053988367319107056\n",
      "Iteration 18786, Loss: 0.05417140573263168\n",
      "Iteration 18787, Loss: 0.05398833006620407\n",
      "Iteration 18788, Loss: 0.05417140573263168\n",
      "Iteration 18789, Loss: 0.05398844927549362\n",
      "Iteration 18790, Loss: 0.054171353578567505\n",
      "Iteration 18791, Loss: 0.05398844927549362\n",
      "Iteration 18792, Loss: 0.05417139083147049\n",
      "Iteration 18793, Loss: 0.05398860573768616\n",
      "Iteration 18794, Loss: 0.0541711151599884\n",
      "Iteration 18795, Loss: 0.05398872494697571\n",
      "Iteration 18796, Loss: 0.05417100340127945\n",
      "Iteration 18797, Loss: 0.053988806903362274\n",
      "Iteration 18798, Loss: 0.0541708879172802\n",
      "Iteration 18799, Loss: 0.0539889931678772\n",
      "Iteration 18800, Loss: 0.054170966148376465\n",
      "Iteration 18801, Loss: 0.05398888513445854\n",
      "Iteration 18802, Loss: 0.05417100712656975\n",
      "Iteration 18803, Loss: 0.05398868769407272\n",
      "Iteration 18804, Loss: 0.054171137511730194\n",
      "Iteration 18805, Loss: 0.05398844927549362\n",
      "Iteration 18806, Loss: 0.054171450436115265\n",
      "Iteration 18807, Loss: 0.05398821085691452\n",
      "Iteration 18808, Loss: 0.05417163670063019\n",
      "Iteration 18809, Loss: 0.05398816987872124\n",
      "Iteration 18810, Loss: 0.05417140573263168\n",
      "Iteration 18811, Loss: 0.05398844927549362\n",
      "Iteration 18812, Loss: 0.054171353578567505\n",
      "Iteration 18813, Loss: 0.05398856848478317\n",
      "Iteration 18814, Loss: 0.054170966148376465\n",
      "Iteration 18815, Loss: 0.05398884043097496\n",
      "Iteration 18816, Loss: 0.0541708879172802\n",
      "Iteration 18817, Loss: 0.05398884415626526\n",
      "Iteration 18818, Loss: 0.05417100340127945\n",
      "Iteration 18819, Loss: 0.05398884043097496\n",
      "Iteration 18820, Loss: 0.0541711151599884\n",
      "Iteration 18821, Loss: 0.05398879572749138\n",
      "Iteration 18822, Loss: 0.05417120084166527\n",
      "Iteration 18823, Loss: 0.05398872122168541\n",
      "Iteration 18824, Loss: 0.05417127534747124\n",
      "Iteration 18825, Loss: 0.05398840829730034\n",
      "Iteration 18826, Loss: 0.054171279072761536\n",
      "Iteration 18827, Loss: 0.05398857221007347\n",
      "Iteration 18828, Loss: 0.0541711151599884\n",
      "Iteration 18829, Loss: 0.053988806903362274\n",
      "Iteration 18830, Loss: 0.05417100712656975\n",
      "Iteration 18831, Loss: 0.053988806903362274\n",
      "Iteration 18832, Loss: 0.054170966148376465\n",
      "Iteration 18833, Loss: 0.05398884043097496\n",
      "Iteration 18834, Loss: 0.054170966148376465\n",
      "Iteration 18835, Loss: 0.05398884043097496\n",
      "Iteration 18836, Loss: 0.05417100712656975\n",
      "Iteration 18837, Loss: 0.05398891121149063\n",
      "Iteration 18838, Loss: 0.054171085357666016\n",
      "Iteration 18839, Loss: 0.053988754749298096\n",
      "Iteration 18840, Loss: 0.05417131632566452\n",
      "Iteration 18841, Loss: 0.05398852750658989\n",
      "Iteration 18842, Loss: 0.05417132377624512\n",
      "Iteration 18843, Loss: 0.05398844927549362\n",
      "Iteration 18844, Loss: 0.054171472787857056\n",
      "Iteration 18845, Loss: 0.05398841202259064\n",
      "Iteration 18846, Loss: 0.054171398282051086\n",
      "Iteration 18847, Loss: 0.05398830026388168\n",
      "Iteration 18848, Loss: 0.054171472787857056\n",
      "Iteration 18849, Loss: 0.05398844927549362\n",
      "Iteration 18850, Loss: 0.05417127534747124\n",
      "Iteration 18851, Loss: 0.0539884939789772\n",
      "Iteration 18852, Loss: 0.054171230643987656\n",
      "Iteration 18853, Loss: 0.05398879572749138\n",
      "Iteration 18854, Loss: 0.0541708879172802\n",
      "Iteration 18855, Loss: 0.0539889931678772\n",
      "Iteration 18856, Loss: 0.0541708879172802\n",
      "Iteration 18857, Loss: 0.05398888513445854\n",
      "Iteration 18858, Loss: 0.05417092889547348\n",
      "Iteration 18859, Loss: 0.053988873958587646\n",
      "Iteration 18860, Loss: 0.054170966148376465\n",
      "Iteration 18861, Loss: 0.05398883670568466\n",
      "Iteration 18862, Loss: 0.054171159863471985\n",
      "Iteration 18863, Loss: 0.05398864671587944\n",
      "Iteration 18864, Loss: 0.054171234369277954\n",
      "Iteration 18865, Loss: 0.05398864671587944\n",
      "Iteration 18866, Loss: 0.05417127534747124\n",
      "Iteration 18867, Loss: 0.05398852750658989\n",
      "Iteration 18868, Loss: 0.05417132005095482\n",
      "Iteration 18869, Loss: 0.05398837849497795\n",
      "Iteration 18870, Loss: 0.05417132005095482\n",
      "Iteration 18871, Loss: 0.05398860573768616\n",
      "Iteration 18872, Loss: 0.054171234369277954\n",
      "Iteration 18873, Loss: 0.05398865044116974\n",
      "Iteration 18874, Loss: 0.0541711263358593\n",
      "Iteration 18875, Loss: 0.053988613188266754\n",
      "Iteration 18876, Loss: 0.054171156138181686\n",
      "Iteration 18877, Loss: 0.05398856848478317\n",
      "Iteration 18878, Loss: 0.054171159863471985\n",
      "Iteration 18879, Loss: 0.05398872494697571\n",
      "Iteration 18880, Loss: 0.054171156138181686\n",
      "Iteration 18881, Loss: 0.05398868769407272\n",
      "Iteration 18882, Loss: 0.0541711151599884\n",
      "Iteration 18883, Loss: 0.05398871749639511\n",
      "Iteration 18884, Loss: 0.05417119711637497\n",
      "Iteration 18885, Loss: 0.053988754749298096\n",
      "Iteration 18886, Loss: 0.054171156138181686\n",
      "Iteration 18887, Loss: 0.05398883670568466\n",
      "Iteration 18888, Loss: 0.05417116731405258\n",
      "Iteration 18889, Loss: 0.053988754749298096\n",
      "Iteration 18890, Loss: 0.054171353578567505\n",
      "Iteration 18891, Loss: 0.053988635540008545\n",
      "Iteration 18892, Loss: 0.05417132377624512\n",
      "Iteration 18893, Loss: 0.05398844927549362\n",
      "Iteration 18894, Loss: 0.054171398282051086\n",
      "Iteration 18895, Loss: 0.05398830026388168\n",
      "Iteration 18896, Loss: 0.0541713647544384\n",
      "Iteration 18897, Loss: 0.05398852750658989\n",
      "Iteration 18898, Loss: 0.05417116731405258\n",
      "Iteration 18899, Loss: 0.053988538682460785\n",
      "Iteration 18900, Loss: 0.05417107790708542\n",
      "Iteration 18901, Loss: 0.05398872494697571\n",
      "Iteration 18902, Loss: 0.054170843213796616\n",
      "Iteration 18903, Loss: 0.053988926112651825\n",
      "Iteration 18904, Loss: 0.05417067930102348\n",
      "Iteration 18905, Loss: 0.05398915335536003\n",
      "Iteration 18906, Loss: 0.054170601069927216\n",
      "Iteration 18907, Loss: 0.0539892315864563\n",
      "Iteration 18908, Loss: 0.05417056009173393\n",
      "Iteration 18909, Loss: 0.053989313542842865\n",
      "Iteration 18910, Loss: 0.054170798510313034\n",
      "Iteration 18911, Loss: 0.05398903787136078\n",
      "Iteration 18912, Loss: 0.0541711151599884\n",
      "Iteration 18913, Loss: 0.05398852750658989\n",
      "Iteration 18914, Loss: 0.05417143553495407\n",
      "Iteration 18915, Loss: 0.05398828908801079\n",
      "Iteration 18916, Loss: 0.05417155846953392\n",
      "Iteration 18917, Loss: 0.053988248109817505\n",
      "Iteration 18918, Loss: 0.05417140573263168\n",
      "Iteration 18919, Loss: 0.05398837476968765\n",
      "Iteration 18920, Loss: 0.054171353578567505\n",
      "Iteration 18921, Loss: 0.05398860573768616\n",
      "Iteration 18922, Loss: 0.05417108163237572\n",
      "Iteration 18923, Loss: 0.053988806903362274\n",
      "Iteration 18924, Loss: 0.0541708879172802\n",
      "Iteration 18925, Loss: 0.05398903414607048\n",
      "Iteration 18926, Loss: 0.0541708767414093\n",
      "Iteration 18927, Loss: 0.05398903787136078\n",
      "Iteration 18928, Loss: 0.054170966148376465\n",
      "Iteration 18929, Loss: 0.05398888513445854\n",
      "Iteration 18930, Loss: 0.05417100712656975\n",
      "Iteration 18931, Loss: 0.053988806903362274\n",
      "Iteration 18932, Loss: 0.05417127534747124\n",
      "Iteration 18933, Loss: 0.05398864671587944\n",
      "Iteration 18934, Loss: 0.054171353578567505\n",
      "Iteration 18935, Loss: 0.05398840829730034\n",
      "Iteration 18936, Loss: 0.05417132377624512\n",
      "Iteration 18937, Loss: 0.053988419473171234\n",
      "Iteration 18938, Loss: 0.05417127534747124\n",
      "Iteration 18939, Loss: 0.05398860573768616\n",
      "Iteration 18940, Loss: 0.0541711263358593\n",
      "Iteration 18941, Loss: 0.05398872494697571\n",
      "Iteration 18942, Loss: 0.05417104810476303\n",
      "Iteration 18943, Loss: 0.05398879572749138\n",
      "Iteration 18944, Loss: 0.05417108163237572\n",
      "Iteration 18945, Loss: 0.05398876592516899\n",
      "Iteration 18946, Loss: 0.05417100712656975\n",
      "Iteration 18947, Loss: 0.05398868769407272\n",
      "Iteration 18948, Loss: 0.05417107790708542\n",
      "Iteration 18949, Loss: 0.05398864671587944\n",
      "Iteration 18950, Loss: 0.05417104810476303\n",
      "Iteration 18951, Loss: 0.05398860573768616\n",
      "Iteration 18952, Loss: 0.054171122610569\n",
      "Iteration 18953, Loss: 0.05398868769407272\n",
      "Iteration 18954, Loss: 0.0541711263358593\n",
      "Iteration 18955, Loss: 0.05398872122168541\n",
      "Iteration 18956, Loss: 0.05417124554514885\n",
      "Iteration 18957, Loss: 0.05398864299058914\n",
      "Iteration 18958, Loss: 0.05417143553495407\n",
      "Iteration 18959, Loss: 0.05398855730891228\n",
      "Iteration 18960, Loss: 0.05417148023843765\n",
      "Iteration 18961, Loss: 0.05398840829730034\n",
      "Iteration 18962, Loss: 0.0541713647544384\n",
      "Iteration 18963, Loss: 0.0539882592856884\n",
      "Iteration 18964, Loss: 0.05417140573263168\n",
      "Iteration 18965, Loss: 0.053988367319107056\n",
      "Iteration 18966, Loss: 0.05417131632566452\n",
      "Iteration 18967, Loss: 0.05398864671587944\n",
      "Iteration 18968, Loss: 0.05417093262076378\n",
      "Iteration 18969, Loss: 0.05398879572749138\n",
      "Iteration 18970, Loss: 0.05417095869779587\n",
      "Iteration 18971, Loss: 0.05398895591497421\n",
      "Iteration 18972, Loss: 0.054170962423086166\n",
      "Iteration 18973, Loss: 0.05398888513445854\n",
      "Iteration 18974, Loss: 0.054170966148376465\n",
      "Iteration 18975, Loss: 0.05398891866207123\n",
      "Iteration 18976, Loss: 0.0541711263358593\n",
      "Iteration 18977, Loss: 0.05398860573768616\n",
      "Iteration 18978, Loss: 0.05417132377624512\n",
      "Iteration 18979, Loss: 0.05398837476968765\n",
      "Iteration 18980, Loss: 0.05417155846953392\n",
      "Iteration 18981, Loss: 0.05398821458220482\n",
      "Iteration 18982, Loss: 0.054171524941921234\n",
      "Iteration 18983, Loss: 0.05398833006620407\n",
      "Iteration 18984, Loss: 0.054171279072761536\n",
      "Iteration 18985, Loss: 0.05398845672607422\n",
      "Iteration 18986, Loss: 0.05417108163237572\n",
      "Iteration 18987, Loss: 0.05398865044116974\n",
      "Iteration 18988, Loss: 0.05417108163237572\n",
      "Iteration 18989, Loss: 0.05398876592516899\n",
      "Iteration 18990, Loss: 0.05417104810476303\n",
      "Iteration 18991, Loss: 0.05398868769407272\n",
      "Iteration 18992, Loss: 0.05417119711637497\n",
      "Iteration 18993, Loss: 0.05398879572749138\n",
      "Iteration 18994, Loss: 0.054170966148376465\n",
      "Iteration 18995, Loss: 0.05398895591497421\n",
      "Iteration 18996, Loss: 0.05417100712656975\n",
      "Iteration 18997, Loss: 0.05398888513445854\n",
      "Iteration 18998, Loss: 0.05417100712656975\n",
      "Iteration 18999, Loss: 0.05398879572749138\n",
      "Iteration 19000, Loss: 0.0541711263358593\n",
      "Iteration 19001, Loss: 0.05398860573768616\n",
      "Iteration 19002, Loss: 0.05417124181985855\n",
      "Iteration 19003, Loss: 0.053988486528396606\n",
      "Iteration 19004, Loss: 0.05417131632566452\n",
      "Iteration 19005, Loss: 0.05398856848478317\n",
      "Iteration 19006, Loss: 0.05417104810476303\n",
      "Iteration 19007, Loss: 0.05398872494697571\n",
      "Iteration 19008, Loss: 0.054171040654182434\n",
      "Iteration 19009, Loss: 0.05398891493678093\n",
      "Iteration 19010, Loss: 0.05417092144489288\n",
      "Iteration 19011, Loss: 0.05398891866207123\n",
      "Iteration 19012, Loss: 0.0541708879172802\n",
      "Iteration 19013, Loss: 0.05398895964026451\n",
      "Iteration 19014, Loss: 0.05417099595069885\n",
      "Iteration 19015, Loss: 0.05398888140916824\n",
      "Iteration 19016, Loss: 0.0541711263358593\n",
      "Iteration 19017, Loss: 0.05398868769407272\n",
      "Iteration 19018, Loss: 0.05417124554514885\n",
      "Iteration 19019, Loss: 0.05398856848478317\n",
      "Iteration 19020, Loss: 0.054171353578567505\n",
      "Iteration 19021, Loss: 0.053988561034202576\n",
      "Iteration 19022, Loss: 0.054171428084373474\n",
      "Iteration 19023, Loss: 0.05398841202259064\n",
      "Iteration 19024, Loss: 0.0541713610291481\n",
      "Iteration 19025, Loss: 0.053988486528396606\n",
      "Iteration 19026, Loss: 0.05417131632566452\n",
      "Iteration 19027, Loss: 0.05398860201239586\n",
      "Iteration 19028, Loss: 0.05417100712656975\n",
      "Iteration 19029, Loss: 0.05398868769407272\n",
      "Iteration 19030, Loss: 0.05417107790708542\n",
      "Iteration 19031, Loss: 0.05398895591497421\n",
      "Iteration 19032, Loss: 0.054170846939086914\n",
      "Iteration 19033, Loss: 0.053988926112651825\n",
      "Iteration 19034, Loss: 0.05417092889547348\n",
      "Iteration 19035, Loss: 0.05398884415626526\n",
      "Iteration 19036, Loss: 0.054171234369277954\n",
      "Iteration 19037, Loss: 0.05398872122168541\n",
      "Iteration 19038, Loss: 0.054171204566955566\n",
      "Iteration 19039, Loss: 0.05398860201239586\n",
      "Iteration 19040, Loss: 0.05417132377624512\n",
      "Iteration 19041, Loss: 0.05398852750658989\n",
      "Iteration 19042, Loss: 0.054171353578567505\n",
      "Iteration 19043, Loss: 0.053988486528396606\n",
      "Iteration 19044, Loss: 0.05417146906256676\n",
      "Iteration 19045, Loss: 0.05398830026388168\n",
      "Iteration 19046, Loss: 0.054171398282051086\n",
      "Iteration 19047, Loss: 0.053988516330718994\n",
      "Iteration 19048, Loss: 0.054171279072761536\n",
      "Iteration 19049, Loss: 0.05398856848478317\n",
      "Iteration 19050, Loss: 0.05417127534747124\n",
      "Iteration 19051, Loss: 0.05398876219987869\n",
      "Iteration 19052, Loss: 0.054171159863471985\n",
      "Iteration 19053, Loss: 0.05398876219987869\n",
      "Iteration 19054, Loss: 0.05417100712656975\n",
      "Iteration 19055, Loss: 0.05398891493678093\n",
      "Iteration 19056, Loss: 0.0541708879172802\n",
      "Iteration 19057, Loss: 0.05398895591497421\n",
      "Iteration 19058, Loss: 0.05417092889547348\n",
      "Iteration 19059, Loss: 0.05398891866207123\n",
      "Iteration 19060, Loss: 0.05417092889547348\n",
      "Iteration 19061, Loss: 0.053988806903362274\n",
      "Iteration 19062, Loss: 0.05417100340127945\n",
      "Iteration 19063, Loss: 0.05398872494697571\n",
      "Iteration 19064, Loss: 0.05417100712656975\n",
      "Iteration 19065, Loss: 0.05398876592516899\n",
      "Iteration 19066, Loss: 0.05417124181985855\n",
      "Iteration 19067, Loss: 0.05398864299058914\n",
      "Iteration 19068, Loss: 0.054171353578567505\n",
      "Iteration 19069, Loss: 0.05398837849497795\n",
      "Iteration 19070, Loss: 0.05417132377624512\n",
      "Iteration 19071, Loss: 0.053988486528396606\n",
      "Iteration 19072, Loss: 0.0541711263358593\n",
      "Iteration 19073, Loss: 0.053988538682460785\n",
      "Iteration 19074, Loss: 0.05417107790708542\n",
      "Iteration 19075, Loss: 0.05398872494697571\n",
      "Iteration 19076, Loss: 0.0541708879172802\n",
      "Iteration 19077, Loss: 0.05398907512426376\n",
      "Iteration 19078, Loss: 0.054170843213796616\n",
      "Iteration 19079, Loss: 0.053989000618457794\n",
      "Iteration 19080, Loss: 0.05417072772979736\n",
      "Iteration 19081, Loss: 0.05398907512426376\n",
      "Iteration 19082, Loss: 0.054170846939086914\n",
      "Iteration 19083, Loss: 0.053988926112651825\n",
      "Iteration 19084, Loss: 0.05417092889547348\n",
      "Iteration 19085, Loss: 0.0539889931678772\n",
      "Iteration 19086, Loss: 0.05417108163237572\n",
      "Iteration 19087, Loss: 0.05398872494697571\n",
      "Iteration 19088, Loss: 0.05417116731405258\n",
      "Iteration 19089, Loss: 0.05398856848478317\n",
      "Iteration 19090, Loss: 0.054171279072761536\n",
      "Iteration 19091, Loss: 0.05398845300078392\n",
      "Iteration 19092, Loss: 0.054171204566955566\n",
      "Iteration 19093, Loss: 0.05398856848478317\n",
      "Iteration 19094, Loss: 0.054171122610569\n",
      "Iteration 19095, Loss: 0.05398868769407272\n",
      "Iteration 19096, Loss: 0.05417100340127945\n",
      "Iteration 19097, Loss: 0.05398884415626526\n",
      "Iteration 19098, Loss: 0.0541708841919899\n",
      "Iteration 19099, Loss: 0.05398903787136078\n",
      "Iteration 19100, Loss: 0.0541708879172802\n",
      "Iteration 19101, Loss: 0.053988926112651825\n",
      "Iteration 19102, Loss: 0.054171036928892136\n",
      "Iteration 19103, Loss: 0.053988806903362274\n",
      "Iteration 19104, Loss: 0.054171156138181686\n",
      "Iteration 19105, Loss: 0.05398872122168541\n",
      "Iteration 19106, Loss: 0.05417119711637497\n",
      "Iteration 19107, Loss: 0.05398856848478317\n",
      "Iteration 19108, Loss: 0.05417124554514885\n",
      "Iteration 19109, Loss: 0.05398856848478317\n",
      "Iteration 19110, Loss: 0.05417124181985855\n",
      "Iteration 19111, Loss: 0.053988680243492126\n",
      "Iteration 19112, Loss: 0.054171085357666016\n",
      "Iteration 19113, Loss: 0.05398864671587944\n",
      "Iteration 19114, Loss: 0.054171085357666016\n",
      "Iteration 19115, Loss: 0.05398869514465332\n",
      "Iteration 19116, Loss: 0.05417100712656975\n",
      "Iteration 19117, Loss: 0.05398876592516899\n",
      "Iteration 19118, Loss: 0.054170966148376465\n",
      "Iteration 19119, Loss: 0.05398876965045929\n",
      "Iteration 19120, Loss: 0.05417104810476303\n",
      "Iteration 19121, Loss: 0.05398872494697571\n",
      "Iteration 19122, Loss: 0.05417131632566452\n",
      "Iteration 19123, Loss: 0.05398860573768616\n",
      "Iteration 19124, Loss: 0.05417132005095482\n",
      "Iteration 19125, Loss: 0.05398852750658989\n",
      "Iteration 19126, Loss: 0.05417143553495407\n",
      "Iteration 19127, Loss: 0.05398840829730034\n",
      "Iteration 19128, Loss: 0.05417143553495407\n",
      "Iteration 19129, Loss: 0.053988486528396606\n",
      "Iteration 19130, Loss: 0.05417127162218094\n",
      "Iteration 19131, Loss: 0.05398861691355705\n",
      "Iteration 19132, Loss: 0.05417100712656975\n",
      "Iteration 19133, Loss: 0.05398872494697571\n",
      "Iteration 19134, Loss: 0.05417073518037796\n",
      "Iteration 19135, Loss: 0.0539889931678772\n",
      "Iteration 19136, Loss: 0.054170843213796616\n",
      "Iteration 19137, Loss: 0.053989000618457794\n",
      "Iteration 19138, Loss: 0.054170846939086914\n",
      "Iteration 19139, Loss: 0.0539889931678772\n",
      "Iteration 19140, Loss: 0.05417104810476303\n",
      "Iteration 19141, Loss: 0.05398883670568466\n",
      "Iteration 19142, Loss: 0.05417124554514885\n",
      "Iteration 19143, Loss: 0.05398845672607422\n",
      "Iteration 19144, Loss: 0.05417124554514885\n",
      "Iteration 19145, Loss: 0.053988486528396606\n",
      "Iteration 19146, Loss: 0.054171349853277206\n",
      "Iteration 19147, Loss: 0.05398856848478317\n",
      "Iteration 19148, Loss: 0.054171085357666016\n",
      "Iteration 19149, Loss: 0.05398872494697571\n",
      "Iteration 19150, Loss: 0.054171040654182434\n",
      "Iteration 19151, Loss: 0.05398891493678093\n",
      "Iteration 19152, Loss: 0.05417099595069885\n",
      "Iteration 19153, Loss: 0.05398891493678093\n",
      "Iteration 19154, Loss: 0.05417100712656975\n",
      "Iteration 19155, Loss: 0.05398876592516899\n",
      "Iteration 19156, Loss: 0.05417124554514885\n",
      "Iteration 19157, Loss: 0.05398856848478317\n",
      "Iteration 19158, Loss: 0.054171279072761536\n",
      "Iteration 19159, Loss: 0.05398833751678467\n",
      "Iteration 19160, Loss: 0.05417128652334213\n",
      "Iteration 19161, Loss: 0.053988486528396606\n",
      "Iteration 19162, Loss: 0.05417117103934288\n",
      "Iteration 19163, Loss: 0.05398864671587944\n",
      "Iteration 19164, Loss: 0.05417104810476303\n",
      "Iteration 19165, Loss: 0.05398879945278168\n",
      "Iteration 19166, Loss: 0.054170891642570496\n",
      "Iteration 19167, Loss: 0.05398883670568466\n",
      "Iteration 19168, Loss: 0.05417100712656975\n",
      "Iteration 19169, Loss: 0.05398891493678093\n",
      "Iteration 19170, Loss: 0.05417092889547348\n",
      "Iteration 19171, Loss: 0.053988806903362274\n",
      "Iteration 19172, Loss: 0.054171085357666016\n",
      "Iteration 19173, Loss: 0.05398872494697571\n",
      "Iteration 19174, Loss: 0.05417116731405258\n",
      "Iteration 19175, Loss: 0.05398852750658989\n",
      "Iteration 19176, Loss: 0.05417121201753616\n",
      "Iteration 19177, Loss: 0.05398845300078392\n",
      "Iteration 19178, Loss: 0.054171204566955566\n",
      "Iteration 19179, Loss: 0.05398841202259064\n",
      "Iteration 19180, Loss: 0.05417128652334213\n",
      "Iteration 19181, Loss: 0.053988419473171234\n",
      "Iteration 19182, Loss: 0.054171279072761536\n",
      "Iteration 19183, Loss: 0.05398856848478317\n",
      "Iteration 19184, Loss: 0.0541711263358593\n",
      "Iteration 19185, Loss: 0.05398868769407272\n",
      "Iteration 19186, Loss: 0.05417108163237572\n",
      "Iteration 19187, Loss: 0.05398876592516899\n",
      "Iteration 19188, Loss: 0.05417100712656975\n",
      "Iteration 19189, Loss: 0.05398883670568466\n",
      "Iteration 19190, Loss: 0.054170891642570496\n",
      "Iteration 19191, Loss: 0.05398895591497421\n",
      "Iteration 19192, Loss: 0.05417093262076378\n",
      "Iteration 19193, Loss: 0.05398876592516899\n",
      "Iteration 19194, Loss: 0.054171204566955566\n",
      "Iteration 19195, Loss: 0.053988754749298096\n",
      "Iteration 19196, Loss: 0.05417132005095482\n",
      "Iteration 19197, Loss: 0.05398837849497795\n",
      "Iteration 19198, Loss: 0.054171137511730194\n",
      "Iteration 19199, Loss: 0.05398852378129959\n",
      "Iteration 19200, Loss: 0.05417120084166527\n",
      "Iteration 19201, Loss: 0.0539884977042675\n",
      "Iteration 19202, Loss: 0.054170966148376465\n",
      "Iteration 19203, Loss: 0.05398876592516899\n",
      "Iteration 19204, Loss: 0.05417077988386154\n",
      "Iteration 19205, Loss: 0.05398895964026451\n",
      "Iteration 19206, Loss: 0.05417073518037796\n",
      "Iteration 19207, Loss: 0.053989000618457794\n",
      "Iteration 19208, Loss: 0.05417073890566826\n",
      "Iteration 19209, Loss: 0.053988926112651825\n",
      "Iteration 19210, Loss: 0.054170966148376465\n",
      "Iteration 19211, Loss: 0.05398883670568466\n",
      "Iteration 19212, Loss: 0.0541711263358593\n",
      "Iteration 19213, Loss: 0.05398867651820183\n",
      "Iteration 19214, Loss: 0.05417139455676079\n",
      "Iteration 19215, Loss: 0.053988561034202576\n",
      "Iteration 19216, Loss: 0.0541713647544384\n",
      "Iteration 19217, Loss: 0.05398833006620407\n",
      "Iteration 19218, Loss: 0.05417129397392273\n",
      "Iteration 19219, Loss: 0.053988292813301086\n",
      "Iteration 19220, Loss: 0.05417128652334213\n",
      "Iteration 19221, Loss: 0.05398852750658989\n",
      "Iteration 19222, Loss: 0.054171085357666016\n",
      "Iteration 19223, Loss: 0.05398861691355705\n",
      "Iteration 19224, Loss: 0.05417107790708542\n",
      "Iteration 19225, Loss: 0.05398868769407272\n",
      "Iteration 19226, Loss: 0.05417100712656975\n",
      "Iteration 19227, Loss: 0.053988538682460785\n",
      "Iteration 19228, Loss: 0.054171085357666016\n",
      "Iteration 19229, Loss: 0.05398856848478317\n",
      "Iteration 19230, Loss: 0.05417116731405258\n",
      "Iteration 19231, Loss: 0.05398845300078392\n",
      "Iteration 19232, Loss: 0.054171137511730194\n",
      "Iteration 19233, Loss: 0.05398853123188019\n",
      "Iteration 19234, Loss: 0.0541711263358593\n",
      "Iteration 19235, Loss: 0.05398857221007347\n",
      "Iteration 19236, Loss: 0.05417108163237572\n",
      "Iteration 19237, Loss: 0.05398869141936302\n",
      "Iteration 19238, Loss: 0.05417107790708542\n",
      "Iteration 19239, Loss: 0.053988732397556305\n",
      "Iteration 19240, Loss: 0.05417100340127945\n",
      "Iteration 19241, Loss: 0.053988806903362274\n",
      "Iteration 19242, Loss: 0.054171040654182434\n",
      "Iteration 19243, Loss: 0.05398884415626526\n",
      "Iteration 19244, Loss: 0.05417100340127945\n",
      "Iteration 19245, Loss: 0.053988657891750336\n",
      "Iteration 19246, Loss: 0.054170891642570496\n",
      "Iteration 19247, Loss: 0.05398861691355705\n",
      "Iteration 19248, Loss: 0.054171010851860046\n",
      "Iteration 19249, Loss: 0.05398860573768616\n",
      "Iteration 19250, Loss: 0.054171137511730194\n",
      "Iteration 19251, Loss: 0.053988419473171234\n",
      "Iteration 19252, Loss: 0.05417116731405258\n",
      "Iteration 19253, Loss: 0.05398856848478317\n",
      "Iteration 19254, Loss: 0.054171204566955566\n",
      "Iteration 19255, Loss: 0.05398864671587944\n",
      "Iteration 19256, Loss: 0.05417109280824661\n",
      "Iteration 19257, Loss: 0.05398868769407272\n",
      "Iteration 19258, Loss: 0.05417108163237572\n",
      "Iteration 19259, Loss: 0.053988732397556305\n",
      "Iteration 19260, Loss: 0.05417107790708542\n",
      "Iteration 19261, Loss: 0.05398868769407272\n",
      "Iteration 19262, Loss: 0.05417100712656975\n",
      "Iteration 19263, Loss: 0.05398857593536377\n",
      "Iteration 19264, Loss: 0.05417120084166527\n",
      "Iteration 19265, Loss: 0.05398857221007347\n",
      "Iteration 19266, Loss: 0.0541711263358593\n",
      "Iteration 19267, Loss: 0.05398856848478317\n",
      "Iteration 19268, Loss: 0.05417116731405258\n",
      "Iteration 19269, Loss: 0.053988613188266754\n",
      "Iteration 19270, Loss: 0.05417108163237572\n",
      "Iteration 19271, Loss: 0.05398864671587944\n",
      "Iteration 19272, Loss: 0.054170966148376465\n",
      "Iteration 19273, Loss: 0.053988806903362274\n",
      "Iteration 19274, Loss: 0.0541708879172802\n",
      "Iteration 19275, Loss: 0.053988777101039886\n",
      "Iteration 19276, Loss: 0.05417085438966751\n",
      "Iteration 19277, Loss: 0.0539889931678772\n",
      "Iteration 19278, Loss: 0.05417077988386154\n",
      "Iteration 19279, Loss: 0.05398888513445854\n",
      "Iteration 19280, Loss: 0.054170891642570496\n",
      "Iteration 19281, Loss: 0.053988806903362274\n",
      "Iteration 19282, Loss: 0.05417104810476303\n",
      "Iteration 19283, Loss: 0.05398864671587944\n",
      "Iteration 19284, Loss: 0.05417116731405258\n",
      "Iteration 19285, Loss: 0.05398837849497795\n",
      "Iteration 19286, Loss: 0.05417116731405258\n",
      "Iteration 19287, Loss: 0.0539884977042675\n",
      "Iteration 19288, Loss: 0.054171156138181686\n",
      "Iteration 19289, Loss: 0.053988613188266754\n",
      "Iteration 19290, Loss: 0.0541711263358593\n",
      "Iteration 19291, Loss: 0.0539884977042675\n",
      "Iteration 19292, Loss: 0.054171085357666016\n",
      "Iteration 19293, Loss: 0.05398860573768616\n",
      "Iteration 19294, Loss: 0.05417100712656975\n",
      "Iteration 19295, Loss: 0.05398868769407272\n",
      "Iteration 19296, Loss: 0.054170966148376465\n",
      "Iteration 19297, Loss: 0.05398876592516899\n",
      "Iteration 19298, Loss: 0.054170966148376465\n",
      "Iteration 19299, Loss: 0.05398884415626526\n",
      "Iteration 19300, Loss: 0.05417092889547348\n",
      "Iteration 19301, Loss: 0.053988732397556305\n",
      "Iteration 19302, Loss: 0.054171040654182434\n",
      "Iteration 19303, Loss: 0.05398872494697571\n",
      "Iteration 19304, Loss: 0.054171040654182434\n",
      "Iteration 19305, Loss: 0.05398868769407272\n",
      "Iteration 19306, Loss: 0.05417108163237572\n",
      "Iteration 19307, Loss: 0.05398868769407272\n",
      "Iteration 19308, Loss: 0.05417105183005333\n",
      "Iteration 19309, Loss: 0.05398868769407272\n",
      "Iteration 19310, Loss: 0.054170966148376465\n",
      "Iteration 19311, Loss: 0.05398876592516899\n",
      "Iteration 19312, Loss: 0.05417077988386154\n",
      "Iteration 19313, Loss: 0.05398888513445854\n",
      "Iteration 19314, Loss: 0.054170846939086914\n",
      "Iteration 19315, Loss: 0.05398900434374809\n",
      "Iteration 19316, Loss: 0.054170846939086914\n",
      "Iteration 19317, Loss: 0.05398888513445854\n",
      "Iteration 19318, Loss: 0.05417093262076378\n",
      "Iteration 19319, Loss: 0.05398865044116974\n",
      "Iteration 19320, Loss: 0.05417104810476303\n",
      "Iteration 19321, Loss: 0.05398852750658989\n",
      "Iteration 19322, Loss: 0.0541711263358593\n",
      "Iteration 19323, Loss: 0.0539884939789772\n",
      "Iteration 19324, Loss: 0.05417127534747124\n",
      "Iteration 19325, Loss: 0.05398856848478317\n",
      "Iteration 19326, Loss: 0.054171085357666016\n",
      "Iteration 19327, Loss: 0.05398864671587944\n",
      "Iteration 19328, Loss: 0.05417108163237572\n",
      "Iteration 19329, Loss: 0.05398857221007347\n",
      "Iteration 19330, Loss: 0.054170891642570496\n",
      "Iteration 19331, Loss: 0.05398884415626526\n",
      "Iteration 19332, Loss: 0.05417081341147423\n",
      "Iteration 19333, Loss: 0.053988926112651825\n",
      "Iteration 19334, Loss: 0.05417073890566826\n",
      "Iteration 19335, Loss: 0.05398895591497421\n",
      "Iteration 19336, Loss: 0.054170846939086914\n",
      "Iteration 19337, Loss: 0.053988732397556305\n",
      "Iteration 19338, Loss: 0.054170817136764526\n",
      "Iteration 19339, Loss: 0.05398876592516899\n",
      "Iteration 19340, Loss: 0.05417092889547348\n",
      "Iteration 19341, Loss: 0.05398876592516899\n",
      "Iteration 19342, Loss: 0.054170768707990646\n",
      "Iteration 19343, Loss: 0.053988926112651825\n",
      "Iteration 19344, Loss: 0.05417050048708916\n",
      "Iteration 19345, Loss: 0.053989045321941376\n",
      "Iteration 19346, Loss: 0.05417057126760483\n",
      "Iteration 19347, Loss: 0.05398919805884361\n",
      "Iteration 19348, Loss: 0.05417060852050781\n",
      "Iteration 19349, Loss: 0.05398908257484436\n",
      "Iteration 19350, Loss: 0.054170772433280945\n",
      "Iteration 19351, Loss: 0.05398888513445854\n",
      "Iteration 19352, Loss: 0.054171085357666016\n",
      "Iteration 19353, Loss: 0.05398860573768616\n",
      "Iteration 19354, Loss: 0.05417124554514885\n",
      "Iteration 19355, Loss: 0.05398844927549362\n",
      "Iteration 19356, Loss: 0.0541711300611496\n",
      "Iteration 19357, Loss: 0.053988419473171234\n",
      "Iteration 19358, Loss: 0.05417104810476303\n",
      "Iteration 19359, Loss: 0.05398861691355705\n",
      "Iteration 19360, Loss: 0.054170817136764526\n",
      "Iteration 19361, Loss: 0.05398869514465332\n",
      "Iteration 19362, Loss: 0.05417076498270035\n",
      "Iteration 19363, Loss: 0.05398900434374809\n",
      "Iteration 19364, Loss: 0.05417034029960632\n",
      "Iteration 19365, Loss: 0.053989164531230927\n",
      "Iteration 19366, Loss: 0.054170411080121994\n",
      "Iteration 19367, Loss: 0.05398912355303764\n",
      "Iteration 19368, Loss: 0.05417050048708916\n",
      "Iteration 19369, Loss: 0.05398901551961899\n",
      "Iteration 19370, Loss: 0.05417073518037796\n",
      "Iteration 19371, Loss: 0.05398884415626526\n",
      "Iteration 19372, Loss: 0.05417100712656975\n",
      "Iteration 19373, Loss: 0.05398845300078392\n",
      "Iteration 19374, Loss: 0.054171279072761536\n",
      "Iteration 19375, Loss: 0.05398841202259064\n",
      "Iteration 19376, Loss: 0.054171204566955566\n",
      "Iteration 19377, Loss: 0.05398853123188019\n",
      "Iteration 19378, Loss: 0.054170966148376465\n",
      "Iteration 19379, Loss: 0.05398876592516899\n",
      "Iteration 19380, Loss: 0.054170917719602585\n",
      "Iteration 19381, Loss: 0.05398900434374809\n",
      "Iteration 19382, Loss: 0.05417057126760483\n",
      "Iteration 19383, Loss: 0.053989313542842865\n",
      "Iteration 19384, Loss: 0.05417030304670334\n",
      "Iteration 19385, Loss: 0.05398931726813316\n",
      "Iteration 19386, Loss: 0.05417037755250931\n",
      "Iteration 19387, Loss: 0.053989194333553314\n",
      "Iteration 19388, Loss: 0.05417072772979736\n",
      "Iteration 19389, Loss: 0.05398888885974884\n",
      "Iteration 19390, Loss: 0.05417081341147423\n",
      "Iteration 19391, Loss: 0.05398884415626526\n",
      "Iteration 19392, Loss: 0.05417085811495781\n",
      "Iteration 19393, Loss: 0.05398861691355705\n",
      "Iteration 19394, Loss: 0.054171040654182434\n",
      "Iteration 19395, Loss: 0.05398857593536377\n",
      "Iteration 19396, Loss: 0.054171036928892136\n",
      "Iteration 19397, Loss: 0.05398872494697571\n",
      "Iteration 19398, Loss: 0.054170768707990646\n",
      "Iteration 19399, Loss: 0.053988926112651825\n",
      "Iteration 19400, Loss: 0.054170768707990646\n",
      "Iteration 19401, Loss: 0.05398896336555481\n",
      "Iteration 19402, Loss: 0.05417060852050781\n",
      "Iteration 19403, Loss: 0.05398907512426376\n",
      "Iteration 19404, Loss: 0.054170649498701096\n",
      "Iteration 19405, Loss: 0.05398915335536003\n",
      "Iteration 19406, Loss: 0.054170653223991394\n",
      "Iteration 19407, Loss: 0.05398896336555481\n",
      "Iteration 19408, Loss: 0.054170817136764526\n",
      "Iteration 19409, Loss: 0.05398876219987869\n",
      "Iteration 19410, Loss: 0.054171085357666016\n",
      "Iteration 19411, Loss: 0.05398852750658989\n",
      "Iteration 19412, Loss: 0.05417124554514885\n",
      "Iteration 19413, Loss: 0.05398859828710556\n",
      "Iteration 19414, Loss: 0.054171204566955566\n",
      "Iteration 19415, Loss: 0.053988538682460785\n",
      "Iteration 19416, Loss: 0.054171010851860046\n",
      "Iteration 19417, Loss: 0.05398864671587944\n",
      "Iteration 19418, Loss: 0.054170966148376465\n",
      "Iteration 19419, Loss: 0.05398872494697571\n",
      "Iteration 19420, Loss: 0.054170966148376465\n",
      "Iteration 19421, Loss: 0.05398876592516899\n",
      "Iteration 19422, Loss: 0.05417089909315109\n",
      "Iteration 19423, Loss: 0.05398861691355705\n",
      "Iteration 19424, Loss: 0.05417109280824661\n",
      "Iteration 19425, Loss: 0.05398845672607422\n",
      "Iteration 19426, Loss: 0.0541711300611496\n",
      "Iteration 19427, Loss: 0.0539884977042675\n",
      "Iteration 19428, Loss: 0.05417109280824661\n",
      "Iteration 19429, Loss: 0.053988538682460785\n",
      "Iteration 19430, Loss: 0.054171234369277954\n",
      "Iteration 19431, Loss: 0.0539884977042675\n",
      "Iteration 19432, Loss: 0.05417104810476303\n",
      "Iteration 19433, Loss: 0.05398861691355705\n",
      "Iteration 19434, Loss: 0.054171036928892136\n",
      "Iteration 19435, Loss: 0.053988806903362274\n",
      "Iteration 19436, Loss: 0.05417089909315109\n",
      "Iteration 19437, Loss: 0.05398888513445854\n",
      "Iteration 19438, Loss: 0.054171040654182434\n",
      "Iteration 19439, Loss: 0.05398868769407272\n",
      "Iteration 19440, Loss: 0.054171010851860046\n",
      "Iteration 19441, Loss: 0.05398857221007347\n",
      "Iteration 19442, Loss: 0.0541711263358593\n",
      "Iteration 19443, Loss: 0.053988635540008545\n",
      "Iteration 19444, Loss: 0.054171085357666016\n",
      "Iteration 19445, Loss: 0.05398857593536377\n",
      "Iteration 19446, Loss: 0.05417089909315109\n",
      "Iteration 19447, Loss: 0.05398872494697571\n",
      "Iteration 19448, Loss: 0.054170966148376465\n",
      "Iteration 19449, Loss: 0.05398876592516899\n",
      "Iteration 19450, Loss: 0.054171036928892136\n",
      "Iteration 19451, Loss: 0.05398865044116974\n",
      "Iteration 19452, Loss: 0.054171122610569\n",
      "Iteration 19453, Loss: 0.05398860573768616\n",
      "Iteration 19454, Loss: 0.05417124181985855\n",
      "Iteration 19455, Loss: 0.053988680243492126\n",
      "Iteration 19456, Loss: 0.054171159863471985\n",
      "Iteration 19457, Loss: 0.05398872122168541\n",
      "Iteration 19458, Loss: 0.05417124554514885\n",
      "Iteration 19459, Loss: 0.05398864671587944\n",
      "Iteration 19460, Loss: 0.054171353578567505\n",
      "Iteration 19461, Loss: 0.05398844927549362\n",
      "Iteration 19462, Loss: 0.05417144298553467\n",
      "Iteration 19463, Loss: 0.053988248109817505\n",
      "Iteration 19464, Loss: 0.05417155846953392\n",
      "Iteration 19465, Loss: 0.05398828908801079\n",
      "Iteration 19466, Loss: 0.0541713610291481\n",
      "Iteration 19467, Loss: 0.05398852750658989\n",
      "Iteration 19468, Loss: 0.05417116731405258\n",
      "Iteration 19469, Loss: 0.05398864671587944\n",
      "Iteration 19470, Loss: 0.05417085438966751\n",
      "Iteration 19471, Loss: 0.05398888140916824\n",
      "Iteration 19472, Loss: 0.05417080968618393\n",
      "Iteration 19473, Loss: 0.05398903414607048\n",
      "Iteration 19474, Loss: 0.054170768707990646\n",
      "Iteration 19475, Loss: 0.05398891866207123\n",
      "Iteration 19476, Loss: 0.05417100712656975\n",
      "Iteration 19477, Loss: 0.05398879945278168\n",
      "Iteration 19478, Loss: 0.0541711263358593\n",
      "Iteration 19479, Loss: 0.05398856848478317\n",
      "Iteration 19480, Loss: 0.05417129024863243\n",
      "Iteration 19481, Loss: 0.053988516330718994\n",
      "Iteration 19482, Loss: 0.05417148396372795\n",
      "Iteration 19483, Loss: 0.05398821085691452\n",
      "Iteration 19484, Loss: 0.054171524941921234\n",
      "Iteration 19485, Loss: 0.0539882592856884\n",
      "Iteration 19486, Loss: 0.0541713647544384\n",
      "Iteration 19487, Loss: 0.053988486528396606\n",
      "Iteration 19488, Loss: 0.05417104810476303\n",
      "Iteration 19489, Loss: 0.05398868769407272\n",
      "Iteration 19490, Loss: 0.054170966148376465\n",
      "Iteration 19491, Loss: 0.05398884415626526\n",
      "Iteration 19492, Loss: 0.05417080968618393\n",
      "Iteration 19493, Loss: 0.053988926112651825\n",
      "Iteration 19494, Loss: 0.0541708879172802\n",
      "Iteration 19495, Loss: 0.05398907512426376\n",
      "Iteration 19496, Loss: 0.0541708879172802\n",
      "Iteration 19497, Loss: 0.05398872494697571\n",
      "Iteration 19498, Loss: 0.05417108163237572\n",
      "Iteration 19499, Loss: 0.05398872494697571\n",
      "Iteration 19500, Loss: 0.05417116731405258\n",
      "Iteration 19501, Loss: 0.05398872122168541\n",
      "Iteration 19502, Loss: 0.054171279072761536\n",
      "Iteration 19503, Loss: 0.053988419473171234\n",
      "Iteration 19504, Loss: 0.05417131632566452\n",
      "Iteration 19505, Loss: 0.05398837849497795\n",
      "Iteration 19506, Loss: 0.05417132005095482\n",
      "Iteration 19507, Loss: 0.053988486528396606\n",
      "Iteration 19508, Loss: 0.05417128652334213\n",
      "Iteration 19509, Loss: 0.0539884939789772\n",
      "Iteration 19510, Loss: 0.054171159863471985\n",
      "Iteration 19511, Loss: 0.05398865044116974\n",
      "Iteration 19512, Loss: 0.05417100712656975\n",
      "Iteration 19513, Loss: 0.05398869141936302\n",
      "Iteration 19514, Loss: 0.054170966148376465\n",
      "Iteration 19515, Loss: 0.05398876592516899\n",
      "Iteration 19516, Loss: 0.05417100340127945\n",
      "Iteration 19517, Loss: 0.05398865044116974\n",
      "Iteration 19518, Loss: 0.054171156138181686\n",
      "Iteration 19519, Loss: 0.053988613188266754\n",
      "Iteration 19520, Loss: 0.05417120084166527\n",
      "Iteration 19521, Loss: 0.05398852750658989\n",
      "Iteration 19522, Loss: 0.05417128652334213\n",
      "Iteration 19523, Loss: 0.05398852750658989\n",
      "Iteration 19524, Loss: 0.05417124554514885\n",
      "Iteration 19525, Loss: 0.05398852750658989\n",
      "Iteration 19526, Loss: 0.05417128652334213\n",
      "Iteration 19527, Loss: 0.05398837476968765\n",
      "Iteration 19528, Loss: 0.05417140573263168\n",
      "Iteration 19529, Loss: 0.05398840829730034\n",
      "Iteration 19530, Loss: 0.0541713647544384\n",
      "Iteration 19531, Loss: 0.053988486528396606\n",
      "Iteration 19532, Loss: 0.05417128652334213\n",
      "Iteration 19533, Loss: 0.053988419473171234\n",
      "Iteration 19534, Loss: 0.0541711263358593\n",
      "Iteration 19535, Loss: 0.05398864671587944\n",
      "Iteration 19536, Loss: 0.05417107790708542\n",
      "Iteration 19537, Loss: 0.053988806903362274\n",
      "Iteration 19538, Loss: 0.05417092889547348\n",
      "Iteration 19539, Loss: 0.05398876592516899\n",
      "Iteration 19540, Loss: 0.05417092144489288\n",
      "Iteration 19541, Loss: 0.05398891493678093\n",
      "Iteration 19542, Loss: 0.054170966148376465\n",
      "Iteration 19543, Loss: 0.053988806903362274\n",
      "Iteration 19544, Loss: 0.054171156138181686\n",
      "Iteration 19545, Loss: 0.05398876219987869\n",
      "Iteration 19546, Loss: 0.054171353578567505\n",
      "Iteration 19547, Loss: 0.053988486528396606\n",
      "Iteration 19548, Loss: 0.054171644151210785\n",
      "Iteration 19549, Loss: 0.05398814007639885\n",
      "Iteration 19550, Loss: 0.05417165160179138\n",
      "Iteration 19551, Loss: 0.05398809164762497\n",
      "Iteration 19552, Loss: 0.0541716031730175\n",
      "Iteration 19553, Loss: 0.0539882592856884\n",
      "Iteration 19554, Loss: 0.05417131632566452\n",
      "Iteration 19555, Loss: 0.05398857221007347\n",
      "Iteration 19556, Loss: 0.0541708767414093\n",
      "Iteration 19557, Loss: 0.05398900434374809\n",
      "Iteration 19558, Loss: 0.05417048558592796\n",
      "Iteration 19559, Loss: 0.05398942157626152\n",
      "Iteration 19560, Loss: 0.054170481860637665\n",
      "Iteration 19561, Loss: 0.05398920178413391\n",
      "Iteration 19562, Loss: 0.05417060852050781\n",
      "Iteration 19563, Loss: 0.05398908257484436\n",
      "Iteration 19564, Loss: 0.054170962423086166\n",
      "Iteration 19565, Loss: 0.05398879945278168\n",
      "Iteration 19566, Loss: 0.054171204566955566\n",
      "Iteration 19567, Loss: 0.05398844927549362\n",
      "Iteration 19568, Loss: 0.05417155846953392\n",
      "Iteration 19569, Loss: 0.05398821085691452\n",
      "Iteration 19570, Loss: 0.05417171120643616\n",
      "Iteration 19571, Loss: 0.053988054394721985\n",
      "Iteration 19572, Loss: 0.05417167395353317\n",
      "Iteration 19573, Loss: 0.053988099098205566\n",
      "Iteration 19574, Loss: 0.05417155474424362\n",
      "Iteration 19575, Loss: 0.05398833751678467\n",
      "Iteration 19576, Loss: 0.054171159863471985\n",
      "Iteration 19577, Loss: 0.05398860573768616\n",
      "Iteration 19578, Loss: 0.054171036928892136\n",
      "Iteration 19579, Loss: 0.05398895591497421\n",
      "Iteration 19580, Loss: 0.054170843213796616\n",
      "Iteration 19581, Loss: 0.05398907512426376\n",
      "Iteration 19582, Loss: 0.0541708879172802\n",
      "Iteration 19583, Loss: 0.05398884415626526\n",
      "Iteration 19584, Loss: 0.054170966148376465\n",
      "Iteration 19585, Loss: 0.053988613188266754\n",
      "Iteration 19586, Loss: 0.054171156138181686\n",
      "Iteration 19587, Loss: 0.05398871749639511\n",
      "Iteration 19588, Loss: 0.0541711263358593\n",
      "Iteration 19589, Loss: 0.05398856848478317\n",
      "Iteration 19590, Loss: 0.054171156138181686\n",
      "Iteration 19591, Loss: 0.05398868769407272\n",
      "Iteration 19592, Loss: 0.05417100712656975\n",
      "Iteration 19593, Loss: 0.05398869514465332\n",
      "Iteration 19594, Loss: 0.05417092889547348\n",
      "Iteration 19595, Loss: 0.05398895591497421\n",
      "Iteration 19596, Loss: 0.054170962423086166\n",
      "Iteration 19597, Loss: 0.053988873958587646\n",
      "Iteration 19598, Loss: 0.0541711151599884\n",
      "Iteration 19599, Loss: 0.05398872494697571\n",
      "Iteration 19600, Loss: 0.0541711263358593\n",
      "Iteration 19601, Loss: 0.05398852750658989\n",
      "Iteration 19602, Loss: 0.054171398282051086\n",
      "Iteration 19603, Loss: 0.05398840829730034\n",
      "Iteration 19604, Loss: 0.05417163670063019\n",
      "Iteration 19605, Loss: 0.05398828908801079\n",
      "Iteration 19606, Loss: 0.05417156219482422\n",
      "Iteration 19607, Loss: 0.05398828908801079\n",
      "Iteration 19608, Loss: 0.0541713610291481\n",
      "Iteration 19609, Loss: 0.05398856848478317\n",
      "Iteration 19610, Loss: 0.0541711263358593\n",
      "Iteration 19611, Loss: 0.05398861691355705\n",
      "Iteration 19612, Loss: 0.05417115241289139\n",
      "Iteration 19613, Loss: 0.05398872494697571\n",
      "Iteration 19614, Loss: 0.05417104810476303\n",
      "Iteration 19615, Loss: 0.05398864671587944\n",
      "Iteration 19616, Loss: 0.054171156138181686\n",
      "Iteration 19617, Loss: 0.05398856848478317\n",
      "Iteration 19618, Loss: 0.05417119711637497\n",
      "Iteration 19619, Loss: 0.05398860573768616\n",
      "Iteration 19620, Loss: 0.054171085357666016\n",
      "Iteration 19621, Loss: 0.0539884977042675\n",
      "Iteration 19622, Loss: 0.05417100712656975\n",
      "Iteration 19623, Loss: 0.05398872494697571\n",
      "Iteration 19624, Loss: 0.05417092144489288\n",
      "Iteration 19625, Loss: 0.05398888513445854\n",
      "Iteration 19626, Loss: 0.05417099595069885\n",
      "Iteration 19627, Loss: 0.05398884415626526\n",
      "Iteration 19628, Loss: 0.054170798510313034\n",
      "Iteration 19629, Loss: 0.053989000618457794\n",
      "Iteration 19630, Loss: 0.05417083948850632\n",
      "Iteration 19631, Loss: 0.05398907884955406\n",
      "Iteration 19632, Loss: 0.05417099595069885\n",
      "Iteration 19633, Loss: 0.0539889931678772\n",
      "Iteration 19634, Loss: 0.054171122610569\n",
      "Iteration 19635, Loss: 0.05398856848478317\n",
      "Iteration 19636, Loss: 0.05417143553495407\n",
      "Iteration 19637, Loss: 0.05398833379149437\n",
      "Iteration 19638, Loss: 0.05417148396372795\n",
      "Iteration 19639, Loss: 0.05398839712142944\n",
      "Iteration 19640, Loss: 0.05417148023843765\n",
      "Iteration 19641, Loss: 0.05398836359381676\n",
      "Iteration 19642, Loss: 0.054171472787857056\n",
      "Iteration 19643, Loss: 0.053988486528396606\n",
      "Iteration 19644, Loss: 0.054171234369277954\n",
      "Iteration 19645, Loss: 0.05398864671587944\n",
      "Iteration 19646, Loss: 0.05417107790708542\n",
      "Iteration 19647, Loss: 0.05398883670568466\n",
      "Iteration 19648, Loss: 0.0541708767414093\n",
      "Iteration 19649, Loss: 0.05398896336555481\n",
      "Iteration 19650, Loss: 0.05417072772979736\n",
      "Iteration 19651, Loss: 0.05398900434374809\n",
      "Iteration 19652, Loss: 0.05417100712656975\n",
      "Iteration 19653, Loss: 0.053988806903362274\n",
      "Iteration 19654, Loss: 0.0541711263358593\n",
      "Iteration 19655, Loss: 0.05398856848478317\n",
      "Iteration 19656, Loss: 0.054171398282051086\n",
      "Iteration 19657, Loss: 0.05398828908801079\n",
      "Iteration 19658, Loss: 0.05417155474424362\n",
      "Iteration 19659, Loss: 0.053988441824913025\n",
      "Iteration 19660, Loss: 0.054171547293663025\n",
      "Iteration 19661, Loss: 0.05398852750658989\n",
      "Iteration 19662, Loss: 0.05417132005095482\n",
      "Iteration 19663, Loss: 0.053988680243492126\n",
      "Iteration 19664, Loss: 0.054171040654182434\n",
      "Iteration 19665, Loss: 0.05398888513445854\n",
      "Iteration 19666, Loss: 0.054170891642570496\n",
      "Iteration 19667, Loss: 0.053988873958587646\n",
      "Iteration 19668, Loss: 0.05417100712656975\n",
      "Iteration 19669, Loss: 0.05398876592516899\n",
      "Iteration 19670, Loss: 0.054171122610569\n",
      "Iteration 19671, Loss: 0.05398876592516899\n",
      "Iteration 19672, Loss: 0.05417120084166527\n",
      "Iteration 19673, Loss: 0.05398864671587944\n",
      "Iteration 19674, Loss: 0.0541711263358593\n",
      "Iteration 19675, Loss: 0.05398868769407272\n",
      "Iteration 19676, Loss: 0.054171085357666016\n",
      "Iteration 19677, Loss: 0.05398871749639511\n",
      "Iteration 19678, Loss: 0.054171156138181686\n",
      "Iteration 19679, Loss: 0.05398864671587944\n",
      "Iteration 19680, Loss: 0.054171159863471985\n",
      "Iteration 19681, Loss: 0.053988613188266754\n",
      "Iteration 19682, Loss: 0.054171156138181686\n",
      "Iteration 19683, Loss: 0.05398879572749138\n",
      "Iteration 19684, Loss: 0.05417104810476303\n",
      "Iteration 19685, Loss: 0.05398879572749138\n",
      "Iteration 19686, Loss: 0.05417115241289139\n",
      "Iteration 19687, Loss: 0.05398876592516899\n",
      "Iteration 19688, Loss: 0.054171159863471985\n",
      "Iteration 19689, Loss: 0.05398879572749138\n",
      "Iteration 19690, Loss: 0.05417116731405258\n",
      "Iteration 19691, Loss: 0.05398860573768616\n",
      "Iteration 19692, Loss: 0.0541711263358593\n",
      "Iteration 19693, Loss: 0.053988538682460785\n",
      "Iteration 19694, Loss: 0.054171159863471985\n",
      "Iteration 19695, Loss: 0.05398860573768616\n",
      "Iteration 19696, Loss: 0.05417100712656975\n",
      "Iteration 19697, Loss: 0.05398879945278168\n",
      "Iteration 19698, Loss: 0.05417089909315109\n",
      "Iteration 19699, Loss: 0.05398884415626526\n",
      "Iteration 19700, Loss: 0.05417099595069885\n",
      "Iteration 19701, Loss: 0.05398888513445854\n",
      "Iteration 19702, Loss: 0.05417099595069885\n",
      "Iteration 19703, Loss: 0.05398888513445854\n",
      "Iteration 19704, Loss: 0.054171036928892136\n",
      "Iteration 19705, Loss: 0.05398879945278168\n",
      "Iteration 19706, Loss: 0.054171085357666016\n",
      "Iteration 19707, Loss: 0.05398872122168541\n",
      "Iteration 19708, Loss: 0.05417128652334213\n",
      "Iteration 19709, Loss: 0.053988486528396606\n",
      "Iteration 19710, Loss: 0.05417128652334213\n",
      "Iteration 19711, Loss: 0.05398844927549362\n",
      "Iteration 19712, Loss: 0.054171543568372726\n",
      "Iteration 19713, Loss: 0.053988441824913025\n",
      "Iteration 19714, Loss: 0.05417131632566452\n",
      "Iteration 19715, Loss: 0.05398860573768616\n",
      "Iteration 19716, Loss: 0.05417116731405258\n",
      "Iteration 19717, Loss: 0.05398860573768616\n",
      "Iteration 19718, Loss: 0.05417100712656975\n",
      "Iteration 19719, Loss: 0.05398879945278168\n",
      "Iteration 19720, Loss: 0.054171040654182434\n",
      "Iteration 19721, Loss: 0.05398814380168915\n",
      "Iteration 19722, Loss: 0.054171085357666016\n",
      "Iteration 19723, Loss: 0.05398806929588318\n",
      "Iteration 19724, Loss: 0.054170578718185425\n",
      "Iteration 19725, Loss: 0.05398779362440109\n",
      "Iteration 19726, Loss: 0.05417066812515259\n",
      "Iteration 19727, Loss: 0.05398779362440109\n",
      "Iteration 19728, Loss: 0.054170697927474976\n",
      "Iteration 19729, Loss: 0.05398775264620781\n",
      "Iteration 19730, Loss: 0.05417061969637871\n",
      "Iteration 19731, Loss: 0.05398798733949661\n",
      "Iteration 19732, Loss: 0.05417042225599289\n",
      "Iteration 19733, Loss: 0.05398811027407646\n",
      "Iteration 19734, Loss: 0.05417030677199364\n",
      "Iteration 19735, Loss: 0.053988225758075714\n",
      "Iteration 19736, Loss: 0.054170262068510056\n",
      "Iteration 19737, Loss: 0.0539882630109787\n",
      "Iteration 19738, Loss: 0.05417030304670334\n",
      "Iteration 19739, Loss: 0.05398830026388168\n",
      "Iteration 19740, Loss: 0.054170385003089905\n",
      "Iteration 19741, Loss: 0.05398811027407646\n",
      "Iteration 19742, Loss: 0.054170459508895874\n",
      "Iteration 19743, Loss: 0.05398810654878616\n",
      "Iteration 19744, Loss: 0.05417054146528244\n",
      "Iteration 19745, Loss: 0.0539880208671093\n",
      "Iteration 19746, Loss: 0.05417054146528244\n",
      "Iteration 19747, Loss: 0.05398791283369064\n",
      "Iteration 19748, Loss: 0.054170459508895874\n",
      "Iteration 19749, Loss: 0.05398814007639885\n",
      "Iteration 19750, Loss: 0.054170381277799606\n",
      "Iteration 19751, Loss: 0.05398821830749512\n",
      "Iteration 19752, Loss: 0.05417030304670334\n",
      "Iteration 19753, Loss: 0.05398818850517273\n",
      "Iteration 19754, Loss: 0.054170381277799606\n",
      "Iteration 19755, Loss: 0.05398818477988243\n",
      "Iteration 19756, Loss: 0.05417030677199364\n",
      "Iteration 19757, Loss: 0.053988032042980194\n",
      "Iteration 19758, Loss: 0.05417042225599289\n",
      "Iteration 19759, Loss: 0.05398799106478691\n",
      "Iteration 19760, Loss: 0.05417050048708916\n",
      "Iteration 19761, Loss: 0.053988032042980194\n",
      "Iteration 19762, Loss: 0.05417050048708916\n",
      "Iteration 19763, Loss: 0.053988032042980194\n",
      "Iteration 19764, Loss: 0.05417042225599289\n",
      "Iteration 19765, Loss: 0.05398806557059288\n",
      "Iteration 19766, Loss: 0.05417050048708916\n",
      "Iteration 19767, Loss: 0.05398806557059288\n",
      "Iteration 19768, Loss: 0.05417050048708916\n",
      "Iteration 19769, Loss: 0.053988032042980194\n",
      "Iteration 19770, Loss: 0.05417054146528244\n",
      "Iteration 19771, Loss: 0.05398806557059288\n",
      "Iteration 19772, Loss: 0.054170459508895874\n",
      "Iteration 19773, Loss: 0.05398810654878616\n",
      "Iteration 19774, Loss: 0.05417050048708916\n",
      "Iteration 19775, Loss: 0.05398798733949661\n",
      "Iteration 19776, Loss: 0.05417073890566826\n",
      "Iteration 19777, Loss: 0.053987786173820496\n",
      "Iteration 19778, Loss: 0.05417078360915184\n",
      "Iteration 19779, Loss: 0.05398767441511154\n",
      "Iteration 19780, Loss: 0.05417089909315109\n",
      "Iteration 19781, Loss: 0.05398763343691826\n",
      "Iteration 19782, Loss: 0.05417073890566826\n",
      "Iteration 19783, Loss: 0.05398783087730408\n",
      "Iteration 19784, Loss: 0.05417053401470184\n",
      "Iteration 19785, Loss: 0.05398799479007721\n",
      "Iteration 19786, Loss: 0.05417030677199364\n",
      "Iteration 19787, Loss: 0.05398830398917198\n",
      "Iteration 19788, Loss: 0.05417030304670334\n",
      "Iteration 19789, Loss: 0.053988225758075714\n",
      "Iteration 19790, Loss: 0.054170455783605576\n",
      "Iteration 19791, Loss: 0.05398818477988243\n",
      "Iteration 19792, Loss: 0.05417050048708916\n",
      "Iteration 19793, Loss: 0.05398814380168915\n",
      "Iteration 19794, Loss: 0.054170653223991394\n",
      "Iteration 19795, Loss: 0.05398794636130333\n",
      "Iteration 19796, Loss: 0.05417077988386154\n",
      "Iteration 19797, Loss: 0.05398763343691826\n",
      "Iteration 19798, Loss: 0.05417097732424736\n",
      "Iteration 19799, Loss: 0.05398763343691826\n",
      "Iteration 19800, Loss: 0.05417089909315109\n",
      "Iteration 19801, Loss: 0.05398767441511154\n",
      "Iteration 19802, Loss: 0.054170697927474976\n",
      "Iteration 19803, Loss: 0.05398787185549736\n",
      "Iteration 19804, Loss: 0.054170459508895874\n",
      "Iteration 19805, Loss: 0.05398799106478691\n",
      "Iteration 19806, Loss: 0.05417034029960632\n",
      "Iteration 19807, Loss: 0.053988419473171234\n",
      "Iteration 19808, Loss: 0.054170262068510056\n",
      "Iteration 19809, Loss: 0.053988419473171234\n",
      "Iteration 19810, Loss: 0.05417023226618767\n",
      "Iteration 19811, Loss: 0.05398811027407646\n",
      "Iteration 19812, Loss: 0.05417049676179886\n",
      "Iteration 19813, Loss: 0.053988032042980194\n",
      "Iteration 19814, Loss: 0.054170653223991394\n",
      "Iteration 19815, Loss: 0.05398779362440109\n",
      "Iteration 19816, Loss: 0.05417066812515259\n",
      "Iteration 19817, Loss: 0.053987860679626465\n",
      "Iteration 19818, Loss: 0.05417080968618393\n",
      "Iteration 19819, Loss: 0.05398797616362572\n",
      "Iteration 19820, Loss: 0.05417061597108841\n",
      "Iteration 19821, Loss: 0.053988032042980194\n",
      "Iteration 19822, Loss: 0.054170459508895874\n",
      "Iteration 19823, Loss: 0.05398811027407646\n",
      "Iteration 19824, Loss: 0.05417042225599289\n",
      "Iteration 19825, Loss: 0.0539882592856884\n",
      "Iteration 19826, Loss: 0.054170459508895874\n",
      "Iteration 19827, Loss: 0.05398811027407646\n",
      "Iteration 19828, Loss: 0.05417042598128319\n",
      "Iteration 19829, Loss: 0.05398810654878616\n",
      "Iteration 19830, Loss: 0.05417047068476677\n",
      "Iteration 19831, Loss: 0.053988032042980194\n",
      "Iteration 19832, Loss: 0.05417047068476677\n",
      "Iteration 19833, Loss: 0.053987979888916016\n",
      "Iteration 19834, Loss: 0.05417061969637871\n",
      "Iteration 19835, Loss: 0.05398795008659363\n",
      "Iteration 19836, Loss: 0.054170578718185425\n",
      "Iteration 19837, Loss: 0.053987883031368256\n",
      "Iteration 19838, Loss: 0.054170459508895874\n",
      "Iteration 19839, Loss: 0.053988032042980194\n",
      "Iteration 19840, Loss: 0.05417042225599289\n",
      "Iteration 19841, Loss: 0.05398803949356079\n",
      "Iteration 19842, Loss: 0.054170381277799606\n",
      "Iteration 19843, Loss: 0.053988657891750336\n",
      "Iteration 19844, Loss: 0.05417030304670334\n",
      "Iteration 19845, Loss: 0.053988777101039886\n",
      "Iteration 19846, Loss: 0.054169707000255585\n",
      "Iteration 19847, Loss: 0.05398889631032944\n",
      "Iteration 19848, Loss: 0.05416978523135185\n",
      "Iteration 19849, Loss: 0.053988661617040634\n",
      "Iteration 19850, Loss: 0.054169993847608566\n",
      "Iteration 19851, Loss: 0.05398834869265556\n",
      "Iteration 19852, Loss: 0.05417042598128319\n",
      "Iteration 19853, Loss: 0.05398811027407646\n",
      "Iteration 19854, Loss: 0.054170578718185425\n",
      "Iteration 19855, Loss: 0.05398787185549736\n",
      "Iteration 19856, Loss: 0.05417078360915184\n",
      "Iteration 19857, Loss: 0.05398782342672348\n",
      "Iteration 19858, Loss: 0.05417093262076378\n",
      "Iteration 19859, Loss: 0.05398768186569214\n",
      "Iteration 19860, Loss: 0.05417070537805557\n",
      "Iteration 19861, Loss: 0.05398794263601303\n",
      "Iteration 19862, Loss: 0.05417061597108841\n",
      "Iteration 19863, Loss: 0.053988151252269745\n",
      "Iteration 19864, Loss: 0.054170459508895874\n",
      "Iteration 19865, Loss: 0.053988151252269745\n",
      "Iteration 19866, Loss: 0.05417042225599289\n",
      "Iteration 19867, Loss: 0.053988151252269745\n",
      "Iteration 19868, Loss: 0.05417034029960632\n",
      "Iteration 19869, Loss: 0.05398822948336601\n",
      "Iteration 19870, Loss: 0.054170262068510056\n",
      "Iteration 19871, Loss: 0.05398887023329735\n",
      "Iteration 19872, Loss: 0.05417018383741379\n",
      "Iteration 19873, Loss: 0.053989022970199585\n",
      "Iteration 19874, Loss: 0.05417023226618767\n",
      "Iteration 19875, Loss: 0.0539887472987175\n",
      "Iteration 19876, Loss: 0.05417085811495781\n",
      "Iteration 19877, Loss: 0.053988512605428696\n",
      "Iteration 19878, Loss: 0.0541711300611496\n",
      "Iteration 19879, Loss: 0.053988512605428696\n",
      "Iteration 19880, Loss: 0.05417109653353691\n",
      "Iteration 19881, Loss: 0.053988438099622726\n",
      "Iteration 19882, Loss: 0.05417117476463318\n",
      "Iteration 19883, Loss: 0.0539885088801384\n",
      "Iteration 19884, Loss: 0.054171063005924225\n",
      "Iteration 19885, Loss: 0.05398839712142944\n",
      "Iteration 19886, Loss: 0.054170988500118256\n",
      "Iteration 19887, Loss: 0.053988318890333176\n",
      "Iteration 19888, Loss: 0.05417094752192497\n",
      "Iteration 19889, Loss: 0.053988438099622726\n",
      "Iteration 19890, Loss: 0.05417078733444214\n",
      "Iteration 19891, Loss: 0.05398867279291153\n",
      "Iteration 19892, Loss: 0.05417066439986229\n",
      "Iteration 19893, Loss: 0.053988754749298096\n",
      "Iteration 19894, Loss: 0.05417058989405632\n",
      "Iteration 19895, Loss: 0.05398883670568466\n",
      "Iteration 19896, Loss: 0.05417066812515259\n",
      "Iteration 19897, Loss: 0.0539887472987175\n",
      "Iteration 19898, Loss: 0.05417086184024811\n",
      "Iteration 19899, Loss: 0.053988512605428696\n",
      "Iteration 19900, Loss: 0.05417114496231079\n",
      "Iteration 19901, Loss: 0.05398830771446228\n",
      "Iteration 19902, Loss: 0.05417134612798691\n",
      "Iteration 19903, Loss: 0.053988080471754074\n",
      "Iteration 19904, Loss: 0.05417146533727646\n",
      "Iteration 19905, Loss: 0.05398803949356079\n",
      "Iteration 19906, Loss: 0.054171375930309296\n",
      "Iteration 19907, Loss: 0.05398859828710556\n",
      "Iteration 19908, Loss: 0.05417117476463318\n",
      "Iteration 19909, Loss: 0.053988903760910034\n",
      "Iteration 19910, Loss: 0.05417141318321228\n",
      "Iteration 19911, Loss: 0.0539892241358757\n",
      "Iteration 19912, Loss: 0.0541708767414093\n",
      "Iteration 19913, Loss: 0.05398938059806824\n",
      "Iteration 19914, Loss: 0.05417083203792572\n",
      "Iteration 19915, Loss: 0.05398938059806824\n",
      "Iteration 19916, Loss: 0.05417102575302124\n",
      "Iteration 19917, Loss: 0.053989529609680176\n",
      "Iteration 19918, Loss: 0.054171185940504074\n",
      "Iteration 19919, Loss: 0.05398913845419884\n",
      "Iteration 19920, Loss: 0.054171424359083176\n",
      "Iteration 19921, Loss: 0.05398871749639511\n",
      "Iteration 19922, Loss: 0.054171621799468994\n",
      "Iteration 19923, Loss: 0.0539887472987175\n",
      "Iteration 19924, Loss: 0.05417177081108093\n",
      "Iteration 19925, Loss: 0.05398859828710556\n",
      "Iteration 19926, Loss: 0.054171692579984665\n",
      "Iteration 19927, Loss: 0.053988754749298096\n",
      "Iteration 19928, Loss: 0.05417153239250183\n",
      "Iteration 19929, Loss: 0.0539889894425869\n",
      "Iteration 19930, Loss: 0.05417121946811676\n",
      "Iteration 19931, Loss: 0.05398911237716675\n",
      "Iteration 19932, Loss: 0.05417094752192497\n",
      "Iteration 19933, Loss: 0.053989604115486145\n",
      "Iteration 19934, Loss: 0.05417102202773094\n",
      "Iteration 19935, Loss: 0.05398934334516525\n",
      "Iteration 19936, Loss: 0.054171185940504074\n",
      "Iteration 19937, Loss: 0.05398910492658615\n",
      "Iteration 19938, Loss: 0.05417146533727646\n",
      "Iteration 19939, Loss: 0.053988829255104065\n",
      "Iteration 19940, Loss: 0.05417170375585556\n",
      "Iteration 19941, Loss: 0.05398855730891228\n",
      "Iteration 19942, Loss: 0.05417189747095108\n",
      "Iteration 19943, Loss: 0.05398854613304138\n",
      "Iteration 19944, Loss: 0.0541718527674675\n",
      "Iteration 19945, Loss: 0.053988516330718994\n",
      "Iteration 19946, Loss: 0.054171621799468994\n",
      "Iteration 19947, Loss: 0.05398879572749138\n",
      "Iteration 19948, Loss: 0.05417133867740631\n",
      "Iteration 19949, Loss: 0.05398903414607048\n",
      "Iteration 19950, Loss: 0.05417102575302124\n",
      "Iteration 19951, Loss: 0.05398926883935928\n",
      "Iteration 19952, Loss: 0.05417109653353691\n",
      "Iteration 19953, Loss: 0.05398934707045555\n",
      "Iteration 19954, Loss: 0.05417102575302124\n",
      "Iteration 19955, Loss: 0.05398934334516525\n",
      "Iteration 19956, Loss: 0.054171111434698105\n",
      "Iteration 19957, Loss: 0.05398914963006973\n",
      "Iteration 19958, Loss: 0.05417119711637497\n",
      "Iteration 19959, Loss: 0.0539889931678772\n",
      "Iteration 19960, Loss: 0.05417141318321228\n",
      "Iteration 19961, Loss: 0.05398910492658615\n",
      "Iteration 19962, Loss: 0.05417138338088989\n",
      "Iteration 19963, Loss: 0.05398883670568466\n",
      "Iteration 19964, Loss: 0.05417150259017944\n",
      "Iteration 19965, Loss: 0.053988825529813766\n",
      "Iteration 19966, Loss: 0.054171692579984665\n",
      "Iteration 19967, Loss: 0.0539887510240078\n",
      "Iteration 19968, Loss: 0.054171543568372726\n",
      "Iteration 19969, Loss: 0.053988829255104065\n",
      "Iteration 19970, Loss: 0.05417150259017944\n",
      "Iteration 19971, Loss: 0.053988903760910034\n",
      "Iteration 19972, Loss: 0.05417153984308243\n",
      "Iteration 19973, Loss: 0.05398879572749138\n",
      "Iteration 19974, Loss: 0.05417146533727646\n",
      "Iteration 19975, Loss: 0.05398891493678093\n",
      "Iteration 19976, Loss: 0.05417145416140556\n",
      "Iteration 19977, Loss: 0.0539889857172966\n",
      "Iteration 19978, Loss: 0.05417141318321228\n",
      "Iteration 19979, Loss: 0.053989022970199585\n",
      "Iteration 19980, Loss: 0.054171495139598846\n",
      "Iteration 19981, Loss: 0.053988948464393616\n",
      "Iteration 19982, Loss: 0.05417146533727646\n",
      "Iteration 19983, Loss: 0.05398891493678093\n",
      "Iteration 19984, Loss: 0.05417158454656601\n",
      "Iteration 19985, Loss: 0.05398894473910332\n",
      "Iteration 19986, Loss: 0.0541716143488884\n",
      "Iteration 19987, Loss: 0.05398879200220108\n",
      "Iteration 19988, Loss: 0.05417153984308243\n",
      "Iteration 19989, Loss: 0.05398894473910332\n",
      "Iteration 19990, Loss: 0.054171498864889145\n",
      "Iteration 19991, Loss: 0.053989019244909286\n",
      "Iteration 19992, Loss: 0.05417141318321228\n",
      "Iteration 19993, Loss: 0.05398906394839287\n",
      "Iteration 19994, Loss: 0.054171182215213776\n",
      "Iteration 19995, Loss: 0.053989335894584656\n",
      "Iteration 19996, Loss: 0.05417102575302124\n",
      "Iteration 19997, Loss: 0.0539892315864563\n",
      "Iteration 19998, Loss: 0.054170988500118256\n",
      "Iteration 19999, Loss: 0.05398930236697197\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.00000001\n",
    "iterations = 20000\n",
    "losses = []\n",
    "determinants = []\n",
    "H_inv = jnp.eye(3)\n",
    "for i in range(iterations):\n",
    "    H_inv = H_inv - alpha * gradient(H_inv, warpedConics)\n",
    "    current_loss = lossConics(H_inv, warpedConics)\n",
    "    det = jnp.linalg.det(H_inv)\n",
    "    determinants.append(det)\n",
    "    losses.append(current_loss)\n",
    "    print(f\"Iteration {i}, Loss: {current_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8232666a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the losses\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel(\"Iteration\")\n",
    "ax1.set_ylabel(\"Loss\", color=color)\n",
    "ax1.plot(losses, color=color, label=\"Loss\")\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel(\"Determinant\", color=color)\n",
    "ax2.plot(determinants, color=color, label=\"Determinant\")\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "plt.title(\"Loss and Determinant over Iterations\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "026ff391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Homography:\n",
      "[[ 1.0000000e+00 -1.4533740e-07  0.0000000e+00]\n",
      " [ 1.0187469e-05  1.0000014e+00  0.0000000e+00]\n",
      " [ 8.7569075e-05 -5.7592955e-03  1.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "H = jnp.linalg.inv(H_inv)\n",
    "print(\"Estimated Homography:\")\n",
    "print(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a5a6b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Conics Warped]\n",
      "Warped Conics:\n",
      "Warped Circle 1: \n",
      "[[ 1.17438731e-04 -4.99526867e-06 -1.04447430e-01]\n",
      " [-4.99526867e-06  1.01833561e-04 -3.92636019e-02]\n",
      " [-1.04447430e-01 -3.92636019e-02  1.11389267e+02]]\n",
      "Det of Warped Circle 1: -3.5999897003256784e-09\n",
      "Warped Circle 2: \n",
      "[[ 1.18595699e-04  7.48967000e-08 -1.12196357e-01]\n",
      " [ 7.48967000e-08  1.18212781e-04 -6.09458670e-02]\n",
      " [-1.12196357e-01 -6.09458670e-02  1.37483475e+02]]\n",
      "Det of Warped Circle 2: -9.999971390144781e-11\n",
      "Warped Circle 3: \n",
      "[[ 1.19780853e-04  5.33190206e-06 -1.20267171e-01]\n",
      " [ 5.33190206e-06  1.35830549e-04 -8.47619059e-02]\n",
      " [-1.20267171e-01 -8.47619059e-02  1.67253753e+02]]\n",
      "Det of Warped Circle 3: -9.999971389058045e-11\n"
     ]
    }
   ],
   "source": [
    "H_reconstructed = Homography(np.array(H))\n",
    "\n",
    "# Warp The Circles\n",
    "warpedConicsRec = ConicWarper().warpConics(img.C_img, H_reconstructed)\n",
    "\n",
    "print(\"[Conics Warped]\")\n",
    "print(\"Warped Conics:\")\n",
    "print(f\"Warped Circle 1: \\n{warpedConicsRec.C1._M}\")\n",
    "print(f\"Det of Warped Circle 1: {np.linalg.det(warpedConicsRec.C1.M)}\")\n",
    "print(f\"Warped Circle 2: \\n{warpedConicsRec.C2._M}\")\n",
    "print(f\"Det of Warped Circle 2: {np.linalg.det(warpedConicsRec.C2.M)}\")\n",
    "print(f\"Warped Circle 3: \\n{warpedConicsRec.C3._M}\")\n",
    "print(f\"Det of Warped Circle 3: {np.linalg.det(warpedConicsRec.C3.M)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20a4437f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotter = Plotter.Plotter(2, 2, title=\"Warped Scene with Circles\")\n",
    "plotter.plotExperiment(\n",
    "    sceneDescription=sceneDescription,\n",
    "    img=img,\n",
    "    warpedConics=warpedConicsRec,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17972a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2bd9a8c56934bf9a40ebc2909cbd2e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed Homography from GDRectifier:\n",
      "[[ 1.1038026e+00 -2.1506295e-01  0.0000000e+00]\n",
      " [-4.5154691e-02  1.0017977e+00  0.0000000e+00]\n",
      " [ 6.1186351e-05 -5.9908805e-03  1.0000000e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\polimi\\master\\2sem\\cv_homotopy_project\\repo\\src\\HomoTopiContinuation\\Plotter\\Plotter.py:80: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  self.ax.legend()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from HomoTopiContinuation.Rectifier.GDRectifier import GDRectifier\n",
    "\n",
    "H_computed, _, _, _, _, _ = GDRectifier.rectify(   \n",
    "    img.C_img_noise,\n",
    "    iterations=3000,\n",
    "    alpha = 1e-4\n",
    ")\n",
    "\n",
    "print(\"Computed Homography from GDRectifier:\")\n",
    "print(H_computed.H)\n",
    "\n",
    "warpedConicsGD = ConicWarper().warpConics(img.C_img_noise, H_computed)\n",
    "\n",
    "plotter = Plotter.Plotter(2, 2, title=\"Warped Scene with Circles (GDRectifier)\")\n",
    "plotter.plotExperiment(\n",
    "    sceneDescription=sceneDescription,\n",
    "    img=img,\n",
    "    warpedConics=warpedConicsGD,\n",
    ")\n",
    "plotter.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
